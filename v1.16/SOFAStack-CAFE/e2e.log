I0206 03:28:45.160301      20 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-529150080
I0206 03:28:45.163592      20 e2e.go:92] Starting e2e run "8f82fbad-c438-4b9f-887d-a41d3b73a82a" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1580959722 - Will randomize all specs
Will run 274 of 4732 specs

Feb  6 03:28:45.229: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 03:28:45.269: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb  6 03:28:45.300: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb  6 03:28:45.409: INFO: 7 / 7 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb  6 03:28:45.409: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Feb  6 03:28:45.409: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb  6 03:28:45.421: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Feb  6 03:28:45.422: INFO: e2e test version: v1.16.3
Feb  6 03:28:45.423: INFO: kube-apiserver version: v1.16.3-130
Feb  6 03:28:45.423: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 03:28:45.462: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:28:45.462: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename aggregator
Feb  6 03:28:45.662: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb  6 03:28:45.673: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-9996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Feb  6 03:28:45.785: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Feb  6 03:28:46.076: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Feb  6 03:28:48.145: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:28:50.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:28:52.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:28:54.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:28:56.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:28:58.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:29:00.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:29:02.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:29:04.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:29:06.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:29:08.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556526, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:29:10.973: INFO: Waited 820.184878ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:29:11.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9996" for this suite.
Feb  6 03:29:17.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:29:17.563: INFO: namespace aggregator-9996 deletion completed in 6.154320722s

• [SLOW TEST:32.101 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:29:17.563: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9979
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-c626892b-93af-4294-92dc-dc634fc81fb1
STEP: Creating a pod to test consume configMaps
Feb  6 03:29:17.747: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f7bd656f-addf-4979-bbb5-729407ef7f24" in namespace "projected-9979" to be "success or failure"
Feb  6 03:29:17.749: INFO: Pod "pod-projected-configmaps-f7bd656f-addf-4979-bbb5-729407ef7f24": Phase="Pending", Reason="", readiness=false. Elapsed: 1.566497ms
Feb  6 03:29:19.768: INFO: Pod "pod-projected-configmaps-f7bd656f-addf-4979-bbb5-729407ef7f24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021099169s
Feb  6 03:29:21.771: INFO: Pod "pod-projected-configmaps-f7bd656f-addf-4979-bbb5-729407ef7f24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023629425s
STEP: Saw pod success
Feb  6 03:29:21.771: INFO: Pod "pod-projected-configmaps-f7bd656f-addf-4979-bbb5-729407ef7f24" satisfied condition "success or failure"
Feb  6 03:29:21.772: INFO: Trying to get logs from node aks-1-4 pod pod-projected-configmaps-f7bd656f-addf-4979-bbb5-729407ef7f24 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 03:29:21.798: INFO: Waiting for pod pod-projected-configmaps-f7bd656f-addf-4979-bbb5-729407ef7f24 to disappear
Feb  6 03:29:21.800: INFO: Pod pod-projected-configmaps-f7bd656f-addf-4979-bbb5-729407ef7f24 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:29:21.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9979" for this suite.
Feb  6 03:29:27.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:29:27.857: INFO: namespace projected-9979 deletion completed in 6.055335051s

• [SLOW TEST:10.294 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:29:27.857: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1083
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Feb  6 03:29:36.502: INFO: Successfully updated pod "adopt-release-g5gmm"
STEP: Checking that the Job readopts the Pod
Feb  6 03:29:36.502: INFO: Waiting up to 15m0s for pod "adopt-release-g5gmm" in namespace "job-1083" to be "adopted"
Feb  6 03:29:36.506: INFO: Pod "adopt-release-g5gmm": Phase="Running", Reason="", readiness=true. Elapsed: 3.351795ms
Feb  6 03:29:38.508: INFO: Pod "adopt-release-g5gmm": Phase="Running", Reason="", readiness=true. Elapsed: 2.005675984s
Feb  6 03:29:38.508: INFO: Pod "adopt-release-g5gmm" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Feb  6 03:29:39.013: INFO: Successfully updated pod "adopt-release-g5gmm"
STEP: Checking that the Job releases the Pod
Feb  6 03:29:39.013: INFO: Waiting up to 15m0s for pod "adopt-release-g5gmm" in namespace "job-1083" to be "released"
Feb  6 03:29:39.021: INFO: Pod "adopt-release-g5gmm": Phase="Running", Reason="", readiness=true. Elapsed: 8.074847ms
Feb  6 03:29:39.021: INFO: Pod "adopt-release-g5gmm" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:29:39.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1083" for this suite.
Feb  6 03:30:25.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:30:25.100: INFO: namespace job-1083 deletion completed in 46.073256473s

• [SLOW TEST:57.243 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:30:25.104: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-3773
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-3773
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3773
STEP: Deleting pre-stop pod
Feb  6 03:30:40.272: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:30:40.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3773" for this suite.
Feb  6 03:31:24.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:31:24.345: INFO: namespace prestop-3773 deletion completed in 44.058893209s

• [SLOW TEST:59.241 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:31:24.346: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-5078
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 03:31:24.470: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:31:24.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5078" for this suite.
Feb  6 03:31:30.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:31:30.600: INFO: namespace custom-resource-definition-5078 deletion completed in 6.056759127s

• [SLOW TEST:6.255 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:31:30.601: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5754
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  6 03:31:40.761: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:31:40.764: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:31:42.764: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:31:42.767: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:31:44.764: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:31:44.767: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:31:44.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5754" for this suite.
Feb  6 03:31:56.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:31:56.826: INFO: namespace container-lifecycle-hook-5754 deletion completed in 12.057212765s

• [SLOW TEST:26.226 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:31:56.826: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7891
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  6 03:31:57.017: INFO: Waiting up to 5m0s for pod "pod-97289b4b-a955-4c4c-aac3-d77a673ba647" in namespace "emptydir-7891" to be "success or failure"
Feb  6 03:31:57.021: INFO: Pod "pod-97289b4b-a955-4c4c-aac3-d77a673ba647": Phase="Pending", Reason="", readiness=false. Elapsed: 3.721781ms
Feb  6 03:31:59.023: INFO: Pod "pod-97289b4b-a955-4c4c-aac3-d77a673ba647": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006183438s
Feb  6 03:32:01.026: INFO: Pod "pod-97289b4b-a955-4c4c-aac3-d77a673ba647": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008693144s
STEP: Saw pod success
Feb  6 03:32:01.026: INFO: Pod "pod-97289b4b-a955-4c4c-aac3-d77a673ba647" satisfied condition "success or failure"
Feb  6 03:32:01.027: INFO: Trying to get logs from node aks-1-4 pod pod-97289b4b-a955-4c4c-aac3-d77a673ba647 container test-container: <nil>
STEP: delete the pod
Feb  6 03:32:01.039: INFO: Waiting for pod pod-97289b4b-a955-4c4c-aac3-d77a673ba647 to disappear
Feb  6 03:32:01.040: INFO: Pod pod-97289b4b-a955-4c4c-aac3-d77a673ba647 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:32:01.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7891" for this suite.
Feb  6 03:32:07.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:32:07.095: INFO: namespace emptydir-7891 deletion completed in 6.053307064s

• [SLOW TEST:10.269 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:32:07.095: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2902
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:33:07.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2902" for this suite.
Feb  6 03:33:19.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:33:19.285: INFO: namespace container-probe-2902 deletion completed in 12.055626908s

• [SLOW TEST:72.190 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:33:19.285: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-7140
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 03:33:19.417: INFO: Waiting up to 5m0s for pod "busybox-user-65534-60459c5c-f570-4d9e-a517-bbccf9b6019b" in namespace "security-context-test-7140" to be "success or failure"
Feb  6 03:33:19.420: INFO: Pod "busybox-user-65534-60459c5c-f570-4d9e-a517-bbccf9b6019b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.142416ms
Feb  6 03:33:21.424: INFO: Pod "busybox-user-65534-60459c5c-f570-4d9e-a517-bbccf9b6019b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007026015s
Feb  6 03:33:21.424: INFO: Pod "busybox-user-65534-60459c5c-f570-4d9e-a517-bbccf9b6019b" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:33:21.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7140" for this suite.
Feb  6 03:33:27.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:33:27.497: INFO: namespace security-context-test-7140 deletion completed in 6.070902229s

• [SLOW TEST:8.212 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:33:27.498: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1106
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-1106
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1106
STEP: creating replication controller externalsvc in namespace services-1106
I0206 03:33:27.660877      20 runners.go:184] Created replication controller with name: externalsvc, namespace: services-1106, replica count: 2
I0206 03:33:30.711261      20 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Feb  6 03:33:30.720: INFO: Creating new exec pod
Feb  6 03:33:32.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-1106 execpodl2tkp -- /bin/sh -x -c nslookup clusterip-service'
Feb  6 03:33:33.524: INFO: stderr: "+ nslookup clusterip-service\n"
Feb  6 03:33:33.524: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-1106.svc.cluster.local\tcanonical name = externalsvc.services-1106.svc.cluster.local.\nName:\texternalsvc.services-1106.svc.cluster.local\nAddress: 10.96.0.144\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1106, will wait for the garbage collector to delete the pods
Feb  6 03:33:33.582: INFO: Deleting ReplicationController externalsvc took: 4.848876ms
Feb  6 03:33:33.882: INFO: Terminating ReplicationController externalsvc pods took: 300.216421ms
Feb  6 03:33:39.997: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:33:40.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1106" for this suite.
Feb  6 03:33:46.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:33:46.099: INFO: namespace services-1106 deletion completed in 6.084276305s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.601 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:33:46.099: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4641
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  6 03:33:52.273: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 03:33:52.276: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 03:33:54.276: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 03:33:54.279: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 03:33:56.276: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 03:33:56.278: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 03:33:58.276: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 03:33:58.281: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 03:34:00.276: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 03:34:00.278: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 03:34:02.277: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 03:34:02.279: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 03:34:04.276: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 03:34:04.278: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:34:04.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4641" for this suite.
Feb  6 03:34:16.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:34:16.338: INFO: namespace container-lifecycle-hook-4641 deletion completed in 12.056914239s

• [SLOW TEST:30.239 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:34:16.338: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6738
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6738
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-6738
I0206 03:34:16.482551      20 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6738, replica count: 2
Feb  6 03:34:19.532: INFO: Creating new exec pod
I0206 03:34:19.532931      20 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 03:34:22.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-6738 execpodsckml -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb  6 03:34:22.703: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb  6 03:34:22.703: INFO: stdout: ""
Feb  6 03:34:22.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-6738 execpodsckml -- /bin/sh -x -c nc -zv -t -w 2 10.96.0.240 80'
Feb  6 03:34:22.877: INFO: stderr: "+ nc -zv -t -w 2 10.96.0.240 80\nConnection to 10.96.0.240 80 port [tcp/http] succeeded!\n"
Feb  6 03:34:22.877: INFO: stdout: ""
Feb  6 03:34:22.877: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:34:22.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6738" for this suite.
Feb  6 03:34:28.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:34:28.956: INFO: namespace services-6738 deletion completed in 6.059756163s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.618 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:34:28.956: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1152
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Feb  6 03:34:29.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 api-versions'
Feb  6 03:34:29.215: INFO: stderr: ""
Feb  6 03:34:29.215: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:34:29.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1152" for this suite.
Feb  6 03:34:35.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:34:35.273: INFO: namespace kubectl-1152 deletion completed in 6.054464254s

• [SLOW TEST:6.317 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:34:35.273: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6675
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 03:34:35.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-6675'
Feb  6 03:34:35.516: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 03:34:35.516: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Feb  6 03:34:35.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete jobs e2e-test-httpd-job --namespace=kubectl-6675'
Feb  6 03:34:35.621: INFO: stderr: ""
Feb  6 03:34:35.621: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:34:35.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6675" for this suite.
Feb  6 03:34:47.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:34:47.704: INFO: namespace kubectl-6675 deletion completed in 12.078663746s

• [SLOW TEST:12.431 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:34:47.704: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1397
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb  6 03:34:47.833: INFO: Waiting up to 5m0s for pod "downward-api-40a60ef2-84cf-4ea3-8ed8-270106e7ca22" in namespace "downward-api-1397" to be "success or failure"
Feb  6 03:34:47.836: INFO: Pod "downward-api-40a60ef2-84cf-4ea3-8ed8-270106e7ca22": Phase="Pending", Reason="", readiness=false. Elapsed: 3.694256ms
Feb  6 03:34:49.838: INFO: Pod "downward-api-40a60ef2-84cf-4ea3-8ed8-270106e7ca22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005524005s
Feb  6 03:34:51.840: INFO: Pod "downward-api-40a60ef2-84cf-4ea3-8ed8-270106e7ca22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007827781s
STEP: Saw pod success
Feb  6 03:34:51.841: INFO: Pod "downward-api-40a60ef2-84cf-4ea3-8ed8-270106e7ca22" satisfied condition "success or failure"
Feb  6 03:34:51.842: INFO: Trying to get logs from node aks-1-4 pod downward-api-40a60ef2-84cf-4ea3-8ed8-270106e7ca22 container dapi-container: <nil>
STEP: delete the pod
Feb  6 03:34:51.859: INFO: Waiting for pod downward-api-40a60ef2-84cf-4ea3-8ed8-270106e7ca22 to disappear
Feb  6 03:34:51.860: INFO: Pod downward-api-40a60ef2-84cf-4ea3-8ed8-270106e7ca22 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:34:51.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1397" for this suite.
Feb  6 03:34:57.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:34:57.924: INFO: namespace downward-api-1397 deletion completed in 6.061785685s

• [SLOW TEST:10.220 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:34:57.926: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8336
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 03:34:58.050: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Feb  6 03:35:01.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-8336 create -f -'
Feb  6 03:35:02.711: INFO: stderr: ""
Feb  6 03:35:02.711: INFO: stdout: "e2e-test-crd-publish-openapi-5328-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb  6 03:35:02.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-8336 delete e2e-test-crd-publish-openapi-5328-crds test-foo'
Feb  6 03:35:02.802: INFO: stderr: ""
Feb  6 03:35:02.802: INFO: stdout: "e2e-test-crd-publish-openapi-5328-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Feb  6 03:35:02.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-8336 apply -f -'
Feb  6 03:35:03.003: INFO: stderr: ""
Feb  6 03:35:03.003: INFO: stdout: "e2e-test-crd-publish-openapi-5328-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb  6 03:35:03.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-8336 delete e2e-test-crd-publish-openapi-5328-crds test-foo'
Feb  6 03:35:03.101: INFO: stderr: ""
Feb  6 03:35:03.101: INFO: stdout: "e2e-test-crd-publish-openapi-5328-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Feb  6 03:35:03.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-8336 create -f -'
Feb  6 03:35:03.344: INFO: rc: 1
Feb  6 03:35:03.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-8336 apply -f -'
Feb  6 03:35:03.533: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Feb  6 03:35:03.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-8336 create -f -'
Feb  6 03:35:03.716: INFO: rc: 1
Feb  6 03:35:03.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-8336 apply -f -'
Feb  6 03:35:03.916: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Feb  6 03:35:03.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 explain e2e-test-crd-publish-openapi-5328-crds'
Feb  6 03:35:04.149: INFO: stderr: ""
Feb  6 03:35:04.149: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5328-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Feb  6 03:35:04.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 explain e2e-test-crd-publish-openapi-5328-crds.metadata'
Feb  6 03:35:04.385: INFO: stderr: ""
Feb  6 03:35:04.385: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5328-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Feb  6 03:35:04.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 explain e2e-test-crd-publish-openapi-5328-crds.spec'
Feb  6 03:35:04.579: INFO: stderr: ""
Feb  6 03:35:04.579: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5328-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Feb  6 03:35:04.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 explain e2e-test-crd-publish-openapi-5328-crds.spec.bars'
Feb  6 03:35:04.772: INFO: stderr: ""
Feb  6 03:35:04.772: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5328-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Feb  6 03:35:04.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 explain e2e-test-crd-publish-openapi-5328-crds.spec.bars2'
Feb  6 03:35:04.989: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:35:08.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8336" for this suite.
Feb  6 03:35:14.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:35:14.853: INFO: namespace crd-publish-openapi-8336 deletion completed in 6.056548772s

• [SLOW TEST:16.928 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:35:14.853: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6098
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 03:35:14.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-6098'
Feb  6 03:35:15.248: INFO: stderr: ""
Feb  6 03:35:15.248: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb  6 03:35:15.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-6098'
Feb  6 03:35:15.504: INFO: stderr: ""
Feb  6 03:35:15.504: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 03:35:16.506: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:35:16.506: INFO: Found 0 / 1
Feb  6 03:35:17.506: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:35:17.506: INFO: Found 0 / 1
Feb  6 03:35:18.506: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:35:18.506: INFO: Found 0 / 1
Feb  6 03:35:19.506: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:35:19.506: INFO: Found 0 / 1
Feb  6 03:35:20.506: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:35:20.506: INFO: Found 0 / 1
Feb  6 03:35:21.506: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:35:21.506: INFO: Found 0 / 1
Feb  6 03:35:22.506: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:35:22.506: INFO: Found 0 / 1
Feb  6 03:35:23.508: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:35:23.508: INFO: Found 1 / 1
Feb  6 03:35:23.508: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  6 03:35:23.510: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:35:23.510: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 03:35:23.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 describe pod redis-master-p572x --namespace=kubectl-6098'
Feb  6 03:35:23.644: INFO: stderr: ""
Feb  6 03:35:23.644: INFO: stdout: "Name:         redis-master-p572x\nNamespace:    kubectl-6098\nPriority:     0\nNode:         aks-1-3/192.168.27.78\nStart Time:   Thu, 06 Feb 2020 03:35:15 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  pod.beta1.sigma.ali/update-status:\n                {\"statuses\":{\"redis-master\":{\"creationTimestamp\":\"2020-02-06T11:35:15.851875943+08:00\",\"finishTimestamp\":\"2020-02-06T11:35:23.462722164+08...\nStatus:       Running\nIP:           10.244.2.69\nIPs:\n  IP:           10.244.2.69\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://24a5a516201d37108c119e8fe8491b7aad2bdbc3f1f191bfd1204e3155c83a23\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 06 Feb 2020 03:35:23 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-twzs6 (ro)\nConditions:\n  Type                    Status\n  Initialized             True \n  Ready                   True \n  ContainersReady         True \n  ContainerDiskPressure   False \n  PodScheduled            True \nVolumes:\n  default-token-twzs6:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-twzs6\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason                Age        From               Message\n  ----    ------                ----       ----               -------\n  Normal  Scheduled             <unknown>  default-scheduler  Successfully assigned kubectl-6098/redis-master-p572x to aks-1-3\n  Normal  Pulling               8s         kubelet, aks-1-3   Pulling image \"docker.io/library/redis:5.0.5-alpine\"\n  Normal  Pulled                0s         kubelet, aks-1-3   Successfully pulled image \"docker.io/library/redis:5.0.5-alpine\"\n  Normal  Created               0s         kubelet, aks-1-3   Created container redis-master\n  Normal  Started               0s         kubelet, aks-1-3   Started container redis-master\n  Normal  WithOutPostStartHook  0s         kubelet, aks-1-3   Container redis-master with out poststart hook\n"
Feb  6 03:35:23.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 describe rc redis-master --namespace=kubectl-6098'
Feb  6 03:35:23.765: INFO: stderr: ""
Feb  6 03:35:23.765: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-6098\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  8s    replication-controller  Created pod: redis-master-p572x\n"
Feb  6 03:35:23.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 describe service redis-master --namespace=kubectl-6098'
Feb  6 03:35:23.859: INFO: stderr: ""
Feb  6 03:35:23.859: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-6098\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.96.0.112\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.2.69:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb  6 03:35:23.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 describe node aks-1-2'
Feb  6 03:35:23.975: INFO: stderr: ""
Feb  6 03:35:23.975: INFO: stdout: "Name:               aks-1-2\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=aks-1-2\n                    kubernetes.io/os=linux\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"ba:8c:d0:41:21:cb\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.27.79\n                    node.alpha.kubernetes.io/ttl: 0\n                    node.beta1.sigma.ali/local-info:\n                      {\"cpuInfos\":[{\"cpu\":0,\"core\":0,\"socket\":0},{\"cpu\":1,\"core\":0,\"socket\":0}],\"diskInfos\":[{\"device\":\"tmpfs\",\"filesystemType\":\"tmpfs\",\"size\":1...\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 21 Jan 2020 14:44:57 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 06 Feb 2020 03:34:45 +0000   Mon, 03 Feb 2020 03:34:23 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 06 Feb 2020 03:34:45 +0000   Wed, 05 Feb 2020 14:55:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 06 Feb 2020 03:34:45 +0000   Mon, 03 Feb 2020 03:34:23 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 06 Feb 2020 03:34:45 +0000   Thu, 06 Feb 2020 03:21:44 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.27.79\n  Hostname:    aks-1-2\nCapacity:\n cpu:                2\n ephemeral-storage:  41152832Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3882328Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  40033474939\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3779928Ki\n pods:               110\nSystem Info:\n Machine ID:                 7d26c16f128042a684ea474c9e2c240f\n System UUID:                33910321-859B-7241-9D3D-6702DDA0150F\n Boot ID:                    ff5ac77e-5410-4ccc-af84-8ff392ad5f27\n Kernel Version:             3.10.0-327.22.2.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.3.1\n Kubelet Version:            v1.16.3-130\n Kube-Proxy Version:         v1.16.3-130\nPodCIDR:                     10.244.0.0/24\nPodCIDRs:                    10.244.0.0/24\nNon-terminated Pods:         (15 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                    nginx-66lj2                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         7m50s\n  default                    nginx-8f556                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         7m48s\n  default                    nginx-98nbt                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         5m17s\n  default                    nginx-gjqqt                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         7m54s\n  default                    nginx-jjf9z                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         5m18s\n  default                    nginx-k4j64                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         7m54s\n  default                    nginx-ktsbf                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         7m52s\n  default                    nginx-m679w                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         5m19s\n  default                    nginx-vnn6h                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         7m55s\n  default                    nginx-xc4tj                                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         7m53s\n  kube-system                coredns-7f6cddc944-qsgx4                                   100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     13h\n  kube-system                kube-flannel-ds-amd64-kln2x                                100m (5%)     100m (5%)   50Mi (1%)        50Mi (1%)      15h\n  sonobuoy                   sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         10m\n  sonobuoy                   sonobuoy-e2e-job-29ae3d20e67a4412                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         10m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-lrnrn    0 (0%)        0 (0%)      0 (0%)           0 (0%)         10m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                200m (10%)  100m (5%)\n  memory             120Mi (3%)  220Mi (5%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age   From              Message\n  ----    ------                   ----  ----              -------\n  Normal  Starting                 58m   kubelet, aks-1-2  Starting kubelet.\n  Normal  NodeHasSufficientMemory  58m   kubelet, aks-1-2  Node aks-1-2 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    58m   kubelet, aks-1-2  Node aks-1-2 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     58m   kubelet, aks-1-2  Node aks-1-2 status is now: NodeHasSufficientPID\n  Normal  NodeNotReady             58m   kubelet, aks-1-2  Node aks-1-2 status is now: NodeNotReady\n  Normal  NodeAllocatableEnforced  58m   kubelet, aks-1-2  Updated Node Allocatable limit across pods\n  Normal  NodeReady                58m   kubelet, aks-1-2  Node aks-1-2 status is now: NodeReady\n  Normal  Starting                 13m   kubelet, aks-1-2  Starting kubelet.\n  Normal  NodeHasSufficientMemory  13m   kubelet, aks-1-2  Node aks-1-2 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    13m   kubelet, aks-1-2  Node aks-1-2 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     13m   kubelet, aks-1-2  Node aks-1-2 status is now: NodeHasSufficientPID\n  Normal  NodeNotReady             13m   kubelet, aks-1-2  Node aks-1-2 status is now: NodeNotReady\n  Normal  NodeAllocatableEnforced  13m   kubelet, aks-1-2  Updated Node Allocatable limit across pods\n  Normal  NodeReady                13m   kubelet, aks-1-2  Node aks-1-2 status is now: NodeReady\n"
Feb  6 03:35:23.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 describe namespace kubectl-6098'
Feb  6 03:35:24.066: INFO: stderr: ""
Feb  6 03:35:24.066: INFO: stdout: "Name:         kubectl-6098\nLabels:       e2e-framework=kubectl\n              e2e-run=8f82fbad-c438-4b9f-887d-a41d3b73a82a\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:35:24.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6098" for this suite.
Feb  6 03:35:36.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:35:36.145: INFO: namespace kubectl-6098 deletion completed in 12.077247599s

• [SLOW TEST:21.292 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:35:36.147: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-5387
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb  6 03:35:36.591: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
Feb  6 03:35:38.597: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556936, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556936, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556936, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716556936, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 03:35:41.608: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 03:35:41.610: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:35:43.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5387" for this suite.
Feb  6 03:35:49.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:35:49.211: INFO: namespace crd-webhook-5387 deletion completed in 6.05789688s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.071 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:35:49.219: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4011
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb  6 03:35:49.344: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 03:35:49.350: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 03:35:49.352: INFO: 
Logging pods the kubelet thinks is on node aks-1-2 before test
Feb  6 03:35:49.364: INFO: sonobuoy-e2e-job-29ae3d20e67a4412 from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container e2e ready: true, restart count 0
Feb  6 03:35:49.365: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:35:49.365: INFO: nginx-8f556 from default started at 2020-02-06 03:27:36 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:35:49.365: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-lrnrn from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:35:49.365: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 03:35:49.365: INFO: nginx-ktsbf from default started at 2020-02-06 03:27:31 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:35:49.365: INFO: nginx-jjf9z from default started at 2020-02-06 03:30:05 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:35:49.365: INFO: kube-flannel-ds-amd64-kln2x from kube-system started at 2020-02-05 11:48:51 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 03:35:49.365: INFO: sonobuoy from sonobuoy started at 2020-02-06 03:24:46 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 03:35:49.365: INFO: nginx-m679w from default started at 2020-02-06 03:30:04 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:35:49.365: INFO: nginx-98nbt from default started at 2020-02-06 03:30:06 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:35:49.365: INFO: coredns-7f6cddc944-qsgx4 from kube-system started at 2020-02-05 13:54:41 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:35:49.365: INFO: nginx-66lj2 from default started at 2020-02-06 03:27:33 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:35:49.365: INFO: nginx-gjqqt from default started at 2020-02-06 03:27:30 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:35:49.365: INFO: nginx-xc4tj from default started at 2020-02-06 03:27:31 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:35:49.365: INFO: nginx-vnn6h from default started at 2020-02-06 03:27:28 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:35:49.365: INFO: nginx-k4j64 from default started at 2020-02-06 03:27:29 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.365: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:35:49.365: INFO: 
Logging pods the kubelet thinks is on node aks-1-3 before test
Feb  6 03:35:49.378: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-kwwvw from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:35:49.378: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:35:49.378: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 03:35:49.378: INFO: kube-flannel-ds-amd64-tkhv8 from kube-system started at 2020-02-05 07:36:26 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.378: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 03:35:49.378: INFO: coredns-7f6cddc944-v22mw from kube-system started at 2020-02-05 08:48:34 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.378: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:35:49.378: INFO: coredns-7f6cddc944-99f6c from kube-system started at 2020-02-05 13:54:41 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.378: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:35:49.378: INFO: 
Logging pods the kubelet thinks is on node aks-1-4 before test
Feb  6 03:35:49.383: INFO: kube-flannel-ds-amd64-plfph from kube-system started at 2020-02-04 14:20:52 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.383: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 03:35:49.383: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-7z6kz from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:35:49.383: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:35:49.383: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 03:35:49.383: INFO: coredns-7f6cddc944-w6w2z from kube-system started at 2020-02-03 03:59:20 +0000 UTC (1 container statuses recorded)
Feb  6 03:35:49.383: INFO: 	Container coredns ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f1d325f0-cc68-416c-a0b9-e6574100d141 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-f1d325f0-cc68-416c-a0b9-e6574100d141 off the node aks-1-4
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f1d325f0-cc68-416c-a0b9-e6574100d141
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:40:53.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4011" for this suite.
Feb  6 03:41:05.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:41:05.510: INFO: namespace sched-pred-4011 deletion completed in 12.058216558s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:316.292 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:41:05.511: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9680
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 03:41:05.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9680'
Feb  6 03:41:05.745: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 03:41:05.745: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Feb  6 03:41:05.756: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-469mx]
Feb  6 03:41:05.756: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-469mx" in namespace "kubectl-9680" to be "running and ready"
Feb  6 03:41:05.759: INFO: Pod "e2e-test-httpd-rc-469mx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.393621ms
Feb  6 03:41:07.761: INFO: Pod "e2e-test-httpd-rc-469mx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004815172s
Feb  6 03:41:09.764: INFO: Pod "e2e-test-httpd-rc-469mx": Phase="Running", Reason="", readiness=true. Elapsed: 4.007244274s
Feb  6 03:41:09.764: INFO: Pod "e2e-test-httpd-rc-469mx" satisfied condition "running and ready"
Feb  6 03:41:09.764: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-469mx]
Feb  6 03:41:09.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 logs rc/e2e-test-httpd-rc --namespace=kubectl-9680'
Feb  6 03:41:09.897: INFO: stderr: ""
Feb  6 03:41:09.897: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.1.48. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.1.48. Set the 'ServerName' directive globally to suppress this message\n[Thu Feb 06 03:41:07.267825 2020] [mpm_event:notice] [pid 1:tid 139725589437288] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Thu Feb 06 03:41:07.267862 2020] [core:notice] [pid 1:tid 139725589437288] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Feb  6 03:41:09.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete rc e2e-test-httpd-rc --namespace=kubectl-9680'
Feb  6 03:41:09.986: INFO: stderr: ""
Feb  6 03:41:09.986: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:41:09.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9680" for this suite.
Feb  6 03:41:15.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:41:16.048: INFO: namespace kubectl-9680 deletion completed in 6.059195444s

• [SLOW TEST:10.537 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:41:16.049: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6735
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-5kftp in namespace proxy-6735
I0206 03:41:16.314232      20 runners.go:184] Created replication controller with name: proxy-service-5kftp, namespace: proxy-6735, replica count: 1
I0206 03:41:17.365085      20 runners.go:184] proxy-service-5kftp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0206 03:41:18.365307      20 runners.go:184] proxy-service-5kftp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0206 03:41:19.365506      20 runners.go:184] proxy-service-5kftp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0206 03:41:20.365814      20 runners.go:184] proxy-service-5kftp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0206 03:41:21.366008      20 runners.go:184] proxy-service-5kftp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0206 03:41:22.366255      20 runners.go:184] proxy-service-5kftp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 03:41:22.369: INFO: setup took 6.064984637s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb  6 03:41:22.385: INFO: (0) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 15.519466ms)
Feb  6 03:41:22.387: INFO: (0) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 17.793602ms)
Feb  6 03:41:22.387: INFO: (0) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 17.558281ms)
Feb  6 03:41:22.388: INFO: (0) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 17.834532ms)
Feb  6 03:41:22.388: INFO: (0) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 18.200893ms)
Feb  6 03:41:22.390: INFO: (0) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 19.488485ms)
Feb  6 03:41:22.391: INFO: (0) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 20.337303ms)
Feb  6 03:41:22.391: INFO: (0) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 21.036476ms)
Feb  6 03:41:22.393: INFO: (0) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 22.683789ms)
Feb  6 03:41:22.393: INFO: (0) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 22.156005ms)
Feb  6 03:41:22.397: INFO: (0) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 26.021944ms)
Feb  6 03:41:22.397: INFO: (0) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 26.113552ms)
Feb  6 03:41:22.397: INFO: (0) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 28.09301ms)
Feb  6 03:41:22.398: INFO: (0) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 27.697663ms)
Feb  6 03:41:22.398: INFO: (0) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 28.072797ms)
Feb  6 03:41:22.400: INFO: (0) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 29.290157ms)
Feb  6 03:41:22.405: INFO: (1) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 5.375527ms)
Feb  6 03:41:22.408: INFO: (1) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 7.790585ms)
Feb  6 03:41:22.410: INFO: (1) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 9.656383ms)
Feb  6 03:41:22.410: INFO: (1) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 9.510074ms)
Feb  6 03:41:22.410: INFO: (1) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 9.50293ms)
Feb  6 03:41:22.411: INFO: (1) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 10.262978ms)
Feb  6 03:41:22.411: INFO: (1) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 10.598146ms)
Feb  6 03:41:22.411: INFO: (1) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 10.94638ms)
Feb  6 03:41:22.412: INFO: (1) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 11.10408ms)
Feb  6 03:41:22.412: INFO: (1) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 11.314121ms)
Feb  6 03:41:22.412: INFO: (1) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 11.779232ms)
Feb  6 03:41:22.413: INFO: (1) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 12.324093ms)
Feb  6 03:41:22.413: INFO: (1) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 13.011249ms)
Feb  6 03:41:22.414: INFO: (1) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 13.193873ms)
Feb  6 03:41:22.414: INFO: (1) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 13.534737ms)
Feb  6 03:41:22.414: INFO: (1) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 13.667065ms)
Feb  6 03:41:22.421: INFO: (2) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 6.841061ms)
Feb  6 03:41:22.421: INFO: (2) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 7.056898ms)
Feb  6 03:41:22.423: INFO: (2) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 8.072732ms)
Feb  6 03:41:22.425: INFO: (2) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 9.812349ms)
Feb  6 03:41:22.425: INFO: (2) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 10.808737ms)
Feb  6 03:41:22.426: INFO: (2) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 11.74773ms)
Feb  6 03:41:22.426: INFO: (2) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 11.804595ms)
Feb  6 03:41:22.426: INFO: (2) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 11.550443ms)
Feb  6 03:41:22.426: INFO: (2) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 11.34534ms)
Feb  6 03:41:22.427: INFO: (2) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 12.176483ms)
Feb  6 03:41:22.427: INFO: (2) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 12.527752ms)
Feb  6 03:41:22.427: INFO: (2) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 12.560909ms)
Feb  6 03:41:22.428: INFO: (2) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 13.441634ms)
Feb  6 03:41:22.428: INFO: (2) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 13.039875ms)
Feb  6 03:41:22.428: INFO: (2) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 12.760022ms)
Feb  6 03:41:22.428: INFO: (2) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 13.632713ms)
Feb  6 03:41:22.431: INFO: (3) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 3.233407ms)
Feb  6 03:41:22.432: INFO: (3) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 3.963449ms)
Feb  6 03:41:22.433: INFO: (3) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 5.087161ms)
Feb  6 03:41:22.435: INFO: (3) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 6.870228ms)
Feb  6 03:41:22.436: INFO: (3) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 7.682141ms)
Feb  6 03:41:22.436: INFO: (3) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 8.153541ms)
Feb  6 03:41:22.438: INFO: (3) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 9.067141ms)
Feb  6 03:41:22.439: INFO: (3) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 10.115324ms)
Feb  6 03:41:22.439: INFO: (3) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 10.323853ms)
Feb  6 03:41:22.440: INFO: (3) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 11.222111ms)
Feb  6 03:41:22.441: INFO: (3) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 12.273154ms)
Feb  6 03:41:22.441: INFO: (3) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 12.096768ms)
Feb  6 03:41:22.442: INFO: (3) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 12.51134ms)
Feb  6 03:41:22.442: INFO: (3) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 13.400939ms)
Feb  6 03:41:22.443: INFO: (3) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 13.906026ms)
Feb  6 03:41:22.443: INFO: (3) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 13.637701ms)
Feb  6 03:41:22.451: INFO: (4) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 8.144728ms)
Feb  6 03:41:22.455: INFO: (4) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 11.264287ms)
Feb  6 03:41:22.455: INFO: (4) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 11.552577ms)
Feb  6 03:41:22.455: INFO: (4) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 12.115985ms)
Feb  6 03:41:22.455: INFO: (4) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 12.366277ms)
Feb  6 03:41:22.456: INFO: (4) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 12.655324ms)
Feb  6 03:41:22.456: INFO: (4) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 12.98447ms)
Feb  6 03:41:22.456: INFO: (4) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 13.71628ms)
Feb  6 03:41:22.459: INFO: (4) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 16.449142ms)
Feb  6 03:41:22.459: INFO: (4) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 16.268731ms)
Feb  6 03:41:22.460: INFO: (4) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 16.419161ms)
Feb  6 03:41:22.460: INFO: (4) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 17.319252ms)
Feb  6 03:41:22.461: INFO: (4) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 18.008373ms)
Feb  6 03:41:22.461: INFO: (4) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 17.602217ms)
Feb  6 03:41:22.461: INFO: (4) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 17.933759ms)
Feb  6 03:41:22.461: INFO: (4) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 17.902967ms)
Feb  6 03:41:22.468: INFO: (5) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 5.930737ms)
Feb  6 03:41:22.469: INFO: (5) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 8.087267ms)
Feb  6 03:41:22.469: INFO: (5) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 7.357048ms)
Feb  6 03:41:22.469: INFO: (5) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 7.86718ms)
Feb  6 03:41:22.469: INFO: (5) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 7.547117ms)
Feb  6 03:41:22.470: INFO: (5) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 8.667859ms)
Feb  6 03:41:22.471: INFO: (5) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 8.950321ms)
Feb  6 03:41:22.471: INFO: (5) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 9.209273ms)
Feb  6 03:41:22.472: INFO: (5) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 10.751049ms)
Feb  6 03:41:22.473: INFO: (5) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 12.114483ms)
Feb  6 03:41:22.474: INFO: (5) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 12.681409ms)
Feb  6 03:41:22.474: INFO: (5) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 12.069533ms)
Feb  6 03:41:22.474: INFO: (5) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 12.600934ms)
Feb  6 03:41:22.474: INFO: (5) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 13.08427ms)
Feb  6 03:41:22.474: INFO: (5) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 12.473175ms)
Feb  6 03:41:22.474: INFO: (5) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 13.057644ms)
Feb  6 03:41:22.481: INFO: (6) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 6.899925ms)
Feb  6 03:41:22.482: INFO: (6) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 7.742569ms)
Feb  6 03:41:22.483: INFO: (6) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 8.179713ms)
Feb  6 03:41:22.483: INFO: (6) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 8.150421ms)
Feb  6 03:41:22.484: INFO: (6) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 9.314445ms)
Feb  6 03:41:22.485: INFO: (6) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 10.232015ms)
Feb  6 03:41:22.486: INFO: (6) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 11.256167ms)
Feb  6 03:41:22.486: INFO: (6) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 10.888899ms)
Feb  6 03:41:22.486: INFO: (6) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 11.704252ms)
Feb  6 03:41:22.486: INFO: (6) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 11.657852ms)
Feb  6 03:41:22.486: INFO: (6) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 11.676679ms)
Feb  6 03:41:22.487: INFO: (6) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 12.184381ms)
Feb  6 03:41:22.487: INFO: (6) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 12.130331ms)
Feb  6 03:41:22.487: INFO: (6) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 12.695426ms)
Feb  6 03:41:22.487: INFO: (6) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 12.320785ms)
Feb  6 03:41:22.487: INFO: (6) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 12.618429ms)
Feb  6 03:41:22.495: INFO: (7) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 7.354811ms)
Feb  6 03:41:22.496: INFO: (7) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 8.342735ms)
Feb  6 03:41:22.497: INFO: (7) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 8.470912ms)
Feb  6 03:41:22.497: INFO: (7) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 8.778149ms)
Feb  6 03:41:22.497: INFO: (7) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 8.9774ms)
Feb  6 03:41:22.498: INFO: (7) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 10.667838ms)
Feb  6 03:41:22.498: INFO: (7) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 11.139088ms)
Feb  6 03:41:22.499: INFO: (7) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 10.780152ms)
Feb  6 03:41:22.499: INFO: (7) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 11.711982ms)
Feb  6 03:41:22.500: INFO: (7) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 12.166902ms)
Feb  6 03:41:22.501: INFO: (7) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 13.033602ms)
Feb  6 03:41:22.501: INFO: (7) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 13.601036ms)
Feb  6 03:41:22.502: INFO: (7) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 14.108781ms)
Feb  6 03:41:22.502: INFO: (7) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 15.229394ms)
Feb  6 03:41:22.503: INFO: (7) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 14.333244ms)
Feb  6 03:41:22.503: INFO: (7) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 14.705401ms)
Feb  6 03:41:22.508: INFO: (8) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 4.87855ms)
Feb  6 03:41:22.512: INFO: (8) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 8.372137ms)
Feb  6 03:41:22.513: INFO: (8) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 9.201979ms)
Feb  6 03:41:22.513: INFO: (8) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 9.480448ms)
Feb  6 03:41:22.514: INFO: (8) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 10.88254ms)
Feb  6 03:41:22.514: INFO: (8) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 10.771878ms)
Feb  6 03:41:22.514: INFO: (8) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 11.117085ms)
Feb  6 03:41:22.515: INFO: (8) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 12.286232ms)
Feb  6 03:41:22.516: INFO: (8) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 12.464167ms)
Feb  6 03:41:22.516: INFO: (8) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 11.692891ms)
Feb  6 03:41:22.516: INFO: (8) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 12.188289ms)
Feb  6 03:41:22.516: INFO: (8) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 12.637856ms)
Feb  6 03:41:22.516: INFO: (8) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 13.11208ms)
Feb  6 03:41:22.516: INFO: (8) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 12.199246ms)
Feb  6 03:41:22.516: INFO: (8) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 12.065289ms)
Feb  6 03:41:22.516: INFO: (8) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 12.587289ms)
Feb  6 03:41:22.524: INFO: (9) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 7.429177ms)
Feb  6 03:41:22.526: INFO: (9) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 9.433576ms)
Feb  6 03:41:22.526: INFO: (9) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 9.411702ms)
Feb  6 03:41:22.526: INFO: (9) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 9.662605ms)
Feb  6 03:41:22.526: INFO: (9) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 9.650173ms)
Feb  6 03:41:22.526: INFO: (9) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 9.594534ms)
Feb  6 03:41:22.526: INFO: (9) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 10.572469ms)
Feb  6 03:41:22.527: INFO: (9) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 10.898539ms)
Feb  6 03:41:22.527: INFO: (9) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 11.400909ms)
Feb  6 03:41:22.527: INFO: (9) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 11.19979ms)
Feb  6 03:41:22.528: INFO: (9) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 11.470412ms)
Feb  6 03:41:22.528: INFO: (9) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 12.045253ms)
Feb  6 03:41:22.528: INFO: (9) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 12.398216ms)
Feb  6 03:41:22.528: INFO: (9) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 12.294552ms)
Feb  6 03:41:22.528: INFO: (9) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 12.595696ms)
Feb  6 03:41:22.529: INFO: (9) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 12.993372ms)
Feb  6 03:41:22.535: INFO: (10) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 5.748782ms)
Feb  6 03:41:22.537: INFO: (10) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 7.141335ms)
Feb  6 03:41:22.538: INFO: (10) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 7.711218ms)
Feb  6 03:41:22.539: INFO: (10) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 8.661011ms)
Feb  6 03:41:22.540: INFO: (10) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 10.154025ms)
Feb  6 03:41:22.541: INFO: (10) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 11.19146ms)
Feb  6 03:41:22.541: INFO: (10) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 11.026445ms)
Feb  6 03:41:22.541: INFO: (10) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 10.875914ms)
Feb  6 03:41:22.541: INFO: (10) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 11.077388ms)
Feb  6 03:41:22.541: INFO: (10) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 11.001837ms)
Feb  6 03:41:22.542: INFO: (10) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 12.000024ms)
Feb  6 03:41:22.542: INFO: (10) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 12.606092ms)
Feb  6 03:41:22.543: INFO: (10) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 12.610031ms)
Feb  6 03:41:22.543: INFO: (10) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 12.75195ms)
Feb  6 03:41:22.544: INFO: (10) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 13.287761ms)
Feb  6 03:41:22.544: INFO: (10) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 13.864457ms)
Feb  6 03:41:22.553: INFO: (11) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 7.765184ms)
Feb  6 03:41:22.554: INFO: (11) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 8.905369ms)
Feb  6 03:41:22.554: INFO: (11) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 9.439542ms)
Feb  6 03:41:22.554: INFO: (11) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 9.184653ms)
Feb  6 03:41:22.555: INFO: (11) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 9.8709ms)
Feb  6 03:41:22.556: INFO: (11) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 10.732476ms)
Feb  6 03:41:22.556: INFO: (11) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 11.362032ms)
Feb  6 03:41:22.556: INFO: (11) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 11.273965ms)
Feb  6 03:41:22.556: INFO: (11) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 11.930445ms)
Feb  6 03:41:22.557: INFO: (11) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 11.782326ms)
Feb  6 03:41:22.557: INFO: (11) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 12.008472ms)
Feb  6 03:41:22.557: INFO: (11) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 11.990479ms)
Feb  6 03:41:22.557: INFO: (11) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 12.204736ms)
Feb  6 03:41:22.557: INFO: (11) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 11.917049ms)
Feb  6 03:41:22.557: INFO: (11) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 11.998587ms)
Feb  6 03:41:22.557: INFO: (11) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 12.151266ms)
Feb  6 03:41:22.564: INFO: (12) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 6.453903ms)
Feb  6 03:41:22.564: INFO: (12) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 7.099935ms)
Feb  6 03:41:22.566: INFO: (12) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 8.299606ms)
Feb  6 03:41:22.566: INFO: (12) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 8.256318ms)
Feb  6 03:41:22.569: INFO: (12) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 10.704151ms)
Feb  6 03:41:22.569: INFO: (12) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 10.334298ms)
Feb  6 03:41:22.569: INFO: (12) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 10.513699ms)
Feb  6 03:41:22.570: INFO: (12) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 12.518317ms)
Feb  6 03:41:22.570: INFO: (12) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 12.296054ms)
Feb  6 03:41:22.571: INFO: (12) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 12.047126ms)
Feb  6 03:41:22.571: INFO: (12) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 12.635782ms)
Feb  6 03:41:22.571: INFO: (12) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 13.244607ms)
Feb  6 03:41:22.571: INFO: (12) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 13.282808ms)
Feb  6 03:41:22.571: INFO: (12) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 12.808996ms)
Feb  6 03:41:22.571: INFO: (12) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 13.589751ms)
Feb  6 03:41:22.572: INFO: (12) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 13.126178ms)
Feb  6 03:41:22.576: INFO: (13) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 4.470247ms)
Feb  6 03:41:22.580: INFO: (13) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 7.540339ms)
Feb  6 03:41:22.582: INFO: (13) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 9.900453ms)
Feb  6 03:41:22.583: INFO: (13) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 10.474765ms)
Feb  6 03:41:22.583: INFO: (13) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 11.082646ms)
Feb  6 03:41:22.583: INFO: (13) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 10.834658ms)
Feb  6 03:41:22.584: INFO: (13) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 11.391618ms)
Feb  6 03:41:22.585: INFO: (13) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 11.725987ms)
Feb  6 03:41:22.586: INFO: (13) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 12.710746ms)
Feb  6 03:41:22.586: INFO: (13) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 13.065929ms)
Feb  6 03:41:22.586: INFO: (13) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 13.728043ms)
Feb  6 03:41:22.586: INFO: (13) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 14.014554ms)
Feb  6 03:41:22.587: INFO: (13) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 14.302815ms)
Feb  6 03:41:22.587: INFO: (13) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 14.777747ms)
Feb  6 03:41:22.587: INFO: (13) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 13.581594ms)
Feb  6 03:41:22.587: INFO: (13) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 14.242692ms)
Feb  6 03:41:22.590: INFO: (14) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 3.175236ms)
Feb  6 03:41:22.592: INFO: (14) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 5.263706ms)
Feb  6 03:41:22.594: INFO: (14) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 6.204712ms)
Feb  6 03:41:22.596: INFO: (14) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 8.327902ms)
Feb  6 03:41:22.596: INFO: (14) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 8.60116ms)
Feb  6 03:41:22.598: INFO: (14) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 10.891065ms)
Feb  6 03:41:22.599: INFO: (14) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 11.064083ms)
Feb  6 03:41:22.600: INFO: (14) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 12.059936ms)
Feb  6 03:41:22.600: INFO: (14) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 12.861293ms)
Feb  6 03:41:22.601: INFO: (14) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 12.719235ms)
Feb  6 03:41:22.601: INFO: (14) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 12.557437ms)
Feb  6 03:41:22.601: INFO: (14) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 14.119783ms)
Feb  6 03:41:22.602: INFO: (14) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 14.294216ms)
Feb  6 03:41:22.603: INFO: (14) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 14.920717ms)
Feb  6 03:41:22.603: INFO: (14) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 14.854438ms)
Feb  6 03:41:22.603: INFO: (14) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 14.749766ms)
Feb  6 03:41:22.607: INFO: (15) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 4.530086ms)
Feb  6 03:41:22.609: INFO: (15) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 5.139514ms)
Feb  6 03:41:22.611: INFO: (15) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 7.67681ms)
Feb  6 03:41:22.612: INFO: (15) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 9.18017ms)
Feb  6 03:41:22.613: INFO: (15) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 9.557026ms)
Feb  6 03:41:22.613: INFO: (15) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 9.725081ms)
Feb  6 03:41:22.613: INFO: (15) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 9.793036ms)
Feb  6 03:41:22.613: INFO: (15) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 9.987156ms)
Feb  6 03:41:22.614: INFO: (15) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 10.886403ms)
Feb  6 03:41:22.615: INFO: (15) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 11.258393ms)
Feb  6 03:41:22.615: INFO: (15) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 11.662395ms)
Feb  6 03:41:22.615: INFO: (15) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 12.177929ms)
Feb  6 03:41:22.616: INFO: (15) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 12.822947ms)
Feb  6 03:41:22.616: INFO: (15) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 12.617234ms)
Feb  6 03:41:22.616: INFO: (15) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 12.641191ms)
Feb  6 03:41:22.616: INFO: (15) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 12.860306ms)
Feb  6 03:41:22.621: INFO: (16) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 4.697733ms)
Feb  6 03:41:22.622: INFO: (16) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 6.010098ms)
Feb  6 03:41:22.622: INFO: (16) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 5.97008ms)
Feb  6 03:41:22.623: INFO: (16) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 6.479234ms)
Feb  6 03:41:22.624: INFO: (16) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 7.847653ms)
Feb  6 03:41:22.628: INFO: (16) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 10.795659ms)
Feb  6 03:41:22.629: INFO: (16) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 11.185156ms)
Feb  6 03:41:22.630: INFO: (16) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 13.193955ms)
Feb  6 03:41:22.631: INFO: (16) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 13.290296ms)
Feb  6 03:41:22.631: INFO: (16) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 13.851574ms)
Feb  6 03:41:22.632: INFO: (16) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 15.859422ms)
Feb  6 03:41:22.634: INFO: (16) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 16.740037ms)
Feb  6 03:41:22.634: INFO: (16) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 17.268551ms)
Feb  6 03:41:22.634: INFO: (16) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 16.726362ms)
Feb  6 03:41:22.635: INFO: (16) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 17.416444ms)
Feb  6 03:41:22.635: INFO: (16) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 17.66243ms)
Feb  6 03:41:22.642: INFO: (17) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 6.66824ms)
Feb  6 03:41:22.644: INFO: (17) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 8.138835ms)
Feb  6 03:41:22.645: INFO: (17) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 9.063914ms)
Feb  6 03:41:22.646: INFO: (17) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 9.459683ms)
Feb  6 03:41:22.647: INFO: (17) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 11.815367ms)
Feb  6 03:41:22.648: INFO: (17) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 12.195842ms)
Feb  6 03:41:22.649: INFO: (17) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 12.247175ms)
Feb  6 03:41:22.649: INFO: (17) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 12.921847ms)
Feb  6 03:41:22.649: INFO: (17) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 12.715396ms)
Feb  6 03:41:22.649: INFO: (17) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 12.902524ms)
Feb  6 03:41:22.649: INFO: (17) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 12.554599ms)
Feb  6 03:41:22.649: INFO: (17) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 13.338036ms)
Feb  6 03:41:22.649: INFO: (17) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 13.447327ms)
Feb  6 03:41:22.649: INFO: (17) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 13.776814ms)
Feb  6 03:41:22.649: INFO: (17) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 13.178944ms)
Feb  6 03:41:22.649: INFO: (17) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 12.953621ms)
Feb  6 03:41:22.657: INFO: (18) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 7.732042ms)
Feb  6 03:41:22.658: INFO: (18) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 8.332094ms)
Feb  6 03:41:22.659: INFO: (18) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 8.851247ms)
Feb  6 03:41:22.660: INFO: (18) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 9.710936ms)
Feb  6 03:41:22.660: INFO: (18) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 10.348704ms)
Feb  6 03:41:22.661: INFO: (18) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 10.731557ms)
Feb  6 03:41:22.661: INFO: (18) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 10.660298ms)
Feb  6 03:41:22.663: INFO: (18) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 12.977621ms)
Feb  6 03:41:22.663: INFO: (18) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 12.34984ms)
Feb  6 03:41:22.663: INFO: (18) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 12.636244ms)
Feb  6 03:41:22.663: INFO: (18) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 13.372452ms)
Feb  6 03:41:22.663: INFO: (18) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 12.999856ms)
Feb  6 03:41:22.664: INFO: (18) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 13.391264ms)
Feb  6 03:41:22.664: INFO: (18) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 13.548566ms)
Feb  6 03:41:22.664: INFO: (18) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 13.68835ms)
Feb  6 03:41:22.664: INFO: (18) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 14.643402ms)
Feb  6 03:41:22.668: INFO: (19) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname2/proxy/: tls qux (200; 3.025248ms)
Feb  6 03:41:22.668: INFO: (19) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">test<... (200; 3.26357ms)
Feb  6 03:41:22.677: INFO: (19) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:462/proxy/: tls qux (200; 12.349573ms)
Feb  6 03:41:22.679: INFO: (19) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname1/proxy/: foo (200; 13.670984ms)
Feb  6 03:41:22.679: INFO: (19) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:460/proxy/: tls baz (200; 13.327554ms)
Feb  6 03:41:22.679: INFO: (19) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf/proxy/rewriteme">test</a> (200; 13.730681ms)
Feb  6 03:41:22.679: INFO: (19) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 14.103161ms)
Feb  6 03:41:22.679: INFO: (19) /api/v1/namespaces/proxy-6735/pods/proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 13.579112ms)
Feb  6 03:41:22.679: INFO: (19) /api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/https:proxy-service-5kftp-c8vqf:443/proxy/tlsrewritem... (200; 13.556292ms)
Feb  6 03:41:22.679: INFO: (19) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname2/proxy/: bar (200; 13.502938ms)
Feb  6 03:41:22.679: INFO: (19) /api/v1/namespaces/proxy-6735/services/http:proxy-service-5kftp:portname1/proxy/: foo (200; 14.425019ms)
Feb  6 03:41:22.680: INFO: (19) /api/v1/namespaces/proxy-6735/services/https:proxy-service-5kftp:tlsportname1/proxy/: tls baz (200; 14.160259ms)
Feb  6 03:41:22.680: INFO: (19) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:162/proxy/: bar (200; 14.377788ms)
Feb  6 03:41:22.680: INFO: (19) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:160/proxy/: foo (200; 14.002967ms)
Feb  6 03:41:22.680: INFO: (19) /api/v1/namespaces/proxy-6735/services/proxy-service-5kftp:portname2/proxy/: bar (200; 14.384661ms)
Feb  6 03:41:22.679: INFO: (19) /api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/: <a href="/api/v1/namespaces/proxy-6735/pods/http:proxy-service-5kftp-c8vqf:1080/proxy/rewriteme">... (200; 13.958073ms)
STEP: deleting ReplicationController proxy-service-5kftp in namespace proxy-6735, will wait for the garbage collector to delete the pods
Feb  6 03:41:22.736: INFO: Deleting ReplicationController proxy-service-5kftp took: 4.037702ms
Feb  6 03:41:22.836: INFO: Terminating ReplicationController proxy-service-5kftp pods took: 100.251478ms
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:41:24.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6735" for this suite.
Feb  6 03:41:30.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:41:30.591: INFO: namespace proxy-6735 deletion completed in 6.052689569s

• [SLOW TEST:14.542 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:41:30.591: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3694
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3694
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 03:41:30.714: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 03:41:54.796: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.50:8080/dial?request=hostName&protocol=http&host=10.244.2.72&port=8080&tries=1'] Namespace:pod-network-test-3694 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 03:41:54.796: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 03:41:54.872: INFO: Waiting for endpoints: map[]
Feb  6 03:41:54.874: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.50:8080/dial?request=hostName&protocol=http&host=10.244.0.250&port=8080&tries=1'] Namespace:pod-network-test-3694 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 03:41:54.874: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 03:41:54.941: INFO: Waiting for endpoints: map[]
Feb  6 03:41:54.942: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.50:8080/dial?request=hostName&protocol=http&host=10.244.1.49&port=8080&tries=1'] Namespace:pod-network-test-3694 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 03:41:54.942: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 03:41:55.011: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:41:55.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3694" for this suite.
Feb  6 03:42:07.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:42:07.070: INFO: namespace pod-network-test-3694 deletion completed in 12.056791386s

• [SLOW TEST:36.479 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:42:07.070: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1794
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  6 03:42:07.199: INFO: Waiting up to 5m0s for pod "pod-6dca6c4e-4629-45e7-8d2f-cf73dd5a5c89" in namespace "emptydir-1794" to be "success or failure"
Feb  6 03:42:07.202: INFO: Pod "pod-6dca6c4e-4629-45e7-8d2f-cf73dd5a5c89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.456002ms
Feb  6 03:42:09.204: INFO: Pod "pod-6dca6c4e-4629-45e7-8d2f-cf73dd5a5c89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004793426s
STEP: Saw pod success
Feb  6 03:42:09.204: INFO: Pod "pod-6dca6c4e-4629-45e7-8d2f-cf73dd5a5c89" satisfied condition "success or failure"
Feb  6 03:42:09.205: INFO: Trying to get logs from node aks-1-4 pod pod-6dca6c4e-4629-45e7-8d2f-cf73dd5a5c89 container test-container: <nil>
STEP: delete the pod
Feb  6 03:42:09.219: INFO: Waiting for pod pod-6dca6c4e-4629-45e7-8d2f-cf73dd5a5c89 to disappear
Feb  6 03:42:09.220: INFO: Pod pod-6dca6c4e-4629-45e7-8d2f-cf73dd5a5c89 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:42:09.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1794" for this suite.
Feb  6 03:42:15.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:42:15.278: INFO: namespace emptydir-1794 deletion completed in 6.055204771s

• [SLOW TEST:8.208 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:42:15.279: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7341
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb  6 03:42:15.457: INFO: Waiting up to 5m0s for pod "pod-9ec8f604-aa97-4627-b0ab-327e91fa5a98" in namespace "emptydir-7341" to be "success or failure"
Feb  6 03:42:15.461: INFO: Pod "pod-9ec8f604-aa97-4627-b0ab-327e91fa5a98": Phase="Pending", Reason="", readiness=false. Elapsed: 3.357129ms
Feb  6 03:42:17.463: INFO: Pod "pod-9ec8f604-aa97-4627-b0ab-327e91fa5a98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005801348s
STEP: Saw pod success
Feb  6 03:42:17.463: INFO: Pod "pod-9ec8f604-aa97-4627-b0ab-327e91fa5a98" satisfied condition "success or failure"
Feb  6 03:42:17.465: INFO: Trying to get logs from node aks-1-4 pod pod-9ec8f604-aa97-4627-b0ab-327e91fa5a98 container test-container: <nil>
STEP: delete the pod
Feb  6 03:42:17.477: INFO: Waiting for pod pod-9ec8f604-aa97-4627-b0ab-327e91fa5a98 to disappear
Feb  6 03:42:17.479: INFO: Pod pod-9ec8f604-aa97-4627-b0ab-327e91fa5a98 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:42:17.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7341" for this suite.
Feb  6 03:42:23.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:42:23.536: INFO: namespace emptydir-7341 deletion completed in 6.055359939s

• [SLOW TEST:8.257 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:42:23.537: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8119
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:42:25.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8119" for this suite.
Feb  6 03:43:11.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:43:11.799: INFO: namespace kubelet-test-8119 deletion completed in 46.057227513s

• [SLOW TEST:48.263 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:43:11.800: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2630
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:43:11.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2630" for this suite.
Feb  6 03:43:17.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:43:17.985: INFO: namespace custom-resource-definition-2630 deletion completed in 6.054659425s

• [SLOW TEST:6.185 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:43:17.985: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9522
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9522.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9522.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9522.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9522.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9522.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9522.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 03:43:44.144: INFO: DNS probes using dns-9522/dns-test-1ad12878-bde5-4bdf-b378-bc25509f4bdc succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:43:44.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9522" for this suite.
Feb  6 03:43:50.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:43:50.214: INFO: namespace dns-9522 deletion completed in 6.059585371s

• [SLOW TEST:32.228 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:43:50.214: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7110
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-45zr
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 03:43:50.398: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-45zr" in namespace "subpath-7110" to be "success or failure"
Feb  6 03:43:50.401: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.602736ms
Feb  6 03:43:52.403: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00471402s
Feb  6 03:43:54.406: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007262994s
Feb  6 03:43:56.408: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Running", Reason="", readiness=true. Elapsed: 6.009802153s
Feb  6 03:43:58.411: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Running", Reason="", readiness=true. Elapsed: 8.012141665s
Feb  6 03:44:00.414: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Running", Reason="", readiness=true. Elapsed: 10.015252054s
Feb  6 03:44:02.416: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Running", Reason="", readiness=true. Elapsed: 12.017851761s
Feb  6 03:44:04.419: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Running", Reason="", readiness=true. Elapsed: 14.020686341s
Feb  6 03:44:06.422: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Running", Reason="", readiness=true. Elapsed: 16.023134917s
Feb  6 03:44:08.424: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Running", Reason="", readiness=true. Elapsed: 18.025566011s
Feb  6 03:44:10.426: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Running", Reason="", readiness=true. Elapsed: 20.027776147s
Feb  6 03:44:12.429: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Running", Reason="", readiness=true. Elapsed: 22.03021022s
Feb  6 03:44:14.431: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Running", Reason="", readiness=true. Elapsed: 24.03281947s
Feb  6 03:44:16.434: INFO: Pod "pod-subpath-test-downwardapi-45zr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.035258078s
STEP: Saw pod success
Feb  6 03:44:16.434: INFO: Pod "pod-subpath-test-downwardapi-45zr" satisfied condition "success or failure"
Feb  6 03:44:16.435: INFO: Trying to get logs from node aks-1-4 pod pod-subpath-test-downwardapi-45zr container test-container-subpath-downwardapi-45zr: <nil>
STEP: delete the pod
Feb  6 03:44:16.450: INFO: Waiting for pod pod-subpath-test-downwardapi-45zr to disappear
Feb  6 03:44:16.453: INFO: Pod pod-subpath-test-downwardapi-45zr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-45zr
Feb  6 03:44:16.453: INFO: Deleting pod "pod-subpath-test-downwardapi-45zr" in namespace "subpath-7110"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:44:16.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7110" for this suite.
Feb  6 03:44:22.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:44:22.511: INFO: namespace subpath-7110 deletion completed in 6.055688439s

• [SLOW TEST:32.297 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:44:22.512: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6294
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  6 03:44:22.640: INFO: Waiting up to 5m0s for pod "pod-34ba9a07-b173-47b9-97ef-534fd6460582" in namespace "emptydir-6294" to be "success or failure"
Feb  6 03:44:22.642: INFO: Pod "pod-34ba9a07-b173-47b9-97ef-534fd6460582": Phase="Pending", Reason="", readiness=false. Elapsed: 1.561172ms
Feb  6 03:44:24.644: INFO: Pod "pod-34ba9a07-b173-47b9-97ef-534fd6460582": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003707648s
Feb  6 03:44:26.647: INFO: Pod "pod-34ba9a07-b173-47b9-97ef-534fd6460582": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006059477s
STEP: Saw pod success
Feb  6 03:44:26.647: INFO: Pod "pod-34ba9a07-b173-47b9-97ef-534fd6460582" satisfied condition "success or failure"
Feb  6 03:44:26.648: INFO: Trying to get logs from node aks-1-3 pod pod-34ba9a07-b173-47b9-97ef-534fd6460582 container test-container: <nil>
STEP: delete the pod
Feb  6 03:44:26.665: INFO: Waiting for pod pod-34ba9a07-b173-47b9-97ef-534fd6460582 to disappear
Feb  6 03:44:26.667: INFO: Pod pod-34ba9a07-b173-47b9-97ef-534fd6460582 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:44:26.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6294" for this suite.
Feb  6 03:44:32.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:44:32.723: INFO: namespace emptydir-6294 deletion completed in 6.05421671s

• [SLOW TEST:10.211 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:44:32.723: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-5661
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7381
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8984
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:44:39.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5661" for this suite.
Feb  6 03:44:45.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:44:45.172: INFO: namespace namespaces-5661 deletion completed in 6.056103202s
STEP: Destroying namespace "nsdeletetest-7381" for this suite.
Feb  6 03:44:45.174: INFO: Namespace nsdeletetest-7381 was already deleted
STEP: Destroying namespace "nsdeletetest-8984" for this suite.
Feb  6 03:44:51.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:44:51.254: INFO: namespace nsdeletetest-8984 deletion completed in 6.079693988s

• [SLOW TEST:18.531 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:44:51.254: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2305
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:45:02.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2305" for this suite.
Feb  6 03:45:08.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:45:08.481: INFO: namespace resourcequota-2305 deletion completed in 6.059961803s

• [SLOW TEST:17.226 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:45:08.481: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5566
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb  6 03:45:08.628: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5566 /api/v1/namespaces/watch-5566/configmaps/e2e-watch-test-label-changed 56b70c76-3b16-423f-bad4-d25601490041 1785896 0 2020-02-06 03:45:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 03:45:08.628: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5566 /api/v1/namespaces/watch-5566/configmaps/e2e-watch-test-label-changed 56b70c76-3b16-423f-bad4-d25601490041 1785897 0 2020-02-06 03:45:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  6 03:45:08.628: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5566 /api/v1/namespaces/watch-5566/configmaps/e2e-watch-test-label-changed 56b70c76-3b16-423f-bad4-d25601490041 1785898 0 2020-02-06 03:45:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb  6 03:45:18.650: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5566 /api/v1/namespaces/watch-5566/configmaps/e2e-watch-test-label-changed 56b70c76-3b16-423f-bad4-d25601490041 1785914 0 2020-02-06 03:45:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 03:45:18.650: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5566 /api/v1/namespaces/watch-5566/configmaps/e2e-watch-test-label-changed 56b70c76-3b16-423f-bad4-d25601490041 1785915 0 2020-02-06 03:45:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb  6 03:45:18.650: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5566 /api/v1/namespaces/watch-5566/configmaps/e2e-watch-test-label-changed 56b70c76-3b16-423f-bad4-d25601490041 1785916 0 2020-02-06 03:45:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:45:18.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5566" for this suite.
Feb  6 03:45:24.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:45:24.707: INFO: namespace watch-5566 deletion completed in 6.055407638s

• [SLOW TEST:16.226 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:45:24.708: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-6411
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb  6 03:45:25.098: INFO: Pod name wrapped-volume-race-0c3c74b8-35ef-4f5f-9c2b-11f9af3d8cba: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0c3c74b8-35ef-4f5f-9c2b-11f9af3d8cba in namespace emptydir-wrapper-6411, will wait for the garbage collector to delete the pods
Feb  6 03:45:45.241: INFO: Deleting ReplicationController wrapped-volume-race-0c3c74b8-35ef-4f5f-9c2b-11f9af3d8cba took: 3.926257ms
Feb  6 03:45:45.542: INFO: Terminating ReplicationController wrapped-volume-race-0c3c74b8-35ef-4f5f-9c2b-11f9af3d8cba pods took: 300.344982ms
STEP: Creating RC which spawns configmap-volume pods
Feb  6 03:46:25.151: INFO: Pod name wrapped-volume-race-8dc9b335-16ba-4cb8-8db3-347ec3f7d9e0: Found 0 pods out of 5
Feb  6 03:46:30.156: INFO: Pod name wrapped-volume-race-8dc9b335-16ba-4cb8-8db3-347ec3f7d9e0: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8dc9b335-16ba-4cb8-8db3-347ec3f7d9e0 in namespace emptydir-wrapper-6411, will wait for the garbage collector to delete the pods
Feb  6 03:46:42.224: INFO: Deleting ReplicationController wrapped-volume-race-8dc9b335-16ba-4cb8-8db3-347ec3f7d9e0 took: 4.412375ms
Feb  6 03:46:42.524: INFO: Terminating ReplicationController wrapped-volume-race-8dc9b335-16ba-4cb8-8db3-347ec3f7d9e0 pods took: 300.301629ms
STEP: Creating RC which spawns configmap-volume pods
Feb  6 03:47:25.136: INFO: Pod name wrapped-volume-race-9b2b382a-5f78-4fb0-a957-4a4f5193c9fd: Found 0 pods out of 5
Feb  6 03:47:30.142: INFO: Pod name wrapped-volume-race-9b2b382a-5f78-4fb0-a957-4a4f5193c9fd: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9b2b382a-5f78-4fb0-a957-4a4f5193c9fd in namespace emptydir-wrapper-6411, will wait for the garbage collector to delete the pods
Feb  6 03:47:42.213: INFO: Deleting ReplicationController wrapped-volume-race-9b2b382a-5f78-4fb0-a957-4a4f5193c9fd took: 3.887733ms
Feb  6 03:47:42.513: INFO: Terminating ReplicationController wrapped-volume-race-9b2b382a-5f78-4fb0-a957-4a4f5193c9fd pods took: 300.326472ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:48:24.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6411" for this suite.
Feb  6 03:48:30.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:48:30.741: INFO: namespace emptydir-wrapper-6411 deletion completed in 6.077996271s

• [SLOW TEST:186.033 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:48:30.741: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1485
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:48:30.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1485" for this suite.
Feb  6 03:48:58.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:48:58.943: INFO: namespace pods-1485 deletion completed in 28.053939209s

• [SLOW TEST:28.203 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:48:58.944: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9632
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb  6 03:48:59.073: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 03:48:59.090: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 03:48:59.092: INFO: 
Logging pods the kubelet thinks is on node aks-1-2 before test
Feb  6 03:48:59.102: INFO: sonobuoy-e2e-job-29ae3d20e67a4412 from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container e2e ready: true, restart count 0
Feb  6 03:48:59.102: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:48:59.102: INFO: nginx-8f556 from default started at 2020-02-06 03:27:36 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:48:59.102: INFO: nginx-ktsbf from default started at 2020-02-06 03:27:31 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:48:59.102: INFO: nginx-jjf9z from default started at 2020-02-06 03:30:05 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:48:59.102: INFO: kube-flannel-ds-amd64-kln2x from kube-system started at 2020-02-05 11:48:51 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 03:48:59.102: INFO: sonobuoy from sonobuoy started at 2020-02-06 03:24:46 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 03:48:59.102: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-lrnrn from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:48:59.102: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 03:48:59.102: INFO: nginx-98nbt from default started at 2020-02-06 03:30:06 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:48:59.102: INFO: coredns-7f6cddc944-qsgx4 from kube-system started at 2020-02-05 13:54:41 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:48:59.102: INFO: nginx-66lj2 from default started at 2020-02-06 03:27:33 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:48:59.102: INFO: nginx-m679w from default started at 2020-02-06 03:30:04 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:48:59.102: INFO: nginx-xc4tj from default started at 2020-02-06 03:27:31 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:48:59.102: INFO: nginx-vnn6h from default started at 2020-02-06 03:27:28 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:48:59.102: INFO: nginx-k4j64 from default started at 2020-02-06 03:27:29 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:48:59.102: INFO: nginx-gjqqt from default started at 2020-02-06 03:27:30 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.102: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:48:59.102: INFO: 
Logging pods the kubelet thinks is on node aks-1-3 before test
Feb  6 03:48:59.110: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-kwwvw from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:48:59.110: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:48:59.110: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 03:48:59.110: INFO: kube-flannel-ds-amd64-tkhv8 from kube-system started at 2020-02-05 07:36:26 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.110: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 03:48:59.110: INFO: coredns-7f6cddc944-v22mw from kube-system started at 2020-02-05 08:48:34 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.110: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:48:59.110: INFO: coredns-7f6cddc944-99f6c from kube-system started at 2020-02-05 13:54:41 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.110: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:48:59.110: INFO: 
Logging pods the kubelet thinks is on node aks-1-4 before test
Feb  6 03:48:59.119: INFO: coredns-7f6cddc944-w6w2z from kube-system started at 2020-02-03 03:59:20 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.119: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:48:59.119: INFO: kube-flannel-ds-amd64-plfph from kube-system started at 2020-02-04 14:20:52 +0000 UTC (1 container statuses recorded)
Feb  6 03:48:59.119: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 03:48:59.119: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-7z6kz from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:48:59.119: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:48:59.119: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-25c10f40-248c-489b-b84d-3f476573bc25 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-25c10f40-248c-489b-b84d-3f476573bc25 off the node aks-1-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-25c10f40-248c-489b-b84d-3f476573bc25
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:49:03.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9632" for this suite.
Feb  6 03:49:11.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:49:11.255: INFO: namespace sched-pred-9632 deletion completed in 8.062721637s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:12.311 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:49:11.256: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-406
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Feb  6 03:49:11.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 cluster-info'
Feb  6 03:49:11.664: INFO: stderr: ""
Feb  6 03:49:11.664: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:49:11.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-406" for this suite.
Feb  6 03:49:17.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:49:17.722: INFO: namespace kubectl-406 deletion completed in 6.055079257s

• [SLOW TEST:6.466 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:49:17.722: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1072
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb  6 03:49:19.911: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:49:19.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1072" for this suite.
Feb  6 03:49:25.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:49:25.977: INFO: namespace container-runtime-1072 deletion completed in 6.056607167s

• [SLOW TEST:8.255 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:49:25.977: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2133
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 03:49:26.706: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 03:49:29.716: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:49:41.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2133" for this suite.
Feb  6 03:49:47.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:49:47.862: INFO: namespace webhook-2133 deletion completed in 6.055368289s
STEP: Destroying namespace "webhook-2133-markers" for this suite.
Feb  6 03:49:53.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:49:53.915: INFO: namespace webhook-2133-markers deletion completed in 6.052973671s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:27.946 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:49:53.924: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1580
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 03:49:54.424: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 03:49:56.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716557794, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716557794, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716557794, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716557794, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 03:49:59.440: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 03:49:59.442: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5371-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:50:00.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1580" for this suite.
Feb  6 03:50:06.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:50:06.599: INFO: namespace webhook-1580 deletion completed in 6.054441653s
STEP: Destroying namespace "webhook-1580-markers" for this suite.
Feb  6 03:50:12.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:50:12.654: INFO: namespace webhook-1580-markers deletion completed in 6.055648056s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.738 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:50:12.663: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3417
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Feb  6 03:50:12.798: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 03:50:15.065: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:50:29.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3417" for this suite.
Feb  6 03:50:35.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:50:35.891: INFO: namespace crd-publish-openapi-3417 deletion completed in 6.054612991s

• [SLOW TEST:23.228 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:50:35.891: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-464
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:50:47.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-464" for this suite.
Feb  6 03:50:53.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:50:53.099: INFO: namespace resourcequota-464 deletion completed in 6.05684514s

• [SLOW TEST:17.208 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:50:53.100: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5111
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-5885f4bb-e580-4784-8989-5cba96b0da2d
STEP: Creating secret with name s-test-opt-upd-5433caa3-d14f-4b10-9907-c0949ede8a9e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5885f4bb-e580-4784-8989-5cba96b0da2d
STEP: Updating secret s-test-opt-upd-5433caa3-d14f-4b10-9907-c0949ede8a9e
STEP: Creating secret with name s-test-opt-create-2c48454f-7d4c-49a2-bdc4-9e9073fad1e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:50:57.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5111" for this suite.
Feb  6 03:51:11.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:51:11.430: INFO: namespace projected-5111 deletion completed in 14.079069136s

• [SLOW TEST:18.330 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:51:11.431: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-4586/configmap-test-d22bec6f-13db-44fb-a02a-00946f93f513
STEP: Creating a pod to test consume configMaps
Feb  6 03:51:11.574: INFO: Waiting up to 5m0s for pod "pod-configmaps-77f6f431-ce94-4fee-b439-e841093f1b5d" in namespace "configmap-4586" to be "success or failure"
Feb  6 03:51:11.576: INFO: Pod "pod-configmaps-77f6f431-ce94-4fee-b439-e841093f1b5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.222724ms
Feb  6 03:51:13.578: INFO: Pod "pod-configmaps-77f6f431-ce94-4fee-b439-e841093f1b5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003786729s
STEP: Saw pod success
Feb  6 03:51:13.578: INFO: Pod "pod-configmaps-77f6f431-ce94-4fee-b439-e841093f1b5d" satisfied condition "success or failure"
Feb  6 03:51:13.580: INFO: Trying to get logs from node aks-1-4 pod pod-configmaps-77f6f431-ce94-4fee-b439-e841093f1b5d container env-test: <nil>
STEP: delete the pod
Feb  6 03:51:13.597: INFO: Waiting for pod pod-configmaps-77f6f431-ce94-4fee-b439-e841093f1b5d to disappear
Feb  6 03:51:13.600: INFO: Pod pod-configmaps-77f6f431-ce94-4fee-b439-e841093f1b5d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:51:13.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4586" for this suite.
Feb  6 03:51:19.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:51:19.661: INFO: namespace configmap-4586 deletion completed in 6.059323031s

• [SLOW TEST:8.230 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:51:19.661: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-553
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb  6 03:51:36.810: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:51:37.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-553" for this suite.
Feb  6 03:52:05.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:52:05.874: INFO: namespace replicaset-553 deletion completed in 28.052660183s

• [SLOW TEST:46.213 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:52:05.875: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-6716
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb  6 03:52:08.031: INFO: &Pod{ObjectMeta:{send-events-0000e14b-8dae-429f-90a3-dbcbf2074fdb  events-6716 /api/v1/namespaces/events-6716/pods/send-events-0000e14b-8dae-429f-90a3-dbcbf2074fdb 360fa496-5903-42fa-ae77-667e113cf686 1787896 0 2020-02-06 03:52:06 +0000 UTC <nil> <nil> map[name:foo time:16506070] map[pod.beta1.sigma.ali/update-status:{"statuses":{"p":{"creationTimestamp":"2020-02-06T11:52:06.626920393+08:00","finishTimestamp":"2020-02-06T11:52:07.100576259+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-45x89,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-45x89,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-45x89,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 03:52:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 03:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 03:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 03:52:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 03:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.81,PodIP:10.244.1.63,StartTime:2020-02-06 03:52:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 03:52:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://b2a61070fc1361e21b25b5ff4894dabef138a3e2c48f416d9bb9953a493b37c3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Feb  6 03:52:10.034: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb  6 03:52:12.037: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:52:12.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6716" for this suite.
Feb  6 03:52:56.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:52:56.111: INFO: namespace events-6716 deletion completed in 44.065962701s

• [SLOW TEST:50.236 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:52:56.111: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7408
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Feb  6 03:52:56.243: INFO: Waiting up to 5m0s for pod "client-containers-deff3a22-f77e-47fb-bd37-fee3c6c6a31f" in namespace "containers-7408" to be "success or failure"
Feb  6 03:52:56.244: INFO: Pod "client-containers-deff3a22-f77e-47fb-bd37-fee3c6c6a31f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.457829ms
Feb  6 03:52:58.247: INFO: Pod "client-containers-deff3a22-f77e-47fb-bd37-fee3c6c6a31f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00379946s
STEP: Saw pod success
Feb  6 03:52:58.247: INFO: Pod "client-containers-deff3a22-f77e-47fb-bd37-fee3c6c6a31f" satisfied condition "success or failure"
Feb  6 03:52:58.248: INFO: Trying to get logs from node aks-1-4 pod client-containers-deff3a22-f77e-47fb-bd37-fee3c6c6a31f container test-container: <nil>
STEP: delete the pod
Feb  6 03:52:58.266: INFO: Waiting for pod client-containers-deff3a22-f77e-47fb-bd37-fee3c6c6a31f to disappear
Feb  6 03:52:58.268: INFO: Pod client-containers-deff3a22-f77e-47fb-bd37-fee3c6c6a31f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:52:58.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7408" for this suite.
Feb  6 03:53:04.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:53:04.325: INFO: namespace containers-7408 deletion completed in 6.055309981s

• [SLOW TEST:8.215 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:53:04.326: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4407
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb  6 03:53:04.465: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4407 /api/v1/namespaces/watch-4407/configmaps/e2e-watch-test-resource-version 4a64631e-b72e-4ef4-8451-270bc1d5e2f5 1788036 0 2020-02-06 03:53:04 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 03:53:04.465: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4407 /api/v1/namespaces/watch-4407/configmaps/e2e-watch-test-resource-version 4a64631e-b72e-4ef4-8451-270bc1d5e2f5 1788037 0 2020-02-06 03:53:04 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:53:04.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4407" for this suite.
Feb  6 03:53:10.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:53:10.521: INFO: namespace watch-4407 deletion completed in 6.053882813s

• [SLOW TEST:6.196 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:53:10.522: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4708
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  6 03:53:10.655: INFO: Waiting up to 5m0s for pod "pod-9a971af1-6f13-4a20-9d6a-904035840c10" in namespace "emptydir-4708" to be "success or failure"
Feb  6 03:53:10.656: INFO: Pod "pod-9a971af1-6f13-4a20-9d6a-904035840c10": Phase="Pending", Reason="", readiness=false. Elapsed: 1.446366ms
Feb  6 03:53:12.659: INFO: Pod "pod-9a971af1-6f13-4a20-9d6a-904035840c10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004191328s
STEP: Saw pod success
Feb  6 03:53:12.659: INFO: Pod "pod-9a971af1-6f13-4a20-9d6a-904035840c10" satisfied condition "success or failure"
Feb  6 03:53:12.661: INFO: Trying to get logs from node aks-1-4 pod pod-9a971af1-6f13-4a20-9d6a-904035840c10 container test-container: <nil>
STEP: delete the pod
Feb  6 03:53:12.673: INFO: Waiting for pod pod-9a971af1-6f13-4a20-9d6a-904035840c10 to disappear
Feb  6 03:53:12.675: INFO: Pod pod-9a971af1-6f13-4a20-9d6a-904035840c10 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:53:12.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4708" for this suite.
Feb  6 03:53:18.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:53:18.729: INFO: namespace emptydir-4708 deletion completed in 6.051652647s

• [SLOW TEST:8.208 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:53:18.730: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5865
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 03:53:18.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-5865'
Feb  6 03:53:18.956: INFO: stderr: ""
Feb  6 03:53:18.956: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Feb  6 03:53:24.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pod e2e-test-httpd-pod --namespace=kubectl-5865 -o json'
Feb  6 03:53:24.113: INFO: stderr: ""
Feb  6 03:53:24.113: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"pod.beta1.sigma.ali/update-status\": \"{\\\"statuses\\\":{\\\"e2e-test-httpd-pod\\\":{\\\"creationTimestamp\\\":\\\"2020-02-06T11:53:19.549075646+08:00\\\",\\\"finishTimestamp\\\":\\\"2020-02-06T11:53:21.744735712+08:00\\\",\\\"retryCount\\\":0,\\\"currentState\\\":\\\"running\\\",\\\"lastState\\\":\\\"unknown\\\",\\\"action\\\":\\\"start\\\",\\\"success\\\":true,\\\"message\\\":\\\"create start and post start success\\\"}}}\"\n        },\n        \"creationTimestamp\": \"2020-02-06T03:53:18Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5865\",\n        \"resourceVersion\": \"1788113\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5865/pods/e2e-test-httpd-pod\",\n        \"uid\": \"8b258b8d-ff30-464e-abf4-7d9ce7b5107e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-kmbct\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"aks-1-4\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-kmbct\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-kmbct\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-06T03:53:18Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-06T03:53:22Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-06T03:53:22Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-06T03:53:18Z\",\n                \"status\": \"False\",\n                \"type\": \"ContainerDiskPressure\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-06T03:53:18Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://05c9d8d3f4c6edece69f4a5495eb789168c97a2cb144772bfebf37abd6975938\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-02-06T03:53:21Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.27.81\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.67\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.1.67\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-02-06T03:53:18Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb  6 03:53:24.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 replace -f - --namespace=kubectl-5865'
Feb  6 03:53:24.370: INFO: stderr: ""
Feb  6 03:53:24.370: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Feb  6 03:53:24.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete pods e2e-test-httpd-pod --namespace=kubectl-5865'
Feb  6 03:53:28.102: INFO: stderr: ""
Feb  6 03:53:28.102: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:53:28.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5865" for this suite.
Feb  6 03:53:34.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:53:34.161: INFO: namespace kubectl-5865 deletion completed in 6.05557748s

• [SLOW TEST:15.432 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:53:34.162: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:53:34.293: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ebadaee-1d2f-494d-bb45-9e9916387dff" in namespace "downward-api-3978" to be "success or failure"
Feb  6 03:53:34.295: INFO: Pod "downwardapi-volume-8ebadaee-1d2f-494d-bb45-9e9916387dff": Phase="Pending", Reason="", readiness=false. Elapsed: 1.408151ms
Feb  6 03:53:36.297: INFO: Pod "downwardapi-volume-8ebadaee-1d2f-494d-bb45-9e9916387dff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003257274s
STEP: Saw pod success
Feb  6 03:53:36.297: INFO: Pod "downwardapi-volume-8ebadaee-1d2f-494d-bb45-9e9916387dff" satisfied condition "success or failure"
Feb  6 03:53:36.298: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-8ebadaee-1d2f-494d-bb45-9e9916387dff container client-container: <nil>
STEP: delete the pod
Feb  6 03:53:36.308: INFO: Waiting for pod downwardapi-volume-8ebadaee-1d2f-494d-bb45-9e9916387dff to disappear
Feb  6 03:53:36.310: INFO: Pod downwardapi-volume-8ebadaee-1d2f-494d-bb45-9e9916387dff no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:53:36.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3978" for this suite.
Feb  6 03:53:42.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:53:42.366: INFO: namespace downward-api-3978 deletion completed in 6.05430752s

• [SLOW TEST:8.204 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:53:42.366: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8600
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Feb  6 03:53:42.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-8600 -- logs-generator --log-lines-total 100 --run-duration 20s'
Feb  6 03:53:42.590: INFO: stderr: ""
Feb  6 03:53:42.590: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Feb  6 03:53:42.590: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Feb  6 03:53:42.590: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8600" to be "running and ready, or succeeded"
Feb  6 03:53:42.593: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.13646ms
Feb  6 03:53:44.597: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.006744971s
Feb  6 03:53:44.597: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Feb  6 03:53:44.597: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Feb  6 03:53:44.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 logs logs-generator logs-generator --namespace=kubectl-8600'
Feb  6 03:53:44.726: INFO: stderr: ""
Feb  6 03:53:44.726: INFO: stdout: "I0206 03:53:43.700530       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/x4xl 302\nI0206 03:53:43.900617       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/tjn 314\nI0206 03:53:44.100661       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/qkw8 263\nI0206 03:53:44.300625       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/7vbr 213\nI0206 03:53:44.500650       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/z8m 446\nI0206 03:53:44.700693       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/xl4m 240\n"
Feb  6 03:53:46.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 logs logs-generator logs-generator --namespace=kubectl-8600'
Feb  6 03:53:46.852: INFO: stderr: ""
Feb  6 03:53:46.852: INFO: stdout: "I0206 03:53:43.700530       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/x4xl 302\nI0206 03:53:43.900617       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/tjn 314\nI0206 03:53:44.100661       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/qkw8 263\nI0206 03:53:44.300625       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/7vbr 213\nI0206 03:53:44.500650       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/z8m 446\nI0206 03:53:44.700693       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/xl4m 240\nI0206 03:53:44.900655       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/k46 349\nI0206 03:53:45.100693       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/25s 565\nI0206 03:53:45.300674       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/gvw9 491\nI0206 03:53:45.500673       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/k4s 535\nI0206 03:53:45.700682       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/2dc5 256\nI0206 03:53:45.900609       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/hfj 580\nI0206 03:53:46.100696       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/gnzl 586\nI0206 03:53:46.300617       1 logs_generator.go:76] 13 POST /api/v1/namespaces/default/pods/4bh 330\nI0206 03:53:46.500687       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/rgj 535\nI0206 03:53:46.700614       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/899f 327\n"
STEP: limiting log lines
Feb  6 03:53:46.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 logs logs-generator logs-generator --namespace=kubectl-8600 --tail=1'
Feb  6 03:53:46.953: INFO: stderr: ""
Feb  6 03:53:46.953: INFO: stdout: "I0206 03:53:46.900605       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/h8c 232\n"
STEP: limiting log bytes
Feb  6 03:53:46.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 logs logs-generator logs-generator --namespace=kubectl-8600 --limit-bytes=1'
Feb  6 03:53:47.049: INFO: stderr: ""
Feb  6 03:53:47.049: INFO: stdout: "I"
STEP: exposing timestamps
Feb  6 03:53:47.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 logs logs-generator logs-generator --namespace=kubectl-8600 --tail=1 --timestamps'
Feb  6 03:53:47.142: INFO: stderr: ""
Feb  6 03:53:47.142: INFO: stdout: "2020-02-06T03:53:47.100781016Z I0206 03:53:47.100647       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/q42l 246\n"
STEP: restricting to a time range
Feb  6 03:53:49.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 logs logs-generator logs-generator --namespace=kubectl-8600 --since=1s'
Feb  6 03:53:49.746: INFO: stderr: ""
Feb  6 03:53:49.746: INFO: stdout: "I0206 03:53:48.900628       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/hfn 391\nI0206 03:53:49.100661       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/9bcc 220\nI0206 03:53:49.300694       1 logs_generator.go:76] 28 GET /api/v1/namespaces/default/pods/hqct 273\nI0206 03:53:49.500608       1 logs_generator.go:76] 29 POST /api/v1/namespaces/default/pods/4sh 341\nI0206 03:53:49.700658       1 logs_generator.go:76] 30 GET /api/v1/namespaces/kube-system/pods/shpr 579\n"
Feb  6 03:53:49.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 logs logs-generator logs-generator --namespace=kubectl-8600 --since=24h'
Feb  6 03:53:49.846: INFO: stderr: ""
Feb  6 03:53:49.846: INFO: stdout: "I0206 03:53:43.700530       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/x4xl 302\nI0206 03:53:43.900617       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/tjn 314\nI0206 03:53:44.100661       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/qkw8 263\nI0206 03:53:44.300625       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/7vbr 213\nI0206 03:53:44.500650       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/z8m 446\nI0206 03:53:44.700693       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/xl4m 240\nI0206 03:53:44.900655       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/k46 349\nI0206 03:53:45.100693       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/25s 565\nI0206 03:53:45.300674       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/gvw9 491\nI0206 03:53:45.500673       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/k4s 535\nI0206 03:53:45.700682       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/2dc5 256\nI0206 03:53:45.900609       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/hfj 580\nI0206 03:53:46.100696       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/gnzl 586\nI0206 03:53:46.300617       1 logs_generator.go:76] 13 POST /api/v1/namespaces/default/pods/4bh 330\nI0206 03:53:46.500687       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/rgj 535\nI0206 03:53:46.700614       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/899f 327\nI0206 03:53:46.900605       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/h8c 232\nI0206 03:53:47.100647       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/q42l 246\nI0206 03:53:47.300690       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/4nwp 572\nI0206 03:53:47.500606       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/tsp4 560\nI0206 03:53:47.700670       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/x84 375\nI0206 03:53:47.900595       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/ftb 276\nI0206 03:53:48.100611       1 logs_generator.go:76] 22 GET /api/v1/namespaces/kube-system/pods/mg7b 243\nI0206 03:53:48.300633       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/w57g 450\nI0206 03:53:48.500612       1 logs_generator.go:76] 24 POST /api/v1/namespaces/default/pods/lkhn 328\nI0206 03:53:48.700592       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/default/pods/nwqd 284\nI0206 03:53:48.900628       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/hfn 391\nI0206 03:53:49.100661       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/9bcc 220\nI0206 03:53:49.300694       1 logs_generator.go:76] 28 GET /api/v1/namespaces/default/pods/hqct 273\nI0206 03:53:49.500608       1 logs_generator.go:76] 29 POST /api/v1/namespaces/default/pods/4sh 341\nI0206 03:53:49.700658       1 logs_generator.go:76] 30 GET /api/v1/namespaces/kube-system/pods/shpr 579\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Feb  6 03:53:49.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete pod logs-generator --namespace=kubectl-8600'
Feb  6 03:53:53.350: INFO: stderr: ""
Feb  6 03:53:53.350: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:53:53.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8600" for this suite.
Feb  6 03:53:59.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:53:59.408: INFO: namespace kubectl-8600 deletion completed in 6.05494374s

• [SLOW TEST:17.041 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:53:59.408: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1812
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb  6 03:53:59.534: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:54:03.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1812" for this suite.
Feb  6 03:54:09.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:54:09.263: INFO: namespace init-container-1812 deletion completed in 6.077035742s

• [SLOW TEST:9.855 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:54:09.263: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7295
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  6 03:54:15.421: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:54:15.423: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:54:17.423: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:54:17.426: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:54:19.423: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:54:19.426: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:54:19.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7295" for this suite.
Feb  6 03:54:31.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:54:31.493: INFO: namespace container-lifecycle-hook-7295 deletion completed in 12.055087127s

• [SLOW TEST:22.230 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:54:31.494: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3062
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-de009d2a-0d64-4ff8-b931-ef9900edab16
STEP: Creating configMap with name cm-test-opt-upd-f8ea55fe-4ec5-4a82-9856-14691aa379ac
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-de009d2a-0d64-4ff8-b931-ef9900edab16
STEP: Updating configmap cm-test-opt-upd-f8ea55fe-4ec5-4a82-9856-14691aa379ac
STEP: Creating configMap with name cm-test-opt-create-9df0ac68-3cbb-48a4-b9cc-a92438452bef
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:55:51.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3062" for this suite.
Feb  6 03:56:03.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:56:03.988: INFO: namespace projected-3062 deletion completed in 12.055127736s

• [SLOW TEST:92.495 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:56:03.989: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5459
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 03:56:04.116: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Feb  6 03:56:05.138: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:56:05.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5459" for this suite.
Feb  6 03:56:11.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:56:11.202: INFO: namespace replication-controller-5459 deletion completed in 6.059604562s

• [SLOW TEST:7.213 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:56:11.202: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 03:56:11.967: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb  6 03:56:13.973: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558171, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558171, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558171, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558171, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:56:15.975: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558171, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558171, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558171, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558171, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 03:56:18.980: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:56:18.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-709" for this suite.
Feb  6 03:56:24.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:56:25.046: INFO: namespace webhook-709 deletion completed in 6.059149024s
STEP: Destroying namespace "webhook-709-markers" for this suite.
Feb  6 03:56:31.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:56:31.153: INFO: namespace webhook-709-markers deletion completed in 6.107517011s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.958 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:56:31.161: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-302
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 03:56:31.288: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-f2c9aac5-d308-4d4f-b6aa-855da6bacad5" in namespace "security-context-test-302" to be "success or failure"
Feb  6 03:56:31.291: INFO: Pod "busybox-readonly-false-f2c9aac5-d308-4d4f-b6aa-855da6bacad5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.001447ms
Feb  6 03:56:33.293: INFO: Pod "busybox-readonly-false-f2c9aac5-d308-4d4f-b6aa-855da6bacad5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005182697s
Feb  6 03:56:33.293: INFO: Pod "busybox-readonly-false-f2c9aac5-d308-4d4f-b6aa-855da6bacad5" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:56:33.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-302" for this suite.
Feb  6 03:56:39.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:56:39.352: INFO: namespace security-context-test-302 deletion completed in 6.056794383s

• [SLOW TEST:8.192 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:56:39.352: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8919
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-51562133-5712-4686-bdd3-99e3cd150cf9
STEP: Creating a pod to test consume secrets
Feb  6 03:56:39.483: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-700e2917-2a35-4102-9154-046fa427db5e" in namespace "projected-8919" to be "success or failure"
Feb  6 03:56:39.486: INFO: Pod "pod-projected-secrets-700e2917-2a35-4102-9154-046fa427db5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.374348ms
Feb  6 03:56:41.488: INFO: Pod "pod-projected-secrets-700e2917-2a35-4102-9154-046fa427db5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004883784s
STEP: Saw pod success
Feb  6 03:56:41.488: INFO: Pod "pod-projected-secrets-700e2917-2a35-4102-9154-046fa427db5e" satisfied condition "success or failure"
Feb  6 03:56:41.490: INFO: Trying to get logs from node aks-1-4 pod pod-projected-secrets-700e2917-2a35-4102-9154-046fa427db5e container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 03:56:41.504: INFO: Waiting for pod pod-projected-secrets-700e2917-2a35-4102-9154-046fa427db5e to disappear
Feb  6 03:56:41.505: INFO: Pod pod-projected-secrets-700e2917-2a35-4102-9154-046fa427db5e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:56:41.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8919" for this suite.
Feb  6 03:56:47.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:56:47.561: INFO: namespace projected-8919 deletion completed in 6.053753294s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:56:47.561: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-688ab757-7bf4-4c9f-8670-b6dca88a2ca4
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:56:47.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8541" for this suite.
Feb  6 03:56:53.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:56:53.749: INFO: namespace configmap-8541 deletion completed in 6.05389946s

• [SLOW TEST:6.188 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:56:53.749: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2497
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 03:56:53.873: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:56:54.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2497" for this suite.
Feb  6 03:57:00.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:57:00.949: INFO: namespace custom-resource-definition-2497 deletion completed in 6.058824407s

• [SLOW TEST:7.200 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:57:00.950: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6299
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 03:57:01.466: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb  6 03:57:03.472: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558221, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558221, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558221, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558221, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 03:57:06.479: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 03:57:06.482: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4331-crds.webhook.example.com via the AdmissionRegistration API
Feb  6 03:57:07.081: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:57:07.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6299" for this suite.
Feb  6 03:57:13.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:57:13.909: INFO: namespace webhook-6299 deletion completed in 6.052958491s
STEP: Destroying namespace "webhook-6299-markers" for this suite.
Feb  6 03:57:19.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:57:19.966: INFO: namespace webhook-6299-markers deletion completed in 6.056638406s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.023 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:57:19.974: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2679
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-e11bc96f-303d-4d11-8495-e7b5b1e154dc
STEP: Creating a pod to test consume secrets
Feb  6 03:57:20.105: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-03156350-6d34-40fd-b66f-71ef759012ae" in namespace "projected-2679" to be "success or failure"
Feb  6 03:57:20.108: INFO: Pod "pod-projected-secrets-03156350-6d34-40fd-b66f-71ef759012ae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.801107ms
Feb  6 03:57:22.111: INFO: Pod "pod-projected-secrets-03156350-6d34-40fd-b66f-71ef759012ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00604074s
STEP: Saw pod success
Feb  6 03:57:22.111: INFO: Pod "pod-projected-secrets-03156350-6d34-40fd-b66f-71ef759012ae" satisfied condition "success or failure"
Feb  6 03:57:22.112: INFO: Trying to get logs from node aks-1-3 pod pod-projected-secrets-03156350-6d34-40fd-b66f-71ef759012ae container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 03:57:22.128: INFO: Waiting for pod pod-projected-secrets-03156350-6d34-40fd-b66f-71ef759012ae to disappear
Feb  6 03:57:22.130: INFO: Pod pod-projected-secrets-03156350-6d34-40fd-b66f-71ef759012ae no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:57:22.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2679" for this suite.
Feb  6 03:57:28.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:57:28.186: INFO: namespace projected-2679 deletion completed in 6.054095911s

• [SLOW TEST:8.213 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:57:28.186: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3342
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Feb  6 03:57:30.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec pod-sharedvolume-0d1ce64e-aaa6-43d5-b461-a9444afc7787 -c busybox-main-container --namespace=emptydir-3342 -- cat /usr/share/volumeshare/shareddata.txt'
Feb  6 03:57:30.523: INFO: stderr: ""
Feb  6 03:57:30.523: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:57:30.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3342" for this suite.
Feb  6 03:57:36.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:57:36.584: INFO: namespace emptydir-3342 deletion completed in 6.058106743s

• [SLOW TEST:8.398 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:57:36.585: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9119
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb  6 03:57:36.714: INFO: Waiting up to 5m0s for pod "downward-api-8f0ba4cf-0d6c-4eb3-96be-bf4cd198bad3" in namespace "downward-api-9119" to be "success or failure"
Feb  6 03:57:36.716: INFO: Pod "downward-api-8f0ba4cf-0d6c-4eb3-96be-bf4cd198bad3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.595191ms
Feb  6 03:57:38.719: INFO: Pod "downward-api-8f0ba4cf-0d6c-4eb3-96be-bf4cd198bad3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00481304s
Feb  6 03:57:40.721: INFO: Pod "downward-api-8f0ba4cf-0d6c-4eb3-96be-bf4cd198bad3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007151725s
STEP: Saw pod success
Feb  6 03:57:40.721: INFO: Pod "downward-api-8f0ba4cf-0d6c-4eb3-96be-bf4cd198bad3" satisfied condition "success or failure"
Feb  6 03:57:40.723: INFO: Trying to get logs from node aks-1-3 pod downward-api-8f0ba4cf-0d6c-4eb3-96be-bf4cd198bad3 container dapi-container: <nil>
STEP: delete the pod
Feb  6 03:57:40.734: INFO: Waiting for pod downward-api-8f0ba4cf-0d6c-4eb3-96be-bf4cd198bad3 to disappear
Feb  6 03:57:40.737: INFO: Pod downward-api-8f0ba4cf-0d6c-4eb3-96be-bf4cd198bad3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:57:40.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9119" for this suite.
Feb  6 03:57:46.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:57:46.795: INFO: namespace downward-api-9119 deletion completed in 6.05573346s

• [SLOW TEST:10.210 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:57:46.795: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-389
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb  6 03:57:46.929: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-389 /api/v1/namespaces/watch-389/configmaps/e2e-watch-test-watch-closed a5c78dae-f2e7-4861-8a30-f55d4fe34f9c 1789149 0 2020-02-06 03:57:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 03:57:46.929: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-389 /api/v1/namespaces/watch-389/configmaps/e2e-watch-test-watch-closed a5c78dae-f2e7-4861-8a30-f55d4fe34f9c 1789150 0 2020-02-06 03:57:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb  6 03:57:46.936: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-389 /api/v1/namespaces/watch-389/configmaps/e2e-watch-test-watch-closed a5c78dae-f2e7-4861-8a30-f55d4fe34f9c 1789151 0 2020-02-06 03:57:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 03:57:46.937: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-389 /api/v1/namespaces/watch-389/configmaps/e2e-watch-test-watch-closed a5c78dae-f2e7-4861-8a30-f55d4fe34f9c 1789152 0 2020-02-06 03:57:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:57:46.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-389" for this suite.
Feb  6 03:57:52.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:57:52.995: INFO: namespace watch-389 deletion completed in 6.056095354s

• [SLOW TEST:6.200 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:57:52.995: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9892
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:57:57.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9892" for this suite.
Feb  6 03:58:03.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:58:03.200: INFO: namespace kubelet-test-9892 deletion completed in 6.066400439s

• [SLOW TEST:10.205 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:58:03.201: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-297
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:58:05.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-297" for this suite.
Feb  6 03:58:11.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:58:11.417: INFO: namespace emptydir-wrapper-297 deletion completed in 6.053926481s

• [SLOW TEST:8.216 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:58:11.417: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8032
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0206 03:58:12.624033      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 03:58:12.624: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:58:12.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8032" for this suite.
Feb  6 03:58:18.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:58:18.707: INFO: namespace gc-8032 deletion completed in 6.081011255s

• [SLOW TEST:7.290 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:58:18.707: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1609
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb  6 03:58:18.833: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 03:58:18.839: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 03:58:18.841: INFO: 
Logging pods the kubelet thinks is on node aks-1-2 before test
Feb  6 03:58:18.850: INFO: sonobuoy-e2e-job-29ae3d20e67a4412 from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:58:18.850: INFO: 	Container e2e ready: true, restart count 0
Feb  6 03:58:18.850: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:58:18.850: INFO: nginx-ktsbf from default started at 2020-02-06 03:27:31 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.850: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:58:18.850: INFO: kube-flannel-ds-amd64-kln2x from kube-system started at 2020-02-05 11:48:51 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.850: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 03:58:18.850: INFO: sonobuoy from sonobuoy started at 2020-02-06 03:24:46 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.850: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 03:58:18.850: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-lrnrn from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:58:18.850: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:58:18.850: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 03:58:18.850: INFO: coredns-7f6cddc944-qsgx4 from kube-system started at 2020-02-05 13:54:41 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.850: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:58:18.850: INFO: nginx-m679w from default started at 2020-02-06 03:30:04 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.850: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:58:18.850: INFO: nginx-xc4tj from default started at 2020-02-06 03:27:31 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.850: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:58:18.850: INFO: nginx-vnn6h from default started at 2020-02-06 03:27:28 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.850: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:58:18.850: INFO: nginx-k4j64 from default started at 2020-02-06 03:27:29 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.850: INFO: 	Container nginx ready: true, restart count 0
Feb  6 03:58:18.850: INFO: 
Logging pods the kubelet thinks is on node aks-1-3 before test
Feb  6 03:58:18.854: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-kwwvw from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:58:18.854: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:58:18.854: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 03:58:18.854: INFO: kube-flannel-ds-amd64-tkhv8 from kube-system started at 2020-02-05 07:36:26 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.854: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 03:58:18.854: INFO: coredns-7f6cddc944-v22mw from kube-system started at 2020-02-05 08:48:34 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.854: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:58:18.854: INFO: coredns-7f6cddc944-99f6c from kube-system started at 2020-02-05 13:54:41 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.854: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:58:18.854: INFO: 
Logging pods the kubelet thinks is on node aks-1-4 before test
Feb  6 03:58:18.862: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-7z6kz from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 03:58:18.862: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:58:18.862: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 03:58:18.862: INFO: coredns-7f6cddc944-w6w2z from kube-system started at 2020-02-03 03:59:20 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.862: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:58:18.862: INFO: kube-flannel-ds-amd64-plfph from kube-system started at 2020-02-04 14:20:52 +0000 UTC (1 container statuses recorded)
Feb  6 03:58:18.862: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-026160cc-ac9f-41c8-8b57-61bc4120cdfc 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-026160cc-ac9f-41c8-8b57-61bc4120cdfc off the node aks-1-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-026160cc-ac9f-41c8-8b57-61bc4120cdfc
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:58:26.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1609" for this suite.
Feb  6 03:58:44.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:58:44.984: INFO: namespace sched-pred-1609 deletion completed in 18.057620269s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:26.277 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:58:44.985: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4241
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:58:45.115: INFO: Waiting up to 5m0s for pod "downwardapi-volume-20cd7ae8-fc3a-4031-9c70-f96aa2e6d338" in namespace "projected-4241" to be "success or failure"
Feb  6 03:58:45.118: INFO: Pod "downwardapi-volume-20cd7ae8-fc3a-4031-9c70-f96aa2e6d338": Phase="Pending", Reason="", readiness=false. Elapsed: 3.116036ms
Feb  6 03:58:47.120: INFO: Pod "downwardapi-volume-20cd7ae8-fc3a-4031-9c70-f96aa2e6d338": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005553539s
STEP: Saw pod success
Feb  6 03:58:47.120: INFO: Pod "downwardapi-volume-20cd7ae8-fc3a-4031-9c70-f96aa2e6d338" satisfied condition "success or failure"
Feb  6 03:58:47.122: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-20cd7ae8-fc3a-4031-9c70-f96aa2e6d338 container client-container: <nil>
STEP: delete the pod
Feb  6 03:58:47.133: INFO: Waiting for pod downwardapi-volume-20cd7ae8-fc3a-4031-9c70-f96aa2e6d338 to disappear
Feb  6 03:58:47.134: INFO: Pod downwardapi-volume-20cd7ae8-fc3a-4031-9c70-f96aa2e6d338 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:58:47.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4241" for this suite.
Feb  6 03:58:53.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:58:53.194: INFO: namespace projected-4241 deletion completed in 6.057911437s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:58:53.195: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6954
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 03:58:53.325: INFO: (0) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 4.737769ms)
Feb  6 03:58:53.327: INFO: (1) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.909843ms)
Feb  6 03:58:53.329: INFO: (2) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 2.020134ms)
Feb  6 03:58:53.331: INFO: (3) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.952227ms)
Feb  6 03:58:53.333: INFO: (4) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.945811ms)
Feb  6 03:58:53.335: INFO: (5) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.870657ms)
Feb  6 03:58:53.337: INFO: (6) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.986951ms)
Feb  6 03:58:53.339: INFO: (7) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.832529ms)
Feb  6 03:58:53.341: INFO: (8) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.916712ms)
Feb  6 03:58:53.343: INFO: (9) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 2.077417ms)
Feb  6 03:58:53.345: INFO: (10) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.902714ms)
Feb  6 03:58:53.347: INFO: (11) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.796262ms)
Feb  6 03:58:53.349: INFO: (12) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 2.014308ms)
Feb  6 03:58:53.350: INFO: (13) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.827204ms)
Feb  6 03:58:53.352: INFO: (14) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.834657ms)
Feb  6 03:58:53.354: INFO: (15) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.942942ms)
Feb  6 03:58:53.356: INFO: (16) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 2.06347ms)
Feb  6 03:58:53.358: INFO: (17) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.871905ms)
Feb  6 03:58:53.360: INFO: (18) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.96845ms)
Feb  6 03:58:53.362: INFO: (19) /api/v1/nodes/aks-1-2/proxy/logs/: <pre>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href="btmp-20200201">btmp-202002... (200; 1.886763ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:58:53.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6954" for this suite.
Feb  6 03:58:59.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:58:59.418: INFO: namespace proxy-6954 deletion completed in 6.053965294s

• [SLOW TEST:6.224 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:58:59.419: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8456
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-0b0f1b3f-37ef-4571-9164-778fc60b7520
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:59:01.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8456" for this suite.
Feb  6 03:59:15.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:59:15.626: INFO: namespace configmap-8456 deletion completed in 14.052224285s

• [SLOW TEST:16.208 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:59:15.626: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3875
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a6c875ae-7a34-476f-9faf-e228a5e94033
STEP: Creating a pod to test consume secrets
Feb  6 03:59:15.762: INFO: Waiting up to 5m0s for pod "pod-secrets-3367e2e1-cc53-4082-be7c-e6f2eca258c5" in namespace "secrets-3875" to be "success or failure"
Feb  6 03:59:15.766: INFO: Pod "pod-secrets-3367e2e1-cc53-4082-be7c-e6f2eca258c5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.698214ms
Feb  6 03:59:17.768: INFO: Pod "pod-secrets-3367e2e1-cc53-4082-be7c-e6f2eca258c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006005511s
STEP: Saw pod success
Feb  6 03:59:17.768: INFO: Pod "pod-secrets-3367e2e1-cc53-4082-be7c-e6f2eca258c5" satisfied condition "success or failure"
Feb  6 03:59:17.770: INFO: Trying to get logs from node aks-1-3 pod pod-secrets-3367e2e1-cc53-4082-be7c-e6f2eca258c5 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 03:59:17.780: INFO: Waiting for pod pod-secrets-3367e2e1-cc53-4082-be7c-e6f2eca258c5 to disappear
Feb  6 03:59:17.782: INFO: Pod pod-secrets-3367e2e1-cc53-4082-be7c-e6f2eca258c5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:59:17.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3875" for this suite.
Feb  6 03:59:23.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:59:23.842: INFO: namespace secrets-3875 deletion completed in 6.057847049s

• [SLOW TEST:8.216 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:59:23.842: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6238
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Feb  6 03:59:23.971: INFO: Waiting up to 5m0s for pod "client-containers-495277b7-ecf9-403f-98d8-7dd301db4b9e" in namespace "containers-6238" to be "success or failure"
Feb  6 03:59:23.972: INFO: Pod "client-containers-495277b7-ecf9-403f-98d8-7dd301db4b9e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.457626ms
Feb  6 03:59:25.975: INFO: Pod "client-containers-495277b7-ecf9-403f-98d8-7dd301db4b9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004614511s
STEP: Saw pod success
Feb  6 03:59:25.976: INFO: Pod "client-containers-495277b7-ecf9-403f-98d8-7dd301db4b9e" satisfied condition "success or failure"
Feb  6 03:59:25.978: INFO: Trying to get logs from node aks-1-4 pod client-containers-495277b7-ecf9-403f-98d8-7dd301db4b9e container test-container: <nil>
STEP: delete the pod
Feb  6 03:59:25.991: INFO: Waiting for pod client-containers-495277b7-ecf9-403f-98d8-7dd301db4b9e to disappear
Feb  6 03:59:25.993: INFO: Pod client-containers-495277b7-ecf9-403f-98d8-7dd301db4b9e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:59:25.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6238" for this suite.
Feb  6 03:59:32.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:59:32.053: INFO: namespace containers-6238 deletion completed in 6.057589261s

• [SLOW TEST:8.211 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:59:32.054: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2719
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8858
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7499
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:59:45.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2719" for this suite.
Feb  6 03:59:51.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:59:51.549: INFO: namespace namespaces-2719 deletion completed in 6.054393854s
STEP: Destroying namespace "nsdeletetest-8858" for this suite.
Feb  6 03:59:51.550: INFO: Namespace nsdeletetest-8858 was already deleted
STEP: Destroying namespace "nsdeletetest-7499" for this suite.
Feb  6 03:59:57.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:59:57.606: INFO: namespace nsdeletetest-7499 deletion completed in 6.055384364s

• [SLOW TEST:25.552 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 03:59:57.606: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5863
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:59:57.737: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c38a06b3-b9a4-45b2-9daf-6db3d65163b6" in namespace "projected-5863" to be "success or failure"
Feb  6 03:59:57.743: INFO: Pod "downwardapi-volume-c38a06b3-b9a4-45b2-9daf-6db3d65163b6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.704549ms
Feb  6 03:59:59.746: INFO: Pod "downwardapi-volume-c38a06b3-b9a4-45b2-9daf-6db3d65163b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009365207s
STEP: Saw pod success
Feb  6 03:59:59.746: INFO: Pod "downwardapi-volume-c38a06b3-b9a4-45b2-9daf-6db3d65163b6" satisfied condition "success or failure"
Feb  6 03:59:59.748: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-c38a06b3-b9a4-45b2-9daf-6db3d65163b6 container client-container: <nil>
STEP: delete the pod
Feb  6 03:59:59.763: INFO: Waiting for pod downwardapi-volume-c38a06b3-b9a4-45b2-9daf-6db3d65163b6 to disappear
Feb  6 03:59:59.766: INFO: Pod downwardapi-volume-c38a06b3-b9a4-45b2-9daf-6db3d65163b6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 03:59:59.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5863" for this suite.
Feb  6 04:00:05.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:00:05.829: INFO: namespace projected-5863 deletion completed in 6.060637254s

• [SLOW TEST:8.223 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:00:05.829: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-737
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Feb  6 04:00:06.469: INFO: created pod pod-service-account-defaultsa
Feb  6 04:00:06.469: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb  6 04:00:06.474: INFO: created pod pod-service-account-mountsa
Feb  6 04:00:06.474: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb  6 04:00:06.480: INFO: created pod pod-service-account-nomountsa
Feb  6 04:00:06.480: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb  6 04:00:06.486: INFO: created pod pod-service-account-defaultsa-mountspec
Feb  6 04:00:06.486: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb  6 04:00:06.492: INFO: created pod pod-service-account-mountsa-mountspec
Feb  6 04:00:06.492: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb  6 04:00:06.502: INFO: created pod pod-service-account-nomountsa-mountspec
Feb  6 04:00:06.502: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb  6 04:00:06.509: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb  6 04:00:06.509: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb  6 04:00:06.514: INFO: created pod pod-service-account-mountsa-nomountspec
Feb  6 04:00:06.514: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb  6 04:00:06.525: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb  6 04:00:06.525: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:00:06.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-737" for this suite.
Feb  6 04:00:12.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:00:12.605: INFO: namespace svcaccounts-737 deletion completed in 6.07377066s

• [SLOW TEST:6.775 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:00:12.605: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1642
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-1642
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1642 to expose endpoints map[]
Feb  6 04:00:12.747: INFO: Get endpoints failed (2.402152ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb  6 04:00:13.750: INFO: successfully validated that service multi-endpoint-test in namespace services-1642 exposes endpoints map[] (1.004595149s elapsed)
STEP: Creating pod pod1 in namespace services-1642
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1642 to expose endpoints map[pod1:[100]]
Feb  6 04:00:15.767: INFO: successfully validated that service multi-endpoint-test in namespace services-1642 exposes endpoints map[pod1:[100]] (2.014163011s elapsed)
STEP: Creating pod pod2 in namespace services-1642
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1642 to expose endpoints map[pod1:[100] pod2:[101]]
Feb  6 04:00:17.788: INFO: successfully validated that service multi-endpoint-test in namespace services-1642 exposes endpoints map[pod1:[100] pod2:[101]] (2.015612865s elapsed)
STEP: Deleting pod pod1 in namespace services-1642
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1642 to expose endpoints map[pod2:[101]]
Feb  6 04:00:17.802: INFO: successfully validated that service multi-endpoint-test in namespace services-1642 exposes endpoints map[pod2:[101]] (11.077919ms elapsed)
STEP: Deleting pod pod2 in namespace services-1642
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1642 to expose endpoints map[]
Feb  6 04:00:18.818: INFO: successfully validated that service multi-endpoint-test in namespace services-1642 exposes endpoints map[] (1.011092336s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:00:18.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1642" for this suite.
Feb  6 04:00:46.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:00:46.913: INFO: namespace services-1642 deletion completed in 28.056928284s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:34.308 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:00:46.914: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8814
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-6wcp
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 04:00:47.052: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-6wcp" in namespace "subpath-8814" to be "success or failure"
Feb  6 04:00:47.056: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Pending", Reason="", readiness=false. Elapsed: 3.708649ms
Feb  6 04:00:49.058: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Running", Reason="", readiness=true. Elapsed: 2.006176662s
Feb  6 04:00:51.061: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Running", Reason="", readiness=true. Elapsed: 4.008505951s
Feb  6 04:00:53.063: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Running", Reason="", readiness=true. Elapsed: 6.010882626s
Feb  6 04:00:55.066: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Running", Reason="", readiness=true. Elapsed: 8.01328084s
Feb  6 04:00:57.068: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Running", Reason="", readiness=true. Elapsed: 10.015605356s
Feb  6 04:00:59.070: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Running", Reason="", readiness=true. Elapsed: 12.017934381s
Feb  6 04:01:01.073: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Running", Reason="", readiness=true. Elapsed: 14.020289358s
Feb  6 04:01:03.075: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Running", Reason="", readiness=true. Elapsed: 16.022771272s
Feb  6 04:01:05.078: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Running", Reason="", readiness=true. Elapsed: 18.025367265s
Feb  6 04:01:07.080: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Running", Reason="", readiness=true. Elapsed: 20.027853779s
Feb  6 04:01:09.088: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Running", Reason="", readiness=true. Elapsed: 22.035661138s
Feb  6 04:01:11.090: INFO: Pod "pod-subpath-test-projected-6wcp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.038160571s
STEP: Saw pod success
Feb  6 04:01:11.090: INFO: Pod "pod-subpath-test-projected-6wcp" satisfied condition "success or failure"
Feb  6 04:01:11.092: INFO: Trying to get logs from node aks-1-4 pod pod-subpath-test-projected-6wcp container test-container-subpath-projected-6wcp: <nil>
STEP: delete the pod
Feb  6 04:01:11.106: INFO: Waiting for pod pod-subpath-test-projected-6wcp to disappear
Feb  6 04:01:11.108: INFO: Pod pod-subpath-test-projected-6wcp no longer exists
STEP: Deleting pod pod-subpath-test-projected-6wcp
Feb  6 04:01:11.108: INFO: Deleting pod "pod-subpath-test-projected-6wcp" in namespace "subpath-8814"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:01:11.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8814" for this suite.
Feb  6 04:01:17.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:01:17.164: INFO: namespace subpath-8814 deletion completed in 6.053280553s

• [SLOW TEST:30.251 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:01:17.165: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5228
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb  6 04:01:17.289: INFO: namespace kubectl-5228
Feb  6 04:01:17.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-5228'
Feb  6 04:01:17.764: INFO: stderr: ""
Feb  6 04:01:17.765: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 04:01:18.767: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:01:18.767: INFO: Found 0 / 1
Feb  6 04:01:19.767: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:01:19.767: INFO: Found 0 / 1
Feb  6 04:01:20.767: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:01:20.768: INFO: Found 0 / 1
Feb  6 04:01:21.767: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:01:21.767: INFO: Found 0 / 1
Feb  6 04:01:22.767: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:01:22.767: INFO: Found 0 / 1
Feb  6 04:01:23.767: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:01:23.767: INFO: Found 0 / 1
Feb  6 04:01:24.767: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:01:24.767: INFO: Found 0 / 1
Feb  6 04:01:25.767: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:01:25.767: INFO: Found 0 / 1
Feb  6 04:01:26.767: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:01:26.767: INFO: Found 1 / 1
Feb  6 04:01:26.767: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  6 04:01:26.769: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:01:26.769: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 04:01:26.769: INFO: wait on redis-master startup in kubectl-5228 
Feb  6 04:01:26.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 logs redis-master-lxhxk redis-master --namespace=kubectl-5228'
Feb  6 04:01:26.867: INFO: stderr: ""
Feb  6 04:01:26.867: INFO: stdout: "1:C 06 Feb 2020 04:01:25.851 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 06 Feb 2020 04:01:25.851 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 06 Feb 2020 04:01:25.851 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 06 Feb 2020 04:01:25.853 * Running mode=standalone, port=6379.\n1:M 06 Feb 2020 04:01:25.853 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Feb 2020 04:01:25.853 # Server initialized\n1:M 06 Feb 2020 04:01:25.853 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Feb 2020 04:01:25.853 * Ready to accept connections\n"
STEP: exposing RC
Feb  6 04:01:26.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5228'
Feb  6 04:01:26.971: INFO: stderr: ""
Feb  6 04:01:26.971: INFO: stdout: "service/rm2 exposed\n"
Feb  6 04:01:26.974: INFO: Service rm2 in namespace kubectl-5228 found.
STEP: exposing service
Feb  6 04:01:28.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5228'
Feb  6 04:01:29.085: INFO: stderr: ""
Feb  6 04:01:29.085: INFO: stdout: "service/rm3 exposed\n"
Feb  6 04:01:29.100: INFO: Service rm3 in namespace kubectl-5228 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:01:31.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5228" for this suite.
Feb  6 04:01:59.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:01:59.164: INFO: namespace kubectl-5228 deletion completed in 28.056143506s

• [SLOW TEST:41.999 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:01:59.164: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5832
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb  6 04:01:59.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-5832'
Feb  6 04:01:59.495: INFO: stderr: ""
Feb  6 04:01:59.495: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 04:01:59.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5832'
Feb  6 04:01:59.608: INFO: stderr: ""
Feb  6 04:01:59.608: INFO: stdout: "update-demo-nautilus-c9mhc update-demo-nautilus-pmw6t "
Feb  6 04:01:59.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-c9mhc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5832'
Feb  6 04:01:59.690: INFO: stderr: ""
Feb  6 04:01:59.690: INFO: stdout: ""
Feb  6 04:01:59.690: INFO: update-demo-nautilus-c9mhc is created but not running
Feb  6 04:02:04.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5832'
Feb  6 04:02:04.782: INFO: stderr: ""
Feb  6 04:02:04.782: INFO: stdout: "update-demo-nautilus-c9mhc update-demo-nautilus-pmw6t "
Feb  6 04:02:04.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-c9mhc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5832'
Feb  6 04:02:04.871: INFO: stderr: ""
Feb  6 04:02:04.871: INFO: stdout: "true"
Feb  6 04:02:04.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-c9mhc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5832'
Feb  6 04:02:04.961: INFO: stderr: ""
Feb  6 04:02:04.961: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 04:02:04.961: INFO: validating pod update-demo-nautilus-c9mhc
Feb  6 04:02:04.964: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 04:02:04.964: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 04:02:04.964: INFO: update-demo-nautilus-c9mhc is verified up and running
Feb  6 04:02:04.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-pmw6t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5832'
Feb  6 04:02:05.057: INFO: stderr: ""
Feb  6 04:02:05.057: INFO: stdout: "true"
Feb  6 04:02:05.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-pmw6t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5832'
Feb  6 04:02:05.153: INFO: stderr: ""
Feb  6 04:02:05.153: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 04:02:05.153: INFO: validating pod update-demo-nautilus-pmw6t
Feb  6 04:02:05.157: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 04:02:05.157: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 04:02:05.157: INFO: update-demo-nautilus-pmw6t is verified up and running
STEP: using delete to clean up resources
Feb  6 04:02:05.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete --grace-period=0 --force -f - --namespace=kubectl-5832'
Feb  6 04:02:05.246: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 04:02:05.246: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  6 04:02:05.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5832'
Feb  6 04:02:05.350: INFO: stderr: "No resources found in kubectl-5832 namespace.\n"
Feb  6 04:02:05.350: INFO: stdout: ""
Feb  6 04:02:05.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -l name=update-demo --namespace=kubectl-5832 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 04:02:05.444: INFO: stderr: ""
Feb  6 04:02:05.444: INFO: stdout: "update-demo-nautilus-c9mhc\nupdate-demo-nautilus-pmw6t\n"
Feb  6 04:02:05.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5832'
Feb  6 04:02:06.040: INFO: stderr: "No resources found in kubectl-5832 namespace.\n"
Feb  6 04:02:06.040: INFO: stdout: ""
Feb  6 04:02:06.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -l name=update-demo --namespace=kubectl-5832 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 04:02:06.148: INFO: stderr: ""
Feb  6 04:02:06.148: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:02:06.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5832" for this suite.
Feb  6 04:02:34.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:02:34.214: INFO: namespace kubectl-5832 deletion completed in 28.062813763s

• [SLOW TEST:35.049 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:02:34.215: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2555
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-6cfa543d-a70b-494e-967f-5af17a5bf2d7 in namespace container-probe-2555
Feb  6 04:02:36.349: INFO: Started pod liveness-6cfa543d-a70b-494e-967f-5af17a5bf2d7 in namespace container-probe-2555
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 04:02:36.350: INFO: Initial restart count of pod liveness-6cfa543d-a70b-494e-967f-5af17a5bf2d7 is 0
Feb  6 04:02:56.379: INFO: Restart count of pod container-probe-2555/liveness-6cfa543d-a70b-494e-967f-5af17a5bf2d7 is now 1 (20.029080772s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:02:56.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2555" for this suite.
Feb  6 04:03:02.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:03:02.444: INFO: namespace container-probe-2555 deletion completed in 6.055447931s

• [SLOW TEST:28.230 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:03:02.444: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5356
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  6 04:03:02.578: INFO: Waiting up to 5m0s for pod "pod-a5527fcb-be1c-40ec-8e94-af236ccd7cf2" in namespace "emptydir-5356" to be "success or failure"
Feb  6 04:03:02.581: INFO: Pod "pod-a5527fcb-be1c-40ec-8e94-af236ccd7cf2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.851544ms
Feb  6 04:03:04.584: INFO: Pod "pod-a5527fcb-be1c-40ec-8e94-af236ccd7cf2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005829953s
Feb  6 04:03:06.586: INFO: Pod "pod-a5527fcb-be1c-40ec-8e94-af236ccd7cf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008055453s
STEP: Saw pod success
Feb  6 04:03:06.586: INFO: Pod "pod-a5527fcb-be1c-40ec-8e94-af236ccd7cf2" satisfied condition "success or failure"
Feb  6 04:03:06.588: INFO: Trying to get logs from node aks-1-3 pod pod-a5527fcb-be1c-40ec-8e94-af236ccd7cf2 container test-container: <nil>
STEP: delete the pod
Feb  6 04:03:06.614: INFO: Waiting for pod pod-a5527fcb-be1c-40ec-8e94-af236ccd7cf2 to disappear
Feb  6 04:03:06.615: INFO: Pod pod-a5527fcb-be1c-40ec-8e94-af236ccd7cf2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:03:06.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5356" for this suite.
Feb  6 04:03:12.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:03:12.677: INFO: namespace emptydir-5356 deletion completed in 6.059782999s

• [SLOW TEST:10.233 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:03:12.678: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2433
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:03:12.859: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:03:19.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2433" for this suite.
Feb  6 04:03:25.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:03:25.401: INFO: namespace custom-resource-definition-2433 deletion completed in 6.05733521s

• [SLOW TEST:12.724 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:03:25.402: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-462
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:03:25.582: INFO: Creating ReplicaSet my-hostname-basic-f5b74748-3afe-46c7-99df-d02a2b104682
Feb  6 04:03:25.589: INFO: Pod name my-hostname-basic-f5b74748-3afe-46c7-99df-d02a2b104682: Found 0 pods out of 1
Feb  6 04:03:30.592: INFO: Pod name my-hostname-basic-f5b74748-3afe-46c7-99df-d02a2b104682: Found 1 pods out of 1
Feb  6 04:03:30.592: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f5b74748-3afe-46c7-99df-d02a2b104682" is running
Feb  6 04:03:30.593: INFO: Pod "my-hostname-basic-f5b74748-3afe-46c7-99df-d02a2b104682-6tcwl" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 04:03:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 04:03:26 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 04:03:26 +0000 UTC Reason: Message:} {Type:ContainerDiskPressure Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 04:03:25 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 04:03:25 +0000 UTC Reason: Message:}])
Feb  6 04:03:30.593: INFO: Trying to dial the pod
Feb  6 04:03:35.600: INFO: Controller my-hostname-basic-f5b74748-3afe-46c7-99df-d02a2b104682: Got expected result from replica 1 [my-hostname-basic-f5b74748-3afe-46c7-99df-d02a2b104682-6tcwl]: "my-hostname-basic-f5b74748-3afe-46c7-99df-d02a2b104682-6tcwl", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:03:35.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-462" for this suite.
Feb  6 04:03:41.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:03:41.660: INFO: namespace replicaset-462 deletion completed in 6.058081669s

• [SLOW TEST:16.258 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:03:41.661: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5367
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb  6 04:03:41.786: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:04:04.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5367" for this suite.
Feb  6 04:04:10.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:04:10.210: INFO: namespace crd-publish-openapi-5367 deletion completed in 6.054319701s

• [SLOW TEST:28.549 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:04:10.210: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5862
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 04:04:10.867: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 04:04:13.884: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:04:13.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5862" for this suite.
Feb  6 04:04:25.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:04:25.976: INFO: namespace webhook-5862 deletion completed in 12.054344611s
STEP: Destroying namespace "webhook-5862-markers" for this suite.
Feb  6 04:04:31.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:04:32.037: INFO: namespace webhook-5862-markers deletion completed in 6.061669699s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.834 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:04:32.045: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9880
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-9d33f52c-1bb9-410f-ae51-79eb243bed49
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-9d33f52c-1bb9-410f-ae51-79eb243bed49
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:04:36.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9880" for this suite.
Feb  6 04:05:04.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:05:04.259: INFO: namespace configmap-9880 deletion completed in 28.055196929s

• [SLOW TEST:32.214 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:05:04.259: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5248
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  6 04:05:06.900: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b89c8965-5994-4405-9ea4-65e9ecffa1df"
Feb  6 04:05:06.901: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b89c8965-5994-4405-9ea4-65e9ecffa1df" in namespace "pods-5248" to be "terminated due to deadline exceeded"
Feb  6 04:05:06.904: INFO: Pod "pod-update-activedeadlineseconds-b89c8965-5994-4405-9ea4-65e9ecffa1df": Phase="Running", Reason="", readiness=true. Elapsed: 3.899625ms
Feb  6 04:05:08.907: INFO: Pod "pod-update-activedeadlineseconds-b89c8965-5994-4405-9ea4-65e9ecffa1df": Phase="Running", Reason="", readiness=true. Elapsed: 2.006265955s
Feb  6 04:05:10.909: INFO: Pod "pod-update-activedeadlineseconds-b89c8965-5994-4405-9ea4-65e9ecffa1df": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.008720282s
Feb  6 04:05:10.909: INFO: Pod "pod-update-activedeadlineseconds-b89c8965-5994-4405-9ea4-65e9ecffa1df" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:05:10.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5248" for this suite.
Feb  6 04:05:16.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:05:16.990: INFO: namespace pods-5248 deletion completed in 6.078646078s

• [SLOW TEST:12.731 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:05:16.990: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4802
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  6 04:05:17.138: INFO: Waiting up to 5m0s for pod "pod-9dfe616a-93ed-459f-b18b-0a5bdc249f06" in namespace "emptydir-4802" to be "success or failure"
Feb  6 04:05:17.140: INFO: Pod "pod-9dfe616a-93ed-459f-b18b-0a5bdc249f06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.722823ms
Feb  6 04:05:19.143: INFO: Pod "pod-9dfe616a-93ed-459f-b18b-0a5bdc249f06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005178441s
STEP: Saw pod success
Feb  6 04:05:19.143: INFO: Pod "pod-9dfe616a-93ed-459f-b18b-0a5bdc249f06" satisfied condition "success or failure"
Feb  6 04:05:19.144: INFO: Trying to get logs from node aks-1-3 pod pod-9dfe616a-93ed-459f-b18b-0a5bdc249f06 container test-container: <nil>
STEP: delete the pod
Feb  6 04:05:19.163: INFO: Waiting for pod pod-9dfe616a-93ed-459f-b18b-0a5bdc249f06 to disappear
Feb  6 04:05:19.164: INFO: Pod pod-9dfe616a-93ed-459f-b18b-0a5bdc249f06 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:05:19.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4802" for this suite.
Feb  6 04:05:25.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:05:25.222: INFO: namespace emptydir-4802 deletion completed in 6.055732527s

• [SLOW TEST:8.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:05:25.222: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-989
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb  6 04:05:25.352: INFO: Waiting up to 5m0s for pod "downward-api-a83217a1-b611-4bdf-b3bf-aca288fe3756" in namespace "downward-api-989" to be "success or failure"
Feb  6 04:05:25.355: INFO: Pod "downward-api-a83217a1-b611-4bdf-b3bf-aca288fe3756": Phase="Pending", Reason="", readiness=false. Elapsed: 3.637505ms
Feb  6 04:05:27.358: INFO: Pod "downward-api-a83217a1-b611-4bdf-b3bf-aca288fe3756": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006381478s
STEP: Saw pod success
Feb  6 04:05:27.358: INFO: Pod "downward-api-a83217a1-b611-4bdf-b3bf-aca288fe3756" satisfied condition "success or failure"
Feb  6 04:05:27.360: INFO: Trying to get logs from node aks-1-4 pod downward-api-a83217a1-b611-4bdf-b3bf-aca288fe3756 container dapi-container: <nil>
STEP: delete the pod
Feb  6 04:05:27.385: INFO: Waiting for pod downward-api-a83217a1-b611-4bdf-b3bf-aca288fe3756 to disappear
Feb  6 04:05:27.386: INFO: Pod downward-api-a83217a1-b611-4bdf-b3bf-aca288fe3756 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:05:27.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-989" for this suite.
Feb  6 04:05:33.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:05:33.447: INFO: namespace downward-api-989 deletion completed in 6.058800604s

• [SLOW TEST:8.225 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:05:33.447: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1505
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 04:05:33.586: INFO: Number of nodes with available pods: 0
Feb  6 04:05:33.586: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:34.591: INFO: Number of nodes with available pods: 0
Feb  6 04:05:34.591: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:35.591: INFO: Number of nodes with available pods: 1
Feb  6 04:05:35.591: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:36.591: INFO: Number of nodes with available pods: 2
Feb  6 04:05:36.591: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:37.591: INFO: Number of nodes with available pods: 2
Feb  6 04:05:37.591: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:38.591: INFO: Number of nodes with available pods: 2
Feb  6 04:05:38.591: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:39.594: INFO: Number of nodes with available pods: 2
Feb  6 04:05:39.594: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:40.592: INFO: Number of nodes with available pods: 2
Feb  6 04:05:40.592: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:41.592: INFO: Number of nodes with available pods: 2
Feb  6 04:05:41.592: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:42.592: INFO: Number of nodes with available pods: 2
Feb  6 04:05:42.593: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:43.592: INFO: Number of nodes with available pods: 2
Feb  6 04:05:43.592: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:44.592: INFO: Number of nodes with available pods: 2
Feb  6 04:05:44.592: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:45.592: INFO: Number of nodes with available pods: 2
Feb  6 04:05:45.592: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:46.958: INFO: Number of nodes with available pods: 2
Feb  6 04:05:46.958: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:47.592: INFO: Number of nodes with available pods: 2
Feb  6 04:05:47.592: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:48.590: INFO: Number of nodes with available pods: 2
Feb  6 04:05:48.591: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:49.592: INFO: Number of nodes with available pods: 2
Feb  6 04:05:49.592: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:50.591: INFO: Number of nodes with available pods: 2
Feb  6 04:05:50.591: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:05:51.591: INFO: Number of nodes with available pods: 3
Feb  6 04:05:51.591: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb  6 04:05:51.608: INFO: Number of nodes with available pods: 2
Feb  6 04:05:51.608: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 04:05:52.613: INFO: Number of nodes with available pods: 2
Feb  6 04:05:52.613: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 04:05:53.615: INFO: Number of nodes with available pods: 2
Feb  6 04:05:53.615: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 04:05:54.613: INFO: Number of nodes with available pods: 2
Feb  6 04:05:54.613: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 04:05:55.616: INFO: Number of nodes with available pods: 3
Feb  6 04:05:55.616: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1505, will wait for the garbage collector to delete the pods
Feb  6 04:05:55.675: INFO: Deleting DaemonSet.extensions daemon-set took: 3.660349ms
Feb  6 04:05:55.975: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.200773ms
Feb  6 04:06:10.082: INFO: Number of nodes with available pods: 0
Feb  6 04:06:10.083: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 04:06:10.088: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1505/daemonsets","resourceVersion":"1791121"},"items":null}

Feb  6 04:06:10.101: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1505/pods","resourceVersion":"1791121"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:06:10.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1505" for this suite.
Feb  6 04:06:16.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:06:16.166: INFO: namespace daemonsets-1505 deletion completed in 6.052769692s

• [SLOW TEST:42.719 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:06:16.167: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9605
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb  6 04:06:18.305: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:06:18.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9605" for this suite.
Feb  6 04:06:24.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:06:24.371: INFO: namespace container-runtime-9605 deletion completed in 6.055646762s

• [SLOW TEST:8.205 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:06:24.372: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4341
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-501323e0-6419-4bd2-9ec7-acb6d8b407f0
STEP: Creating a pod to test consume configMaps
Feb  6 04:06:24.557: INFO: Waiting up to 5m0s for pod "pod-configmaps-0bbe985b-8b43-4bfd-8404-93a91358e81e" in namespace "configmap-4341" to be "success or failure"
Feb  6 04:06:24.562: INFO: Pod "pod-configmaps-0bbe985b-8b43-4bfd-8404-93a91358e81e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.266357ms
Feb  6 04:06:26.567: INFO: Pod "pod-configmaps-0bbe985b-8b43-4bfd-8404-93a91358e81e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010691483s
STEP: Saw pod success
Feb  6 04:06:26.568: INFO: Pod "pod-configmaps-0bbe985b-8b43-4bfd-8404-93a91358e81e" satisfied condition "success or failure"
Feb  6 04:06:26.569: INFO: Trying to get logs from node aks-1-4 pod pod-configmaps-0bbe985b-8b43-4bfd-8404-93a91358e81e container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 04:06:26.579: INFO: Waiting for pod pod-configmaps-0bbe985b-8b43-4bfd-8404-93a91358e81e to disappear
Feb  6 04:06:26.582: INFO: Pod pod-configmaps-0bbe985b-8b43-4bfd-8404-93a91358e81e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:06:26.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4341" for this suite.
Feb  6 04:06:32.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:06:32.640: INFO: namespace configmap-4341 deletion completed in 6.055734828s

• [SLOW TEST:8.268 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:06:32.641: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-6263
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb  6 04:06:33.409: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Feb  6 04:06:35.414: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558793, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558793, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558793, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558793, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 04:06:38.421: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:06:38.423: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:06:39.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6263" for this suite.
Feb  6 04:06:45.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:06:45.561: INFO: namespace crd-webhook-6263 deletion completed in 6.051294571s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:12.928 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:06:45.569: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-138
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Feb  6 04:06:45.699: INFO: Waiting up to 5m0s for pod "pod-03393b4e-a52f-4aa4-b6c2-04fef0018288" in namespace "emptydir-138" to be "success or failure"
Feb  6 04:06:45.701: INFO: Pod "pod-03393b4e-a52f-4aa4-b6c2-04fef0018288": Phase="Pending", Reason="", readiness=false. Elapsed: 1.511993ms
Feb  6 04:06:47.703: INFO: Pod "pod-03393b4e-a52f-4aa4-b6c2-04fef0018288": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003881758s
STEP: Saw pod success
Feb  6 04:06:47.703: INFO: Pod "pod-03393b4e-a52f-4aa4-b6c2-04fef0018288" satisfied condition "success or failure"
Feb  6 04:06:47.705: INFO: Trying to get logs from node aks-1-4 pod pod-03393b4e-a52f-4aa4-b6c2-04fef0018288 container test-container: <nil>
STEP: delete the pod
Feb  6 04:06:47.715: INFO: Waiting for pod pod-03393b4e-a52f-4aa4-b6c2-04fef0018288 to disappear
Feb  6 04:06:47.718: INFO: Pod pod-03393b4e-a52f-4aa4-b6c2-04fef0018288 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:06:47.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-138" for this suite.
Feb  6 04:06:53.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:06:53.775: INFO: namespace emptydir-138 deletion completed in 6.054525489s

• [SLOW TEST:8.206 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:06:53.775: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1512
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:06:53.918: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb  6 04:06:58.921: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 04:06:58.921: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb  6 04:06:58.935: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-1512 /apis/apps/v1/namespaces/deployment-1512/deployments/test-cleanup-deployment ee975db2-0f41-470e-9ae3-41ce8a2e993d 1791417 1 2020-02-06 04:06:58 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004527d28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Feb  6 04:06:58.940: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-1512 /apis/apps/v1/namespaces/deployment-1512/replicasets/test-cleanup-deployment-65db99849b 245e9772-5ec9-4300-9038-b1f9529c5026 1791419 1 2020-02-06 04:06:58 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment ee975db2-0f41-470e-9ae3-41ce8a2e993d 0xc005524177 0xc005524178}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0055241d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 04:06:58.940: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb  6 04:06:58.940: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-1512 /apis/apps/v1/namespaces/deployment-1512/replicasets/test-cleanup-controller 64a044dd-8b90-4118-9cd7-3af728365515 1791418 1 2020-02-06 04:06:53 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment ee975db2-0f41-470e-9ae3-41ce8a2e993d 0xc0055240a7 0xc0055240a8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005524108 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb  6 04:06:58.945: INFO: Pod "test-cleanup-controller-5t92s" is available:
&Pod{ObjectMeta:{test-cleanup-controller-5t92s test-cleanup-controller- deployment-1512 /api/v1/namespaces/deployment-1512/pods/test-cleanup-controller-5t92s e1425529-327a-49b8-9c6f-9752afb1eed2 1791413 0 2020-02-06 04:06:53 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[pod.beta1.sigma.ali/update-status:{"statuses":{"httpd":{"creationTimestamp":"2020-02-06T12:06:54.514323376+08:00","finishTimestamp":"2020-02-06T12:06:55.862327562+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [{apps/v1 ReplicaSet test-cleanup-controller 64a044dd-8b90-4118-9cd7-3af728365515 0xc0074841a7 0xc0074841a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h6wnb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h6wnb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h6wnb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:06:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:06:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:06:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:06:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:06:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.118,StartTime:2020-02-06 04:06:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 04:06:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://968d47f7f92218781bfa0a3413c2582ff3f9dbd13df2c6e9eaebd4ee89df1256,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.118,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 04:06:58.946: INFO: Pod "test-cleanup-deployment-65db99849b-zn75l" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-zn75l test-cleanup-deployment-65db99849b- deployment-1512 /api/v1/namespaces/deployment-1512/pods/test-cleanup-deployment-65db99849b-zn75l c520cfc3-70ec-4b08-8bfe-b0d623fb2adc 1791422 0 2020-02-06 04:06:58 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 245e9772-5ec9-4300-9038-b1f9529c5026 0xc007484347 0xc007484348}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h6wnb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h6wnb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h6wnb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:06:58.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1512" for this suite.
Feb  6 04:07:04.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:07:05.039: INFO: namespace deployment-1512 deletion completed in 6.081682318s

• [SLOW TEST:11.264 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:07:05.039: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0206 04:07:45.231273      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 04:07:45.231: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:07:45.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7343" for this suite.
Feb  6 04:07:51.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:07:51.286: INFO: namespace gc-7343 deletion completed in 6.053629978s

• [SLOW TEST:46.247 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:07:51.286: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2678
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  6 04:07:51.421: INFO: Waiting up to 5m0s for pod "pod-758595b7-219b-40e7-8fa0-3916d0d36a84" in namespace "emptydir-2678" to be "success or failure"
Feb  6 04:07:51.423: INFO: Pod "pod-758595b7-219b-40e7-8fa0-3916d0d36a84": Phase="Pending", Reason="", readiness=false. Elapsed: 2.343044ms
Feb  6 04:07:53.426: INFO: Pod "pod-758595b7-219b-40e7-8fa0-3916d0d36a84": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004715791s
Feb  6 04:07:55.428: INFO: Pod "pod-758595b7-219b-40e7-8fa0-3916d0d36a84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006939803s
STEP: Saw pod success
Feb  6 04:07:55.428: INFO: Pod "pod-758595b7-219b-40e7-8fa0-3916d0d36a84" satisfied condition "success or failure"
Feb  6 04:07:55.429: INFO: Trying to get logs from node aks-1-3 pod pod-758595b7-219b-40e7-8fa0-3916d0d36a84 container test-container: <nil>
STEP: delete the pod
Feb  6 04:07:55.450: INFO: Waiting for pod pod-758595b7-219b-40e7-8fa0-3916d0d36a84 to disappear
Feb  6 04:07:55.451: INFO: Pod pod-758595b7-219b-40e7-8fa0-3916d0d36a84 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:07:55.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2678" for this suite.
Feb  6 04:08:01.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:08:01.512: INFO: namespace emptydir-2678 deletion completed in 6.058795092s

• [SLOW TEST:10.226 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:08:01.512: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3625
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:08:14.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3625" for this suite.
Feb  6 04:08:20.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:08:20.745: INFO: namespace resourcequota-3625 deletion completed in 6.056214357s

• [SLOW TEST:19.233 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:08:20.745: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7612
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-881b12f9-42f6-4989-91aa-002160eb886c
STEP: Creating secret with name secret-projected-all-test-volume-5913a246-eba6-4337-85c5-40684496cb25
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb  6 04:08:20.877: INFO: Waiting up to 5m0s for pod "projected-volume-d1fa5f27-5772-4e8e-b959-e55bbe640fbe" in namespace "projected-7612" to be "success or failure"
Feb  6 04:08:20.883: INFO: Pod "projected-volume-d1fa5f27-5772-4e8e-b959-e55bbe640fbe": Phase="Pending", Reason="", readiness=false. Elapsed: 5.977808ms
Feb  6 04:08:22.886: INFO: Pod "projected-volume-d1fa5f27-5772-4e8e-b959-e55bbe640fbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008573639s
STEP: Saw pod success
Feb  6 04:08:22.886: INFO: Pod "projected-volume-d1fa5f27-5772-4e8e-b959-e55bbe640fbe" satisfied condition "success or failure"
Feb  6 04:08:22.887: INFO: Trying to get logs from node aks-1-4 pod projected-volume-d1fa5f27-5772-4e8e-b959-e55bbe640fbe container projected-all-volume-test: <nil>
STEP: delete the pod
Feb  6 04:08:22.902: INFO: Waiting for pod projected-volume-d1fa5f27-5772-4e8e-b959-e55bbe640fbe to disappear
Feb  6 04:08:22.904: INFO: Pod projected-volume-d1fa5f27-5772-4e8e-b959-e55bbe640fbe no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:08:22.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7612" for this suite.
Feb  6 04:08:28.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:08:28.963: INFO: namespace projected-7612 deletion completed in 6.057221692s

• [SLOW TEST:8.218 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:08:28.963: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7284
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  6 04:08:29.091: INFO: Waiting up to 5m0s for pod "pod-cebae949-35af-4827-8162-fa0056b4d8d7" in namespace "emptydir-7284" to be "success or failure"
Feb  6 04:08:29.094: INFO: Pod "pod-cebae949-35af-4827-8162-fa0056b4d8d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.862611ms
Feb  6 04:08:31.096: INFO: Pod "pod-cebae949-35af-4827-8162-fa0056b4d8d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005365373s
STEP: Saw pod success
Feb  6 04:08:31.096: INFO: Pod "pod-cebae949-35af-4827-8162-fa0056b4d8d7" satisfied condition "success or failure"
Feb  6 04:08:31.097: INFO: Trying to get logs from node aks-1-3 pod pod-cebae949-35af-4827-8162-fa0056b4d8d7 container test-container: <nil>
STEP: delete the pod
Feb  6 04:08:31.110: INFO: Waiting for pod pod-cebae949-35af-4827-8162-fa0056b4d8d7 to disappear
Feb  6 04:08:31.112: INFO: Pod pod-cebae949-35af-4827-8162-fa0056b4d8d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:08:31.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7284" for this suite.
Feb  6 04:08:37.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:08:37.168: INFO: namespace emptydir-7284 deletion completed in 6.05411739s

• [SLOW TEST:8.205 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:08:37.168: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-f8c02e4a-b482-4497-aedf-b0edd69490bf
STEP: Creating a pod to test consume configMaps
Feb  6 04:08:37.300: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e581a01b-c66b-449f-9c90-356b965f8ae1" in namespace "projected-1347" to be "success or failure"
Feb  6 04:08:37.303: INFO: Pod "pod-projected-configmaps-e581a01b-c66b-449f-9c90-356b965f8ae1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.837216ms
Feb  6 04:08:39.306: INFO: Pod "pod-projected-configmaps-e581a01b-c66b-449f-9c90-356b965f8ae1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00510989s
STEP: Saw pod success
Feb  6 04:08:39.306: INFO: Pod "pod-projected-configmaps-e581a01b-c66b-449f-9c90-356b965f8ae1" satisfied condition "success or failure"
Feb  6 04:08:39.307: INFO: Trying to get logs from node aks-1-4 pod pod-projected-configmaps-e581a01b-c66b-449f-9c90-356b965f8ae1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 04:08:39.322: INFO: Waiting for pod pod-projected-configmaps-e581a01b-c66b-449f-9c90-356b965f8ae1 to disappear
Feb  6 04:08:39.323: INFO: Pod pod-projected-configmaps-e581a01b-c66b-449f-9c90-356b965f8ae1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:08:39.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1347" for this suite.
Feb  6 04:08:45.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:08:45.379: INFO: namespace projected-1347 deletion completed in 6.054050712s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:08:45.379: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7925
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 04:08:46.240: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 04:08:49.256: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:08:49.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7925" for this suite.
Feb  6 04:08:55.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:08:55.355: INFO: namespace webhook-7925 deletion completed in 6.056901627s
STEP: Destroying namespace "webhook-7925-markers" for this suite.
Feb  6 04:09:01.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:09:01.411: INFO: namespace webhook-7925-markers deletion completed in 6.05547596s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.038 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:09:01.418: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-753
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb  6 04:09:01.545: INFO: PodSpec: initContainers in spec.initContainers
Feb  6 04:09:46.318: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d4b88db3-1197-41fa-888b-dbea16976901", GenerateName:"", Namespace:"init-container-753", SelfLink:"/api/v1/namespaces/init-container-753/pods/pod-init-d4b88db3-1197-41fa-888b-dbea16976901", UID:"98d628fa-2e2e-4e8d-8a60-5174625ba87a", ResourceVersion:"1792194", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63716558941, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"545490911"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-ltx95", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc005b7e000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ltx95", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ltx95", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ltx95", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004106088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"aks-1-4", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00325c060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004106110)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004106140)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004106148), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00410614c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558941, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558941, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558941, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainerDiskPressure", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558941, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716558941, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.27.81", PodIP:"10.244.1.119", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.1.119"}}, StartTime:(*v1.Time)(0xc002112060), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00095c0e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00095c150)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://392d4a25f4bff89e2610c4d885ac20f350019c2455404d95577a517dfae45b99", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0021120a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002112080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0041061df)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:09:46.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-753" for this suite.
Feb  6 04:10:14.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:10:14.384: INFO: namespace init-container-753 deletion completed in 28.062363895s

• [SLOW TEST:72.966 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:10:14.385: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2352
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb  6 04:10:14.516: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:10:16.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2352" for this suite.
Feb  6 04:10:22.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:10:22.680: INFO: namespace init-container-2352 deletion completed in 6.055742857s

• [SLOW TEST:8.295 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:10:22.680: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7161
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7161
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 04:10:22.853: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 04:10:46.896: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.122:8080/dial?request=hostName&protocol=udp&host=10.244.1.121&port=8081&tries=1'] Namespace:pod-network-test-7161 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 04:10:46.896: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 04:10:46.985: INFO: Waiting for endpoints: map[]
Feb  6 04:10:46.987: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.122:8080/dial?request=hostName&protocol=udp&host=10.244.2.128&port=8081&tries=1'] Namespace:pod-network-test-7161 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 04:10:46.987: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 04:10:47.065: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:10:47.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7161" for this suite.
Feb  6 04:10:59.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:10:59.123: INFO: namespace pod-network-test-7161 deletion completed in 12.055140533s

• [SLOW TEST:36.443 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:10:59.124: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7513
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Feb  6 04:11:01.765: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7513 pod-service-account-03bab25e-fc42-4be4-b827-fed8c49219ae -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Feb  6 04:11:01.933: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7513 pod-service-account-03bab25e-fc42-4be4-b827-fed8c49219ae -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Feb  6 04:11:02.107: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7513 pod-service-account-03bab25e-fc42-4be4-b827-fed8c49219ae -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:11:02.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7513" for this suite.
Feb  6 04:11:08.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:11:08.340: INFO: namespace svcaccounts-7513 deletion completed in 6.053545269s

• [SLOW TEST:9.217 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:11:08.340: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9995
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 04:11:08.518: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7ca0b372-5b42-44c6-b836-05e72acf2b73" in namespace "projected-9995" to be "success or failure"
Feb  6 04:11:08.520: INFO: Pod "downwardapi-volume-7ca0b372-5b42-44c6-b836-05e72acf2b73": Phase="Pending", Reason="", readiness=false. Elapsed: 1.709738ms
Feb  6 04:11:10.522: INFO: Pod "downwardapi-volume-7ca0b372-5b42-44c6-b836-05e72acf2b73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00414686s
STEP: Saw pod success
Feb  6 04:11:10.522: INFO: Pod "downwardapi-volume-7ca0b372-5b42-44c6-b836-05e72acf2b73" satisfied condition "success or failure"
Feb  6 04:11:10.524: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-7ca0b372-5b42-44c6-b836-05e72acf2b73 container client-container: <nil>
STEP: delete the pod
Feb  6 04:11:10.540: INFO: Waiting for pod downwardapi-volume-7ca0b372-5b42-44c6-b836-05e72acf2b73 to disappear
Feb  6 04:11:10.541: INFO: Pod downwardapi-volume-7ca0b372-5b42-44c6-b836-05e72acf2b73 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:11:10.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9995" for this suite.
Feb  6 04:11:16.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:11:16.607: INFO: namespace projected-9995 deletion completed in 6.063633743s

• [SLOW TEST:8.267 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:11:16.608: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6943
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:11:27.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6943" for this suite.
Feb  6 04:11:33.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:11:33.874: INFO: namespace resourcequota-6943 deletion completed in 6.056243127s

• [SLOW TEST:17.267 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:11:33.875: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4838
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:11:50.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4838" for this suite.
Feb  6 04:11:56.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:11:56.128: INFO: namespace resourcequota-4838 deletion completed in 6.069452825s

• [SLOW TEST:22.253 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:11:56.129: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1523
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 04:11:56.566: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 04:11:58.571: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559116, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559116, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559116, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559116, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 04:12:01.584: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:12:01.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1523" for this suite.
Feb  6 04:12:07.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:12:07.844: INFO: namespace webhook-1523 deletion completed in 6.061975728s
STEP: Destroying namespace "webhook-1523-markers" for this suite.
Feb  6 04:12:13.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:12:13.906: INFO: namespace webhook-1523-markers deletion completed in 6.062827459s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.785 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:12:13.914: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:12:30.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2598" for this suite.
Feb  6 04:12:36.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:12:36.182: INFO: namespace resourcequota-2598 deletion completed in 6.06492748s

• [SLOW TEST:22.269 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:12:36.182: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7869
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-wsjl
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 04:12:36.315: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wsjl" in namespace "subpath-7869" to be "success or failure"
Feb  6 04:12:36.317: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Pending", Reason="", readiness=false. Elapsed: 1.746386ms
Feb  6 04:12:38.319: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Running", Reason="", readiness=true. Elapsed: 2.004173439s
Feb  6 04:12:40.322: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Running", Reason="", readiness=true. Elapsed: 4.006694206s
Feb  6 04:12:42.324: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Running", Reason="", readiness=true. Elapsed: 6.009157417s
Feb  6 04:12:44.327: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Running", Reason="", readiness=true. Elapsed: 8.01176157s
Feb  6 04:12:46.330: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Running", Reason="", readiness=true. Elapsed: 10.014321784s
Feb  6 04:12:48.332: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Running", Reason="", readiness=true. Elapsed: 12.01659013s
Feb  6 04:12:50.334: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Running", Reason="", readiness=true. Elapsed: 14.019046438s
Feb  6 04:12:52.337: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Running", Reason="", readiness=true. Elapsed: 16.021335772s
Feb  6 04:12:54.339: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Running", Reason="", readiness=true. Elapsed: 18.023669703s
Feb  6 04:12:56.341: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Running", Reason="", readiness=true. Elapsed: 20.026145312s
Feb  6 04:12:58.344: INFO: Pod "pod-subpath-test-configmap-wsjl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.028323701s
STEP: Saw pod success
Feb  6 04:12:58.344: INFO: Pod "pod-subpath-test-configmap-wsjl" satisfied condition "success or failure"
Feb  6 04:12:58.345: INFO: Trying to get logs from node aks-1-3 pod pod-subpath-test-configmap-wsjl container test-container-subpath-configmap-wsjl: <nil>
STEP: delete the pod
Feb  6 04:12:58.365: INFO: Waiting for pod pod-subpath-test-configmap-wsjl to disappear
Feb  6 04:12:58.367: INFO: Pod pod-subpath-test-configmap-wsjl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wsjl
Feb  6 04:12:58.367: INFO: Deleting pod "pod-subpath-test-configmap-wsjl" in namespace "subpath-7869"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:12:58.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7869" for this suite.
Feb  6 04:13:04.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:13:04.431: INFO: namespace subpath-7869 deletion completed in 6.059972989s

• [SLOW TEST:28.248 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:13:04.431: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5798
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-5798
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5798
STEP: creating replication controller externalsvc in namespace services-5798
I0206 04:13:04.590032      20 runners.go:184] Created replication controller with name: externalsvc, namespace: services-5798, replica count: 2
I0206 04:13:07.640564      20 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Feb  6 04:13:07.653: INFO: Creating new exec pod
Feb  6 04:13:09.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-5798 execpod7sp9j -- /bin/sh -x -c nslookup nodeport-service'
Feb  6 04:13:10.021: INFO: stderr: "+ nslookup nodeport-service\n"
Feb  6 04:13:10.021: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-5798.svc.cluster.local\tcanonical name = externalsvc.services-5798.svc.cluster.local.\nName:\texternalsvc.services-5798.svc.cluster.local\nAddress: 10.96.0.74\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5798, will wait for the garbage collector to delete the pods
Feb  6 04:13:10.093: INFO: Deleting ReplicationController externalsvc took: 19.511239ms
Feb  6 04:13:10.293: INFO: Terminating ReplicationController externalsvc pods took: 200.171061ms
Feb  6 04:13:23.409: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:13:23.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5798" for this suite.
Feb  6 04:13:29.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:13:29.497: INFO: namespace services-5798 deletion completed in 6.072723776s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:25.066 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:13:29.498: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1008
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-fdc0e3f3-e356-4b48-831e-eed7db8d5bcc
STEP: Creating a pod to test consume configMaps
Feb  6 04:13:29.630: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0ff04b7b-147c-4aed-a2d3-b49e55a44e1a" in namespace "projected-1008" to be "success or failure"
Feb  6 04:13:29.632: INFO: Pod "pod-projected-configmaps-0ff04b7b-147c-4aed-a2d3-b49e55a44e1a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.790458ms
Feb  6 04:13:31.635: INFO: Pod "pod-projected-configmaps-0ff04b7b-147c-4aed-a2d3-b49e55a44e1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004248384s
STEP: Saw pod success
Feb  6 04:13:31.635: INFO: Pod "pod-projected-configmaps-0ff04b7b-147c-4aed-a2d3-b49e55a44e1a" satisfied condition "success or failure"
Feb  6 04:13:31.636: INFO: Trying to get logs from node aks-1-4 pod pod-projected-configmaps-0ff04b7b-147c-4aed-a2d3-b49e55a44e1a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 04:13:31.652: INFO: Waiting for pod pod-projected-configmaps-0ff04b7b-147c-4aed-a2d3-b49e55a44e1a to disappear
Feb  6 04:13:31.654: INFO: Pod pod-projected-configmaps-0ff04b7b-147c-4aed-a2d3-b49e55a44e1a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:13:31.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1008" for this suite.
Feb  6 04:13:37.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:13:37.710: INFO: namespace projected-1008 deletion completed in 6.054327357s

• [SLOW TEST:8.213 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:13:37.711: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3608
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3608
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-3608
Feb  6 04:13:37.849: INFO: Found 0 stateful pods, waiting for 1
Feb  6 04:13:47.851: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 04:13:47.862: INFO: Deleting all statefulset in ns statefulset-3608
Feb  6 04:13:47.868: INFO: Scaling statefulset ss to 0
Feb  6 04:14:17.898: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 04:14:17.900: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:14:17.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3608" for this suite.
Feb  6 04:14:23.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:14:23.963: INFO: namespace statefulset-3608 deletion completed in 6.054738331s

• [SLOW TEST:46.253 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:14:23.963: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6765
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 04:14:24.625: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 04:14:26.630: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559264, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559264, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559264, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559264, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 04:14:29.637: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:14:39.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6765" for this suite.
Feb  6 04:14:45.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:14:45.784: INFO: namespace webhook-6765 deletion completed in 6.066241616s
STEP: Destroying namespace "webhook-6765-markers" for this suite.
Feb  6 04:14:51.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:14:51.845: INFO: namespace webhook-6765-markers deletion completed in 6.06061349s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:27.889 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:14:51.853: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-8a8397da-7be9-435f-baaf-b450c79a33a5
STEP: Creating a pod to test consume configMaps
Feb  6 04:14:51.987: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f49fa39d-f3c4-4442-8f21-823576419f8f" in namespace "projected-5176" to be "success or failure"
Feb  6 04:14:51.990: INFO: Pod "pod-projected-configmaps-f49fa39d-f3c4-4442-8f21-823576419f8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.889529ms
Feb  6 04:14:53.993: INFO: Pod "pod-projected-configmaps-f49fa39d-f3c4-4442-8f21-823576419f8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00551002s
STEP: Saw pod success
Feb  6 04:14:53.993: INFO: Pod "pod-projected-configmaps-f49fa39d-f3c4-4442-8f21-823576419f8f" satisfied condition "success or failure"
Feb  6 04:14:53.995: INFO: Trying to get logs from node aks-1-4 pod pod-projected-configmaps-f49fa39d-f3c4-4442-8f21-823576419f8f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 04:14:54.007: INFO: Waiting for pod pod-projected-configmaps-f49fa39d-f3c4-4442-8f21-823576419f8f to disappear
Feb  6 04:14:54.009: INFO: Pod pod-projected-configmaps-f49fa39d-f3c4-4442-8f21-823576419f8f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:14:54.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5176" for this suite.
Feb  6 04:15:00.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:15:00.065: INFO: namespace projected-5176 deletion completed in 6.053962752s

• [SLOW TEST:8.212 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:15:00.065: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4866
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:15:17.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4866" for this suite.
Feb  6 04:15:23.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:15:23.322: INFO: namespace resourcequota-4866 deletion completed in 6.055957871s

• [SLOW TEST:23.257 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:15:23.323: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2490
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb  6 04:15:23.449: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 04:15:23.456: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 04:15:23.457: INFO: 
Logging pods the kubelet thinks is on node aks-1-3 before test
Feb  6 04:15:23.466: INFO: coredns-7f6cddc944-99f6c from kube-system started at 2020-02-05 13:54:41 +0000 UTC (1 container statuses recorded)
Feb  6 04:15:23.466: INFO: 	Container coredns ready: true, restart count 0
Feb  6 04:15:23.466: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-kwwvw from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 04:15:23.466: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 04:15:23.466: INFO: 	Container systemd-logs ready: true, restart count 0
Feb  6 04:15:23.466: INFO: kube-flannel-ds-amd64-tkhv8 from kube-system started at 2020-02-05 07:36:26 +0000 UTC (1 container statuses recorded)
Feb  6 04:15:23.466: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 04:15:23.466: INFO: coredns-7f6cddc944-v22mw from kube-system started at 2020-02-05 08:48:34 +0000 UTC (1 container statuses recorded)
Feb  6 04:15:23.466: INFO: 	Container coredns ready: true, restart count 0
Feb  6 04:15:23.466: INFO: 
Logging pods the kubelet thinks is on node aks-1-4 before test
Feb  6 04:15:23.469: INFO: coredns-7f6cddc944-w6w2z from kube-system started at 2020-02-03 03:59:20 +0000 UTC (1 container statuses recorded)
Feb  6 04:15:23.469: INFO: 	Container coredns ready: true, restart count 0
Feb  6 04:15:23.469: INFO: kube-flannel-ds-amd64-plfph from kube-system started at 2020-02-04 14:20:52 +0000 UTC (1 container statuses recorded)
Feb  6 04:15:23.469: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 04:15:23.469: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-7z6kz from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 04:15:23.469: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 04:15:23.469: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node aks-1-3
STEP: verifying the node has the label node aks-1-4
Feb  6 04:15:23.496: INFO: Pod coredns-7f6cddc944-99f6c requesting resource cpu=100m on Node aks-1-3
Feb  6 04:15:23.496: INFO: Pod coredns-7f6cddc944-v22mw requesting resource cpu=100m on Node aks-1-3
Feb  6 04:15:23.496: INFO: Pod coredns-7f6cddc944-w6w2z requesting resource cpu=100m on Node aks-1-4
Feb  6 04:15:23.496: INFO: Pod kube-flannel-ds-amd64-plfph requesting resource cpu=100m on Node aks-1-4
Feb  6 04:15:23.496: INFO: Pod kube-flannel-ds-amd64-tkhv8 requesting resource cpu=100m on Node aks-1-3
Feb  6 04:15:23.496: INFO: Pod sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-7z6kz requesting resource cpu=0m on Node aks-1-4
Feb  6 04:15:23.496: INFO: Pod sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-kwwvw requesting resource cpu=0m on Node aks-1-3
STEP: Starting Pods to consume most of the cluster CPU.
Feb  6 04:15:23.496: INFO: Creating a pod which consumes cpu=1190m on Node aks-1-3
Feb  6 04:15:23.500: INFO: Creating a pod which consumes cpu=1260m on Node aks-1-4
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-06d65c20-c34e-4c74-ad36-188633bf8151.15f0b509f0c1ebb2], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2490/filler-pod-06d65c20-c34e-4c74-ad36-188633bf8151 to aks-1-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-06d65c20-c34e-4c74-ad36-188633bf8151.15f0b50a16219780], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-06d65c20-c34e-4c74-ad36-188633bf8151.15f0b50a181d627a], Reason = [Created], Message = [Created container filler-pod-06d65c20-c34e-4c74-ad36-188633bf8151]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-06d65c20-c34e-4c74-ad36-188633bf8151.15f0b50a1ccefd64], Reason = [Started], Message = [Started container filler-pod-06d65c20-c34e-4c74-ad36-188633bf8151]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-06d65c20-c34e-4c74-ad36-188633bf8151.15f0b50a1cd04d6b], Reason = [WithOutPostStartHook], Message = [Container filler-pod-06d65c20-c34e-4c74-ad36-188633bf8151 with out poststart hook]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-44e994a4-fea3-4ec9-976d-b8e7b6c744a0.15f0b509f1991cf9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2490/filler-pod-44e994a4-fea3-4ec9-976d-b8e7b6c744a0 to aks-1-4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-44e994a4-fea3-4ec9-976d-b8e7b6c744a0.15f0b50a1982886f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-44e994a4-fea3-4ec9-976d-b8e7b6c744a0.15f0b50a1b47d1d9], Reason = [Created], Message = [Created container filler-pod-44e994a4-fea3-4ec9-976d-b8e7b6c744a0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-44e994a4-fea3-4ec9-976d-b8e7b6c744a0.15f0b50a1f992649], Reason = [Started], Message = [Started container filler-pod-44e994a4-fea3-4ec9-976d-b8e7b6c744a0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-44e994a4-fea3-4ec9-976d-b8e7b6c744a0.15f0b50a1f9a18a0], Reason = [WithOutPostStartHook], Message = [Container filler-pod-44e994a4-fea3-4ec9-976d-b8e7b6c744a0 with out poststart hook]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f0b50a69b4bd03], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) were unschedulable, 2 Insufficient cpu.]
STEP: removing the label node off the node aks-1-3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node aks-1-4
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:15:26.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2490" for this suite.
Feb  6 04:15:32.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:15:32.615: INFO: namespace sched-pred-2490 deletion completed in 6.056487674s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:9.293 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:15:32.615: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4227
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-9db8baab-67a9-4bcb-a319-68eaf43df399
STEP: Creating a pod to test consume configMaps
Feb  6 04:15:32.747: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-04d4d35a-f9e5-465a-abe4-875cb22b72d3" in namespace "projected-4227" to be "success or failure"
Feb  6 04:15:32.750: INFO: Pod "pod-projected-configmaps-04d4d35a-f9e5-465a-abe4-875cb22b72d3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.129939ms
Feb  6 04:15:34.753: INFO: Pod "pod-projected-configmaps-04d4d35a-f9e5-465a-abe4-875cb22b72d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005700034s
STEP: Saw pod success
Feb  6 04:15:34.753: INFO: Pod "pod-projected-configmaps-04d4d35a-f9e5-465a-abe4-875cb22b72d3" satisfied condition "success or failure"
Feb  6 04:15:34.754: INFO: Trying to get logs from node aks-1-4 pod pod-projected-configmaps-04d4d35a-f9e5-465a-abe4-875cb22b72d3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 04:15:34.765: INFO: Waiting for pod pod-projected-configmaps-04d4d35a-f9e5-465a-abe4-875cb22b72d3 to disappear
Feb  6 04:15:34.766: INFO: Pod pod-projected-configmaps-04d4d35a-f9e5-465a-abe4-875cb22b72d3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:15:34.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4227" for this suite.
Feb  6 04:15:40.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:15:40.822: INFO: namespace projected-4227 deletion completed in 6.054036179s

• [SLOW TEST:8.207 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:15:40.823: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1645
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb  6 04:15:43.474: INFO: Successfully updated pod "annotationupdate7402d92e-eedf-47a2-abd5-9ac467a70487"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:15:47.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1645" for this suite.
Feb  6 04:16:01.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:16:01.550: INFO: namespace downward-api-1645 deletion completed in 14.055466931s

• [SLOW TEST:20.727 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:16:01.550: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5212
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  6 04:16:01.681: INFO: Waiting up to 5m0s for pod "pod-aaac20f8-0fab-4cdd-b4c6-94f80485e62c" in namespace "emptydir-5212" to be "success or failure"
Feb  6 04:16:01.684: INFO: Pod "pod-aaac20f8-0fab-4cdd-b4c6-94f80485e62c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.247684ms
Feb  6 04:16:03.686: INFO: Pod "pod-aaac20f8-0fab-4cdd-b4c6-94f80485e62c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005699019s
STEP: Saw pod success
Feb  6 04:16:03.686: INFO: Pod "pod-aaac20f8-0fab-4cdd-b4c6-94f80485e62c" satisfied condition "success or failure"
Feb  6 04:16:03.688: INFO: Trying to get logs from node aks-1-4 pod pod-aaac20f8-0fab-4cdd-b4c6-94f80485e62c container test-container: <nil>
STEP: delete the pod
Feb  6 04:16:03.700: INFO: Waiting for pod pod-aaac20f8-0fab-4cdd-b4c6-94f80485e62c to disappear
Feb  6 04:16:03.701: INFO: Pod pod-aaac20f8-0fab-4cdd-b4c6-94f80485e62c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:16:03.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5212" for this suite.
Feb  6 04:16:09.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:16:09.757: INFO: namespace emptydir-5212 deletion completed in 6.053596186s

• [SLOW TEST:8.207 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:16:09.758: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6812
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 04:16:10.296: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 04:16:12.301: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559370, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559370, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559370, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559370, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 04:16:15.308: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:16:15.310: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1422-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:16:16.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6812" for this suite.
Feb  6 04:16:22.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:16:22.572: INFO: namespace webhook-6812 deletion completed in 6.057693291s
STEP: Destroying namespace "webhook-6812-markers" for this suite.
Feb  6 04:16:28.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:16:28.626: INFO: namespace webhook-6812-markers deletion completed in 6.054085635s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.876 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:16:28.634: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-812
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 04:16:28.762: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4cb09fb-fe19-4d36-895b-bca874b111dd" in namespace "downward-api-812" to be "success or failure"
Feb  6 04:16:28.764: INFO: Pod "downwardapi-volume-b4cb09fb-fe19-4d36-895b-bca874b111dd": Phase="Pending", Reason="", readiness=false. Elapsed: 1.864073ms
Feb  6 04:16:30.767: INFO: Pod "downwardapi-volume-b4cb09fb-fe19-4d36-895b-bca874b111dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004443873s
STEP: Saw pod success
Feb  6 04:16:30.767: INFO: Pod "downwardapi-volume-b4cb09fb-fe19-4d36-895b-bca874b111dd" satisfied condition "success or failure"
Feb  6 04:16:30.768: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-b4cb09fb-fe19-4d36-895b-bca874b111dd container client-container: <nil>
STEP: delete the pod
Feb  6 04:16:30.780: INFO: Waiting for pod downwardapi-volume-b4cb09fb-fe19-4d36-895b-bca874b111dd to disappear
Feb  6 04:16:30.781: INFO: Pod downwardapi-volume-b4cb09fb-fe19-4d36-895b-bca874b111dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:16:30.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-812" for this suite.
Feb  6 04:16:36.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:16:36.840: INFO: namespace downward-api-812 deletion completed in 6.055708947s

• [SLOW TEST:8.205 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:16:36.840: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2583
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0206 04:16:43.031278      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 04:16:43.031: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:16:43.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2583" for this suite.
Feb  6 04:16:49.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:16:49.093: INFO: namespace gc-2583 deletion completed in 6.05987235s

• [SLOW TEST:12.253 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:16:49.093: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-50fa9c0b-5ea8-464f-9c82-6ee64c307ede
STEP: Creating a pod to test consume secrets
Feb  6 04:16:49.228: INFO: Waiting up to 5m0s for pod "pod-secrets-30ac8490-a60b-4e13-821b-039b2f963ba1" in namespace "secrets-6576" to be "success or failure"
Feb  6 04:16:49.231: INFO: Pod "pod-secrets-30ac8490-a60b-4e13-821b-039b2f963ba1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.973917ms
Feb  6 04:16:51.233: INFO: Pod "pod-secrets-30ac8490-a60b-4e13-821b-039b2f963ba1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00549313s
STEP: Saw pod success
Feb  6 04:16:51.233: INFO: Pod "pod-secrets-30ac8490-a60b-4e13-821b-039b2f963ba1" satisfied condition "success or failure"
Feb  6 04:16:51.235: INFO: Trying to get logs from node aks-1-4 pod pod-secrets-30ac8490-a60b-4e13-821b-039b2f963ba1 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 04:16:51.251: INFO: Waiting for pod pod-secrets-30ac8490-a60b-4e13-821b-039b2f963ba1 to disappear
Feb  6 04:16:51.253: INFO: Pod pod-secrets-30ac8490-a60b-4e13-821b-039b2f963ba1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:16:51.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6576" for this suite.
Feb  6 04:16:57.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:16:57.308: INFO: namespace secrets-6576 deletion completed in 6.053078406s

• [SLOW TEST:8.215 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:16:57.308: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:16:57.446: INFO: Create a RollingUpdate DaemonSet
Feb  6 04:16:57.448: INFO: Check that daemon pods launch on every node of the cluster
Feb  6 04:16:57.453: INFO: Number of nodes with available pods: 0
Feb  6 04:16:57.453: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:16:58.460: INFO: Number of nodes with available pods: 0
Feb  6 04:16:58.460: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:16:59.567: INFO: Number of nodes with available pods: 0
Feb  6 04:16:59.567: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:17:00.458: INFO: Number of nodes with available pods: 1
Feb  6 04:17:00.458: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:17:01.457: INFO: Number of nodes with available pods: 3
Feb  6 04:17:01.458: INFO: Number of running nodes: 3, number of available pods: 3
Feb  6 04:17:01.458: INFO: Update the DaemonSet to trigger a rollout
Feb  6 04:17:01.462: INFO: Updating DaemonSet daemon-set
Feb  6 04:17:10.476: INFO: Roll back the DaemonSet before rollout is complete
Feb  6 04:17:10.483: INFO: Updating DaemonSet daemon-set
Feb  6 04:17:10.483: INFO: Make sure DaemonSet rollback is complete
Feb  6 04:17:10.486: INFO: Wrong image for pod: daemon-set-gzhxp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 04:17:10.486: INFO: Pod daemon-set-gzhxp is not available
Feb  6 04:17:11.496: INFO: Wrong image for pod: daemon-set-gzhxp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 04:17:11.497: INFO: Pod daemon-set-gzhxp is not available
Feb  6 04:17:12.495: INFO: Wrong image for pod: daemon-set-gzhxp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 04:17:12.495: INFO: Pod daemon-set-gzhxp is not available
Feb  6 04:17:13.494: INFO: Wrong image for pod: daemon-set-gzhxp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 04:17:13.494: INFO: Pod daemon-set-gzhxp is not available
Feb  6 04:17:14.495: INFO: Wrong image for pod: daemon-set-gzhxp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 04:17:14.495: INFO: Pod daemon-set-gzhxp is not available
Feb  6 04:17:15.494: INFO: Wrong image for pod: daemon-set-gzhxp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 04:17:15.494: INFO: Pod daemon-set-gzhxp is not available
Feb  6 04:17:16.494: INFO: Wrong image for pod: daemon-set-gzhxp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 04:17:16.495: INFO: Pod daemon-set-gzhxp is not available
Feb  6 04:17:17.494: INFO: Wrong image for pod: daemon-set-gzhxp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 04:17:17.494: INFO: Pod daemon-set-gzhxp is not available
Feb  6 04:17:18.495: INFO: Wrong image for pod: daemon-set-gzhxp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 04:17:18.495: INFO: Pod daemon-set-gzhxp is not available
Feb  6 04:17:19.495: INFO: Wrong image for pod: daemon-set-gzhxp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb  6 04:17:19.495: INFO: Pod daemon-set-gzhxp is not available
Feb  6 04:17:20.495: INFO: Pod daemon-set-n2vbg is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2909, will wait for the garbage collector to delete the pods
Feb  6 04:17:20.556: INFO: Deleting DaemonSet.extensions daemon-set took: 3.420739ms
Feb  6 04:17:20.856: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.217819ms
Feb  6 04:17:33.357: INFO: Number of nodes with available pods: 0
Feb  6 04:17:33.357: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 04:17:33.359: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2909/daemonsets","resourceVersion":"1794316"},"items":null}

Feb  6 04:17:33.360: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2909/pods","resourceVersion":"1794316"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:17:33.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2909" for this suite.
Feb  6 04:17:39.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:17:39.419: INFO: namespace daemonsets-2909 deletion completed in 6.050317639s

• [SLOW TEST:42.110 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:17:39.419: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7025
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 04:17:39.598: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7e8ac9d0-11d4-4cf5-bbd8-9d90dc42e9e1" in namespace "projected-7025" to be "success or failure"
Feb  6 04:17:39.600: INFO: Pod "downwardapi-volume-7e8ac9d0-11d4-4cf5-bbd8-9d90dc42e9e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.472712ms
Feb  6 04:17:41.603: INFO: Pod "downwardapi-volume-7e8ac9d0-11d4-4cf5-bbd8-9d90dc42e9e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005057236s
STEP: Saw pod success
Feb  6 04:17:41.603: INFO: Pod "downwardapi-volume-7e8ac9d0-11d4-4cf5-bbd8-9d90dc42e9e1" satisfied condition "success or failure"
Feb  6 04:17:41.605: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-7e8ac9d0-11d4-4cf5-bbd8-9d90dc42e9e1 container client-container: <nil>
STEP: delete the pod
Feb  6 04:17:41.618: INFO: Waiting for pod downwardapi-volume-7e8ac9d0-11d4-4cf5-bbd8-9d90dc42e9e1 to disappear
Feb  6 04:17:41.622: INFO: Pod downwardapi-volume-7e8ac9d0-11d4-4cf5-bbd8-9d90dc42e9e1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:17:41.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7025" for this suite.
Feb  6 04:17:47.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:17:47.679: INFO: namespace projected-7025 deletion completed in 6.055014116s

• [SLOW TEST:8.260 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:17:47.681: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3637
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  6 04:17:51.839: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 04:17:51.841: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 04:17:53.841: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 04:17:53.844: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 04:17:55.841: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 04:17:55.844: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 04:17:57.841: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 04:17:57.844: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 04:17:59.841: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 04:17:59.844: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 04:18:01.841: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 04:18:01.844: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 04:18:03.841: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 04:18:03.844: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:18:03.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3637" for this suite.
Feb  6 04:18:31.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:18:31.909: INFO: namespace container-lifecycle-hook-3637 deletion completed in 28.057003993s

• [SLOW TEST:44.228 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:18:31.909: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1800
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:18:55.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1800" for this suite.
Feb  6 04:19:01.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:19:01.214: INFO: namespace container-runtime-1800 deletion completed in 6.062454908s

• [SLOW TEST:29.304 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:19:01.214: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2862
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb  6 04:19:01.351: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:19:05.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2862" for this suite.
Feb  6 04:19:33.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:19:33.095: INFO: namespace init-container-2862 deletion completed in 28.063306499s

• [SLOW TEST:31.881 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:19:33.095: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5569
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-92051c9b-0db5-4dfe-a29e-873086566616
STEP: Creating a pod to test consume configMaps
Feb  6 04:19:33.226: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3de690c5-d099-4e79-9012-68fe3d9a51e6" in namespace "projected-5569" to be "success or failure"
Feb  6 04:19:33.230: INFO: Pod "pod-projected-configmaps-3de690c5-d099-4e79-9012-68fe3d9a51e6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.824849ms
Feb  6 04:19:35.232: INFO: Pod "pod-projected-configmaps-3de690c5-d099-4e79-9012-68fe3d9a51e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006351156s
STEP: Saw pod success
Feb  6 04:19:35.232: INFO: Pod "pod-projected-configmaps-3de690c5-d099-4e79-9012-68fe3d9a51e6" satisfied condition "success or failure"
Feb  6 04:19:35.234: INFO: Trying to get logs from node aks-1-3 pod pod-projected-configmaps-3de690c5-d099-4e79-9012-68fe3d9a51e6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 04:19:35.249: INFO: Waiting for pod pod-projected-configmaps-3de690c5-d099-4e79-9012-68fe3d9a51e6 to disappear
Feb  6 04:19:35.251: INFO: Pod pod-projected-configmaps-3de690c5-d099-4e79-9012-68fe3d9a51e6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:19:35.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5569" for this suite.
Feb  6 04:19:41.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:19:41.312: INFO: namespace projected-5569 deletion completed in 6.057914916s

• [SLOW TEST:8.217 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:19:41.312: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6350
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-192b9dc6-e5cb-4f44-a496-c037d1989428
STEP: Creating a pod to test consume secrets
Feb  6 04:19:41.445: INFO: Waiting up to 5m0s for pod "pod-secrets-ec8ed76d-c9e4-4223-9481-0d6c3535d521" in namespace "secrets-6350" to be "success or failure"
Feb  6 04:19:41.449: INFO: Pod "pod-secrets-ec8ed76d-c9e4-4223-9481-0d6c3535d521": Phase="Pending", Reason="", readiness=false. Elapsed: 3.590643ms
Feb  6 04:19:43.452: INFO: Pod "pod-secrets-ec8ed76d-c9e4-4223-9481-0d6c3535d521": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006166913s
STEP: Saw pod success
Feb  6 04:19:43.452: INFO: Pod "pod-secrets-ec8ed76d-c9e4-4223-9481-0d6c3535d521" satisfied condition "success or failure"
Feb  6 04:19:43.453: INFO: Trying to get logs from node aks-1-3 pod pod-secrets-ec8ed76d-c9e4-4223-9481-0d6c3535d521 container secret-env-test: <nil>
STEP: delete the pod
Feb  6 04:19:43.464: INFO: Waiting for pod pod-secrets-ec8ed76d-c9e4-4223-9481-0d6c3535d521 to disappear
Feb  6 04:19:43.465: INFO: Pod pod-secrets-ec8ed76d-c9e4-4223-9481-0d6c3535d521 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:19:43.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6350" for this suite.
Feb  6 04:19:49.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:19:49.523: INFO: namespace secrets-6350 deletion completed in 6.055221041s

• [SLOW TEST:8.211 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:19:49.524: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-286
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb  6 04:19:49.652: INFO: Waiting up to 5m0s for pod "downward-api-d78aecbd-9c73-4033-8232-b0014c85bbe7" in namespace "downward-api-286" to be "success or failure"
Feb  6 04:19:49.657: INFO: Pod "downward-api-d78aecbd-9c73-4033-8232-b0014c85bbe7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.343571ms
Feb  6 04:19:51.660: INFO: Pod "downward-api-d78aecbd-9c73-4033-8232-b0014c85bbe7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007871332s
STEP: Saw pod success
Feb  6 04:19:51.660: INFO: Pod "downward-api-d78aecbd-9c73-4033-8232-b0014c85bbe7" satisfied condition "success or failure"
Feb  6 04:19:51.661: INFO: Trying to get logs from node aks-1-4 pod downward-api-d78aecbd-9c73-4033-8232-b0014c85bbe7 container dapi-container: <nil>
STEP: delete the pod
Feb  6 04:19:51.679: INFO: Waiting for pod downward-api-d78aecbd-9c73-4033-8232-b0014c85bbe7 to disappear
Feb  6 04:19:51.683: INFO: Pod downward-api-d78aecbd-9c73-4033-8232-b0014c85bbe7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:19:51.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-286" for this suite.
Feb  6 04:19:57.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:19:57.740: INFO: namespace downward-api-286 deletion completed in 6.055462659s

• [SLOW TEST:8.216 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:19:57.741: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-727
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:20:00.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-727" for this suite.
Feb  6 04:20:12.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:20:12.943: INFO: namespace replication-controller-727 deletion completed in 12.055774374s

• [SLOW TEST:15.203 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:20:12.943: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8182
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-f7f143f5-e4fb-49f2-ba08-221e9959e427
STEP: Creating a pod to test consume configMaps
Feb  6 04:20:13.073: INFO: Waiting up to 5m0s for pod "pod-configmaps-16cc8e14-23c6-4063-b904-627d99cb3f5f" in namespace "configmap-8182" to be "success or failure"
Feb  6 04:20:13.078: INFO: Pod "pod-configmaps-16cc8e14-23c6-4063-b904-627d99cb3f5f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.749668ms
Feb  6 04:20:15.081: INFO: Pod "pod-configmaps-16cc8e14-23c6-4063-b904-627d99cb3f5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007145296s
STEP: Saw pod success
Feb  6 04:20:15.081: INFO: Pod "pod-configmaps-16cc8e14-23c6-4063-b904-627d99cb3f5f" satisfied condition "success or failure"
Feb  6 04:20:15.082: INFO: Trying to get logs from node aks-1-3 pod pod-configmaps-16cc8e14-23c6-4063-b904-627d99cb3f5f container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 04:20:15.099: INFO: Waiting for pod pod-configmaps-16cc8e14-23c6-4063-b904-627d99cb3f5f to disappear
Feb  6 04:20:15.101: INFO: Pod pod-configmaps-16cc8e14-23c6-4063-b904-627d99cb3f5f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:20:15.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8182" for this suite.
Feb  6 04:20:21.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:20:21.160: INFO: namespace configmap-8182 deletion completed in 6.057671844s

• [SLOW TEST:8.217 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:20:21.161: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 04:20:21.290: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8af0bb4-8cc6-434d-b7d0-9e6586447485" in namespace "projected-7203" to be "success or failure"
Feb  6 04:20:21.292: INFO: Pod "downwardapi-volume-a8af0bb4-8cc6-434d-b7d0-9e6586447485": Phase="Pending", Reason="", readiness=false. Elapsed: 1.956063ms
Feb  6 04:20:23.295: INFO: Pod "downwardapi-volume-a8af0bb4-8cc6-434d-b7d0-9e6586447485": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004551765s
STEP: Saw pod success
Feb  6 04:20:23.295: INFO: Pod "downwardapi-volume-a8af0bb4-8cc6-434d-b7d0-9e6586447485" satisfied condition "success or failure"
Feb  6 04:20:23.296: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-a8af0bb4-8cc6-434d-b7d0-9e6586447485 container client-container: <nil>
STEP: delete the pod
Feb  6 04:20:23.308: INFO: Waiting for pod downwardapi-volume-a8af0bb4-8cc6-434d-b7d0-9e6586447485 to disappear
Feb  6 04:20:23.310: INFO: Pod downwardapi-volume-a8af0bb4-8cc6-434d-b7d0-9e6586447485 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:20:23.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7203" for this suite.
Feb  6 04:20:29.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:20:29.364: INFO: namespace projected-7203 deletion completed in 6.050580381s

• [SLOW TEST:8.203 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:20:29.365: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3095
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb  6 04:20:32.013: INFO: Successfully updated pod "annotationupdateff827f90-97a8-4f0a-8010-1d96dfc34f3e"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:20:36.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3095" for this suite.
Feb  6 04:20:58.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:20:58.104: INFO: namespace projected-3095 deletion completed in 22.069606012s

• [SLOW TEST:28.740 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:20:58.105: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4467
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 04:20:58.237: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6ff7697-c83e-4ba2-833a-3844bece4418" in namespace "downward-api-4467" to be "success or failure"
Feb  6 04:20:58.239: INFO: Pod "downwardapi-volume-d6ff7697-c83e-4ba2-833a-3844bece4418": Phase="Pending", Reason="", readiness=false. Elapsed: 1.90269ms
Feb  6 04:21:00.240: INFO: Pod "downwardapi-volume-d6ff7697-c83e-4ba2-833a-3844bece4418": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003821289s
STEP: Saw pod success
Feb  6 04:21:00.240: INFO: Pod "downwardapi-volume-d6ff7697-c83e-4ba2-833a-3844bece4418" satisfied condition "success or failure"
Feb  6 04:21:00.242: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-d6ff7697-c83e-4ba2-833a-3844bece4418 container client-container: <nil>
STEP: delete the pod
Feb  6 04:21:00.252: INFO: Waiting for pod downwardapi-volume-d6ff7697-c83e-4ba2-833a-3844bece4418 to disappear
Feb  6 04:21:00.254: INFO: Pod downwardapi-volume-d6ff7697-c83e-4ba2-833a-3844bece4418 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:21:00.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4467" for this suite.
Feb  6 04:21:06.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:21:06.311: INFO: namespace downward-api-4467 deletion completed in 6.054627548s

• [SLOW TEST:8.206 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:21:06.311: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2634
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 04:21:06.492: INFO: Waiting up to 5m0s for pod "downwardapi-volume-78525428-835e-4258-802a-18e4e9605757" in namespace "projected-2634" to be "success or failure"
Feb  6 04:21:06.493: INFO: Pod "downwardapi-volume-78525428-835e-4258-802a-18e4e9605757": Phase="Pending", Reason="", readiness=false. Elapsed: 1.774493ms
Feb  6 04:21:08.496: INFO: Pod "downwardapi-volume-78525428-835e-4258-802a-18e4e9605757": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004253471s
STEP: Saw pod success
Feb  6 04:21:08.496: INFO: Pod "downwardapi-volume-78525428-835e-4258-802a-18e4e9605757" satisfied condition "success or failure"
Feb  6 04:21:08.497: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-78525428-835e-4258-802a-18e4e9605757 container client-container: <nil>
STEP: delete the pod
Feb  6 04:21:08.512: INFO: Waiting for pod downwardapi-volume-78525428-835e-4258-802a-18e4e9605757 to disappear
Feb  6 04:21:08.513: INFO: Pod downwardapi-volume-78525428-835e-4258-802a-18e4e9605757 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:21:08.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2634" for this suite.
Feb  6 04:21:14.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:21:14.570: INFO: namespace projected-2634 deletion completed in 6.054525059s

• [SLOW TEST:8.259 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:21:14.570: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6905
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:21:14.699: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-8529a42d-15a9-4cb8-b225-7df5c7ac45d5" in namespace "security-context-test-6905" to be "success or failure"
Feb  6 04:21:14.703: INFO: Pod "alpine-nnp-false-8529a42d-15a9-4cb8-b225-7df5c7ac45d5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.156829ms
Feb  6 04:21:16.705: INFO: Pod "alpine-nnp-false-8529a42d-15a9-4cb8-b225-7df5c7ac45d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005714166s
Feb  6 04:21:18.708: INFO: Pod "alpine-nnp-false-8529a42d-15a9-4cb8-b225-7df5c7ac45d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008135326s
Feb  6 04:21:20.710: INFO: Pod "alpine-nnp-false-8529a42d-15a9-4cb8-b225-7df5c7ac45d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010892691s
Feb  6 04:21:20.710: INFO: Pod "alpine-nnp-false-8529a42d-15a9-4cb8-b225-7df5c7ac45d5" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:21:20.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6905" for this suite.
Feb  6 04:21:26.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:21:26.772: INFO: namespace security-context-test-6905 deletion completed in 6.053989323s

• [SLOW TEST:12.202 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:21:26.772: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8788
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb  6 04:21:26.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-8788'
Feb  6 04:21:27.173: INFO: stderr: ""
Feb  6 04:21:27.173: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 04:21:28.176: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:21:28.176: INFO: Found 0 / 1
Feb  6 04:21:29.176: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:21:29.176: INFO: Found 1 / 1
Feb  6 04:21:29.176: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb  6 04:21:29.177: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:21:29.177: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 04:21:29.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 patch pod redis-master-h5rbd --namespace=kubectl-8788 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb  6 04:21:29.304: INFO: stderr: ""
Feb  6 04:21:29.304: INFO: stdout: "pod/redis-master-h5rbd patched\n"
STEP: checking annotations
Feb  6 04:21:29.307: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 04:21:29.307: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:21:29.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8788" for this suite.
Feb  6 04:21:57.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:21:57.366: INFO: namespace kubectl-8788 deletion completed in 28.057543279s

• [SLOW TEST:30.594 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:21:57.367: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3260
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  6 04:21:57.494: INFO: Waiting up to 5m0s for pod "pod-3b37258e-0aa8-4c9a-a2d0-dc9c57123a11" in namespace "emptydir-3260" to be "success or failure"
Feb  6 04:21:57.499: INFO: Pod "pod-3b37258e-0aa8-4c9a-a2d0-dc9c57123a11": Phase="Pending", Reason="", readiness=false. Elapsed: 5.632313ms
Feb  6 04:21:59.502: INFO: Pod "pod-3b37258e-0aa8-4c9a-a2d0-dc9c57123a11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008109608s
STEP: Saw pod success
Feb  6 04:21:59.502: INFO: Pod "pod-3b37258e-0aa8-4c9a-a2d0-dc9c57123a11" satisfied condition "success or failure"
Feb  6 04:21:59.503: INFO: Trying to get logs from node aks-1-3 pod pod-3b37258e-0aa8-4c9a-a2d0-dc9c57123a11 container test-container: <nil>
STEP: delete the pod
Feb  6 04:21:59.518: INFO: Waiting for pod pod-3b37258e-0aa8-4c9a-a2d0-dc9c57123a11 to disappear
Feb  6 04:21:59.520: INFO: Pod pod-3b37258e-0aa8-4c9a-a2d0-dc9c57123a11 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:21:59.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3260" for this suite.
Feb  6 04:22:05.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:22:05.578: INFO: namespace emptydir-3260 deletion completed in 6.055877511s

• [SLOW TEST:8.211 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:22:05.579: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4724
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:22:05.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4724" for this suite.
Feb  6 04:22:11.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:22:11.776: INFO: namespace resourcequota-4724 deletion completed in 6.055299999s

• [SLOW TEST:6.197 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:22:11.776: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Feb  6 04:22:11.908: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:22:23.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-588" for this suite.
Feb  6 04:22:29.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:22:29.407: INFO: namespace pods-588 deletion completed in 6.053933834s

• [SLOW TEST:17.630 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:22:29.407: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1128
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Feb  6 04:22:29.533: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-529150080 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:22:29.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1128" for this suite.
Feb  6 04:22:35.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:22:35.678: INFO: namespace kubectl-1128 deletion completed in 6.057862704s

• [SLOW TEST:6.272 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:22:35.679: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3269
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 04:22:35.812: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ad94bede-37f1-45c0-a38d-1d2788e88403" in namespace "projected-3269" to be "success or failure"
Feb  6 04:22:35.814: INFO: Pod "downwardapi-volume-ad94bede-37f1-45c0-a38d-1d2788e88403": Phase="Pending", Reason="", readiness=false. Elapsed: 1.950679ms
Feb  6 04:22:37.816: INFO: Pod "downwardapi-volume-ad94bede-37f1-45c0-a38d-1d2788e88403": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004344183s
STEP: Saw pod success
Feb  6 04:22:37.816: INFO: Pod "downwardapi-volume-ad94bede-37f1-45c0-a38d-1d2788e88403" satisfied condition "success or failure"
Feb  6 04:22:37.818: INFO: Trying to get logs from node aks-1-3 pod downwardapi-volume-ad94bede-37f1-45c0-a38d-1d2788e88403 container client-container: <nil>
STEP: delete the pod
Feb  6 04:22:37.830: INFO: Waiting for pod downwardapi-volume-ad94bede-37f1-45c0-a38d-1d2788e88403 to disappear
Feb  6 04:22:37.831: INFO: Pod downwardapi-volume-ad94bede-37f1-45c0-a38d-1d2788e88403 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:22:37.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3269" for this suite.
Feb  6 04:22:43.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:22:43.884: INFO: namespace projected-3269 deletion completed in 6.051390166s

• [SLOW TEST:8.206 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:22:43.885: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5880
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb  6 04:22:46.553: INFO: Successfully updated pod "labelsupdate10e3d9ee-b1c3-460d-aa00-5aa88a3c8578"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:22:50.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5880" for this suite.
Feb  6 04:23:18.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:23:18.651: INFO: namespace projected-5880 deletion completed in 28.078217097s

• [SLOW TEST:34.767 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:23:18.652: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9036
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0206 04:23:28.826835      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 04:23:28.826: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:23:28.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9036" for this suite.
Feb  6 04:23:34.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:23:34.880: INFO: namespace gc-9036 deletion completed in 6.052283626s

• [SLOW TEST:16.228 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:23:34.881: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8616
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Feb  6 04:23:35.061: INFO: Waiting up to 5m0s for pod "var-expansion-e27823dc-a42a-43f7-830a-71624e2752d4" in namespace "var-expansion-8616" to be "success or failure"
Feb  6 04:23:35.065: INFO: Pod "var-expansion-e27823dc-a42a-43f7-830a-71624e2752d4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.065392ms
Feb  6 04:23:37.067: INFO: Pod "var-expansion-e27823dc-a42a-43f7-830a-71624e2752d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006651274s
STEP: Saw pod success
Feb  6 04:23:37.067: INFO: Pod "var-expansion-e27823dc-a42a-43f7-830a-71624e2752d4" satisfied condition "success or failure"
Feb  6 04:23:37.069: INFO: Trying to get logs from node aks-1-3 pod var-expansion-e27823dc-a42a-43f7-830a-71624e2752d4 container dapi-container: <nil>
STEP: delete the pod
Feb  6 04:23:37.092: INFO: Waiting for pod var-expansion-e27823dc-a42a-43f7-830a-71624e2752d4 to disappear
Feb  6 04:23:37.093: INFO: Pod var-expansion-e27823dc-a42a-43f7-830a-71624e2752d4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:23:37.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8616" for this suite.
Feb  6 04:23:43.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:23:43.153: INFO: namespace var-expansion-8616 deletion completed in 6.057283177s

• [SLOW TEST:8.272 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:23:43.153: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6828
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:23:43.302: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"73ed9d5d-5040-4768-9583-2d98aa2b04f5", Controller:(*bool)(0xc0006f7c8a), BlockOwnerDeletion:(*bool)(0xc0006f7c8b)}}
Feb  6 04:23:43.309: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"55143db6-ddc7-486f-9b0f-6566554e6c63", Controller:(*bool)(0xc0006f7e6a), BlockOwnerDeletion:(*bool)(0xc0006f7e6b)}}
Feb  6 04:23:43.314: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"e70db11f-55d9-40cd-a6d8-b2cdc8a5e3df", Controller:(*bool)(0xc00066d43a), BlockOwnerDeletion:(*bool)(0xc00066d43b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:23:48.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6828" for this suite.
Feb  6 04:23:54.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:23:54.378: INFO: namespace gc-6828 deletion completed in 6.054856595s

• [SLOW TEST:11.225 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:23:54.379: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1199
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 04:23:54.509: INFO: Waiting up to 5m0s for pod "downwardapi-volume-042b7c17-0f4b-412a-a0c3-854f575699c8" in namespace "projected-1199" to be "success or failure"
Feb  6 04:23:54.512: INFO: Pod "downwardapi-volume-042b7c17-0f4b-412a-a0c3-854f575699c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.87984ms
Feb  6 04:23:56.515: INFO: Pod "downwardapi-volume-042b7c17-0f4b-412a-a0c3-854f575699c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005516552s
STEP: Saw pod success
Feb  6 04:23:56.515: INFO: Pod "downwardapi-volume-042b7c17-0f4b-412a-a0c3-854f575699c8" satisfied condition "success or failure"
Feb  6 04:23:56.517: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-042b7c17-0f4b-412a-a0c3-854f575699c8 container client-container: <nil>
STEP: delete the pod
Feb  6 04:23:56.528: INFO: Waiting for pod downwardapi-volume-042b7c17-0f4b-412a-a0c3-854f575699c8 to disappear
Feb  6 04:23:56.529: INFO: Pod downwardapi-volume-042b7c17-0f4b-412a-a0c3-854f575699c8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:23:56.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1199" for this suite.
Feb  6 04:24:02.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:24:02.588: INFO: namespace projected-1199 deletion completed in 6.056973675s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:24:02.589: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-623
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Feb  6 04:24:02.718: INFO: Waiting up to 5m0s for pod "var-expansion-d7b289a3-9f1e-4d7c-9f29-a8af0933d47b" in namespace "var-expansion-623" to be "success or failure"
Feb  6 04:24:02.721: INFO: Pod "var-expansion-d7b289a3-9f1e-4d7c-9f29-a8af0933d47b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022765ms
Feb  6 04:24:04.722: INFO: Pod "var-expansion-d7b289a3-9f1e-4d7c-9f29-a8af0933d47b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003850389s
STEP: Saw pod success
Feb  6 04:24:04.722: INFO: Pod "var-expansion-d7b289a3-9f1e-4d7c-9f29-a8af0933d47b" satisfied condition "success or failure"
Feb  6 04:24:04.724: INFO: Trying to get logs from node aks-1-3 pod var-expansion-d7b289a3-9f1e-4d7c-9f29-a8af0933d47b container dapi-container: <nil>
STEP: delete the pod
Feb  6 04:24:04.738: INFO: Waiting for pod var-expansion-d7b289a3-9f1e-4d7c-9f29-a8af0933d47b to disappear
Feb  6 04:24:04.740: INFO: Pod var-expansion-d7b289a3-9f1e-4d7c-9f29-a8af0933d47b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:24:04.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-623" for this suite.
Feb  6 04:24:10.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:24:10.801: INFO: namespace var-expansion-623 deletion completed in 6.058306508s

• [SLOW TEST:8.212 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:24:10.801: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7188
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb  6 04:24:12.940: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:24:12.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7188" for this suite.
Feb  6 04:24:18.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:24:19.054: INFO: namespace container-runtime-7188 deletion completed in 6.106128999s

• [SLOW TEST:8.253 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:24:19.055: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6102
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 04:24:19.201: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 04:24:39.246: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.170 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6102 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 04:24:39.246: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 04:24:40.314: INFO: Found all expected endpoints: [netserver-0]
Feb  6 04:24:40.316: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.167 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6102 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 04:24:40.317: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 04:24:41.381: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:24:41.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6102" for this suite.
Feb  6 04:24:53.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:24:53.438: INFO: namespace pod-network-test-6102 deletion completed in 12.054617803s

• [SLOW TEST:34.383 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:24:53.439: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6099
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-6099
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6099 to expose endpoints map[]
Feb  6 04:24:53.623: INFO: Get endpoints failed (5.934839ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb  6 04:24:54.625: INFO: successfully validated that service endpoint-test2 in namespace services-6099 exposes endpoints map[] (1.008243931s elapsed)
STEP: Creating pod pod1 in namespace services-6099
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6099 to expose endpoints map[pod1:[80]]
Feb  6 04:24:58.651: INFO: successfully validated that service endpoint-test2 in namespace services-6099 exposes endpoints map[pod1:[80]] (4.021731863s elapsed)
STEP: Creating pod pod2 in namespace services-6099
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6099 to expose endpoints map[pod1:[80] pod2:[80]]
Feb  6 04:25:01.675: INFO: successfully validated that service endpoint-test2 in namespace services-6099 exposes endpoints map[pod1:[80] pod2:[80]] (3.022058709s elapsed)
STEP: Deleting pod pod1 in namespace services-6099
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6099 to expose endpoints map[pod2:[80]]
Feb  6 04:25:02.692: INFO: successfully validated that service endpoint-test2 in namespace services-6099 exposes endpoints map[pod2:[80]] (1.013172642s elapsed)
STEP: Deleting pod pod2 in namespace services-6099
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6099 to expose endpoints map[]
Feb  6 04:25:03.700: INFO: successfully validated that service endpoint-test2 in namespace services-6099 exposes endpoints map[] (1.005833172s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:25:03.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6099" for this suite.
Feb  6 04:25:15.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:25:15.776: INFO: namespace services-6099 deletion completed in 12.056304606s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:22.337 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:25:15.776: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8043
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 04:25:16.171: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 04:25:18.177: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559916, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559916, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559916, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716559916, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 04:25:21.185: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Feb  6 04:25:23.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 attach --namespace=webhook-8043 to-be-attached-pod -i -c=container1'
Feb  6 04:25:23.496: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:25:23.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8043" for this suite.
Feb  6 04:25:35.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:25:35.563: INFO: namespace webhook-8043 deletion completed in 12.058268067s
STEP: Destroying namespace "webhook-8043-markers" for this suite.
Feb  6 04:25:41.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:25:41.618: INFO: namespace webhook-8043-markers deletion completed in 6.055238212s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.848 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:25:41.626: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-490
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-5578bc37-eea2-45ab-bceb-4456fa5fbcbf
Feb  6 04:25:41.807: INFO: Pod name my-hostname-basic-5578bc37-eea2-45ab-bceb-4456fa5fbcbf: Found 0 pods out of 1
Feb  6 04:25:46.810: INFO: Pod name my-hostname-basic-5578bc37-eea2-45ab-bceb-4456fa5fbcbf: Found 1 pods out of 1
Feb  6 04:25:46.810: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-5578bc37-eea2-45ab-bceb-4456fa5fbcbf" are running
Feb  6 04:25:46.811: INFO: Pod "my-hostname-basic-5578bc37-eea2-45ab-bceb-4456fa5fbcbf-hcxt6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 04:25:41 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 04:25:43 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 04:25:43 +0000 UTC Reason: Message:} {Type:ContainerDiskPressure Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 04:25:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-06 04:25:41 +0000 UTC Reason: Message:}])
Feb  6 04:25:46.812: INFO: Trying to dial the pod
Feb  6 04:25:51.818: INFO: Controller my-hostname-basic-5578bc37-eea2-45ab-bceb-4456fa5fbcbf: Got expected result from replica 1 [my-hostname-basic-5578bc37-eea2-45ab-bceb-4456fa5fbcbf-hcxt6]: "my-hostname-basic-5578bc37-eea2-45ab-bceb-4456fa5fbcbf-hcxt6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:25:51.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-490" for this suite.
Feb  6 04:25:57.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:25:57.875: INFO: namespace replication-controller-490 deletion completed in 6.054089946s

• [SLOW TEST:16.249 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:25:57.875: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 04:25:58.004: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dc483c26-18dc-493d-82c2-e0d359a30f97" in namespace "downward-api-8709" to be "success or failure"
Feb  6 04:25:58.007: INFO: Pod "downwardapi-volume-dc483c26-18dc-493d-82c2-e0d359a30f97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.932669ms
Feb  6 04:26:00.010: INFO: Pod "downwardapi-volume-dc483c26-18dc-493d-82c2-e0d359a30f97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005482751s
STEP: Saw pod success
Feb  6 04:26:00.010: INFO: Pod "downwardapi-volume-dc483c26-18dc-493d-82c2-e0d359a30f97" satisfied condition "success or failure"
Feb  6 04:26:00.011: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-dc483c26-18dc-493d-82c2-e0d359a30f97 container client-container: <nil>
STEP: delete the pod
Feb  6 04:26:00.029: INFO: Waiting for pod downwardapi-volume-dc483c26-18dc-493d-82c2-e0d359a30f97 to disappear
Feb  6 04:26:00.030: INFO: Pod downwardapi-volume-dc483c26-18dc-493d-82c2-e0d359a30f97 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:26:00.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8709" for this suite.
Feb  6 04:26:06.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:26:06.098: INFO: namespace downward-api-8709 deletion completed in 6.066130348s

• [SLOW TEST:8.223 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:26:06.098: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7537
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-388d0810-3534-4cc7-862b-025b153e1c31
STEP: Creating a pod to test consume configMaps
Feb  6 04:26:06.280: INFO: Waiting up to 5m0s for pod "pod-configmaps-f95405cd-d3c3-4040-8179-393eb3f5c586" in namespace "configmap-7537" to be "success or failure"
Feb  6 04:26:06.283: INFO: Pod "pod-configmaps-f95405cd-d3c3-4040-8179-393eb3f5c586": Phase="Pending", Reason="", readiness=false. Elapsed: 3.338691ms
Feb  6 04:26:08.286: INFO: Pod "pod-configmaps-f95405cd-d3c3-4040-8179-393eb3f5c586": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005811876s
STEP: Saw pod success
Feb  6 04:26:08.286: INFO: Pod "pod-configmaps-f95405cd-d3c3-4040-8179-393eb3f5c586" satisfied condition "success or failure"
Feb  6 04:26:08.287: INFO: Trying to get logs from node aks-1-3 pod pod-configmaps-f95405cd-d3c3-4040-8179-393eb3f5c586 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 04:26:08.315: INFO: Waiting for pod pod-configmaps-f95405cd-d3c3-4040-8179-393eb3f5c586 to disappear
Feb  6 04:26:08.317: INFO: Pod pod-configmaps-f95405cd-d3c3-4040-8179-393eb3f5c586 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:26:08.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7537" for this suite.
Feb  6 04:26:14.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:26:14.377: INFO: namespace configmap-7537 deletion completed in 6.058469086s

• [SLOW TEST:8.279 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:26:14.378: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6583
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:26:14.507: INFO: (0) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 3.225168ms)
Feb  6 04:26:14.509: INFO: (1) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.206292ms)
Feb  6 04:26:14.511: INFO: (2) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.106457ms)
Feb  6 04:26:14.513: INFO: (3) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 1.941672ms)
Feb  6 04:26:14.516: INFO: (4) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.018562ms)
Feb  6 04:26:14.518: INFO: (5) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.016621ms)
Feb  6 04:26:14.520: INFO: (6) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 1.965922ms)
Feb  6 04:26:14.522: INFO: (7) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.230216ms)
Feb  6 04:26:14.524: INFO: (8) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.192238ms)
Feb  6 04:26:14.526: INFO: (9) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.287084ms)
Feb  6 04:26:14.529: INFO: (10) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.14818ms)
Feb  6 04:26:14.531: INFO: (11) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.128846ms)
Feb  6 04:26:14.533: INFO: (12) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.665875ms)
Feb  6 04:26:14.536: INFO: (13) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.14659ms)
Feb  6 04:26:14.538: INFO: (14) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 1.972365ms)
Feb  6 04:26:14.540: INFO: (15) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 1.981032ms)
Feb  6 04:26:14.542: INFO: (16) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.042286ms)
Feb  6 04:26:14.544: INFO: (17) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.05598ms)
Feb  6 04:26:14.546: INFO: (18) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 2.206079ms)
Feb  6 04:26:14.548: INFO: (19) /api/v1/nodes/aks-1-3:10250/proxy/logs/: <pre>
<a href="aliyun-util.log">aliyun-util.log</a>
<a href="anaconda/">anaconda/</a>
<a href="au... (200; 1.973589ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:26:14.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6583" for this suite.
Feb  6 04:26:20.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:26:20.604: INFO: namespace proxy-6583 deletion completed in 6.054406998s

• [SLOW TEST:6.227 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:26:20.605: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6005
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-cbb8c66d-9a1b-4308-a2e1-26d8fc6ed4d7
STEP: Creating a pod to test consume configMaps
Feb  6 04:26:20.734: INFO: Waiting up to 5m0s for pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf" in namespace "configmap-6005" to be "success or failure"
Feb  6 04:26:20.736: INFO: Pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.844611ms
Feb  6 04:26:22.738: INFO: Pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004283445s
Feb  6 04:26:24.741: INFO: Pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006494562s
Feb  6 04:26:26.745: INFO: Pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010820913s
Feb  6 04:26:28.748: INFO: Pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01333695s
Feb  6 04:26:30.750: INFO: Pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.015662322s
Feb  6 04:26:32.752: INFO: Pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.018208523s
Feb  6 04:26:34.755: INFO: Pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf": Phase="Pending", Reason="", readiness=false. Elapsed: 14.020994972s
Feb  6 04:26:36.758: INFO: Pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf": Phase="Pending", Reason="", readiness=false. Elapsed: 16.02334836s
Feb  6 04:26:38.760: INFO: Pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.025947791s
STEP: Saw pod success
Feb  6 04:26:38.760: INFO: Pod "pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf" satisfied condition "success or failure"
Feb  6 04:26:38.762: INFO: Trying to get logs from node aks-1-4 pod pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 04:26:38.807: INFO: Waiting for pod pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf to disappear
Feb  6 04:26:38.809: INFO: Pod pod-configmaps-e921327c-b8cc-418b-8106-5402cdc60daf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:26:38.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6005" for this suite.
Feb  6 04:26:44.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:26:44.908: INFO: namespace configmap-6005 deletion completed in 6.09616967s

• [SLOW TEST:24.304 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:26:44.909: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2726
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-6cd9415a-4021-4b61-8068-1d2824dee4b9
STEP: Creating a pod to test consume configMaps
Feb  6 04:26:45.667: INFO: Waiting up to 5m0s for pod "pod-configmaps-02bbd128-0e28-4a66-a8e6-a7d7868fd425" in namespace "configmap-2726" to be "success or failure"
Feb  6 04:26:45.758: INFO: Pod "pod-configmaps-02bbd128-0e28-4a66-a8e6-a7d7868fd425": Phase="Pending", Reason="", readiness=false. Elapsed: 90.584957ms
Feb  6 04:26:47.959: INFO: Pod "pod-configmaps-02bbd128-0e28-4a66-a8e6-a7d7868fd425": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.292244775s
STEP: Saw pod success
Feb  6 04:26:47.960: INFO: Pod "pod-configmaps-02bbd128-0e28-4a66-a8e6-a7d7868fd425" satisfied condition "success or failure"
Feb  6 04:26:47.964: INFO: Trying to get logs from node aks-1-4 pod pod-configmaps-02bbd128-0e28-4a66-a8e6-a7d7868fd425 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 04:26:48.557: INFO: Waiting for pod pod-configmaps-02bbd128-0e28-4a66-a8e6-a7d7868fd425 to disappear
Feb  6 04:26:49.368: INFO: Pod pod-configmaps-02bbd128-0e28-4a66-a8e6-a7d7868fd425 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:26:49.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2726" for this suite.
Feb  6 04:26:56.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:26:56.163: INFO: namespace configmap-2726 deletion completed in 6.767570718s

• [SLOW TEST:11.254 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:26:56.285: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3478
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3478
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3478
STEP: Creating statefulset with conflicting port in namespace statefulset-3478
STEP: Waiting until pod test-pod will start running in namespace statefulset-3478
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3478
Feb  6 04:27:00.713: INFO: Observed stateful pod in namespace: statefulset-3478, name: ss-0, uid: ca52ad43-13c9-4f12-8de8-e9f599685556, status phase: Pending. Waiting for statefulset controller to delete.
Feb  6 04:27:00.885: INFO: Observed stateful pod in namespace: statefulset-3478, name: ss-0, uid: ca52ad43-13c9-4f12-8de8-e9f599685556, status phase: Failed. Waiting for statefulset controller to delete.
Feb  6 04:27:00.890: INFO: Observed stateful pod in namespace: statefulset-3478, name: ss-0, uid: ca52ad43-13c9-4f12-8de8-e9f599685556, status phase: Failed. Waiting for statefulset controller to delete.
Feb  6 04:27:00.895: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3478
STEP: Removing pod with conflicting port in namespace statefulset-3478
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3478 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 04:27:06.918: INFO: Deleting all statefulset in ns statefulset-3478
Feb  6 04:27:06.923: INFO: Scaling statefulset ss to 0
Feb  6 04:27:26.933: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 04:27:26.940: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:27:26.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3478" for this suite.
Feb  6 04:27:32.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:27:33.019: INFO: namespace statefulset-3478 deletion completed in 6.064087509s

• [SLOW TEST:36.735 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:27:33.026: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6965
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:27:37.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6965" for this suite.
Feb  6 04:27:55.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:27:55.229: INFO: namespace containers-6965 deletion completed in 18.053210347s

• [SLOW TEST:22.204 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:27:55.229: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4470
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Feb  6 04:28:25.383: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:28:25.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4470" for this suite.
W0206 04:28:25.383501      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 04:28:31.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:28:31.443: INFO: namespace gc-4470 deletion completed in 6.057632715s

• [SLOW TEST:36.214 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:28:31.443: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3888
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 04:28:31.581: INFO: Waiting up to 5m0s for pod "downwardapi-volume-819083c4-0359-4d67-98e7-de6db084b103" in namespace "projected-3888" to be "success or failure"
Feb  6 04:28:31.583: INFO: Pod "downwardapi-volume-819083c4-0359-4d67-98e7-de6db084b103": Phase="Pending", Reason="", readiness=false. Elapsed: 1.668331ms
Feb  6 04:28:33.585: INFO: Pod "downwardapi-volume-819083c4-0359-4d67-98e7-de6db084b103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003818366s
STEP: Saw pod success
Feb  6 04:28:33.585: INFO: Pod "downwardapi-volume-819083c4-0359-4d67-98e7-de6db084b103" satisfied condition "success or failure"
Feb  6 04:28:33.586: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-819083c4-0359-4d67-98e7-de6db084b103 container client-container: <nil>
STEP: delete the pod
Feb  6 04:28:33.607: INFO: Waiting for pod downwardapi-volume-819083c4-0359-4d67-98e7-de6db084b103 to disappear
Feb  6 04:28:33.608: INFO: Pod downwardapi-volume-819083c4-0359-4d67-98e7-de6db084b103 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:28:33.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3888" for this suite.
Feb  6 04:28:39.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:28:39.676: INFO: namespace projected-3888 deletion completed in 6.065648653s

• [SLOW TEST:8.233 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:28:39.677: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9559
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 04:28:40.260: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 04:28:42.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716560120, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716560120, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716560120, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716560120, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 04:28:45.274: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:28:45.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9559" for this suite.
Feb  6 04:28:51.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:28:51.353: INFO: namespace webhook-9559 deletion completed in 6.055601922s
STEP: Destroying namespace "webhook-9559-markers" for this suite.
Feb  6 04:28:57.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:28:57.409: INFO: namespace webhook-9559-markers deletion completed in 6.055243719s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.739 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:28:57.417: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9731
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9731
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-9731
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9731
Feb  6 04:28:57.552: INFO: Found 0 stateful pods, waiting for 1
Feb  6 04:29:07.554: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb  6 04:29:07.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 04:29:07.805: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 04:29:07.805: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 04:29:07.805: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 04:29:07.831: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  6 04:29:17.834: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 04:29:17.834: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 04:29:17.842: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Feb  6 04:29:17.842: INFO: ss-0  aks-1-4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  }]
Feb  6 04:29:17.842: INFO: 
Feb  6 04:29:17.842: INFO: StatefulSet ss has not reached scale 3, at 1
Feb  6 04:29:18.844: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99807805s
Feb  6 04:29:19.860: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.983011086s
Feb  6 04:29:20.907: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.979981531s
Feb  6 04:29:21.911: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.932546424s
Feb  6 04:29:22.914: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.928934153s
Feb  6 04:29:23.917: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.925873127s
Feb  6 04:29:24.920: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.922655632s
Feb  6 04:29:25.924: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.919648257s
Feb  6 04:29:26.927: INFO: Verifying statefulset ss doesn't scale past 3 for another 916.422253ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9731
Feb  6 04:29:27.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:29:28.219: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 04:29:28.219: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 04:29:28.219: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 04:29:28.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:29:28.481: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb  6 04:29:28.481: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 04:29:28.481: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 04:29:28.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:29:28.657: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb  6 04:29:28.657: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 04:29:28.657: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 04:29:28.659: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 04:29:28.659: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 04:29:28.659: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb  6 04:29:28.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 04:29:28.825: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 04:29:28.825: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 04:29:28.825: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 04:29:28.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 04:29:28.979: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 04:29:28.979: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 04:29:28.979: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 04:29:28.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 04:29:29.166: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 04:29:29.166: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 04:29:29.166: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 04:29:29.166: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 04:29:29.168: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb  6 04:29:39.172: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 04:29:39.172: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 04:29:39.172: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 04:29:39.179: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Feb  6 04:29:39.179: INFO: ss-0  aks-1-4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  }]
Feb  6 04:29:39.179: INFO: ss-1  aks-1-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:39.179: INFO: ss-2  aks-1-4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:39.179: INFO: 
Feb  6 04:29:39.179: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 04:29:40.182: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Feb  6 04:29:40.182: INFO: ss-0  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  }]
Feb  6 04:29:40.182: INFO: ss-1  aks-1-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:40.182: INFO: ss-2  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:40.182: INFO: 
Feb  6 04:29:40.182: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 04:29:41.185: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Feb  6 04:29:41.185: INFO: ss-0  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:28:57 +0000 UTC  }]
Feb  6 04:29:41.185: INFO: ss-2  aks-1-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:41.185: INFO: 
Feb  6 04:29:41.185: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 04:29:42.188: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Feb  6 04:29:42.188: INFO: ss-2  aks-1-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:42.188: INFO: 
Feb  6 04:29:42.188: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  6 04:29:43.190: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Feb  6 04:29:43.190: INFO: ss-2  aks-1-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:43.190: INFO: 
Feb  6 04:29:43.190: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  6 04:29:44.193: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Feb  6 04:29:44.193: INFO: ss-2  aks-1-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:44.193: INFO: 
Feb  6 04:29:44.193: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  6 04:29:45.195: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Feb  6 04:29:45.195: INFO: ss-2  aks-1-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:45.195: INFO: 
Feb  6 04:29:45.195: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  6 04:29:46.198: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Feb  6 04:29:46.198: INFO: ss-2  aks-1-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:46.198: INFO: 
Feb  6 04:29:46.198: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  6 04:29:47.201: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Feb  6 04:29:47.201: INFO: ss-2  aks-1-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:47.201: INFO: 
Feb  6 04:29:47.201: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  6 04:29:48.204: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Feb  6 04:29:48.204: INFO: ss-2  aks-1-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainerDiskPressure False 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-06 04:29:17 +0000 UTC  }]
Feb  6 04:29:48.204: INFO: 
Feb  6 04:29:48.204: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9731
Feb  6 04:29:49.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:29:49.321: INFO: rc: 1
Feb  6 04:29:49.333: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc002d64c60 exit status 1 <nil> <nil> true [0xc003034458 0xc003034498 0xc003034500] [0xc003034458 0xc003034498 0xc003034500] [0xc003034480 0xc0030344d0] [0x10efe30 0x10efe30] 0xc003725b00 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Feb  6 04:29:59.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:29:59.422: INFO: rc: 1
Feb  6 04:29:59.422: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d64ff0 exit status 1 <nil> <nil> true [0xc003034508 0xc003034520 0xc003034538] [0xc003034508 0xc003034520 0xc003034538] [0xc003034518 0xc003034530] [0x10efe30 0x10efe30] 0xc003725f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:30:09.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:30:09.507: INFO: rc: 1
Feb  6 04:30:09.507: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d65380 exit status 1 <nil> <nil> true [0xc003034540 0xc003034558 0xc003034570] [0xc003034540 0xc003034558 0xc003034570] [0xc003034550 0xc003034568] [0x10efe30 0x10efe30] 0xc002aa45a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:30:19.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:30:19.594: INFO: rc: 1
Feb  6 04:30:19.594: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d65740 exit status 1 <nil> <nil> true [0xc003034578 0xc003034590 0xc0030345a8] [0xc003034578 0xc003034590 0xc0030345a8] [0xc003034588 0xc0030345a0] [0x10efe30 0x10efe30] 0xc002aa4de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:30:29.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:30:29.678: INFO: rc: 1
Feb  6 04:30:29.678: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d65ce0 exit status 1 <nil> <nil> true [0xc0030345b0 0xc0030345c8 0xc0030345e0] [0xc0030345b0 0xc0030345c8 0xc0030345e0] [0xc0030345c0 0xc0030345d8] [0x10efe30 0x10efe30] 0xc002aa54a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:30:39.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:30:39.764: INFO: rc: 1
Feb  6 04:30:39.764: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00355a7e0 exit status 1 <nil> <nil> true [0xc0033c8520 0xc0033c8538 0xc0033c8550] [0xc0033c8520 0xc0033c8538 0xc0033c8550] [0xc0033c8530 0xc0033c8548] [0x10efe30 0x10efe30] 0xc00332e840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:30:49.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:30:49.848: INFO: rc: 1
Feb  6 04:30:49.848: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00295e0c0 exit status 1 <nil> <nil> true [0xc0030345e8 0xc003034600 0xc003034618] [0xc0030345e8 0xc003034600 0xc003034618] [0xc0030345f8 0xc003034610] [0x10efe30 0x10efe30] 0xc002aa5c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:30:59.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:30:59.933: INFO: rc: 1
Feb  6 04:30:59.933: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00295e540 exit status 1 <nil> <nil> true [0xc003034620 0xc003034638 0xc003034650] [0xc003034620 0xc003034638 0xc003034650] [0xc003034630 0xc003034648] [0x10efe30 0x10efe30] 0xc002518300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:31:09.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:31:10.022: INFO: rc: 1
Feb  6 04:31:10.022: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00295e9c0 exit status 1 <nil> <nil> true [0xc003034658 0xc003034670 0xc003034688] [0xc003034658 0xc003034670 0xc003034688] [0xc003034668 0xc003034680] [0x10efe30 0x10efe30] 0xc0025188a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:31:20.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:31:20.127: INFO: rc: 1
Feb  6 04:31:20.127: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d64360 exit status 1 <nil> <nil> true [0xc0007aed40 0xc0007aefe8 0xc0007af0f8] [0xc0007aed40 0xc0007aefe8 0xc0007af0f8] [0xc0007aef48 0xc0007af0d8] [0x10efe30 0x10efe30] 0xc002aa45a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:31:30.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:31:30.217: INFO: rc: 1
Feb  6 04:31:30.218: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d64a50 exit status 1 <nil> <nil> true [0xc0007af150 0xc0007af290 0xc0007af398] [0xc0007af150 0xc0007af290 0xc0007af398] [0xc0007af230 0xc0007af310] [0x10efe30 0x10efe30] 0xc002aa4de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:31:40.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:31:40.307: INFO: rc: 1
Feb  6 04:31:40.307: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d64e10 exit status 1 <nil> <nil> true [0xc0007af3d8 0xc0007af4a8 0xc0007af610] [0xc0007af3d8 0xc0007af4a8 0xc0007af610] [0xc0007af480 0xc0007af540] [0x10efe30 0x10efe30] 0xc002aa54a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:31:50.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:31:50.395: INFO: rc: 1
Feb  6 04:31:50.395: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00302e3c0 exit status 1 <nil> <nil> true [0xc003034018 0xc003034058 0xc003034090] [0xc003034018 0xc003034058 0xc003034090] [0xc003034048 0xc003034078] [0x10efe30 0x10efe30] 0xc0037242a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:32:00.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:32:00.483: INFO: rc: 1
Feb  6 04:32:00.483: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d65200 exit status 1 <nil> <nil> true [0xc0007af638 0xc0007af780 0xc0007af7f8] [0xc0007af638 0xc0007af780 0xc0007af7f8] [0xc0007af6a0 0xc0007af7a8] [0x10efe30 0x10efe30] 0xc002aa5c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:32:10.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:32:10.568: INFO: rc: 1
Feb  6 04:32:10.568: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d655f0 exit status 1 <nil> <nil> true [0xc0007af880 0xc0007af970 0xc0007af9f8] [0xc0007af880 0xc0007af970 0xc0007af9f8] [0xc0007af960 0xc0007af9c0] [0x10efe30 0x10efe30] 0xc00287d260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:32:20.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:32:20.652: INFO: rc: 1
Feb  6 04:32:20.653: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d659b0 exit status 1 <nil> <nil> true [0xc0007afa60 0xc0007afaa0 0xc0007afb80] [0xc0007afa60 0xc0007afaa0 0xc0007afb80] [0xc0007afa90 0xc0007afb70] [0x10efe30 0x10efe30] 0xc00570a240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:32:30.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:32:30.737: INFO: rc: 1
Feb  6 04:32:30.737: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00302e870 exit status 1 <nil> <nil> true [0xc0030340a0 0xc0030340f0 0xc003034120] [0xc0030340a0 0xc0030340f0 0xc003034120] [0xc0030340d0 0xc003034110] [0x10efe30 0x10efe30] 0xc003724660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:32:40.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:32:40.825: INFO: rc: 1
Feb  6 04:32:40.825: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00302ec60 exit status 1 <nil> <nil> true [0xc003034138 0xc003034170 0xc0030341b0] [0xc003034138 0xc003034170 0xc0030341b0] [0xc003034160 0xc003034190] [0x10efe30 0x10efe30] 0xc0037249c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:32:50.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:32:50.954: INFO: rc: 1
Feb  6 04:32:50.954: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003436000 exit status 1 <nil> <nil> true [0xc0007afb98 0xc0007afc68 0xc0007afd38] [0xc0007afb98 0xc0007afc68 0xc0007afd38] [0xc0007afc00 0xc0007afd28] [0x10efe30 0x10efe30] 0xc00570a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:33:00.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:33:01.045: INFO: rc: 1
Feb  6 04:33:01.045: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00302f050 exit status 1 <nil> <nil> true [0xc0030341c0 0xc0030341f8 0xc003034228] [0xc0030341c0 0xc0030341f8 0xc003034228] [0xc0030341e8 0xc003034218] [0x10efe30 0x10efe30] 0xc003724d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:33:11.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:33:11.140: INFO: rc: 1
Feb  6 04:33:11.140: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00302f440 exit status 1 <nil> <nil> true [0xc003034248 0xc003034278 0xc0030342c0] [0xc003034248 0xc003034278 0xc0030342c0] [0xc003034268 0xc003034298] [0x10efe30 0x10efe30] 0xc003725080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:33:21.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:33:21.224: INFO: rc: 1
Feb  6 04:33:21.224: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d64390 exit status 1 <nil> <nil> true [0xc003034028 0xc003034068 0xc0030340a0] [0xc003034028 0xc003034068 0xc0030340a0] [0xc003034058 0xc003034090] [0x10efe30 0x10efe30] 0xc002aa4000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:33:31.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:33:31.312: INFO: rc: 1
Feb  6 04:33:31.312: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d64ab0 exit status 1 <nil> <nil> true [0xc0030340c0 0xc003034100 0xc003034138] [0xc0030340c0 0xc003034100 0xc003034138] [0xc0030340f0 0xc003034120] [0x10efe30 0x10efe30] 0xc002aa4720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:33:41.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:33:41.397: INFO: rc: 1
Feb  6 04:33:41.397: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d64e70 exit status 1 <nil> <nil> true [0xc003034148 0xc003034180 0xc0030341c0] [0xc003034148 0xc003034180 0xc0030341c0] [0xc003034170 0xc0030341b0] [0x10efe30 0x10efe30] 0xc002aa4f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:33:51.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:33:51.484: INFO: rc: 1
Feb  6 04:33:51.484: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d65230 exit status 1 <nil> <nil> true [0xc0030341d0 0xc003034208 0xc003034248] [0xc0030341d0 0xc003034208 0xc003034248] [0xc0030341f8 0xc003034228] [0x10efe30 0x10efe30] 0xc002aa56e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:34:01.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:34:01.594: INFO: rc: 1
Feb  6 04:34:01.594: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d65620 exit status 1 <nil> <nil> true [0xc003034258 0xc003034288 0xc0030342d0] [0xc003034258 0xc003034288 0xc0030342d0] [0xc003034278 0xc0030342c0] [0x10efe30 0x10efe30] 0xc002aa5da0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:34:11.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:34:11.684: INFO: rc: 1
Feb  6 04:34:11.684: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002d659e0 exit status 1 <nil> <nil> true [0xc0030342e0 0xc003034310 0xc003034350] [0xc0030342e0 0xc003034310 0xc003034350] [0xc003034300 0xc003034348] [0x10efe30 0x10efe30] 0xc003724240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:34:21.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:34:21.769: INFO: rc: 1
Feb  6 04:34:21.769: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00302e480 exit status 1 <nil> <nil> true [0xc0007aeca0 0xc0007aef48 0xc0007af0d8] [0xc0007aeca0 0xc0007aef48 0xc0007af0d8] [0xc0007aee90 0xc0007af030] [0x10efe30 0x10efe30] 0xc00570a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:34:31.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:34:31.861: INFO: rc: 1
Feb  6 04:34:31.861: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00302e8d0 exit status 1 <nil> <nil> true [0xc0007af0f8 0xc0007af230 0xc0007af310] [0xc0007af0f8 0xc0007af230 0xc0007af310] [0xc0007af1b0 0xc0007af2b8] [0x10efe30 0x10efe30] 0xc00570a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:34:41.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:34:41.945: INFO: rc: 1
Feb  6 04:34:41.945: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00302ecf0 exit status 1 <nil> <nil> true [0xc0007af398 0xc0007af480 0xc0007af540] [0xc0007af398 0xc0007af480 0xc0007af540] [0xc0007af418 0xc0007af508] [0x10efe30 0x10efe30] 0xc00570a9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 04:34:51.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-9731 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:34:52.037: INFO: rc: 1
Feb  6 04:34:52.037: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Feb  6 04:34:52.037: INFO: Scaling statefulset ss to 0
Feb  6 04:34:52.042: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 04:34:52.043: INFO: Deleting all statefulset in ns statefulset-9731
Feb  6 04:34:52.045: INFO: Scaling statefulset ss to 0
Feb  6 04:34:52.050: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 04:34:52.051: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:34:52.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9731" for this suite.
Feb  6 04:34:58.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:34:58.140: INFO: namespace statefulset-9731 deletion completed in 6.077205416s

• [SLOW TEST:360.723 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:34:58.140: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 04:34:58.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-616'
Feb  6 04:34:58.365: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 04:34:58.365: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Feb  6 04:34:58.438: INFO: scanned /root for discovery docs: <nil>
Feb  6 04:34:58.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-616'
Feb  6 04:35:14.266: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  6 04:35:14.266: INFO: stdout: "Created e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c\nScaling up e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Feb  6 04:35:14.266: INFO: stdout: "Created e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c\nScaling up e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Feb  6 04:35:14.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-616'
Feb  6 04:35:14.356: INFO: stderr: ""
Feb  6 04:35:14.356: INFO: stdout: "e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c-frqp5 "
Feb  6 04:35:14.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c-frqp5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-616'
Feb  6 04:35:14.439: INFO: stderr: ""
Feb  6 04:35:14.439: INFO: stdout: "true"
Feb  6 04:35:14.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c-frqp5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-616'
Feb  6 04:35:14.532: INFO: stderr: ""
Feb  6 04:35:14.532: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Feb  6 04:35:14.532: INFO: e2e-test-httpd-rc-e779f85f76a75433d5464979c3383d0c-frqp5 is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Feb  6 04:35:14.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete rc e2e-test-httpd-rc --namespace=kubectl-616'
Feb  6 04:35:14.623: INFO: stderr: ""
Feb  6 04:35:14.623: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:35:14.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-616" for this suite.
Feb  6 04:35:26.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:35:26.681: INFO: namespace kubectl-616 deletion completed in 12.053098901s

• [SLOW TEST:28.541 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:35:26.681: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7382
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Feb  6 04:35:26.812: INFO: Waiting up to 5m0s for pod "client-containers-05b8b7e1-d85e-431a-9493-f006649f5c52" in namespace "containers-7382" to be "success or failure"
Feb  6 04:35:26.814: INFO: Pod "client-containers-05b8b7e1-d85e-431a-9493-f006649f5c52": Phase="Pending", Reason="", readiness=false. Elapsed: 1.555269ms
Feb  6 04:35:28.816: INFO: Pod "client-containers-05b8b7e1-d85e-431a-9493-f006649f5c52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003836962s
STEP: Saw pod success
Feb  6 04:35:28.816: INFO: Pod "client-containers-05b8b7e1-d85e-431a-9493-f006649f5c52" satisfied condition "success or failure"
Feb  6 04:35:28.817: INFO: Trying to get logs from node aks-1-3 pod client-containers-05b8b7e1-d85e-431a-9493-f006649f5c52 container test-container: <nil>
STEP: delete the pod
Feb  6 04:35:28.835: INFO: Waiting for pod client-containers-05b8b7e1-d85e-431a-9493-f006649f5c52 to disappear
Feb  6 04:35:28.837: INFO: Pod client-containers-05b8b7e1-d85e-431a-9493-f006649f5c52 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:35:28.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7382" for this suite.
Feb  6 04:35:34.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:35:34.897: INFO: namespace containers-7382 deletion completed in 6.057629504s

• [SLOW TEST:8.216 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:35:34.897: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4562
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-3f938fb7-a621-4667-a861-dc38c0f22bbe in namespace container-probe-4562
Feb  6 04:35:37.034: INFO: Started pod liveness-3f938fb7-a621-4667-a861-dc38c0f22bbe in namespace container-probe-4562
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 04:35:37.035: INFO: Initial restart count of pod liveness-3f938fb7-a621-4667-a861-dc38c0f22bbe is 0
Feb  6 04:35:51.054: INFO: Restart count of pod container-probe-4562/liveness-3f938fb7-a621-4667-a861-dc38c0f22bbe is now 1 (14.018697397s elapsed)
Feb  6 04:36:11.077: INFO: Restart count of pod container-probe-4562/liveness-3f938fb7-a621-4667-a861-dc38c0f22bbe is now 2 (34.042198314s elapsed)
Feb  6 04:36:31.105: INFO: Restart count of pod container-probe-4562/liveness-3f938fb7-a621-4667-a861-dc38c0f22bbe is now 3 (54.070049155s elapsed)
Feb  6 04:36:51.271: INFO: Restart count of pod container-probe-4562/liveness-3f938fb7-a621-4667-a861-dc38c0f22bbe is now 4 (1m14.236269933s elapsed)
Feb  6 04:37:53.376: INFO: Restart count of pod container-probe-4562/liveness-3f938fb7-a621-4667-a861-dc38c0f22bbe is now 5 (2m16.341060698s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:37:53.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4562" for this suite.
Feb  6 04:37:59.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:37:59.447: INFO: namespace container-probe-4562 deletion completed in 6.062776175s

• [SLOW TEST:144.549 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:37:59.447: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6261
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 04:38:00.116: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb  6 04:38:02.121: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716560680, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716560680, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716560680, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716560680, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 04:38:05.127: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:38:05.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6261" for this suite.
Feb  6 04:38:11.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:38:11.322: INFO: namespace webhook-6261 deletion completed in 6.054630451s
STEP: Destroying namespace "webhook-6261-markers" for this suite.
Feb  6 04:38:17.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:38:17.380: INFO: namespace webhook-6261-markers deletion completed in 6.057668323s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.941 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:38:17.388: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5224
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:38:17.512: INFO: Creating deployment "test-recreate-deployment"
Feb  6 04:38:17.514: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb  6 04:38:17.529: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb  6 04:38:19.533: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb  6 04:38:19.534: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb  6 04:38:19.577: INFO: Updating deployment test-recreate-deployment
Feb  6 04:38:19.577: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb  6 04:38:19.667: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5224 /apis/apps/v1/namespaces/deployment-5224/deployments/test-recreate-deployment a1e0ecae-dd05-4fbf-a1c1-f1907f1e3199 1798581 2 2020-02-06 04:38:17 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001d04db8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-02-06 04:38:19 +0000 UTC,LastTransitionTime:2020-02-06 04:38:19 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-02-06 04:38:19 +0000 UTC,LastTransitionTime:2020-02-06 04:38:17 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Feb  6 04:38:19.669: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-5224 /apis/apps/v1/namespaces/deployment-5224/replicasets/test-recreate-deployment-5f94c574ff c24b5c52-4b20-4fa5-9af3-73574e2363b5 1798578 1 2020-02-06 04:38:19 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment a1e0ecae-dd05-4fbf-a1c1-f1907f1e3199 0xc00261de47 0xc00261de48}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00261dea8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 04:38:19.669: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb  6 04:38:19.670: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-5224 /apis/apps/v1/namespaces/deployment-5224/replicasets/test-recreate-deployment-68fc85c7bb de41db15-c6c6-4b4a-9b36-db967d8ee954 1798570 2 2020-02-06 04:38:17 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment a1e0ecae-dd05-4fbf-a1c1-f1907f1e3199 0xc00261df17 0xc00261df18}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00261df78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 04:38:19.672: INFO: Pod "test-recreate-deployment-5f94c574ff-79zm5" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-79zm5 test-recreate-deployment-5f94c574ff- deployment-5224 /api/v1/namespaces/deployment-5224/pods/test-recreate-deployment-5f94c574ff-79zm5 6d98c16e-b5da-47b1-9142-7439cf95b878 1798582 0 2020-02-06 04:38:19 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff c24b5c52-4b20-4fa5-9af3-73574e2363b5 0xc001d05187 0xc001d05188}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tq5wj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tq5wj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tq5wj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:38:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:38:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:38:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:38:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:38:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.78,PodIP:,StartTime:2020-02-06 04:38:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:38:19.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5224" for this suite.
Feb  6 04:38:25.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:38:25.748: INFO: namespace deployment-5224 deletion completed in 6.07296509s

• [SLOW TEST:8.360 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:38:25.748: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7958
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:38:41.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7958" for this suite.
Feb  6 04:38:47.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:38:47.967: INFO: namespace resourcequota-7958 deletion completed in 6.056381609s

• [SLOW TEST:22.220 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:38:47.967: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2257
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2257
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-2257
I0206 04:38:48.143610      20 runners.go:184] Created replication controller with name: externalname-service, namespace: services-2257, replica count: 2
I0206 04:38:51.195825      20 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 04:38:51.195: INFO: Creating new exec pod
Feb  6 04:38:54.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-2257 execpoddpz4t -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb  6 04:38:54.577: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb  6 04:38:54.577: INFO: stdout: ""
Feb  6 04:38:54.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-2257 execpoddpz4t -- /bin/sh -x -c nc -zv -t -w 2 10.96.0.14 80'
Feb  6 04:38:54.751: INFO: stderr: "+ nc -zv -t -w 2 10.96.0.14 80\nConnection to 10.96.0.14 80 port [tcp/http] succeeded!\n"
Feb  6 04:38:54.751: INFO: stdout: ""
Feb  6 04:38:54.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-2257 execpoddpz4t -- /bin/sh -x -c nc -zv -t -w 2 192.168.27.78 30865'
Feb  6 04:38:54.940: INFO: stderr: "+ nc -zv -t -w 2 192.168.27.78 30865\nConnection to 192.168.27.78 30865 port [tcp/30865] succeeded!\n"
Feb  6 04:38:54.940: INFO: stdout: ""
Feb  6 04:38:54.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-2257 execpoddpz4t -- /bin/sh -x -c nc -zv -t -w 2 192.168.27.81 30865'
Feb  6 04:38:55.105: INFO: stderr: "+ nc -zv -t -w 2 192.168.27.81 30865\nConnection to 192.168.27.81 30865 port [tcp/30865] succeeded!\n"
Feb  6 04:38:55.105: INFO: stdout: ""
Feb  6 04:38:55.105: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:38:55.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2257" for this suite.
Feb  6 04:39:01.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:39:01.187: INFO: namespace services-2257 deletion completed in 6.063069041s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.220 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:39:01.187: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9689
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-b9cd5656-63ed-4438-b021-b64bcf5b90ad
STEP: Creating a pod to test consume secrets
Feb  6 04:39:01.319: INFO: Waiting up to 5m0s for pod "pod-secrets-e5b5e750-7ff4-4460-ba58-80372cf30990" in namespace "secrets-9689" to be "success or failure"
Feb  6 04:39:01.321: INFO: Pod "pod-secrets-e5b5e750-7ff4-4460-ba58-80372cf30990": Phase="Pending", Reason="", readiness=false. Elapsed: 2.215555ms
Feb  6 04:39:03.324: INFO: Pod "pod-secrets-e5b5e750-7ff4-4460-ba58-80372cf30990": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00464235s
STEP: Saw pod success
Feb  6 04:39:03.324: INFO: Pod "pod-secrets-e5b5e750-7ff4-4460-ba58-80372cf30990" satisfied condition "success or failure"
Feb  6 04:39:03.325: INFO: Trying to get logs from node aks-1-3 pod pod-secrets-e5b5e750-7ff4-4460-ba58-80372cf30990 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 04:39:03.341: INFO: Waiting for pod pod-secrets-e5b5e750-7ff4-4460-ba58-80372cf30990 to disappear
Feb  6 04:39:03.343: INFO: Pod pod-secrets-e5b5e750-7ff4-4460-ba58-80372cf30990 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:39:03.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9689" for this suite.
Feb  6 04:39:09.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:39:09.398: INFO: namespace secrets-9689 deletion completed in 6.053049886s

• [SLOW TEST:8.211 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:39:09.398: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2189
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 04:39:09.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-2189'
Feb  6 04:39:09.631: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 04:39:09.631: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Feb  6 04:39:11.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete deployment e2e-test-httpd-deployment --namespace=kubectl-2189'
Feb  6 04:39:11.729: INFO: stderr: ""
Feb  6 04:39:11.729: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:39:11.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2189" for this suite.
Feb  6 04:40:37.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:40:37.789: INFO: namespace kubectl-2189 deletion completed in 1m26.057211752s

• [SLOW TEST:88.391 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:40:37.789: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7656
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-md5p
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 04:40:37.942: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-md5p" in namespace "subpath-7656" to be "success or failure"
Feb  6 04:40:37.946: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Pending", Reason="", readiness=false. Elapsed: 4.269657ms
Feb  6 04:40:39.948: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Running", Reason="", readiness=true. Elapsed: 2.006625526s
Feb  6 04:40:41.950: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Running", Reason="", readiness=true. Elapsed: 4.008375095s
Feb  6 04:40:43.953: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Running", Reason="", readiness=true. Elapsed: 6.0109963s
Feb  6 04:40:45.955: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Running", Reason="", readiness=true. Elapsed: 8.013157209s
Feb  6 04:40:47.958: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Running", Reason="", readiness=true. Elapsed: 10.015729028s
Feb  6 04:40:49.960: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Running", Reason="", readiness=true. Elapsed: 12.018215021s
Feb  6 04:40:51.962: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Running", Reason="", readiness=true. Elapsed: 14.019989085s
Feb  6 04:40:53.964: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Running", Reason="", readiness=true. Elapsed: 16.022548799s
Feb  6 04:40:55.967: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Running", Reason="", readiness=true. Elapsed: 18.024687734s
Feb  6 04:40:57.969: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Running", Reason="", readiness=true. Elapsed: 20.027080386s
Feb  6 04:40:59.971: INFO: Pod "pod-subpath-test-configmap-md5p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.029422259s
STEP: Saw pod success
Feb  6 04:40:59.971: INFO: Pod "pod-subpath-test-configmap-md5p" satisfied condition "success or failure"
Feb  6 04:40:59.973: INFO: Trying to get logs from node aks-1-3 pod pod-subpath-test-configmap-md5p container test-container-subpath-configmap-md5p: <nil>
STEP: delete the pod
Feb  6 04:40:59.993: INFO: Waiting for pod pod-subpath-test-configmap-md5p to disappear
Feb  6 04:40:59.995: INFO: Pod pod-subpath-test-configmap-md5p no longer exists
STEP: Deleting pod pod-subpath-test-configmap-md5p
Feb  6 04:40:59.995: INFO: Deleting pod "pod-subpath-test-configmap-md5p" in namespace "subpath-7656"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:40:59.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7656" for this suite.
Feb  6 04:41:06.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:41:06.068: INFO: namespace subpath-7656 deletion completed in 6.069204805s

• [SLOW TEST:28.278 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:41:06.083: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9425
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:41:12.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9425" for this suite.
Feb  6 04:41:18.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:41:18.364: INFO: namespace job-9425 deletion completed in 6.051876004s

• [SLOW TEST:12.281 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:41:18.364: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4209
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 04:41:18.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4209'
Feb  6 04:41:18.597: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 04:41:18.597: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Feb  6 04:41:18.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete deployment e2e-test-httpd-deployment --namespace=kubectl-4209'
Feb  6 04:41:18.707: INFO: stderr: ""
Feb  6 04:41:18.707: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:41:18.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4209" for this suite.
Feb  6 04:41:46.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:41:46.767: INFO: namespace kubectl-4209 deletion completed in 28.05722279s

• [SLOW TEST:28.403 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:41:46.767: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1499
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:41:48.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1499" for this suite.
Feb  6 04:42:32.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:42:32.996: INFO: namespace kubelet-test-1499 deletion completed in 44.052340452s

• [SLOW TEST:46.229 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:42:32.996: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9878
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Feb  6 04:42:33.127: INFO: Waiting up to 5m0s for pod "var-expansion-80539513-4f79-464b-b5a7-aa4868b2fb70" in namespace "var-expansion-9878" to be "success or failure"
Feb  6 04:42:33.130: INFO: Pod "var-expansion-80539513-4f79-464b-b5a7-aa4868b2fb70": Phase="Pending", Reason="", readiness=false. Elapsed: 3.208299ms
Feb  6 04:42:35.132: INFO: Pod "var-expansion-80539513-4f79-464b-b5a7-aa4868b2fb70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005609922s
STEP: Saw pod success
Feb  6 04:42:35.132: INFO: Pod "var-expansion-80539513-4f79-464b-b5a7-aa4868b2fb70" satisfied condition "success or failure"
Feb  6 04:42:35.134: INFO: Trying to get logs from node aks-1-3 pod var-expansion-80539513-4f79-464b-b5a7-aa4868b2fb70 container dapi-container: <nil>
STEP: delete the pod
Feb  6 04:42:35.149: INFO: Waiting for pod var-expansion-80539513-4f79-464b-b5a7-aa4868b2fb70 to disappear
Feb  6 04:42:35.151: INFO: Pod var-expansion-80539513-4f79-464b-b5a7-aa4868b2fb70 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:42:35.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9878" for this suite.
Feb  6 04:42:41.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:42:41.209: INFO: namespace var-expansion-9878 deletion completed in 6.055512905s

• [SLOW TEST:8.213 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:42:41.209: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9236
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:42:48.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9236" for this suite.
Feb  6 04:42:54.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:42:54.419: INFO: namespace resourcequota-9236 deletion completed in 6.07665701s

• [SLOW TEST:13.210 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:42:54.421: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8998
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8998
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb  6 04:42:54.564: INFO: Found 0 stateful pods, waiting for 3
Feb  6 04:43:04.566: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 04:43:04.566: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 04:43:04.566: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=false
Feb  6 04:43:14.566: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 04:43:14.566: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 04:43:14.566: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 04:43:14.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8998 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 04:43:14.725: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 04:43:14.725: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 04:43:14.725: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb  6 04:43:24.749: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb  6 04:43:34.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8998 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:43:34.927: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 04:43:34.927: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 04:43:34.927: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 04:43:44.940: INFO: Waiting for StatefulSet statefulset-8998/ss2 to complete update
Feb  6 04:43:44.940: INFO: Waiting for Pod statefulset-8998/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 04:43:44.940: INFO: Waiting for Pod statefulset-8998/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 04:43:54.944: INFO: Waiting for StatefulSet statefulset-8998/ss2 to complete update
Feb  6 04:43:54.944: INFO: Waiting for Pod statefulset-8998/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 04:43:54.944: INFO: Waiting for Pod statefulset-8998/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 04:44:04.944: INFO: Waiting for StatefulSet statefulset-8998/ss2 to complete update
Feb  6 04:44:04.944: INFO: Waiting for Pod statefulset-8998/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 04:44:04.944: INFO: Waiting for Pod statefulset-8998/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 04:44:14.944: INFO: Waiting for StatefulSet statefulset-8998/ss2 to complete update
Feb  6 04:44:14.944: INFO: Waiting for Pod statefulset-8998/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 04:44:24.944: INFO: Waiting for StatefulSet statefulset-8998/ss2 to complete update
Feb  6 04:44:24.944: INFO: Waiting for Pod statefulset-8998/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 04:44:34.944: INFO: Waiting for StatefulSet statefulset-8998/ss2 to complete update
STEP: Rolling back to a previous revision
Feb  6 04:44:44.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8998 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 04:44:45.115: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 04:44:45.115: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 04:44:45.115: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 04:44:55.139: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb  6 04:45:05.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8998 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 04:45:05.319: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 04:45:05.319: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 04:45:05.319: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 04:45:15.331: INFO: Waiting for StatefulSet statefulset-8998/ss2 to complete update
Feb  6 04:45:15.331: INFO: Waiting for Pod statefulset-8998/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb  6 04:45:15.331: INFO: Waiting for Pod statefulset-8998/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb  6 04:45:25.336: INFO: Waiting for StatefulSet statefulset-8998/ss2 to complete update
Feb  6 04:45:25.336: INFO: Waiting for Pod statefulset-8998/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb  6 04:45:25.336: INFO: Waiting for Pod statefulset-8998/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb  6 04:45:35.335: INFO: Waiting for StatefulSet statefulset-8998/ss2 to complete update
Feb  6 04:45:35.335: INFO: Waiting for Pod statefulset-8998/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb  6 04:45:45.335: INFO: Waiting for StatefulSet statefulset-8998/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 04:45:55.335: INFO: Deleting all statefulset in ns statefulset-8998
Feb  6 04:45:55.337: INFO: Scaling statefulset ss2 to 0
Feb  6 04:46:25.352: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 04:46:25.353: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:46:25.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8998" for this suite.
Feb  6 04:46:31.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:46:31.419: INFO: namespace statefulset-8998 deletion completed in 6.053259557s

• [SLOW TEST:216.998 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:46:31.419: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2669
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Feb  6 04:46:31.548: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-529150080 proxy --unix-socket=/tmp/kubectl-proxy-unix204884667/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:46:31.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2669" for this suite.
Feb  6 04:46:37.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:46:37.730: INFO: namespace kubectl-2669 deletion completed in 6.056245436s

• [SLOW TEST:6.311 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:46:37.731: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7518
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-d96080d5-14d8-4969-be53-200db12a74d9
STEP: Creating a pod to test consume secrets
Feb  6 04:46:37.864: INFO: Waiting up to 5m0s for pod "pod-secrets-2c4a59ce-1625-4649-8987-16120ce56dc7" in namespace "secrets-7518" to be "success or failure"
Feb  6 04:46:37.866: INFO: Pod "pod-secrets-2c4a59ce-1625-4649-8987-16120ce56dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.973491ms
Feb  6 04:46:39.869: INFO: Pod "pod-secrets-2c4a59ce-1625-4649-8987-16120ce56dc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004463124s
STEP: Saw pod success
Feb  6 04:46:39.869: INFO: Pod "pod-secrets-2c4a59ce-1625-4649-8987-16120ce56dc7" satisfied condition "success or failure"
Feb  6 04:46:39.870: INFO: Trying to get logs from node aks-1-3 pod pod-secrets-2c4a59ce-1625-4649-8987-16120ce56dc7 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 04:46:39.885: INFO: Waiting for pod pod-secrets-2c4a59ce-1625-4649-8987-16120ce56dc7 to disappear
Feb  6 04:46:39.886: INFO: Pod pod-secrets-2c4a59ce-1625-4649-8987-16120ce56dc7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:46:39.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7518" for this suite.
Feb  6 04:46:45.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:46:45.948: INFO: namespace secrets-7518 deletion completed in 6.059256826s

• [SLOW TEST:8.217 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:46:45.949: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-8638
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Feb  6 04:46:46.146: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8638" to be "success or failure"
Feb  6 04:46:46.148: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.612174ms
Feb  6 04:46:48.184: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037900261s
STEP: Saw pod success
Feb  6 04:46:48.184: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb  6 04:46:48.185: INFO: Trying to get logs from node aks-1-4 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb  6 04:46:48.201: INFO: Waiting for pod pod-host-path-test to disappear
Feb  6 04:46:48.204: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:46:48.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-8638" for this suite.
Feb  6 04:46:54.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:46:54.264: INFO: namespace hostpath-8638 deletion completed in 6.056795107s

• [SLOW TEST:8.315 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:46:54.265: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2528
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 04:46:54.396: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c745e063-4904-4a83-8a6d-dd16d1908f1a" in namespace "downward-api-2528" to be "success or failure"
Feb  6 04:46:54.398: INFO: Pod "downwardapi-volume-c745e063-4904-4a83-8a6d-dd16d1908f1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.164591ms
Feb  6 04:46:56.400: INFO: Pod "downwardapi-volume-c745e063-4904-4a83-8a6d-dd16d1908f1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004269878s
STEP: Saw pod success
Feb  6 04:46:56.400: INFO: Pod "downwardapi-volume-c745e063-4904-4a83-8a6d-dd16d1908f1a" satisfied condition "success or failure"
Feb  6 04:46:56.402: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-c745e063-4904-4a83-8a6d-dd16d1908f1a container client-container: <nil>
STEP: delete the pod
Feb  6 04:46:56.416: INFO: Waiting for pod downwardapi-volume-c745e063-4904-4a83-8a6d-dd16d1908f1a to disappear
Feb  6 04:46:56.417: INFO: Pod downwardapi-volume-c745e063-4904-4a83-8a6d-dd16d1908f1a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:46:56.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2528" for this suite.
Feb  6 04:47:02.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:47:02.479: INFO: namespace downward-api-2528 deletion completed in 6.059034455s

• [SLOW TEST:8.214 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:47:02.480: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8973
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-48531d77-cfcb-4179-9cd4-2aca6d44518b in namespace container-probe-8973
Feb  6 04:47:04.618: INFO: Started pod busybox-48531d77-cfcb-4179-9cd4-2aca6d44518b in namespace container-probe-8973
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 04:47:04.619: INFO: Initial restart count of pod busybox-48531d77-cfcb-4179-9cd4-2aca6d44518b is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:51:04.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8973" for this suite.
Feb  6 04:51:10.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:51:10.995: INFO: namespace container-probe-8973 deletion completed in 6.0554704s

• [SLOW TEST:248.516 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:51:10.996: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7278
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb  6 04:51:11.177: INFO: Pod name pod-release: Found 0 pods out of 1
Feb  6 04:51:16.180: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:51:17.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7278" for this suite.
Feb  6 04:51:23.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:51:23.256: INFO: namespace replication-controller-7278 deletion completed in 6.063478941s

• [SLOW TEST:12.260 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:51:23.256: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3964
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Feb  6 04:51:25.392: INFO: Pod pod-hostip-51142d6e-b245-40e8-9919-5e0a1ebfbfcb has hostIP: 192.168.27.81
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:51:25.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3964" for this suite.
Feb  6 04:51:53.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:51:53.451: INFO: namespace pods-3964 deletion completed in 28.05740232s

• [SLOW TEST:30.195 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:51:53.451: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1245
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb  6 04:51:53.577: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:52:13.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1245" for this suite.
Feb  6 04:52:19.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:52:19.902: INFO: namespace crd-publish-openapi-1245 deletion completed in 6.057167004s

• [SLOW TEST:26.451 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:52:19.903: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9906
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 04:52:20.354: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb  6 04:52:22.360: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716561540, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716561540, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716561540, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716561540, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 04:52:25.367: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:52:25.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9906" for this suite.
Feb  6 04:52:31.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:52:31.496: INFO: namespace webhook-9906 deletion completed in 6.08823242s
STEP: Destroying namespace "webhook-9906-markers" for this suite.
Feb  6 04:52:37.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:52:37.552: INFO: namespace webhook-9906-markers deletion completed in 6.056237588s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.657 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:52:37.561: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9674
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9674.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9674.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 04:53:01.761: INFO: DNS probes using dns-9674/dns-test-f31ef538-3bcc-4f33-8d0c-8d82fd038f64 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:53:01.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9674" for this suite.
Feb  6 04:53:07.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:53:07.827: INFO: namespace dns-9674 deletion completed in 6.054128608s

• [SLOW TEST:30.266 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:53:07.827: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6570
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  6 04:53:10.472: INFO: Successfully updated pod "pod-update-1e1eff70-91d5-4688-a0e9-486e8d599624"
STEP: verifying the updated pod is in kubernetes
Feb  6 04:53:10.475: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:53:10.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6570" for this suite.
Feb  6 04:53:22.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:53:22.535: INFO: namespace pods-6570 deletion completed in 12.057299219s

• [SLOW TEST:14.708 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:53:22.535: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2831
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-2831
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 04:53:22.668: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 04:53:42.717: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.198:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2831 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 04:53:42.717: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 04:53:42.829: INFO: Found all expected endpoints: [netserver-0]
Feb  6 04:53:42.831: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.207:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2831 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 04:53:42.831: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 04:53:42.903: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:53:42.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2831" for this suite.
Feb  6 04:53:54.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:53:54.972: INFO: namespace pod-network-test-2831 deletion completed in 12.065847743s

• [SLOW TEST:32.438 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:53:54.973: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8108.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8108.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8108.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8108.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8108.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8108.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8108.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8108.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8108.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8108.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8108.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 124.0.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.0.124_udp@PTR;check="$$(dig +tcp +noall +answer +search 124.0.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.0.124_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8108.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8108.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8108.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8108.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8108.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8108.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8108.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8108.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8108.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8108.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8108.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 124.0.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.0.124_udp@PTR;check="$$(dig +tcp +noall +answer +search 124.0.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.0.124_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 04:54:05.139: INFO: Unable to read wheezy_udp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:05.141: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:05.143: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:05.145: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:05.160: INFO: Unable to read jessie_udp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:05.162: INFO: Unable to read jessie_tcp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:05.164: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:05.166: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:05.177: INFO: Lookups using dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db failed for: [wheezy_udp@dns-test-service.dns-8108.svc.cluster.local wheezy_tcp@dns-test-service.dns-8108.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local jessie_udp@dns-test-service.dns-8108.svc.cluster.local jessie_tcp@dns-test-service.dns-8108.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local]

Feb  6 04:54:10.179: INFO: Unable to read wheezy_udp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:10.181: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:10.183: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:10.185: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:10.199: INFO: Unable to read jessie_udp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:10.201: INFO: Unable to read jessie_tcp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:10.203: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:10.204: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:10.215: INFO: Lookups using dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db failed for: [wheezy_udp@dns-test-service.dns-8108.svc.cluster.local wheezy_tcp@dns-test-service.dns-8108.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local jessie_udp@dns-test-service.dns-8108.svc.cluster.local jessie_tcp@dns-test-service.dns-8108.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local]

Feb  6 04:54:15.277: INFO: Unable to read wheezy_udp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:15.279: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:15.281: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:15.283: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:15.295: INFO: Unable to read jessie_udp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:15.297: INFO: Unable to read jessie_tcp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:15.299: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:15.301: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:15.313: INFO: Lookups using dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db failed for: [wheezy_udp@dns-test-service.dns-8108.svc.cluster.local wheezy_tcp@dns-test-service.dns-8108.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local jessie_udp@dns-test-service.dns-8108.svc.cluster.local jessie_tcp@dns-test-service.dns-8108.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local]

Feb  6 04:54:20.179: INFO: Unable to read wheezy_udp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:20.181: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:20.183: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:20.185: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:20.199: INFO: Unable to read jessie_udp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:20.201: INFO: Unable to read jessie_tcp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:20.203: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:20.204: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:20.216: INFO: Lookups using dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db failed for: [wheezy_udp@dns-test-service.dns-8108.svc.cluster.local wheezy_tcp@dns-test-service.dns-8108.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local jessie_udp@dns-test-service.dns-8108.svc.cluster.local jessie_tcp@dns-test-service.dns-8108.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local]

Feb  6 04:54:25.180: INFO: Unable to read wheezy_udp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:25.182: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:25.184: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:25.186: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:25.202: INFO: Unable to read jessie_udp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:25.204: INFO: Unable to read jessie_tcp@dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:25.206: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:25.208: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local from pod dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db: the server could not find the requested resource (get pods dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db)
Feb  6 04:54:25.220: INFO: Lookups using dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db failed for: [wheezy_udp@dns-test-service.dns-8108.svc.cluster.local wheezy_tcp@dns-test-service.dns-8108.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local jessie_udp@dns-test-service.dns-8108.svc.cluster.local jessie_tcp@dns-test-service.dns-8108.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8108.svc.cluster.local]

Feb  6 04:54:30.219: INFO: DNS probes using dns-8108/dns-test-2bd0706c-5a0b-4f6e-9943-8e6793cf34db succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:54:30.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8108" for this suite.
Feb  6 04:54:36.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:54:36.318: INFO: namespace dns-8108 deletion completed in 6.05432563s

• [SLOW TEST:41.345 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:54:36.318: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6118
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-07a040ff-86a7-4d0f-9ec2-c427ff612223
STEP: Creating a pod to test consume secrets
Feb  6 04:54:36.451: INFO: Waiting up to 5m0s for pod "pod-secrets-6d0604ee-c8fb-463b-b820-d8b318ff7a45" in namespace "secrets-6118" to be "success or failure"
Feb  6 04:54:36.457: INFO: Pod "pod-secrets-6d0604ee-c8fb-463b-b820-d8b318ff7a45": Phase="Pending", Reason="", readiness=false. Elapsed: 5.674777ms
Feb  6 04:54:38.460: INFO: Pod "pod-secrets-6d0604ee-c8fb-463b-b820-d8b318ff7a45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00834418s
STEP: Saw pod success
Feb  6 04:54:38.460: INFO: Pod "pod-secrets-6d0604ee-c8fb-463b-b820-d8b318ff7a45" satisfied condition "success or failure"
Feb  6 04:54:38.461: INFO: Trying to get logs from node aks-1-4 pod pod-secrets-6d0604ee-c8fb-463b-b820-d8b318ff7a45 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 04:54:38.490: INFO: Waiting for pod pod-secrets-6d0604ee-c8fb-463b-b820-d8b318ff7a45 to disappear
Feb  6 04:54:38.497: INFO: Pod pod-secrets-6d0604ee-c8fb-463b-b820-d8b318ff7a45 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:54:38.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6118" for this suite.
Feb  6 04:54:44.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:54:44.600: INFO: namespace secrets-6118 deletion completed in 6.099124575s

• [SLOW TEST:8.282 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:54:44.601: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3172
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-cea9b3c0-ac4d-4636-82af-053085547111
STEP: Creating secret with name s-test-opt-upd-2ddeec6d-cb3c-45b1-af58-9184360859e5
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-cea9b3c0-ac4d-4636-82af-053085547111
STEP: Updating secret s-test-opt-upd-2ddeec6d-cb3c-45b1-af58-9184360859e5
STEP: Creating secret with name s-test-opt-create-ec646146-d0ba-4503-94df-ca9f4e377671
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:54:50.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3172" for this suite.
Feb  6 04:55:12.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:55:12.946: INFO: namespace secrets-3172 deletion completed in 22.064155795s

• [SLOW TEST:28.345 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:55:12.947: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5917
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:55:37.133: INFO: Container started at 2020-02-06 04:55:13 +0000 UTC, pod became ready at 2020-02-06 04:55:36 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:55:37.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5917" for this suite.
Feb  6 04:56:05.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:56:05.188: INFO: namespace container-probe-5917 deletion completed in 28.053082158s

• [SLOW TEST:52.241 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:56:05.188: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7353
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Feb  6 04:56:05.314: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 04:56:09.108: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:56:23.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7353" for this suite.
Feb  6 04:56:29.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:56:29.109: INFO: namespace crd-publish-openapi-7353 deletion completed in 6.078527401s

• [SLOW TEST:23.921 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:56:29.109: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-752
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:56:29.242: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:56:31.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-752" for this suite.
Feb  6 04:57:15.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:57:15.460: INFO: namespace pods-752 deletion completed in 44.052386277s

• [SLOW TEST:46.351 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:57:15.460: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4211
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:57:15.595: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 04:57:15.603: INFO: Number of nodes with available pods: 0
Feb  6 04:57:15.603: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:57:16.608: INFO: Number of nodes with available pods: 0
Feb  6 04:57:16.608: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:57:17.643: INFO: Number of nodes with available pods: 0
Feb  6 04:57:17.643: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:57:18.831: INFO: Number of nodes with available pods: 1
Feb  6 04:57:18.831: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:57:19.608: INFO: Number of nodes with available pods: 2
Feb  6 04:57:19.608: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 04:57:20.608: INFO: Number of nodes with available pods: 3
Feb  6 04:57:20.608: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb  6 04:57:20.723: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:20.723: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:20.723: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:21.733: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:21.733: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:21.733: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:22.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:22.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:22.734: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:23.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:23.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:23.734: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:23.734: INFO: Pod daemon-set-shwtz is not available
Feb  6 04:57:24.733: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:24.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:24.734: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:24.734: INFO: Pod daemon-set-shwtz is not available
Feb  6 04:57:25.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:25.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:25.734: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:25.734: INFO: Pod daemon-set-shwtz is not available
Feb  6 04:57:26.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:26.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:26.734: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:26.734: INFO: Pod daemon-set-shwtz is not available
Feb  6 04:57:27.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:27.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:27.734: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:27.734: INFO: Pod daemon-set-shwtz is not available
Feb  6 04:57:28.733: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:28.733: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:28.733: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:28.733: INFO: Pod daemon-set-shwtz is not available
Feb  6 04:57:29.733: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:29.733: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:29.733: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:29.733: INFO: Pod daemon-set-shwtz is not available
Feb  6 04:57:30.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:30.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:30.734: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:30.734: INFO: Pod daemon-set-shwtz is not available
Feb  6 04:57:31.733: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:31.733: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:31.733: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:31.733: INFO: Pod daemon-set-shwtz is not available
Feb  6 04:57:32.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:32.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:32.734: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:32.734: INFO: Pod daemon-set-shwtz is not available
Feb  6 04:57:33.733: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:33.733: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:33.733: INFO: Wrong image for pod: daemon-set-shwtz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:33.733: INFO: Pod daemon-set-shwtz is not available
Feb  6 04:57:34.735: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:34.735: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:34.735: INFO: Pod daemon-set-wtw4c is not available
Feb  6 04:57:35.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:35.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:35.734: INFO: Pod daemon-set-wtw4c is not available
Feb  6 04:57:36.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:36.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:36.734: INFO: Pod daemon-set-wtw4c is not available
Feb  6 04:57:37.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:37.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:37.734: INFO: Pod daemon-set-wtw4c is not available
Feb  6 04:57:38.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:38.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:38.734: INFO: Pod daemon-set-wtw4c is not available
Feb  6 04:57:39.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:39.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:39.734: INFO: Pod daemon-set-wtw4c is not available
Feb  6 04:57:40.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:40.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:40.734: INFO: Pod daemon-set-wtw4c is not available
Feb  6 04:57:41.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:41.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:41.734: INFO: Pod daemon-set-wtw4c is not available
Feb  6 04:57:42.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:42.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:42.734: INFO: Pod daemon-set-wtw4c is not available
Feb  6 04:57:43.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:43.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:43.734: INFO: Pod daemon-set-wtw4c is not available
Feb  6 04:57:44.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:44.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:45.733: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:45.733: INFO: Pod daemon-set-cxqhr is not available
Feb  6 04:57:45.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:46.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:46.734: INFO: Pod daemon-set-cxqhr is not available
Feb  6 04:57:46.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:47.734: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:47.734: INFO: Pod daemon-set-cxqhr is not available
Feb  6 04:57:47.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:48.865: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:48.865: INFO: Pod daemon-set-cxqhr is not available
Feb  6 04:57:48.865: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:49.733: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:49.733: INFO: Pod daemon-set-cxqhr is not available
Feb  6 04:57:49.733: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:50.733: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:50.733: INFO: Pod daemon-set-cxqhr is not available
Feb  6 04:57:50.733: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:51.733: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:51.734: INFO: Pod daemon-set-cxqhr is not available
Feb  6 04:57:51.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:52.733: INFO: Wrong image for pod: daemon-set-cxqhr. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:52.733: INFO: Pod daemon-set-cxqhr is not available
Feb  6 04:57:52.733: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:53.733: INFO: Pod daemon-set-qjvv9 is not available
Feb  6 04:57:53.733: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:54.734: INFO: Pod daemon-set-qjvv9 is not available
Feb  6 04:57:54.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:55.733: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:56.733: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:56.734: INFO: Pod daemon-set-r7z2d is not available
Feb  6 04:57:57.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:57.734: INFO: Pod daemon-set-r7z2d is not available
Feb  6 04:57:58.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:58.734: INFO: Pod daemon-set-r7z2d is not available
Feb  6 04:57:59.734: INFO: Wrong image for pod: daemon-set-r7z2d. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb  6 04:57:59.734: INFO: Pod daemon-set-r7z2d is not available
Feb  6 04:58:00.735: INFO: Pod daemon-set-j8f2g is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb  6 04:58:00.741: INFO: Number of nodes with available pods: 2
Feb  6 04:58:00.741: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 04:58:01.745: INFO: Number of nodes with available pods: 2
Feb  6 04:58:01.745: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 04:58:02.746: INFO: Number of nodes with available pods: 2
Feb  6 04:58:02.746: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 04:58:03.746: INFO: Number of nodes with available pods: 3
Feb  6 04:58:03.746: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4211, will wait for the garbage collector to delete the pods
Feb  6 04:58:03.809: INFO: Deleting DaemonSet.extensions daemon-set took: 3.611202ms
Feb  6 04:58:04.109: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.260281ms
Feb  6 04:58:13.412: INFO: Number of nodes with available pods: 0
Feb  6 04:58:13.412: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 04:58:13.415: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4211/daemonsets","resourceVersion":"1802044"},"items":null}

Feb  6 04:58:13.416: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4211/pods","resourceVersion":"1802044"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:58:13.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4211" for this suite.
Feb  6 04:58:19.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:58:19.479: INFO: namespace daemonsets-4211 deletion completed in 6.056174983s

• [SLOW TEST:64.019 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:58:19.480: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7404
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:58:19.655: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:58:21.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7404" for this suite.
Feb  6 04:59:05.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:59:05.738: INFO: namespace pods-7404 deletion completed in 44.05569231s

• [SLOW TEST:46.259 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:59:05.738: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7970
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:59:10.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7970" for this suite.
Feb  6 04:59:17.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:59:17.162: INFO: namespace watch-7970 deletion completed in 6.168464847s

• [SLOW TEST:11.423 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:59:17.162: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6040
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  6 04:59:17.293: INFO: Waiting up to 5m0s for pod "pod-b937f108-4987-415e-bd09-0f4d6915c563" in namespace "emptydir-6040" to be "success or failure"
Feb  6 04:59:17.297: INFO: Pod "pod-b937f108-4987-415e-bd09-0f4d6915c563": Phase="Pending", Reason="", readiness=false. Elapsed: 4.245911ms
Feb  6 04:59:19.299: INFO: Pod "pod-b937f108-4987-415e-bd09-0f4d6915c563": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006012291s
STEP: Saw pod success
Feb  6 04:59:19.299: INFO: Pod "pod-b937f108-4987-415e-bd09-0f4d6915c563" satisfied condition "success or failure"
Feb  6 04:59:19.301: INFO: Trying to get logs from node aks-1-3 pod pod-b937f108-4987-415e-bd09-0f4d6915c563 container test-container: <nil>
STEP: delete the pod
Feb  6 04:59:19.315: INFO: Waiting for pod pod-b937f108-4987-415e-bd09-0f4d6915c563 to disappear
Feb  6 04:59:19.317: INFO: Pod pod-b937f108-4987-415e-bd09-0f4d6915c563 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:59:19.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6040" for this suite.
Feb  6 04:59:25.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:59:25.372: INFO: namespace emptydir-6040 deletion completed in 6.052932184s

• [SLOW TEST:8.210 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:59:25.372: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1482
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-d69d440f-31d8-48a9-b07c-8cefa8365acf
STEP: Creating a pod to test consume configMaps
Feb  6 04:59:25.508: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9f83ce4e-88d0-42ff-a2b0-34b902db90db" in namespace "projected-1482" to be "success or failure"
Feb  6 04:59:25.511: INFO: Pod "pod-projected-configmaps-9f83ce4e-88d0-42ff-a2b0-34b902db90db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.499278ms
Feb  6 04:59:27.513: INFO: Pod "pod-projected-configmaps-9f83ce4e-88d0-42ff-a2b0-34b902db90db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004848805s
STEP: Saw pod success
Feb  6 04:59:27.513: INFO: Pod "pod-projected-configmaps-9f83ce4e-88d0-42ff-a2b0-34b902db90db" satisfied condition "success or failure"
Feb  6 04:59:27.514: INFO: Trying to get logs from node aks-1-3 pod pod-projected-configmaps-9f83ce4e-88d0-42ff-a2b0-34b902db90db container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 04:59:27.526: INFO: Waiting for pod pod-projected-configmaps-9f83ce4e-88d0-42ff-a2b0-34b902db90db to disappear
Feb  6 04:59:27.528: INFO: Pod pod-projected-configmaps-9f83ce4e-88d0-42ff-a2b0-34b902db90db no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:59:27.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1482" for this suite.
Feb  6 04:59:33.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:59:33.583: INFO: namespace projected-1482 deletion completed in 6.052981329s

• [SLOW TEST:8.211 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:59:33.584: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-537
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 04:59:34.011: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb  6 04:59:36.017: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716561974, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716561974, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716561974, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716561974, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 04:59:39.030: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Feb  6 04:59:39.070: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 04:59:39.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-537" for this suite.
Feb  6 04:59:45.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:59:45.137: INFO: namespace webhook-537 deletion completed in 6.054649959s
STEP: Destroying namespace "webhook-537-markers" for this suite.
Feb  6 04:59:51.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 04:59:51.194: INFO: namespace webhook-537-markers deletion completed in 6.056575757s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.617 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 04:59:51.201: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4811
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 04:59:51.347: INFO: Creating deployment "webserver-deployment"
Feb  6 04:59:51.350: INFO: Waiting for observed generation 1
Feb  6 04:59:53.354: INFO: Waiting for all required pods to come up
Feb  6 04:59:53.357: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb  6 05:00:13.366: INFO: Waiting for deployment "webserver-deployment" to complete
Feb  6 05:00:13.369: INFO: Updating deployment "webserver-deployment" with a non-existent image
Feb  6 05:00:13.372: INFO: Updating deployment webserver-deployment
Feb  6 05:00:13.372: INFO: Waiting for observed generation 2
Feb  6 05:00:15.377: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb  6 05:00:15.402: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb  6 05:00:15.403: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb  6 05:00:15.407: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb  6 05:00:15.407: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb  6 05:00:15.409: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb  6 05:00:15.411: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Feb  6 05:00:15.411: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Feb  6 05:00:15.415: INFO: Updating deployment webserver-deployment
Feb  6 05:00:15.415: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Feb  6 05:00:15.422: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb  6 05:00:15.429: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb  6 05:00:15.460: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-4811 /apis/apps/v1/namespaces/deployment-4811/deployments/webserver-deployment 6e9b22f0-d3fe-466b-aeba-443bcb2ae26c 1802779 3 2020-02-06 04:59:51 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00230a018 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-02-06 05:00:13 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-02-06 05:00:15 +0000 UTC,LastTransitionTime:2020-02-06 05:00:15 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Feb  6 05:00:15.492: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-4811 /apis/apps/v1/namespaces/deployment-4811/replicasets/webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 1802764 3 2020-02-06 05:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 6e9b22f0-d3fe-466b-aeba-443bcb2ae26c 0xc00230a537 0xc00230a538}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00230a5a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 05:00:15.492: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Feb  6 05:00:15.492: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-4811 /apis/apps/v1/namespaces/deployment-4811/replicasets/webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 1802763 3 2020-02-06 04:59:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 6e9b22f0-d3fe-466b-aeba-443bcb2ae26c 0xc00230a477 0xc00230a478}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00230a4d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Feb  6 05:00:15.509: INFO: Pod "webserver-deployment-595b5b9587-2lmrq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2lmrq webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-2lmrq 003e10de-ee59-471e-84fa-01c3ecd2a2fa 1802795 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230aa87 0xc00230aa88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.510: INFO: Pod "webserver-deployment-595b5b9587-52pls" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-52pls webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-52pls 9d6360c0-98e5-4b91-b1a4-8b6dca72d9de 1802790 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230ab80 0xc00230ab81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.510: INFO: Pod "webserver-deployment-595b5b9587-7tl6n" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7tl6n webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-7tl6n ba228592-1f35-498a-adc3-dc4d3570cf1b 1802797 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230ac97 0xc00230ac98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.510: INFO: Pod "webserver-deployment-595b5b9587-8khkz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8khkz webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-8khkz 00f44b92-5ad1-47c6-9bff-1b752079c38a 1802796 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230adb7 0xc00230adb8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.510: INFO: Pod "webserver-deployment-595b5b9587-8zctq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8zctq webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-8zctq 8333b2bf-15a5-4aa1-a65a-7d33cac7ad78 1802798 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230aeb0 0xc00230aeb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.511: INFO: Pod "webserver-deployment-595b5b9587-b8grz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-b8grz webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-b8grz 6ef0f875-90ab-4b21-aec2-748361f2d2bc 1802793 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230afa0 0xc00230afa1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.511: INFO: Pod "webserver-deployment-595b5b9587-g6ll7" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-g6ll7 webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-g6ll7 492b272e-b0d6-49ac-ac4f-0f934e668211 1802778 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230b0b7 0xc00230b0b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.511: INFO: Pod "webserver-deployment-595b5b9587-gphwx" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gphwx webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-gphwx 07ff278b-3a7e-47fd-983f-e0f511508c24 1802654 0 2020-02-06 04:59:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[pod.beta1.sigma.ali/update-status:{"statuses":{"httpd":{"creationTimestamp":"2020-02-06T12:59:52.670453863+08:00","finishTimestamp":"2020-02-06T13:00:02.208154272+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230b1d7 0xc00230b1d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.81,PodIP:10.244.1.208,StartTime:2020-02-06 04:59:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 05:00:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b6d96ae993fa581c463d751a5d51f51024cab1f76739e5945ca139f68a1ea7ee,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.208,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.512: INFO: Pod "webserver-deployment-595b5b9587-h7bct" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-h7bct webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-h7bct 09925fc7-2442-4b04-92c7-2422a5d70f3d 1802615 0 2020-02-06 04:59:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[pod.beta1.sigma.ali/update-status:{"statuses":{"httpd":{"creationTimestamp":"2020-02-06T12:59:52.358626668+08:00","finishTimestamp":"2020-02-06T12:59:54.699670391+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230b367 0xc00230b368}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.81,PodIP:10.244.1.207,StartTime:2020-02-06 04:59:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 04:59:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://daed9da9833ed6869b026ae953158f7940e287273b98475ce5433b536da64a43,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.207,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.512: INFO: Pod "webserver-deployment-595b5b9587-hdtrp" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hdtrp webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-hdtrp 591dd7a7-5681-44ee-9a6d-e27507f9d219 1802634 0 2020-02-06 04:59:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[pod.beta1.sigma.ali/update-status:{"statuses":{"httpd":{"creationTimestamp":"2020-02-06T12:59:52.787034648+08:00","finishTimestamp":"2020-02-06T12:59:57.465252186+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230b4f7 0xc00230b4f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.215,StartTime:2020-02-06 04:59:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 04:59:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b1f345cb7e7039850945ca2bfadd829b9b93208a339d520f1130cac349cb85ed,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.215,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.513: INFO: Pod "webserver-deployment-595b5b9587-j6fk2" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-j6fk2 webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-j6fk2 8f695554-854a-4455-a587-849990fbb4e4 1802637 0 2020-02-06 04:59:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[pod.beta1.sigma.ali/update-status:{"statuses":{"httpd":{"creationTimestamp":"2020-02-06T12:59:52.644907082+08:00","finishTimestamp":"2020-02-06T12:59:58.293206336+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230b687 0xc00230b688}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.81,PodIP:10.244.1.209,StartTime:2020-02-06 04:59:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 04:59:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3c763bd1b97736635ab2b7f3291fb3aea298952e31cba9be2c4cf54d3c49d9a3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.209,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.513: INFO: Pod "webserver-deployment-595b5b9587-jpr8f" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jpr8f webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-jpr8f ce5da275-1ff9-4429-b103-a295d7174d8e 1802777 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230b817 0xc00230b818}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.513: INFO: Pod "webserver-deployment-595b5b9587-jtdfd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jtdfd webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-jtdfd 832c6ff9-3ca7-4048-a661-2ec67b983cd0 1802767 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230b947 0xc00230b948}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.513: INFO: Pod "webserver-deployment-595b5b9587-kn26d" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kn26d webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-kn26d c6763ba7-c473-4aad-930c-cf5c097f6274 1802788 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230ba67 0xc00230ba68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.514: INFO: Pod "webserver-deployment-595b5b9587-kqs6m" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kqs6m webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-kqs6m 5d0370c4-4587-4325-8829-ac01fb489cb8 1802800 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230bb87 0xc00230bb88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.514: INFO: Pod "webserver-deployment-595b5b9587-mvbkw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mvbkw webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-mvbkw c786374b-bb45-45ff-a709-8c549639e68b 1802801 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230bc80 0xc00230bc81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.514: INFO: Pod "webserver-deployment-595b5b9587-njjnl" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-njjnl webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-njjnl 9a1df04d-3ac3-4758-a3ea-776d1c77bcc6 1802673 0 2020-02-06 04:59:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[pod.beta1.sigma.ali/update-status:{"statuses":{"httpd":{"creationTimestamp":"2020-02-06T12:59:52.842302674+08:00","finishTimestamp":"2020-02-06T13:00:06.262947953+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230bd70 0xc00230bd71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.217,StartTime:2020-02-06 04:59:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 05:00:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a577bfbe06d0f7f1b6317ccab9d04b9c6c969944f119744923fa2f200a790e88,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.217,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.514: INFO: Pod "webserver-deployment-595b5b9587-nkdbz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nkdbz webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-nkdbz a1fc2a85-7dbc-40f5-b62c-b5231b6342fc 1802648 0 2020-02-06 04:59:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[pod.beta1.sigma.ali/update-status:{"statuses":{"httpd":{"creationTimestamp":"2020-02-06T12:59:52.817626591+08:00","finishTimestamp":"2020-02-06T13:00:01.351572364+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc00230bef7 0xc00230bef8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.216,StartTime:2020-02-06 04:59:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 05:00:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://49f7ba3d0fd3d292d6fe535f701efe558c2dce60f9a8bbca185465d5cc514ea3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.216,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.515: INFO: Pod "webserver-deployment-595b5b9587-pwh5l" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pwh5l webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-pwh5l f0c243a0-e515-4963-a1ce-2d8aa992f4e8 1802678 0 2020-02-06 04:59:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[pod.beta1.sigma.ali/update-status:{"statuses":{"httpd":{"creationTimestamp":"2020-02-06T12:59:52.721129982+08:00","finishTimestamp":"2020-02-06T13:00:06.800709777+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc004206087 0xc004206088}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.81,PodIP:10.244.1.210,StartTime:2020-02-06 04:59:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 05:00:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9ada070a85f6ec79773751ff36c6fe2b2069bc544267fa6b2ce8f51cbfe78df8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.210,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.516: INFO: Pod "webserver-deployment-595b5b9587-s4hr8" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-s4hr8 webserver-deployment-595b5b9587- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-595b5b9587-s4hr8 59041d7d-b22a-43c3-8f73-591e0f6e7735 1802626 0 2020-02-06 04:59:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[pod.beta1.sigma.ali/update-status:{"statuses":{"httpd":{"creationTimestamp":"2020-02-06T12:59:52.589321266+08:00","finishTimestamp":"2020-02-06T12:59:55.56873063+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 354e2878-651c-4239-9c18-d881c9243397 0xc004206227 0xc004206228}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 04:59:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.214,StartTime:2020-02-06 04:59:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 04:59:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://ac1d7efb8382feaab512ec15debb616d951154ad1d5b989943565da6c8154b9a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.214,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.516: INFO: Pod "webserver-deployment-c7997dcc8-4jbp9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4jbp9 webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-4jbp9 dc98c9c8-6443-489e-898e-bcf976accfd4 1802752 0 2020-02-06 05:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc0042063b7 0xc0042063b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.81,PodIP:,StartTime:2020-02-06 05:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.516: INFO: Pod "webserver-deployment-c7997dcc8-56qzj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-56qzj webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-56qzj 9e8262f2-ae53-46f1-a376-8d535ec1100c 1802799 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc004206557 0xc004206558}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.516: INFO: Pod "webserver-deployment-c7997dcc8-62nxh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-62nxh webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-62nxh c61bd494-53a2-4178-8c12-3b2f3dfe2d27 1802751 0 2020-02-06 05:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc004206660 0xc004206661}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.78,PodIP:,StartTime:2020-02-06 05:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.517: INFO: Pod "webserver-deployment-c7997dcc8-8tmlx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8tmlx webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-8tmlx 99fa0d53-48e1-467c-a474-bee488f139d0 1802748 0 2020-02-06 05:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc0042067e7 0xc0042067e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.78,PodIP:,StartTime:2020-02-06 05:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.517: INFO: Pod "webserver-deployment-c7997dcc8-c6vcb" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-c6vcb webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-c6vcb c6bf9f4b-45bd-472b-9423-c4a56d14d9ba 1802794 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc004206977 0xc004206978}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.528: INFO: Pod "webserver-deployment-c7997dcc8-dl5ml" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-dl5ml webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-dl5ml 1cbf668f-7253-4e1a-a504-59eb6eac8f7b 1802789 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc004206a80 0xc004206a81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.528: INFO: Pod "webserver-deployment-c7997dcc8-klswd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-klswd webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-klswd fc27a006-34b5-48fa-90b5-69d064adf48d 1802753 0 2020-02-06 05:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc004206bd7 0xc004206bd8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.78,PodIP:,StartTime:2020-02-06 05:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.528: INFO: Pod "webserver-deployment-c7997dcc8-kmshw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kmshw webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-kmshw 7d35f4b5-0b47-48cf-8a4f-2760faac336b 1802746 0 2020-02-06 05:00:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc004206d77 0xc004206d78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.81,PodIP:,StartTime:2020-02-06 05:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.529: INFO: Pod "webserver-deployment-c7997dcc8-qfmqf" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qfmqf webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-qfmqf 8ad3c11a-8402-4659-af79-1dfc7bd34296 1802802 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc004206f07 0xc004206f08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.529: INFO: Pod "webserver-deployment-c7997dcc8-stj74" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-stj74 webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-stj74 97ec7493-fe08-46df-9445-f676f29a14d8 1802803 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc004207020 0xc004207021}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.529: INFO: Pod "webserver-deployment-c7997dcc8-w5zpl" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-w5zpl webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-w5zpl f8b1f1ca-b96f-4827-ab86-acc01ce0dd23 1802774 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc004207130 0xc004207131}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb  6 05:00:15.529: INFO: Pod "webserver-deployment-c7997dcc8-xzft2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xzft2 webserver-deployment-c7997dcc8- deployment-4811 /api/v1/namespaces/deployment-4811/pods/webserver-deployment-c7997dcc8-xzft2 8933bec0-8a80-49e8-a7b0-c81011b2800b 1802787 0 2020-02-06 05:00:15 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 09f76ee4-80a5-417f-bea3-790246d51a8b 0xc004207257 0xc004207258}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4wfxx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4wfxx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4wfxx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:00:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:00:15.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4811" for this suite.
Feb  6 05:00:21.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:00:21.644: INFO: namespace deployment-4811 deletion completed in 6.083556808s

• [SLOW TEST:30.443 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:00:21.644: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7157
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-ce94a917-4473-4220-8157-81756fdf8a41
STEP: Creating a pod to test consume secrets
Feb  6 05:00:21.781: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8" in namespace "projected-7157" to be "success or failure"
Feb  6 05:00:21.783: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.914382ms
Feb  6 05:00:23.785: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003835246s
Feb  6 05:00:25.787: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006026531s
Feb  6 05:00:27.789: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008246s
Feb  6 05:00:29.791: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010562648s
Feb  6 05:00:31.794: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012946805s
Feb  6 05:00:33.796: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.015467447s
Feb  6 05:00:35.799: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.017778769s
Feb  6 05:00:37.800: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.019643704s
Feb  6 05:00:39.803: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 18.022036471s
Feb  6 05:00:41.806: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 20.024959509s
Feb  6 05:00:43.808: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 22.027282209s
Feb  6 05:00:45.810: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 24.029761388s
Feb  6 05:00:47.812: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Pending", Reason="", readiness=false. Elapsed: 26.031744426s
Feb  6 05:00:49.815: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.034202666s
STEP: Saw pod success
Feb  6 05:00:49.815: INFO: Pod "pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8" satisfied condition "success or failure"
Feb  6 05:00:49.816: INFO: Trying to get logs from node aks-1-3 pod pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 05:00:49.830: INFO: Waiting for pod pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8 to disappear
Feb  6 05:00:49.835: INFO: Pod pod-projected-secrets-41b95e42-4f6a-496f-bdd3-17a5ed73e4e8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:00:49.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7157" for this suite.
Feb  6 05:00:55.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:00:55.897: INFO: namespace projected-7157 deletion completed in 6.060286559s

• [SLOW TEST:34.253 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:00:55.898: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-854
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-854
I0206 05:00:56.094300      20 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-854, replica count: 1
I0206 05:00:57.144723      20 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0206 05:00:58.144930      20 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 05:00:58.251: INFO: Created: latency-svc-z9kvt
Feb  6 05:00:58.258: INFO: Got endpoints: latency-svc-z9kvt [13.32169ms]
Feb  6 05:00:58.281: INFO: Created: latency-svc-r9r4k
Feb  6 05:00:58.282: INFO: Created: latency-svc-zstf6
Feb  6 05:00:58.282: INFO: Created: latency-svc-ndp5f
Feb  6 05:00:58.283: INFO: Created: latency-svc-l95sp
Feb  6 05:00:58.294: INFO: Got endpoints: latency-svc-r9r4k [35.629936ms]
Feb  6 05:00:58.301: INFO: Got endpoints: latency-svc-l95sp [42.494727ms]
Feb  6 05:00:58.301: INFO: Got endpoints: latency-svc-ndp5f [42.671171ms]
Feb  6 05:00:58.301: INFO: Got endpoints: latency-svc-zstf6 [41.482702ms]
Feb  6 05:00:58.307: INFO: Created: latency-svc-q2vtr
Feb  6 05:00:58.310: INFO: Created: latency-svc-qgzdh
Feb  6 05:00:58.319: INFO: Got endpoints: latency-svc-q2vtr [60.149935ms]
Feb  6 05:00:58.327: INFO: Got endpoints: latency-svc-qgzdh [68.374411ms]
Feb  6 05:00:58.343: INFO: Created: latency-svc-5sgg2
Feb  6 05:00:58.343: INFO: Got endpoints: latency-svc-5sgg2 [83.69066ms]
Feb  6 05:00:58.354: INFO: Created: latency-svc-4z7cg
Feb  6 05:00:58.358: INFO: Got endpoints: latency-svc-4z7cg [99.333194ms]
Feb  6 05:00:58.361: INFO: Created: latency-svc-9hslf
Feb  6 05:00:58.368: INFO: Got endpoints: latency-svc-9hslf [108.994672ms]
Feb  6 05:00:58.371: INFO: Created: latency-svc-bt44v
Feb  6 05:00:58.377: INFO: Got endpoints: latency-svc-bt44v [117.396453ms]
Feb  6 05:00:58.379: INFO: Created: latency-svc-4g8d8
Feb  6 05:00:58.391: INFO: Got endpoints: latency-svc-4g8d8 [131.238652ms]
Feb  6 05:00:58.396: INFO: Created: latency-svc-6swsm
Feb  6 05:00:58.407: INFO: Got endpoints: latency-svc-6swsm [147.321556ms]
Feb  6 05:00:58.409: INFO: Created: latency-svc-8s486
Feb  6 05:00:58.416: INFO: Created: latency-svc-fq5h2
Feb  6 05:00:58.418: INFO: Got endpoints: latency-svc-8s486 [158.24162ms]
Feb  6 05:00:58.428: INFO: Created: latency-svc-h6cfz
Feb  6 05:00:58.428: INFO: Got endpoints: latency-svc-fq5h2 [168.51203ms]
Feb  6 05:00:58.439: INFO: Got endpoints: latency-svc-h6cfz [178.854374ms]
Feb  6 05:00:58.452: INFO: Created: latency-svc-t9rr9
Feb  6 05:00:58.453: INFO: Created: latency-svc-5lqdf
Feb  6 05:00:58.459: INFO: Got endpoints: latency-svc-t9rr9 [164.469203ms]
Feb  6 05:00:58.462: INFO: Got endpoints: latency-svc-5lqdf [160.323525ms]
Feb  6 05:00:58.465: INFO: Created: latency-svc-qxsfx
Feb  6 05:00:58.469: INFO: Got endpoints: latency-svc-qxsfx [167.235168ms]
Feb  6 05:00:58.474: INFO: Created: latency-svc-qxmj2
Feb  6 05:00:58.476: INFO: Created: latency-svc-wjrhs
Feb  6 05:00:58.481: INFO: Got endpoints: latency-svc-wjrhs [179.405065ms]
Feb  6 05:00:58.488: INFO: Created: latency-svc-wf799
Feb  6 05:00:58.493: INFO: Got endpoints: latency-svc-qxmj2 [173.740795ms]
Feb  6 05:00:58.504: INFO: Created: latency-svc-9wbwp
Feb  6 05:00:58.506: INFO: Got endpoints: latency-svc-wf799 [162.866727ms]
Feb  6 05:00:58.511: INFO: Created: latency-svc-nrkdh
Feb  6 05:00:58.519: INFO: Got endpoints: latency-svc-nrkdh [160.664428ms]
Feb  6 05:00:58.522: INFO: Got endpoints: latency-svc-9wbwp [194.552355ms]
Feb  6 05:00:58.527: INFO: Created: latency-svc-5tjd9
Feb  6 05:00:58.534: INFO: Created: latency-svc-vglb5
Feb  6 05:00:58.538: INFO: Got endpoints: latency-svc-5tjd9 [170.063729ms]
Feb  6 05:00:58.543: INFO: Got endpoints: latency-svc-vglb5 [165.809796ms]
Feb  6 05:00:58.567: INFO: Created: latency-svc-r2srx
Feb  6 05:00:58.568: INFO: Created: latency-svc-2827q
Feb  6 05:00:58.573: INFO: Created: latency-svc-rhfvl
Feb  6 05:00:58.587: INFO: Created: latency-svc-fq9h8
Feb  6 05:00:58.590: INFO: Got endpoints: latency-svc-2827q [199.471474ms]
Feb  6 05:00:58.594: INFO: Got endpoints: latency-svc-r2srx [187.45884ms]
Feb  6 05:00:58.604: INFO: Created: latency-svc-pfk4x
Feb  6 05:00:58.616: INFO: Got endpoints: latency-svc-pfk4x [177.735355ms]
Feb  6 05:00:58.616: INFO: Got endpoints: latency-svc-rhfvl [198.594884ms]
Feb  6 05:00:58.616: INFO: Got endpoints: latency-svc-fq9h8 [188.270656ms]
Feb  6 05:00:58.625: INFO: Created: latency-svc-v8sjt
Feb  6 05:00:58.631: INFO: Got endpoints: latency-svc-v8sjt [172.48273ms]
Feb  6 05:00:58.637: INFO: Created: latency-svc-pgrnp
Feb  6 05:00:58.645: INFO: Created: latency-svc-tsrj6
Feb  6 05:00:58.655: INFO: Created: latency-svc-jtvjx
Feb  6 05:00:58.664: INFO: Got endpoints: latency-svc-jtvjx [182.928339ms]
Feb  6 05:00:58.664: INFO: Got endpoints: latency-svc-pgrnp [201.812098ms]
Feb  6 05:00:58.664: INFO: Got endpoints: latency-svc-tsrj6 [195.463447ms]
Feb  6 05:00:58.680: INFO: Created: latency-svc-s2dwm
Feb  6 05:00:58.680: INFO: Created: latency-svc-xvgmh
Feb  6 05:00:58.680: INFO: Created: latency-svc-ljqhp
Feb  6 05:00:58.680: INFO: Got endpoints: latency-svc-s2dwm [187.282133ms]
Feb  6 05:00:58.680: INFO: Got endpoints: latency-svc-xvgmh [174.422547ms]
Feb  6 05:00:58.685: INFO: Created: latency-svc-kcqj5
Feb  6 05:00:58.688: INFO: Got endpoints: latency-svc-ljqhp [168.304388ms]
Feb  6 05:00:58.693: INFO: Created: latency-svc-pqrmq
Feb  6 05:00:58.702: INFO: Created: latency-svc-g6597
Feb  6 05:00:58.704: INFO: Created: latency-svc-k9pdm
Feb  6 05:00:58.711: INFO: Created: latency-svc-s6z5n
Feb  6 05:00:58.713: INFO: Got endpoints: latency-svc-kcqj5 [191.066216ms]
Feb  6 05:00:58.719: INFO: Created: latency-svc-m5756
Feb  6 05:00:58.733: INFO: Created: latency-svc-ht6gz
Feb  6 05:00:58.735: INFO: Created: latency-svc-cr6r5
Feb  6 05:00:58.738: INFO: Created: latency-svc-pln78
Feb  6 05:00:58.741: INFO: Created: latency-svc-2fpmd
Feb  6 05:00:58.743: INFO: Created: latency-svc-8fs5s
Feb  6 05:00:58.743: INFO: Created: latency-svc-svczw
Feb  6 05:00:58.744: INFO: Created: latency-svc-fw97s
Feb  6 05:00:58.748: INFO: Created: latency-svc-jjf95
Feb  6 05:00:58.750: INFO: Created: latency-svc-r2f97
Feb  6 05:00:58.754: INFO: Got endpoints: latency-svc-pqrmq [90.051154ms]
Feb  6 05:00:58.763: INFO: Created: latency-svc-lvtr6
Feb  6 05:00:58.764: INFO: Created: latency-svc-m22lt
Feb  6 05:00:58.804: INFO: Got endpoints: latency-svc-g6597 [261.778945ms]
Feb  6 05:00:58.811: INFO: Created: latency-svc-wbqb5
Feb  6 05:00:58.854: INFO: Got endpoints: latency-svc-k9pdm [315.293554ms]
Feb  6 05:00:58.865: INFO: Created: latency-svc-55nrb
Feb  6 05:00:58.904: INFO: Got endpoints: latency-svc-s6z5n [313.89674ms]
Feb  6 05:00:58.908: INFO: Created: latency-svc-txtn9
Feb  6 05:00:58.956: INFO: Got endpoints: latency-svc-ht6gz [361.234265ms]
Feb  6 05:00:58.962: INFO: Created: latency-svc-6qplr
Feb  6 05:00:59.006: INFO: Got endpoints: latency-svc-m5756 [388.79753ms]
Feb  6 05:00:59.017: INFO: Created: latency-svc-2tb5s
Feb  6 05:00:59.054: INFO: Got endpoints: latency-svc-8fs5s [437.686849ms]
Feb  6 05:00:59.063: INFO: Created: latency-svc-ns7s7
Feb  6 05:00:59.105: INFO: Got endpoints: latency-svc-svczw [487.471946ms]
Feb  6 05:00:59.108: INFO: Created: latency-svc-42pdw
Feb  6 05:00:59.153: INFO: Got endpoints: latency-svc-cr6r5 [521.547ms]
Feb  6 05:00:59.159: INFO: Created: latency-svc-dfhjh
Feb  6 05:00:59.203: INFO: Got endpoints: latency-svc-pln78 [538.944701ms]
Feb  6 05:00:59.210: INFO: Created: latency-svc-n8lrb
Feb  6 05:00:59.253: INFO: Got endpoints: latency-svc-2fpmd [587.853848ms]
Feb  6 05:00:59.258: INFO: Created: latency-svc-wztkg
Feb  6 05:00:59.304: INFO: Got endpoints: latency-svc-fw97s [623.911246ms]
Feb  6 05:00:59.313: INFO: Created: latency-svc-xz6mw
Feb  6 05:00:59.352: INFO: Got endpoints: latency-svc-jjf95 [671.824606ms]
Feb  6 05:00:59.358: INFO: Created: latency-svc-t79fq
Feb  6 05:00:59.403: INFO: Got endpoints: latency-svc-r2f97 [715.827508ms]
Feb  6 05:00:59.407: INFO: Created: latency-svc-jww9l
Feb  6 05:00:59.455: INFO: Got endpoints: latency-svc-m22lt [741.36504ms]
Feb  6 05:00:59.462: INFO: Created: latency-svc-f7f58
Feb  6 05:00:59.505: INFO: Got endpoints: latency-svc-lvtr6 [750.918628ms]
Feb  6 05:00:59.510: INFO: Created: latency-svc-b6lx8
Feb  6 05:00:59.553: INFO: Got endpoints: latency-svc-wbqb5 [748.827291ms]
Feb  6 05:00:59.557: INFO: Created: latency-svc-hhc6n
Feb  6 05:00:59.603: INFO: Got endpoints: latency-svc-55nrb [749.566781ms]
Feb  6 05:00:59.607: INFO: Created: latency-svc-d8jcq
Feb  6 05:00:59.654: INFO: Got endpoints: latency-svc-txtn9 [749.54309ms]
Feb  6 05:00:59.658: INFO: Created: latency-svc-5lmvr
Feb  6 05:00:59.704: INFO: Got endpoints: latency-svc-6qplr [747.969025ms]
Feb  6 05:00:59.707: INFO: Created: latency-svc-wjjsl
Feb  6 05:00:59.754: INFO: Got endpoints: latency-svc-2tb5s [748.488742ms]
Feb  6 05:00:59.760: INFO: Created: latency-svc-wnmsh
Feb  6 05:00:59.803: INFO: Got endpoints: latency-svc-ns7s7 [749.082326ms]
Feb  6 05:00:59.807: INFO: Created: latency-svc-vxjxd
Feb  6 05:00:59.854: INFO: Got endpoints: latency-svc-42pdw [748.945932ms]
Feb  6 05:00:59.859: INFO: Created: latency-svc-mml4n
Feb  6 05:00:59.903: INFO: Got endpoints: latency-svc-dfhjh [750.529124ms]
Feb  6 05:00:59.912: INFO: Created: latency-svc-k7hhc
Feb  6 05:00:59.954: INFO: Got endpoints: latency-svc-n8lrb [749.924184ms]
Feb  6 05:00:59.958: INFO: Created: latency-svc-plzm9
Feb  6 05:01:00.003: INFO: Got endpoints: latency-svc-wztkg [749.992275ms]
Feb  6 05:01:00.007: INFO: Created: latency-svc-cmw7k
Feb  6 05:01:00.054: INFO: Got endpoints: latency-svc-xz6mw [749.733184ms]
Feb  6 05:01:00.061: INFO: Created: latency-svc-pmj5j
Feb  6 05:01:00.106: INFO: Got endpoints: latency-svc-t79fq [754.046723ms]
Feb  6 05:01:00.116: INFO: Created: latency-svc-lzstf
Feb  6 05:01:00.154: INFO: Got endpoints: latency-svc-jww9l [750.619875ms]
Feb  6 05:01:00.165: INFO: Created: latency-svc-zxbl4
Feb  6 05:01:00.204: INFO: Got endpoints: latency-svc-f7f58 [748.914008ms]
Feb  6 05:01:00.210: INFO: Created: latency-svc-kr66c
Feb  6 05:01:00.256: INFO: Got endpoints: latency-svc-b6lx8 [750.519529ms]
Feb  6 05:01:00.264: INFO: Created: latency-svc-6j924
Feb  6 05:01:00.304: INFO: Got endpoints: latency-svc-hhc6n [750.324327ms]
Feb  6 05:01:00.313: INFO: Created: latency-svc-5dgj9
Feb  6 05:01:00.353: INFO: Got endpoints: latency-svc-d8jcq [749.817067ms]
Feb  6 05:01:00.360: INFO: Created: latency-svc-xckz8
Feb  6 05:01:00.403: INFO: Got endpoints: latency-svc-5lmvr [749.446ms]
Feb  6 05:01:00.410: INFO: Created: latency-svc-4gjg6
Feb  6 05:01:00.455: INFO: Got endpoints: latency-svc-wjjsl [751.00814ms]
Feb  6 05:01:00.460: INFO: Created: latency-svc-5hxk5
Feb  6 05:01:00.503: INFO: Got endpoints: latency-svc-wnmsh [749.019393ms]
Feb  6 05:01:00.508: INFO: Created: latency-svc-6df5j
Feb  6 05:01:00.553: INFO: Got endpoints: latency-svc-vxjxd [749.42396ms]
Feb  6 05:01:00.559: INFO: Created: latency-svc-g9nfn
Feb  6 05:01:00.605: INFO: Got endpoints: latency-svc-mml4n [751.550488ms]
Feb  6 05:01:00.616: INFO: Created: latency-svc-j5hz9
Feb  6 05:01:00.653: INFO: Got endpoints: latency-svc-k7hhc [749.807499ms]
Feb  6 05:01:00.658: INFO: Created: latency-svc-kq28c
Feb  6 05:01:00.704: INFO: Got endpoints: latency-svc-plzm9 [749.921184ms]
Feb  6 05:01:00.711: INFO: Created: latency-svc-68cfq
Feb  6 05:01:00.753: INFO: Got endpoints: latency-svc-cmw7k [750.019262ms]
Feb  6 05:01:00.758: INFO: Created: latency-svc-2gc25
Feb  6 05:01:00.804: INFO: Got endpoints: latency-svc-pmj5j [750.205577ms]
Feb  6 05:01:00.815: INFO: Created: latency-svc-bwhgw
Feb  6 05:01:00.855: INFO: Got endpoints: latency-svc-lzstf [748.694737ms]
Feb  6 05:01:00.859: INFO: Created: latency-svc-vq7pp
Feb  6 05:01:00.904: INFO: Got endpoints: latency-svc-zxbl4 [749.658078ms]
Feb  6 05:01:00.913: INFO: Created: latency-svc-49f4m
Feb  6 05:01:00.955: INFO: Got endpoints: latency-svc-kr66c [751.180726ms]
Feb  6 05:01:00.965: INFO: Created: latency-svc-62dxc
Feb  6 05:01:01.004: INFO: Got endpoints: latency-svc-6j924 [747.760118ms]
Feb  6 05:01:01.009: INFO: Created: latency-svc-twjb6
Feb  6 05:01:01.055: INFO: Got endpoints: latency-svc-5dgj9 [750.909197ms]
Feb  6 05:01:01.062: INFO: Created: latency-svc-xtfd7
Feb  6 05:01:01.104: INFO: Got endpoints: latency-svc-xckz8 [750.663103ms]
Feb  6 05:01:01.111: INFO: Created: latency-svc-d7nx9
Feb  6 05:01:01.154: INFO: Got endpoints: latency-svc-4gjg6 [750.32428ms]
Feb  6 05:01:01.160: INFO: Created: latency-svc-wchf2
Feb  6 05:01:01.205: INFO: Got endpoints: latency-svc-5hxk5 [750.582775ms]
Feb  6 05:01:01.215: INFO: Created: latency-svc-tcjpt
Feb  6 05:01:01.263: INFO: Got endpoints: latency-svc-6df5j [760.010735ms]
Feb  6 05:01:01.294: INFO: Created: latency-svc-qdhbt
Feb  6 05:01:01.305: INFO: Got endpoints: latency-svc-g9nfn [752.279884ms]
Feb  6 05:01:01.316: INFO: Created: latency-svc-nzxrp
Feb  6 05:01:01.361: INFO: Got endpoints: latency-svc-j5hz9 [755.313448ms]
Feb  6 05:01:01.373: INFO: Created: latency-svc-29kqz
Feb  6 05:01:01.411: INFO: Got endpoints: latency-svc-kq28c [757.39155ms]
Feb  6 05:01:01.435: INFO: Created: latency-svc-ccnvb
Feb  6 05:01:01.454: INFO: Got endpoints: latency-svc-68cfq [750.53248ms]
Feb  6 05:01:01.461: INFO: Created: latency-svc-7kjsq
Feb  6 05:01:01.504: INFO: Got endpoints: latency-svc-2gc25 [751.208278ms]
Feb  6 05:01:01.512: INFO: Created: latency-svc-sc7vl
Feb  6 05:01:01.553: INFO: Got endpoints: latency-svc-bwhgw [748.822162ms]
Feb  6 05:01:01.560: INFO: Created: latency-svc-2b7bd
Feb  6 05:01:01.606: INFO: Got endpoints: latency-svc-vq7pp [750.782888ms]
Feb  6 05:01:01.633: INFO: Created: latency-svc-mpxzq
Feb  6 05:01:01.654: INFO: Got endpoints: latency-svc-49f4m [749.558885ms]
Feb  6 05:01:01.670: INFO: Created: latency-svc-7n289
Feb  6 05:01:01.704: INFO: Got endpoints: latency-svc-62dxc [749.24735ms]
Feb  6 05:01:01.710: INFO: Created: latency-svc-9k5qm
Feb  6 05:01:01.753: INFO: Got endpoints: latency-svc-twjb6 [749.720522ms]
Feb  6 05:01:01.761: INFO: Created: latency-svc-r9rw8
Feb  6 05:01:01.804: INFO: Got endpoints: latency-svc-xtfd7 [748.706168ms]
Feb  6 05:01:01.808: INFO: Created: latency-svc-6kjs7
Feb  6 05:01:01.856: INFO: Got endpoints: latency-svc-d7nx9 [751.824324ms]
Feb  6 05:01:01.866: INFO: Created: latency-svc-9ppv4
Feb  6 05:01:01.904: INFO: Got endpoints: latency-svc-wchf2 [750.064116ms]
Feb  6 05:01:01.912: INFO: Created: latency-svc-qxtft
Feb  6 05:01:01.955: INFO: Got endpoints: latency-svc-tcjpt [749.054848ms]
Feb  6 05:01:01.964: INFO: Created: latency-svc-shts7
Feb  6 05:01:02.004: INFO: Got endpoints: latency-svc-qdhbt [740.723549ms]
Feb  6 05:01:02.012: INFO: Created: latency-svc-hjfhl
Feb  6 05:01:02.055: INFO: Got endpoints: latency-svc-nzxrp [750.093443ms]
Feb  6 05:01:02.061: INFO: Created: latency-svc-qbxmw
Feb  6 05:01:02.105: INFO: Got endpoints: latency-svc-29kqz [743.65645ms]
Feb  6 05:01:02.110: INFO: Created: latency-svc-mlfs9
Feb  6 05:01:02.157: INFO: Got endpoints: latency-svc-ccnvb [746.061253ms]
Feb  6 05:01:02.169: INFO: Created: latency-svc-jgr72
Feb  6 05:01:02.204: INFO: Got endpoints: latency-svc-7kjsq [749.465181ms]
Feb  6 05:01:02.213: INFO: Created: latency-svc-kjrjm
Feb  6 05:01:02.253: INFO: Got endpoints: latency-svc-sc7vl [748.946317ms]
Feb  6 05:01:02.257: INFO: Created: latency-svc-kgkr6
Feb  6 05:01:02.304: INFO: Got endpoints: latency-svc-2b7bd [750.253425ms]
Feb  6 05:01:02.307: INFO: Created: latency-svc-2ph2r
Feb  6 05:01:02.354: INFO: Got endpoints: latency-svc-mpxzq [747.535727ms]
Feb  6 05:01:02.361: INFO: Created: latency-svc-kmzfw
Feb  6 05:01:02.403: INFO: Got endpoints: latency-svc-7n289 [749.292513ms]
Feb  6 05:01:02.410: INFO: Created: latency-svc-9djcm
Feb  6 05:01:02.454: INFO: Got endpoints: latency-svc-9k5qm [749.201691ms]
Feb  6 05:01:02.460: INFO: Created: latency-svc-v5rbj
Feb  6 05:01:02.504: INFO: Got endpoints: latency-svc-r9rw8 [750.540336ms]
Feb  6 05:01:02.511: INFO: Created: latency-svc-bfgt7
Feb  6 05:01:02.554: INFO: Got endpoints: latency-svc-6kjs7 [750.43137ms]
Feb  6 05:01:02.560: INFO: Created: latency-svc-dp77g
Feb  6 05:01:02.605: INFO: Got endpoints: latency-svc-9ppv4 [748.362553ms]
Feb  6 05:01:02.614: INFO: Created: latency-svc-rls5z
Feb  6 05:01:02.653: INFO: Got endpoints: latency-svc-qxtft [748.848402ms]
Feb  6 05:01:02.662: INFO: Created: latency-svc-qfkz4
Feb  6 05:01:02.705: INFO: Got endpoints: latency-svc-shts7 [750.086457ms]
Feb  6 05:01:02.713: INFO: Created: latency-svc-6n4mv
Feb  6 05:01:02.754: INFO: Got endpoints: latency-svc-hjfhl [749.495984ms]
Feb  6 05:01:02.761: INFO: Created: latency-svc-vgzkz
Feb  6 05:01:02.806: INFO: Got endpoints: latency-svc-qbxmw [750.280539ms]
Feb  6 05:01:02.816: INFO: Created: latency-svc-9fbnj
Feb  6 05:01:02.853: INFO: Got endpoints: latency-svc-mlfs9 [748.124863ms]
Feb  6 05:01:02.861: INFO: Created: latency-svc-khr5t
Feb  6 05:01:02.904: INFO: Got endpoints: latency-svc-jgr72 [746.76506ms]
Feb  6 05:01:02.913: INFO: Created: latency-svc-dpzdn
Feb  6 05:01:02.954: INFO: Got endpoints: latency-svc-kjrjm [750.244892ms]
Feb  6 05:01:02.963: INFO: Created: latency-svc-gnl58
Feb  6 05:01:03.004: INFO: Got endpoints: latency-svc-kgkr6 [751.169874ms]
Feb  6 05:01:03.009: INFO: Created: latency-svc-fm7ln
Feb  6 05:01:03.054: INFO: Got endpoints: latency-svc-2ph2r [750.141568ms]
Feb  6 05:01:03.061: INFO: Created: latency-svc-fhzx9
Feb  6 05:01:03.106: INFO: Got endpoints: latency-svc-kmzfw [751.682806ms]
Feb  6 05:01:03.112: INFO: Created: latency-svc-g55s8
Feb  6 05:01:03.154: INFO: Got endpoints: latency-svc-9djcm [750.523765ms]
Feb  6 05:01:03.157: INFO: Created: latency-svc-5hznw
Feb  6 05:01:03.205: INFO: Got endpoints: latency-svc-v5rbj [750.810476ms]
Feb  6 05:01:03.214: INFO: Created: latency-svc-rw59m
Feb  6 05:01:03.254: INFO: Got endpoints: latency-svc-bfgt7 [749.72598ms]
Feb  6 05:01:03.259: INFO: Created: latency-svc-lh8d4
Feb  6 05:01:03.303: INFO: Got endpoints: latency-svc-dp77g [748.71308ms]
Feb  6 05:01:03.308: INFO: Created: latency-svc-cgvsc
Feb  6 05:01:03.354: INFO: Got endpoints: latency-svc-rls5z [749.022456ms]
Feb  6 05:01:03.363: INFO: Created: latency-svc-rqp6r
Feb  6 05:01:03.403: INFO: Got endpoints: latency-svc-qfkz4 [749.958545ms]
Feb  6 05:01:03.409: INFO: Created: latency-svc-4ht2w
Feb  6 05:01:03.454: INFO: Got endpoints: latency-svc-6n4mv [749.258572ms]
Feb  6 05:01:03.459: INFO: Created: latency-svc-rwmmr
Feb  6 05:01:03.505: INFO: Got endpoints: latency-svc-vgzkz [750.793704ms]
Feb  6 05:01:03.509: INFO: Created: latency-svc-7m85j
Feb  6 05:01:03.554: INFO: Got endpoints: latency-svc-9fbnj [747.939932ms]
Feb  6 05:01:03.560: INFO: Created: latency-svc-5lnzk
Feb  6 05:01:03.604: INFO: Got endpoints: latency-svc-khr5t [751.102525ms]
Feb  6 05:01:03.612: INFO: Created: latency-svc-t4ww4
Feb  6 05:01:03.653: INFO: Got endpoints: latency-svc-dpzdn [749.246144ms]
Feb  6 05:01:03.659: INFO: Created: latency-svc-tjfrw
Feb  6 05:01:03.706: INFO: Got endpoints: latency-svc-gnl58 [751.979906ms]
Feb  6 05:01:03.713: INFO: Created: latency-svc-phvl5
Feb  6 05:01:03.753: INFO: Got endpoints: latency-svc-fm7ln [748.147298ms]
Feb  6 05:01:03.760: INFO: Created: latency-svc-9wnvw
Feb  6 05:01:03.806: INFO: Got endpoints: latency-svc-fhzx9 [752.126465ms]
Feb  6 05:01:03.812: INFO: Created: latency-svc-pflgl
Feb  6 05:01:03.854: INFO: Got endpoints: latency-svc-g55s8 [747.917412ms]
Feb  6 05:01:03.861: INFO: Created: latency-svc-62nll
Feb  6 05:01:03.903: INFO: Got endpoints: latency-svc-5hznw [749.269082ms]
Feb  6 05:01:03.908: INFO: Created: latency-svc-hlj42
Feb  6 05:01:03.954: INFO: Got endpoints: latency-svc-rw59m [749.300289ms]
Feb  6 05:01:03.960: INFO: Created: latency-svc-7qxcc
Feb  6 05:01:04.003: INFO: Got endpoints: latency-svc-lh8d4 [748.801725ms]
Feb  6 05:01:04.011: INFO: Created: latency-svc-4kvb6
Feb  6 05:01:04.058: INFO: Got endpoints: latency-svc-cgvsc [755.168515ms]
Feb  6 05:01:04.065: INFO: Created: latency-svc-l7m5s
Feb  6 05:01:04.105: INFO: Got endpoints: latency-svc-rqp6r [750.696156ms]
Feb  6 05:01:04.114: INFO: Created: latency-svc-fvwp8
Feb  6 05:01:04.159: INFO: Got endpoints: latency-svc-4ht2w [755.675051ms]
Feb  6 05:01:04.165: INFO: Created: latency-svc-m8fng
Feb  6 05:01:04.203: INFO: Got endpoints: latency-svc-rwmmr [749.111626ms]
Feb  6 05:01:04.208: INFO: Created: latency-svc-z5s9l
Feb  6 05:01:04.254: INFO: Got endpoints: latency-svc-7m85j [749.242027ms]
Feb  6 05:01:04.259: INFO: Created: latency-svc-q2vsb
Feb  6 05:01:04.306: INFO: Got endpoints: latency-svc-5lnzk [751.717534ms]
Feb  6 05:01:04.314: INFO: Created: latency-svc-cnkxx
Feb  6 05:01:04.354: INFO: Got endpoints: latency-svc-t4ww4 [749.768016ms]
Feb  6 05:01:04.362: INFO: Created: latency-svc-qjn9p
Feb  6 05:01:04.404: INFO: Got endpoints: latency-svc-tjfrw [750.802319ms]
Feb  6 05:01:04.412: INFO: Created: latency-svc-rv7h7
Feb  6 05:01:04.455: INFO: Got endpoints: latency-svc-phvl5 [748.574457ms]
Feb  6 05:01:04.464: INFO: Created: latency-svc-kxxgm
Feb  6 05:01:04.504: INFO: Got endpoints: latency-svc-9wnvw [751.240671ms]
Feb  6 05:01:04.508: INFO: Created: latency-svc-htw2n
Feb  6 05:01:04.554: INFO: Got endpoints: latency-svc-pflgl [747.534003ms]
Feb  6 05:01:04.557: INFO: Created: latency-svc-vnlkf
Feb  6 05:01:04.604: INFO: Got endpoints: latency-svc-62nll [749.92767ms]
Feb  6 05:01:04.608: INFO: Created: latency-svc-nlrgn
Feb  6 05:01:04.653: INFO: Got endpoints: latency-svc-hlj42 [750.1477ms]
Feb  6 05:01:04.661: INFO: Created: latency-svc-68g94
Feb  6 05:01:04.705: INFO: Got endpoints: latency-svc-7qxcc [750.676994ms]
Feb  6 05:01:04.710: INFO: Created: latency-svc-h46vv
Feb  6 05:01:04.755: INFO: Got endpoints: latency-svc-4kvb6 [751.515778ms]
Feb  6 05:01:04.763: INFO: Created: latency-svc-rz8rt
Feb  6 05:01:04.804: INFO: Got endpoints: latency-svc-l7m5s [745.509994ms]
Feb  6 05:01:04.810: INFO: Created: latency-svc-r6cv2
Feb  6 05:01:04.853: INFO: Got endpoints: latency-svc-fvwp8 [748.425499ms]
Feb  6 05:01:04.858: INFO: Created: latency-svc-2m96c
Feb  6 05:01:04.905: INFO: Got endpoints: latency-svc-m8fng [745.478916ms]
Feb  6 05:01:04.917: INFO: Created: latency-svc-h97df
Feb  6 05:01:04.953: INFO: Got endpoints: latency-svc-z5s9l [749.615349ms]
Feb  6 05:01:04.961: INFO: Created: latency-svc-sbzd8
Feb  6 05:01:05.005: INFO: Got endpoints: latency-svc-q2vsb [750.358422ms]
Feb  6 05:01:05.009: INFO: Created: latency-svc-n8z59
Feb  6 05:01:05.054: INFO: Got endpoints: latency-svc-cnkxx [748.486862ms]
Feb  6 05:01:05.060: INFO: Created: latency-svc-56gxw
Feb  6 05:01:05.104: INFO: Got endpoints: latency-svc-qjn9p [749.693942ms]
Feb  6 05:01:05.109: INFO: Created: latency-svc-bpw69
Feb  6 05:01:05.156: INFO: Got endpoints: latency-svc-rv7h7 [752.078642ms]
Feb  6 05:01:05.161: INFO: Created: latency-svc-xwbpm
Feb  6 05:01:05.204: INFO: Got endpoints: latency-svc-kxxgm [749.274956ms]
Feb  6 05:01:05.212: INFO: Created: latency-svc-htf2k
Feb  6 05:01:05.254: INFO: Got endpoints: latency-svc-htw2n [750.256493ms]
Feb  6 05:01:05.261: INFO: Created: latency-svc-jgxmr
Feb  6 05:01:05.303: INFO: Got endpoints: latency-svc-vnlkf [748.705404ms]
Feb  6 05:01:05.310: INFO: Created: latency-svc-26v8t
Feb  6 05:01:05.354: INFO: Got endpoints: latency-svc-nlrgn [749.845613ms]
Feb  6 05:01:05.358: INFO: Created: latency-svc-xdm8g
Feb  6 05:01:05.403: INFO: Got endpoints: latency-svc-68g94 [749.604597ms]
Feb  6 05:01:05.410: INFO: Created: latency-svc-sdhqw
Feb  6 05:01:05.454: INFO: Got endpoints: latency-svc-h46vv [748.618898ms]
Feb  6 05:01:05.464: INFO: Created: latency-svc-4fvf2
Feb  6 05:01:05.504: INFO: Got endpoints: latency-svc-rz8rt [748.992802ms]
Feb  6 05:01:05.508: INFO: Created: latency-svc-5pr2m
Feb  6 05:01:05.555: INFO: Got endpoints: latency-svc-r6cv2 [750.529931ms]
Feb  6 05:01:05.563: INFO: Created: latency-svc-8cffb
Feb  6 05:01:05.608: INFO: Got endpoints: latency-svc-2m96c [755.048972ms]
Feb  6 05:01:05.619: INFO: Created: latency-svc-6kfz6
Feb  6 05:01:05.658: INFO: Got endpoints: latency-svc-h97df [753.034931ms]
Feb  6 05:01:05.666: INFO: Created: latency-svc-mg4bf
Feb  6 05:01:05.706: INFO: Got endpoints: latency-svc-sbzd8 [752.815052ms]
Feb  6 05:01:05.719: INFO: Created: latency-svc-g6685
Feb  6 05:01:05.754: INFO: Got endpoints: latency-svc-n8z59 [749.59024ms]
Feb  6 05:01:05.763: INFO: Created: latency-svc-l2lqt
Feb  6 05:01:05.806: INFO: Got endpoints: latency-svc-56gxw [751.049567ms]
Feb  6 05:01:05.812: INFO: Created: latency-svc-twwb5
Feb  6 05:01:05.854: INFO: Got endpoints: latency-svc-bpw69 [749.713075ms]
Feb  6 05:01:05.861: INFO: Created: latency-svc-7r7zg
Feb  6 05:01:05.905: INFO: Got endpoints: latency-svc-xwbpm [748.204037ms]
Feb  6 05:01:05.911: INFO: Created: latency-svc-49qvj
Feb  6 05:01:05.954: INFO: Got endpoints: latency-svc-htf2k [750.145208ms]
Feb  6 05:01:05.958: INFO: Created: latency-svc-ps26h
Feb  6 05:01:06.003: INFO: Got endpoints: latency-svc-jgxmr [748.830463ms]
Feb  6 05:01:06.007: INFO: Created: latency-svc-hls8p
Feb  6 05:01:06.054: INFO: Got endpoints: latency-svc-26v8t [751.021713ms]
Feb  6 05:01:06.058: INFO: Created: latency-svc-7btnn
Feb  6 05:01:06.103: INFO: Got endpoints: latency-svc-xdm8g [749.562307ms]
Feb  6 05:01:06.154: INFO: Got endpoints: latency-svc-sdhqw [750.438508ms]
Feb  6 05:01:06.204: INFO: Got endpoints: latency-svc-4fvf2 [750.469513ms]
Feb  6 05:01:06.254: INFO: Got endpoints: latency-svc-5pr2m [750.08643ms]
Feb  6 05:01:06.310: INFO: Got endpoints: latency-svc-8cffb [754.850935ms]
Feb  6 05:01:06.353: INFO: Got endpoints: latency-svc-6kfz6 [744.634981ms]
Feb  6 05:01:06.404: INFO: Got endpoints: latency-svc-mg4bf [746.05926ms]
Feb  6 05:01:06.463: INFO: Got endpoints: latency-svc-g6685 [757.023813ms]
Feb  6 05:01:06.504: INFO: Got endpoints: latency-svc-l2lqt [749.433524ms]
Feb  6 05:01:06.554: INFO: Got endpoints: latency-svc-twwb5 [747.934032ms]
Feb  6 05:01:06.603: INFO: Got endpoints: latency-svc-7r7zg [749.628521ms]
Feb  6 05:01:06.654: INFO: Got endpoints: latency-svc-49qvj [749.510162ms]
Feb  6 05:01:06.704: INFO: Got endpoints: latency-svc-ps26h [749.827807ms]
Feb  6 05:01:06.756: INFO: Got endpoints: latency-svc-hls8p [752.464528ms]
Feb  6 05:01:06.804: INFO: Got endpoints: latency-svc-7btnn [750.083519ms]
Feb  6 05:01:06.804: INFO: Latencies: [35.629936ms 41.482702ms 42.494727ms 42.671171ms 60.149935ms 68.374411ms 83.69066ms 90.051154ms 99.333194ms 108.994672ms 117.396453ms 131.238652ms 147.321556ms 158.24162ms 160.323525ms 160.664428ms 162.866727ms 164.469203ms 165.809796ms 167.235168ms 168.304388ms 168.51203ms 170.063729ms 172.48273ms 173.740795ms 174.422547ms 177.735355ms 178.854374ms 179.405065ms 182.928339ms 187.282133ms 187.45884ms 188.270656ms 191.066216ms 194.552355ms 195.463447ms 198.594884ms 199.471474ms 201.812098ms 261.778945ms 313.89674ms 315.293554ms 361.234265ms 388.79753ms 437.686849ms 487.471946ms 521.547ms 538.944701ms 587.853848ms 623.911246ms 671.824606ms 715.827508ms 740.723549ms 741.36504ms 743.65645ms 744.634981ms 745.478916ms 745.509994ms 746.05926ms 746.061253ms 746.76506ms 747.534003ms 747.535727ms 747.760118ms 747.917412ms 747.934032ms 747.939932ms 747.969025ms 748.124863ms 748.147298ms 748.204037ms 748.362553ms 748.425499ms 748.486862ms 748.488742ms 748.574457ms 748.618898ms 748.694737ms 748.705404ms 748.706168ms 748.71308ms 748.801725ms 748.822162ms 748.827291ms 748.830463ms 748.848402ms 748.914008ms 748.945932ms 748.946317ms 748.992802ms 749.019393ms 749.022456ms 749.054848ms 749.082326ms 749.111626ms 749.201691ms 749.242027ms 749.246144ms 749.24735ms 749.258572ms 749.269082ms 749.274956ms 749.292513ms 749.300289ms 749.42396ms 749.433524ms 749.446ms 749.465181ms 749.495984ms 749.510162ms 749.54309ms 749.558885ms 749.562307ms 749.566781ms 749.59024ms 749.604597ms 749.615349ms 749.628521ms 749.658078ms 749.693942ms 749.713075ms 749.720522ms 749.72598ms 749.733184ms 749.768016ms 749.807499ms 749.817067ms 749.827807ms 749.845613ms 749.921184ms 749.924184ms 749.92767ms 749.958545ms 749.992275ms 750.019262ms 750.064116ms 750.083519ms 750.08643ms 750.086457ms 750.093443ms 750.141568ms 750.145208ms 750.1477ms 750.205577ms 750.244892ms 750.253425ms 750.256493ms 750.280539ms 750.32428ms 750.324327ms 750.358422ms 750.43137ms 750.438508ms 750.469513ms 750.519529ms 750.523765ms 750.529124ms 750.529931ms 750.53248ms 750.540336ms 750.582775ms 750.619875ms 750.663103ms 750.676994ms 750.696156ms 750.782888ms 750.793704ms 750.802319ms 750.810476ms 750.909197ms 750.918628ms 751.00814ms 751.021713ms 751.049567ms 751.102525ms 751.169874ms 751.180726ms 751.208278ms 751.240671ms 751.515778ms 751.550488ms 751.682806ms 751.717534ms 751.824324ms 751.979906ms 752.078642ms 752.126465ms 752.279884ms 752.464528ms 752.815052ms 753.034931ms 754.046723ms 754.850935ms 755.048972ms 755.168515ms 755.313448ms 755.675051ms 757.023813ms 757.39155ms 760.010735ms]
Feb  6 05:01:06.805: INFO: 50 %ile: 749.269082ms
Feb  6 05:01:06.805: INFO: 90 %ile: 751.550488ms
Feb  6 05:01:06.805: INFO: 99 %ile: 757.39155ms
Feb  6 05:01:06.805: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:01:06.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-854" for this suite.
Feb  6 05:01:20.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:01:20.863: INFO: namespace svc-latency-854 deletion completed in 14.055173993s

• [SLOW TEST:24.965 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:01:20.863: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1881
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-1881
STEP: creating replication controller nodeport-test in namespace services-1881
I0206 05:01:21.026994      20 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-1881, replica count: 2
I0206 05:01:24.077428      20 runners.go:184] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 05:01:27.077: INFO: Creating new exec pod
I0206 05:01:27.077748      20 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 05:01:32.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-1881 execpodgtb7p -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Feb  6 05:01:32.631: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Feb  6 05:01:32.631: INFO: stdout: ""
Feb  6 05:01:32.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-1881 execpodgtb7p -- /bin/sh -x -c nc -zv -t -w 2 10.96.0.47 80'
Feb  6 05:01:32.853: INFO: stderr: "+ nc -zv -t -w 2 10.96.0.47 80\nConnection to 10.96.0.47 80 port [tcp/http] succeeded!\n"
Feb  6 05:01:32.853: INFO: stdout: ""
Feb  6 05:01:32.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-1881 execpodgtb7p -- /bin/sh -x -c nc -zv -t -w 2 192.168.27.78 32066'
Feb  6 05:01:33.020: INFO: stderr: "+ nc -zv -t -w 2 192.168.27.78 32066\nConnection to 192.168.27.78 32066 port [tcp/32066] succeeded!\n"
Feb  6 05:01:33.020: INFO: stdout: ""
Feb  6 05:01:33.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=services-1881 execpodgtb7p -- /bin/sh -x -c nc -zv -t -w 2 192.168.27.81 32066'
Feb  6 05:01:33.185: INFO: stderr: "+ nc -zv -t -w 2 192.168.27.81 32066\nConnection to 192.168.27.81 32066 port [tcp/32066] succeeded!\n"
Feb  6 05:01:33.185: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:01:33.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1881" for this suite.
Feb  6 05:01:39.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:01:39.250: INFO: namespace services-1881 deletion completed in 6.06205309s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.387 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:01:39.251: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4147
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 05:01:39.432: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-f413cf97-732f-4d46-93c3-87cc54f2e046" in namespace "security-context-test-4147" to be "success or failure"
Feb  6 05:01:39.436: INFO: Pod "busybox-privileged-false-f413cf97-732f-4d46-93c3-87cc54f2e046": Phase="Pending", Reason="", readiness=false. Elapsed: 3.879084ms
Feb  6 05:01:41.438: INFO: Pod "busybox-privileged-false-f413cf97-732f-4d46-93c3-87cc54f2e046": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006248759s
Feb  6 05:01:41.438: INFO: Pod "busybox-privileged-false-f413cf97-732f-4d46-93c3-87cc54f2e046" satisfied condition "success or failure"
Feb  6 05:01:41.450: INFO: Got logs for pod "busybox-privileged-false-f413cf97-732f-4d46-93c3-87cc54f2e046": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:01:41.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4147" for this suite.
Feb  6 05:01:47.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:01:47.508: INFO: namespace security-context-test-4147 deletion completed in 6.055786975s

• [SLOW TEST:8.257 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:01:47.508: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7507
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-23f8b85b-657d-4f8f-a334-29a0da36f72b
STEP: Creating a pod to test consume secrets
Feb  6 05:01:47.655: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a7e87df4-b96c-4204-9579-bf01152a4f06" in namespace "projected-7507" to be "success or failure"
Feb  6 05:01:47.662: INFO: Pod "pod-projected-secrets-a7e87df4-b96c-4204-9579-bf01152a4f06": Phase="Pending", Reason="", readiness=false. Elapsed: 7.707971ms
Feb  6 05:01:49.665: INFO: Pod "pod-projected-secrets-a7e87df4-b96c-4204-9579-bf01152a4f06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010210527s
STEP: Saw pod success
Feb  6 05:01:49.665: INFO: Pod "pod-projected-secrets-a7e87df4-b96c-4204-9579-bf01152a4f06" satisfied condition "success or failure"
Feb  6 05:01:49.666: INFO: Trying to get logs from node aks-1-3 pod pod-projected-secrets-a7e87df4-b96c-4204-9579-bf01152a4f06 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 05:01:49.679: INFO: Waiting for pod pod-projected-secrets-a7e87df4-b96c-4204-9579-bf01152a4f06 to disappear
Feb  6 05:01:49.681: INFO: Pod pod-projected-secrets-a7e87df4-b96c-4204-9579-bf01152a4f06 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:01:49.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7507" for this suite.
Feb  6 05:01:55.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:01:55.738: INFO: namespace projected-7507 deletion completed in 6.054911998s

• [SLOW TEST:8.230 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:01:55.738: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8089
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  6 05:01:55.867: INFO: Waiting up to 5m0s for pod "pod-19541154-522e-4375-a8ea-4909588a3987" in namespace "emptydir-8089" to be "success or failure"
Feb  6 05:01:55.872: INFO: Pod "pod-19541154-522e-4375-a8ea-4909588a3987": Phase="Pending", Reason="", readiness=false. Elapsed: 5.015623ms
Feb  6 05:01:57.874: INFO: Pod "pod-19541154-522e-4375-a8ea-4909588a3987": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007267459s
STEP: Saw pod success
Feb  6 05:01:57.874: INFO: Pod "pod-19541154-522e-4375-a8ea-4909588a3987" satisfied condition "success or failure"
Feb  6 05:01:57.876: INFO: Trying to get logs from node aks-1-3 pod pod-19541154-522e-4375-a8ea-4909588a3987 container test-container: <nil>
STEP: delete the pod
Feb  6 05:01:57.886: INFO: Waiting for pod pod-19541154-522e-4375-a8ea-4909588a3987 to disappear
Feb  6 05:01:57.888: INFO: Pod pod-19541154-522e-4375-a8ea-4909588a3987 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:01:57.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8089" for this suite.
Feb  6 05:02:03.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:02:03.945: INFO: namespace emptydir-8089 deletion completed in 6.055049811s

• [SLOW TEST:8.207 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:02:03.946: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5417
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 05:02:04.129: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb  6 05:02:04.134: INFO: Number of nodes with available pods: 0
Feb  6 05:02:04.134: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb  6 05:02:04.146: INFO: Number of nodes with available pods: 0
Feb  6 05:02:04.146: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:05.149: INFO: Number of nodes with available pods: 0
Feb  6 05:02:05.149: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:06.162: INFO: Number of nodes with available pods: 0
Feb  6 05:02:06.162: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:07.149: INFO: Number of nodes with available pods: 1
Feb  6 05:02:07.149: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb  6 05:02:07.158: INFO: Number of nodes with available pods: 1
Feb  6 05:02:07.158: INFO: Number of running nodes: 0, number of available pods: 1
Feb  6 05:02:08.161: INFO: Number of nodes with available pods: 0
Feb  6 05:02:08.161: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb  6 05:02:08.167: INFO: Number of nodes with available pods: 0
Feb  6 05:02:08.167: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:09.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:09.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:10.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:10.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:11.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:11.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:12.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:12.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:13.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:13.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:14.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:14.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:15.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:15.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:16.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:16.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:17.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:17.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:18.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:18.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:19.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:19.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:20.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:20.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:21.170: INFO: Number of nodes with available pods: 0
Feb  6 05:02:21.170: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:22.172: INFO: Number of nodes with available pods: 0
Feb  6 05:02:22.172: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:02:23.170: INFO: Number of nodes with available pods: 1
Feb  6 05:02:23.170: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5417, will wait for the garbage collector to delete the pods
Feb  6 05:02:23.229: INFO: Deleting DaemonSet.extensions daemon-set took: 5.249482ms
Feb  6 05:02:25.230: INFO: Terminating DaemonSet.extensions daemon-set pods took: 2.00028499s
Feb  6 05:02:30.032: INFO: Number of nodes with available pods: 0
Feb  6 05:02:30.032: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 05:02:30.033: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5417/daemonsets","resourceVersion":"1804747"},"items":null}

Feb  6 05:02:30.034: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5417/pods","resourceVersion":"1804747"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:02:30.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5417" for this suite.
Feb  6 05:02:36.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:02:36.111: INFO: namespace daemonsets-5417 deletion completed in 6.06517593s

• [SLOW TEST:32.165 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:02:36.111: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2658
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Feb  6 05:02:36.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-2658'
Feb  6 05:02:36.597: INFO: stderr: ""
Feb  6 05:02:36.597: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 05:02:36.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2658'
Feb  6 05:02:36.711: INFO: stderr: ""
Feb  6 05:02:36.711: INFO: stdout: "update-demo-nautilus-jqtmr update-demo-nautilus-mqdj8 "
Feb  6 05:02:36.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-jqtmr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2658'
Feb  6 05:02:36.822: INFO: stderr: ""
Feb  6 05:02:36.822: INFO: stdout: ""
Feb  6 05:02:36.822: INFO: update-demo-nautilus-jqtmr is created but not running
Feb  6 05:02:41.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2658'
Feb  6 05:02:41.915: INFO: stderr: ""
Feb  6 05:02:41.915: INFO: stdout: "update-demo-nautilus-jqtmr update-demo-nautilus-mqdj8 "
Feb  6 05:02:41.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-jqtmr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2658'
Feb  6 05:02:42.002: INFO: stderr: ""
Feb  6 05:02:42.002: INFO: stdout: "true"
Feb  6 05:02:42.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-jqtmr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2658'
Feb  6 05:02:42.091: INFO: stderr: ""
Feb  6 05:02:42.091: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 05:02:42.091: INFO: validating pod update-demo-nautilus-jqtmr
Feb  6 05:02:42.099: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 05:02:42.099: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 05:02:42.099: INFO: update-demo-nautilus-jqtmr is verified up and running
Feb  6 05:02:42.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-mqdj8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2658'
Feb  6 05:02:42.193: INFO: stderr: ""
Feb  6 05:02:42.193: INFO: stdout: "true"
Feb  6 05:02:42.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-mqdj8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2658'
Feb  6 05:02:42.276: INFO: stderr: ""
Feb  6 05:02:42.276: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 05:02:42.276: INFO: validating pod update-demo-nautilus-mqdj8
Feb  6 05:02:42.280: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 05:02:42.280: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 05:02:42.280: INFO: update-demo-nautilus-mqdj8 is verified up and running
STEP: rolling-update to new replication controller
Feb  6 05:02:42.281: INFO: scanned /root for discovery docs: <nil>
Feb  6 05:02:42.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-2658'
Feb  6 05:03:04.662: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  6 05:03:04.662: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 05:03:04.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2658'
Feb  6 05:03:04.752: INFO: stderr: ""
Feb  6 05:03:04.752: INFO: stdout: "update-demo-kitten-2486v update-demo-kitten-wlchk "
Feb  6 05:03:04.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-kitten-2486v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2658'
Feb  6 05:03:04.837: INFO: stderr: ""
Feb  6 05:03:04.837: INFO: stdout: "true"
Feb  6 05:03:04.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-kitten-2486v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2658'
Feb  6 05:03:04.920: INFO: stderr: ""
Feb  6 05:03:04.920: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  6 05:03:04.920: INFO: validating pod update-demo-kitten-2486v
Feb  6 05:03:04.923: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  6 05:03:04.923: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  6 05:03:04.923: INFO: update-demo-kitten-2486v is verified up and running
Feb  6 05:03:04.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-kitten-wlchk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2658'
Feb  6 05:03:05.015: INFO: stderr: ""
Feb  6 05:03:05.015: INFO: stdout: "true"
Feb  6 05:03:05.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-kitten-wlchk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2658'
Feb  6 05:03:05.110: INFO: stderr: ""
Feb  6 05:03:05.110: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  6 05:03:05.110: INFO: validating pod update-demo-kitten-wlchk
Feb  6 05:03:05.114: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  6 05:03:05.114: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  6 05:03:05.114: INFO: update-demo-kitten-wlchk is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:03:05.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2658" for this suite.
Feb  6 05:03:33.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:03:33.173: INFO: namespace kubectl-2658 deletion completed in 28.056447447s

• [SLOW TEST:57.062 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:03:33.174: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-780
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-780/secret-test-657e5642-2c9a-43c8-b9d1-db1f7bc6293b
STEP: Creating a pod to test consume secrets
Feb  6 05:03:33.307: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1c0fc22-4a53-4f64-b6c7-7a8181fd2ad0" in namespace "secrets-780" to be "success or failure"
Feb  6 05:03:33.310: INFO: Pod "pod-configmaps-c1c0fc22-4a53-4f64-b6c7-7a8181fd2ad0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.850443ms
Feb  6 05:03:35.313: INFO: Pod "pod-configmaps-c1c0fc22-4a53-4f64-b6c7-7a8181fd2ad0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006433821s
STEP: Saw pod success
Feb  6 05:03:35.313: INFO: Pod "pod-configmaps-c1c0fc22-4a53-4f64-b6c7-7a8181fd2ad0" satisfied condition "success or failure"
Feb  6 05:03:35.315: INFO: Trying to get logs from node aks-1-4 pod pod-configmaps-c1c0fc22-4a53-4f64-b6c7-7a8181fd2ad0 container env-test: <nil>
STEP: delete the pod
Feb  6 05:03:35.330: INFO: Waiting for pod pod-configmaps-c1c0fc22-4a53-4f64-b6c7-7a8181fd2ad0 to disappear
Feb  6 05:03:35.331: INFO: Pod pod-configmaps-c1c0fc22-4a53-4f64-b6c7-7a8181fd2ad0 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:03:35.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-780" for this suite.
Feb  6 05:03:41.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:03:41.387: INFO: namespace secrets-780 deletion completed in 6.053844477s

• [SLOW TEST:8.214 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:03:41.388: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1520
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-hknb
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 05:03:41.525: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-hknb" in namespace "subpath-1520" to be "success or failure"
Feb  6 05:03:41.528: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.67688ms
Feb  6 05:03:43.530: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Running", Reason="", readiness=true. Elapsed: 2.005286985s
Feb  6 05:03:45.533: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Running", Reason="", readiness=true. Elapsed: 4.007559257s
Feb  6 05:03:47.535: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Running", Reason="", readiness=true. Elapsed: 6.00988324s
Feb  6 05:03:49.537: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Running", Reason="", readiness=true. Elapsed: 8.012144279s
Feb  6 05:03:51.540: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Running", Reason="", readiness=true. Elapsed: 10.014571474s
Feb  6 05:03:53.542: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Running", Reason="", readiness=true. Elapsed: 12.016830075s
Feb  6 05:03:55.544: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Running", Reason="", readiness=true. Elapsed: 14.019116085s
Feb  6 05:03:57.547: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Running", Reason="", readiness=true. Elapsed: 16.021455592s
Feb  6 05:03:59.549: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Running", Reason="", readiness=true. Elapsed: 18.023953995s
Feb  6 05:04:01.551: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Running", Reason="", readiness=true. Elapsed: 20.026307271s
Feb  6 05:04:03.553: INFO: Pod "pod-subpath-test-secret-hknb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.02817351s
STEP: Saw pod success
Feb  6 05:04:03.553: INFO: Pod "pod-subpath-test-secret-hknb" satisfied condition "success or failure"
Feb  6 05:04:03.555: INFO: Trying to get logs from node aks-1-3 pod pod-subpath-test-secret-hknb container test-container-subpath-secret-hknb: <nil>
STEP: delete the pod
Feb  6 05:04:03.571: INFO: Waiting for pod pod-subpath-test-secret-hknb to disappear
Feb  6 05:04:03.574: INFO: Pod pod-subpath-test-secret-hknb no longer exists
STEP: Deleting pod pod-subpath-test-secret-hknb
Feb  6 05:04:03.574: INFO: Deleting pod "pod-subpath-test-secret-hknb" in namespace "subpath-1520"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:04:03.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1520" for this suite.
Feb  6 05:04:09.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:04:09.634: INFO: namespace subpath-1520 deletion completed in 6.057572912s

• [SLOW TEST:28.247 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:04:09.635: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4232
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:04:11.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4232" for this suite.
Feb  6 05:04:55.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:04:55.841: INFO: namespace kubelet-test-4232 deletion completed in 44.055930173s

• [SLOW TEST:46.207 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:04:55.842: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-6323a19d-b7f1-40ad-9fc3-b7f741d1b191
STEP: Creating a pod to test consume configMaps
Feb  6 05:04:56.023: INFO: Waiting up to 5m0s for pod "pod-configmaps-a4231bce-f891-4d4a-8609-0432421cbd82" in namespace "configmap-855" to be "success or failure"
Feb  6 05:04:56.025: INFO: Pod "pod-configmaps-a4231bce-f891-4d4a-8609-0432421cbd82": Phase="Pending", Reason="", readiness=false. Elapsed: 1.418496ms
Feb  6 05:04:58.028: INFO: Pod "pod-configmaps-a4231bce-f891-4d4a-8609-0432421cbd82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004288682s
STEP: Saw pod success
Feb  6 05:04:58.028: INFO: Pod "pod-configmaps-a4231bce-f891-4d4a-8609-0432421cbd82" satisfied condition "success or failure"
Feb  6 05:04:58.029: INFO: Trying to get logs from node aks-1-4 pod pod-configmaps-a4231bce-f891-4d4a-8609-0432421cbd82 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 05:04:58.040: INFO: Waiting for pod pod-configmaps-a4231bce-f891-4d4a-8609-0432421cbd82 to disappear
Feb  6 05:04:58.042: INFO: Pod pod-configmaps-a4231bce-f891-4d4a-8609-0432421cbd82 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:04:58.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-855" for this suite.
Feb  6 05:05:04.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:05:04.121: INFO: namespace configmap-855 deletion completed in 6.076552211s

• [SLOW TEST:8.280 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:05:04.122: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9064
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Feb  6 05:05:04.285: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb  6 05:05:04.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-9064'
Feb  6 05:05:04.495: INFO: stderr: ""
Feb  6 05:05:04.495: INFO: stdout: "service/redis-slave created\n"
Feb  6 05:05:04.495: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb  6 05:05:04.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-9064'
Feb  6 05:05:04.762: INFO: stderr: ""
Feb  6 05:05:04.762: INFO: stdout: "service/redis-master created\n"
Feb  6 05:05:04.791: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb  6 05:05:04.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-9064'
Feb  6 05:05:05.031: INFO: stderr: ""
Feb  6 05:05:05.031: INFO: stdout: "service/frontend created\n"
Feb  6 05:05:05.031: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb  6 05:05:05.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-9064'
Feb  6 05:05:05.269: INFO: stderr: ""
Feb  6 05:05:05.269: INFO: stdout: "deployment.apps/frontend created\n"
Feb  6 05:05:05.269: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb  6 05:05:05.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-9064'
Feb  6 05:05:05.672: INFO: stderr: ""
Feb  6 05:05:05.672: INFO: stdout: "deployment.apps/redis-master created\n"
Feb  6 05:05:05.685: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb  6 05:05:05.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-9064'
Feb  6 05:05:05.915: INFO: stderr: ""
Feb  6 05:05:05.915: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Feb  6 05:05:05.915: INFO: Waiting for all frontend pods to be Running.
Feb  6 05:07:30.970: INFO: Waiting for frontend to serve content.
Feb  6 05:07:31.064: INFO: Trying to add a new entry to the guestbook.
Feb  6 05:07:31.074: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb  6 05:07:31.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete --grace-period=0 --force -f - --namespace=kubectl-9064'
Feb  6 05:07:31.215: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 05:07:31.215: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 05:07:31.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete --grace-period=0 --force -f - --namespace=kubectl-9064'
Feb  6 05:07:31.377: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 05:07:31.377: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 05:07:31.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete --grace-period=0 --force -f - --namespace=kubectl-9064'
Feb  6 05:07:31.537: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 05:07:31.537: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 05:07:31.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete --grace-period=0 --force -f - --namespace=kubectl-9064'
Feb  6 05:07:31.668: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 05:07:31.668: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 05:07:31.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete --grace-period=0 --force -f - --namespace=kubectl-9064'
Feb  6 05:07:31.792: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 05:07:31.792: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 05:07:31.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete --grace-period=0 --force -f - --namespace=kubectl-9064'
Feb  6 05:07:31.936: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 05:07:31.936: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:07:31.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9064" for this suite.
Feb  6 05:07:59.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:07:59.999: INFO: namespace kubectl-9064 deletion completed in 28.058756765s

• [SLOW TEST:175.877 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:07:59.999: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-991
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 05:08:00.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 version'
Feb  6 05:08:00.251: INFO: stderr: ""
Feb  6 05:08:00.251: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:23:11Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16+\", GitVersion:\"v1.16.3-130\", GitCommit:\"f62f861acfd2e8d16aa003eed8f070e089c322c9\", GitTreeState:\"clean\", BuildDate:\"2020-01-20T13:04:34Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:08:00.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-991" for this suite.
Feb  6 05:08:06.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:08:06.309: INFO: namespace kubectl-991 deletion completed in 6.055722557s

• [SLOW TEST:6.311 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:08:06.310: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 05:08:06.752: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 05:08:08.758: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562486, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562486, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562486, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562486, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 05:08:11.770: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:08:11.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3821" for this suite.
Feb  6 05:08:17.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:08:17.888: INFO: namespace webhook-3821 deletion completed in 6.060083747s
STEP: Destroying namespace "webhook-3821-markers" for this suite.
Feb  6 05:08:23.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:08:23.942: INFO: namespace webhook-3821-markers deletion completed in 6.053994511s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.640 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:08:23.951: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3571
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:08:24.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3571" for this suite.
Feb  6 05:08:36.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:08:36.165: INFO: namespace kubelet-test-3571 deletion completed in 12.061094143s

• [SLOW TEST:12.214 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:08:36.165: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6828
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6828.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6828.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6828.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6828.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 05:08:48.319: INFO: DNS probes using dns-test-7ebc7852-a8d5-4b83-aa6a-6a1f90395f98 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6828.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6828.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6828.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6828.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 05:08:58.352: INFO: DNS probes using dns-test-3681f73c-f992-4ab6-8246-6d04916c6477 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6828.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6828.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6828.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6828.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 05:09:02.404: INFO: DNS probes using dns-test-ca158c64-70c8-421e-92b3-0752ece4705a succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:09:02.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6828" for this suite.
Feb  6 05:09:08.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:09:08.482: INFO: namespace dns-6828 deletion completed in 6.05720387s

• [SLOW TEST:32.317 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:09:08.482: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9797
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-2b539256-d6ee-4f9a-a057-09bc8e905f1b
STEP: Creating a pod to test consume secrets
Feb  6 05:09:08.614: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2ac7ea56-542a-4f73-8efa-825e2b5ad5b5" in namespace "projected-9797" to be "success or failure"
Feb  6 05:09:08.616: INFO: Pod "pod-projected-secrets-2ac7ea56-542a-4f73-8efa-825e2b5ad5b5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.614683ms
Feb  6 05:09:10.618: INFO: Pod "pod-projected-secrets-2ac7ea56-542a-4f73-8efa-825e2b5ad5b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004094921s
STEP: Saw pod success
Feb  6 05:09:10.618: INFO: Pod "pod-projected-secrets-2ac7ea56-542a-4f73-8efa-825e2b5ad5b5" satisfied condition "success or failure"
Feb  6 05:09:10.620: INFO: Trying to get logs from node aks-1-3 pod pod-projected-secrets-2ac7ea56-542a-4f73-8efa-825e2b5ad5b5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 05:09:10.645: INFO: Waiting for pod pod-projected-secrets-2ac7ea56-542a-4f73-8efa-825e2b5ad5b5 to disappear
Feb  6 05:09:10.646: INFO: Pod pod-projected-secrets-2ac7ea56-542a-4f73-8efa-825e2b5ad5b5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:09:10.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9797" for this suite.
Feb  6 05:09:16.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:09:16.708: INFO: namespace projected-9797 deletion completed in 6.059537025s

• [SLOW TEST:8.226 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:09:16.708: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3808
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb  6 05:09:16.832: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 05:09:16.838: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 05:09:16.840: INFO: 
Logging pods the kubelet thinks is on node aks-1-3 before test
Feb  6 05:09:16.846: INFO: coredns-7f6cddc944-v22mw from kube-system started at 2020-02-05 08:48:34 +0000 UTC (1 container statuses recorded)
Feb  6 05:09:16.846: INFO: 	Container coredns ready: true, restart count 0
Feb  6 05:09:16.846: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-kwwvw from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 05:09:16.846: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 05:09:16.846: INFO: 	Container systemd-logs ready: true, restart count 1
Feb  6 05:09:16.846: INFO: kube-flannel-ds-amd64-tkhv8 from kube-system started at 2020-02-05 07:36:26 +0000 UTC (1 container statuses recorded)
Feb  6 05:09:16.846: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 05:09:16.846: INFO: coredns-7f6cddc944-99f6c from kube-system started at 2020-02-05 13:54:41 +0000 UTC (1 container statuses recorded)
Feb  6 05:09:16.846: INFO: 	Container coredns ready: true, restart count 0
Feb  6 05:09:16.846: INFO: 
Logging pods the kubelet thinks is on node aks-1-4 before test
Feb  6 05:09:16.867: INFO: kube-flannel-ds-amd64-plfph from kube-system started at 2020-02-04 14:20:52 +0000 UTC (1 container statuses recorded)
Feb  6 05:09:16.867: INFO: 	Container kube-flannel ready: true, restart count 0
Feb  6 05:09:16.867: INFO: sonobuoy-systemd-logs-daemon-set-28042f8b5b7f47d6-7z6kz from sonobuoy started at 2020-02-06 03:24:58 +0000 UTC (2 container statuses recorded)
Feb  6 05:09:16.867: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 05:09:16.867: INFO: 	Container systemd-logs ready: true, restart count 1
Feb  6 05:09:16.867: INFO: coredns-7f6cddc944-w6w2z from kube-system started at 2020-02-03 03:59:20 +0000 UTC (1 container statuses recorded)
Feb  6 05:09:16.867: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f0b7fac4daf762], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) were unschedulable, 2 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f0b7fac54b4f98], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) were unschedulable, 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:09:17.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3808" for this suite.
Feb  6 05:09:23.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:09:23.944: INFO: namespace sched-pred-3808 deletion completed in 6.058986078s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.236 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:09:23.944: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1992
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-d1d1819f-cd1c-469f-89a9-f7ddc2b82e1e in namespace container-probe-1992
Feb  6 05:09:26.130: INFO: Started pod test-webserver-d1d1819f-cd1c-469f-89a9-f7ddc2b82e1e in namespace container-probe-1992
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 05:09:26.131: INFO: Initial restart count of pod test-webserver-d1d1819f-cd1c-469f-89a9-f7ddc2b82e1e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:13:26.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1992" for this suite.
Feb  6 05:13:32.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:13:32.532: INFO: namespace container-probe-1992 deletion completed in 6.056419043s

• [SLOW TEST:248.588 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:13:32.533: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2036
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 05:13:32.656: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb  6 05:13:36.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-2036 create -f -'
Feb  6 05:13:37.019: INFO: stderr: ""
Feb  6 05:13:37.019: INFO: stdout: "e2e-test-crd-publish-openapi-8377-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb  6 05:13:37.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-2036 delete e2e-test-crd-publish-openapi-8377-crds test-cr'
Feb  6 05:13:37.108: INFO: stderr: ""
Feb  6 05:13:37.108: INFO: stdout: "e2e-test-crd-publish-openapi-8377-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Feb  6 05:13:37.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-2036 apply -f -'
Feb  6 05:13:37.314: INFO: stderr: ""
Feb  6 05:13:37.314: INFO: stdout: "e2e-test-crd-publish-openapi-8377-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb  6 05:13:37.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-2036 delete e2e-test-crd-publish-openapi-8377-crds test-cr'
Feb  6 05:13:37.401: INFO: stderr: ""
Feb  6 05:13:37.401: INFO: stdout: "e2e-test-crd-publish-openapi-8377-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb  6 05:13:37.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 explain e2e-test-crd-publish-openapi-8377-crds'
Feb  6 05:13:37.596: INFO: stderr: ""
Feb  6 05:13:37.596: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8377-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:13:41.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2036" for this suite.
Feb  6 05:13:47.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:13:47.391: INFO: namespace crd-publish-openapi-2036 deletion completed in 6.052919305s

• [SLOW TEST:14.859 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:13:47.392: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6603
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 05:13:47.520: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e3d8d72-ac5e-4cf2-b95a-6e0d298ac0aa" in namespace "downward-api-6603" to be "success or failure"
Feb  6 05:13:47.522: INFO: Pod "downwardapi-volume-9e3d8d72-ac5e-4cf2-b95a-6e0d298ac0aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.694108ms
Feb  6 05:13:49.525: INFO: Pod "downwardapi-volume-9e3d8d72-ac5e-4cf2-b95a-6e0d298ac0aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00510923s
STEP: Saw pod success
Feb  6 05:13:49.525: INFO: Pod "downwardapi-volume-9e3d8d72-ac5e-4cf2-b95a-6e0d298ac0aa" satisfied condition "success or failure"
Feb  6 05:13:49.526: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-9e3d8d72-ac5e-4cf2-b95a-6e0d298ac0aa container client-container: <nil>
STEP: delete the pod
Feb  6 05:13:49.544: INFO: Waiting for pod downwardapi-volume-9e3d8d72-ac5e-4cf2-b95a-6e0d298ac0aa to disappear
Feb  6 05:13:49.546: INFO: Pod downwardapi-volume-9e3d8d72-ac5e-4cf2-b95a-6e0d298ac0aa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:13:49.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6603" for this suite.
Feb  6 05:13:55.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:13:55.605: INFO: namespace downward-api-6603 deletion completed in 6.05726992s

• [SLOW TEST:8.213 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:13:55.607: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1220
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb  6 05:13:55.790: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-a 2045cf08-8702-4118-bd4e-65ac9d05c76b 1806643 0 2020-02-06 05:13:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 05:13:55.790: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-a 2045cf08-8702-4118-bd4e-65ac9d05c76b 1806643 0 2020-02-06 05:13:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb  6 05:14:05.794: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-a 2045cf08-8702-4118-bd4e-65ac9d05c76b 1806658 0 2020-02-06 05:13:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  6 05:14:05.794: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-a 2045cf08-8702-4118-bd4e-65ac9d05c76b 1806658 0 2020-02-06 05:13:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb  6 05:14:15.801: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-a 2045cf08-8702-4118-bd4e-65ac9d05c76b 1806672 0 2020-02-06 05:13:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 05:14:15.801: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-a 2045cf08-8702-4118-bd4e-65ac9d05c76b 1806672 0 2020-02-06 05:13:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb  6 05:14:25.805: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-a 2045cf08-8702-4118-bd4e-65ac9d05c76b 1806687 0 2020-02-06 05:13:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 05:14:25.805: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-a 2045cf08-8702-4118-bd4e-65ac9d05c76b 1806687 0 2020-02-06 05:13:55 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb  6 05:14:35.810: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-b fee643a3-6fcd-47f5-810a-b75967b24e5d 1806704 0 2020-02-06 05:14:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 05:14:35.810: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-b fee643a3-6fcd-47f5-810a-b75967b24e5d 1806704 0 2020-02-06 05:14:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb  6 05:14:45.814: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-b fee643a3-6fcd-47f5-810a-b75967b24e5d 1806719 0 2020-02-06 05:14:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 05:14:45.814: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1220 /api/v1/namespaces/watch-1220/configmaps/e2e-watch-test-configmap-b fee643a3-6fcd-47f5-810a-b75967b24e5d 1806719 0 2020-02-06 05:14:35 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:14:55.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1220" for this suite.
Feb  6 05:15:01.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:15:01.911: INFO: namespace watch-1220 deletion completed in 6.094039453s

• [SLOW TEST:66.305 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:15:01.913: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-1556
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:15:02.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-1556" for this suite.
Feb  6 05:15:08.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:15:08.207: INFO: namespace tables-1556 deletion completed in 6.055674282s

• [SLOW TEST:6.295 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:15:08.207: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8095
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-8095, will wait for the garbage collector to delete the pods
Feb  6 05:15:10.393: INFO: Deleting Job.batch foo took: 3.202439ms
Feb  6 05:15:10.694: INFO: Terminating Job.batch foo pods took: 300.308815ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:15:53.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8095" for this suite.
Feb  6 05:15:59.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:15:59.454: INFO: namespace job-8095 deletion completed in 6.056232843s

• [SLOW TEST:51.247 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:15:59.455: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2847
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 05:15:59.584: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb  6 05:16:04.586: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 05:16:08.590: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb  6 05:16:10.592: INFO: Creating deployment "test-rollover-deployment"
Feb  6 05:16:10.596: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb  6 05:16:12.602: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb  6 05:16:12.605: INFO: Ensure that both replica sets have 1 created replica
Feb  6 05:16:12.608: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb  6 05:16:12.611: INFO: Updating deployment test-rollover-deployment
Feb  6 05:16:12.611: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb  6 05:16:14.618: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb  6 05:16:14.621: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb  6 05:16:14.624: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 05:16:14.625: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562972, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 05:16:16.629: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 05:16:16.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562975, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 05:16:18.629: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 05:16:18.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562975, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 05:16:20.629: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 05:16:20.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562975, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 05:16:22.629: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 05:16:22.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562975, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 05:16:24.629: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 05:16:24.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562975, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562970, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 05:16:26.629: INFO: 
Feb  6 05:16:26.629: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb  6 05:16:26.633: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-2847 /apis/apps/v1/namespaces/deployment-2847/deployments/test-rollover-deployment c663ad00-5e6d-45bb-ad49-18c67301ef4e 1807020 2 2020-02-06 05:16:10 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0057c3918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-06 05:16:10 +0000 UTC,LastTransitionTime:2020-02-06 05:16:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-02-06 05:16:25 +0000 UTC,LastTransitionTime:2020-02-06 05:16:10 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb  6 05:16:26.636: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-2847 /apis/apps/v1/namespaces/deployment-2847/replicasets/test-rollover-deployment-7d7dc6548c cebc57bb-166d-48b3-99f6-588da9521758 1807010 2 2020-02-06 05:16:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment c663ad00-5e6d-45bb-ad49-18c67301ef4e 0xc0057c3e07 0xc0057c3e08}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0057c3e68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb  6 05:16:26.636: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb  6 05:16:26.636: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-2847 /apis/apps/v1/namespaces/deployment-2847/replicasets/test-rollover-controller cd931e45-28ef-4621-8a07-08641a98325c 1807018 2 2020-02-06 05:15:59 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment c663ad00-5e6d-45bb-ad49-18c67301ef4e 0xc0057c3d0f 0xc0057c3d20}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0057c3d88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 05:16:26.636: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-2847 /apis/apps/v1/namespaces/deployment-2847/replicasets/test-rollover-deployment-f6c94f66c 4107a13d-91eb-4e65-9bb0-f1957ab08195 1806976 2 2020-02-06 05:16:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment c663ad00-5e6d-45bb-ad49-18c67301ef4e 0xc0057c3ed0 0xc0057c3ed1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0057c3f48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 05:16:26.638: INFO: Pod "test-rollover-deployment-7d7dc6548c-gp5hp" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-gp5hp test-rollover-deployment-7d7dc6548c- deployment-2847 /api/v1/namespaces/deployment-2847/pods/test-rollover-deployment-7d7dc6548c-gp5hp 0a58c129-c463-41e9-a3b8-21c05bb33ef2 1806993 0 2020-02-06 05:16:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[pod.beta1.sigma.ali/update-status:{"statuses":{"redis":{"creationTimestamp":"2020-02-06T13:16:13.310163222+08:00","finishTimestamp":"2020-02-06T13:16:14.210711217+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c cebc57bb-166d-48b3-99f6-588da9521758 0xc0079424a7 0xc0079424a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-lpzkj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-lpzkj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-lpzkj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:16:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:16:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:16:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:16:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:16:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.78,PodIP:10.244.2.249,StartTime:2020-02-06 05:16:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 05:16:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://48a2803547bb09f6ff2fc8a8b57909bd960795eef636537e644a482b01bd5fc2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.249,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:16:26.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2847" for this suite.
Feb  6 05:16:32.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:16:32.709: INFO: namespace deployment-2847 deletion completed in 6.068212651s

• [SLOW TEST:33.254 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:16:32.710: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2769
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 05:16:32.840: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb  6 05:16:32.845: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb  6 05:16:37.848: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 05:16:37.848: INFO: Creating deployment "test-rolling-update-deployment"
Feb  6 05:16:37.851: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb  6 05:16:37.857: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb  6 05:16:39.861: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb  6 05:16:39.862: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562997, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562997, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562997, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716562997, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 05:16:41.864: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb  6 05:16:41.869: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2769 /apis/apps/v1/namespaces/deployment-2769/deployments/test-rolling-update-deployment 6b9dc44a-93e7-44b5-975d-a263e16eba71 1807133 1 2020-02-06 05:16:37 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00370c138 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-06 05:16:37 +0000 UTC,LastTransitionTime:2020-02-06 05:16:37 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-02-06 05:16:40 +0000 UTC,LastTransitionTime:2020-02-06 05:16:37 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb  6 05:16:41.871: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-2769 /apis/apps/v1/namespaces/deployment-2769/replicasets/test-rolling-update-deployment-55d946486 256a5788-91b2-41c2-a327-90c09e66bd7d 1807123 1 2020-02-06 05:16:37 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 6b9dc44a-93e7-44b5-975d-a263e16eba71 0xc0052eeeb0 0xc0052eeeb1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0052eef18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb  6 05:16:41.871: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb  6 05:16:41.871: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2769 /apis/apps/v1/namespaces/deployment-2769/replicasets/test-rolling-update-controller fdb56a6b-2477-4282-adc3-b2c889ab6b26 1807132 2 2020-02-06 05:16:32 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 6b9dc44a-93e7-44b5-975d-a263e16eba71 0xc0052eede7 0xc0052eede8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0052eee48 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb  6 05:16:41.873: INFO: Pod "test-rolling-update-deployment-55d946486-qsdfg" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-qsdfg test-rolling-update-deployment-55d946486- deployment-2769 /api/v1/namespaces/deployment-2769/pods/test-rolling-update-deployment-55d946486-qsdfg ba94278f-19f5-4fb1-88d7-c0d35d760441 1807122 0 2020-02-06 05:16:37 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[pod.beta1.sigma.ali/update-status:{"statuses":{"redis":{"creationTimestamp":"2020-02-06T13:16:38.523341126+08:00","finishTimestamp":"2020-02-06T13:16:40.492630271+08:00","retryCount":0,"currentState":"running","lastState":"unknown","action":"start","success":true,"message":"create start and post start success"}}}] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 256a5788-91b2-41c2-a327-90c09e66bd7d 0xc00370c530 0xc00370c531}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tkn6l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tkn6l,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tkn6l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:aks-1-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:16:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:16:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:16:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainerDiskPressure,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:16:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-06 05:16:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.27.81,PodIP:10.244.1.247,StartTime:2020-02-06 05:16:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-06 05:16:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://ba061e5d8589fc7bf06ef1d88f15a1d810a338046f69768bd018982f93e36da8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.247,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:16:41.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2769" for this suite.
Feb  6 05:16:47.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:16:47.927: INFO: namespace deployment-2769 deletion completed in 6.052385031s

• [SLOW TEST:15.218 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:16:47.928: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-3058
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 05:16:48.052: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Creating first CR 
Feb  6 05:16:48.791: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T05:16:48Z generation:1 name:name1 resourceVersion:1807188 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:ef637630-f3db-4978-b88e-2747b00c03de] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Feb  6 05:16:58.794: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T05:16:58Z generation:1 name:name2 resourceVersion:1807204 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:cec2359a-c587-4431-8f7c-12b55ff4f454] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Feb  6 05:17:08.813: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T05:16:48Z generation:2 name:name1 resourceVersion:1807219 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:ef637630-f3db-4978-b88e-2747b00c03de] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Feb  6 05:17:18.818: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T05:16:58Z generation:2 name:name2 resourceVersion:1807234 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:cec2359a-c587-4431-8f7c-12b55ff4f454] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Feb  6 05:17:28.822: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T05:16:48Z generation:2 name:name1 resourceVersion:1807250 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:ef637630-f3db-4978-b88e-2747b00c03de] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Feb  6 05:17:38.827: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-06T05:16:58Z generation:2 name:name2 resourceVersion:1807267 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:cec2359a-c587-4431-8f7c-12b55ff4f454] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:17:49.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-3058" for this suite.
Feb  6 05:17:55.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:17:55.393: INFO: namespace crd-watch-3058 deletion completed in 6.056882675s

• [SLOW TEST:67.465 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:17:55.393: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9090
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 05:17:55.895: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb  6 05:17:57.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716563075, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716563075, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716563075, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716563075, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 05:18:00.908: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:18:00.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9090" for this suite.
Feb  6 05:18:06.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:18:07.002: INFO: namespace webhook-9090 deletion completed in 6.05537607s
STEP: Destroying namespace "webhook-9090-markers" for this suite.
Feb  6 05:18:13.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:18:13.057: INFO: namespace webhook-9090-markers deletion completed in 6.055121501s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.671 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:18:13.064: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8458
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb  6 05:18:15.204: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:18:15.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8458" for this suite.
Feb  6 05:18:21.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:18:21.272: INFO: namespace container-runtime-8458 deletion completed in 6.056422889s

• [SLOW TEST:8.208 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:18:21.273: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-412
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 05:18:21.407: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e516805-a2dc-4339-8eb4-487a534f37b4" in namespace "downward-api-412" to be "success or failure"
Feb  6 05:18:21.415: INFO: Pod "downwardapi-volume-4e516805-a2dc-4339-8eb4-487a534f37b4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.547177ms
Feb  6 05:18:23.418: INFO: Pod "downwardapi-volume-4e516805-a2dc-4339-8eb4-487a534f37b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011293798s
STEP: Saw pod success
Feb  6 05:18:23.418: INFO: Pod "downwardapi-volume-4e516805-a2dc-4339-8eb4-487a534f37b4" satisfied condition "success or failure"
Feb  6 05:18:23.420: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-4e516805-a2dc-4339-8eb4-487a534f37b4 container client-container: <nil>
STEP: delete the pod
Feb  6 05:18:23.437: INFO: Waiting for pod downwardapi-volume-4e516805-a2dc-4339-8eb4-487a534f37b4 to disappear
Feb  6 05:18:23.438: INFO: Pod downwardapi-volume-4e516805-a2dc-4339-8eb4-487a534f37b4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:18:23.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-412" for this suite.
Feb  6 05:18:29.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:18:29.496: INFO: namespace downward-api-412 deletion completed in 6.055648241s

• [SLOW TEST:8.223 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:18:29.496: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2911
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-2911/configmap-test-7c462404-9aea-48f5-84ad-6cced9087436
STEP: Creating a pod to test consume configMaps
Feb  6 05:18:29.679: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd443453-0882-4f5b-8206-f1270b850fd5" in namespace "configmap-2911" to be "success or failure"
Feb  6 05:18:29.680: INFO: Pod "pod-configmaps-fd443453-0882-4f5b-8206-f1270b850fd5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.439233ms
Feb  6 05:18:31.683: INFO: Pod "pod-configmaps-fd443453-0882-4f5b-8206-f1270b850fd5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003805074s
STEP: Saw pod success
Feb  6 05:18:31.683: INFO: Pod "pod-configmaps-fd443453-0882-4f5b-8206-f1270b850fd5" satisfied condition "success or failure"
Feb  6 05:18:31.684: INFO: Trying to get logs from node aks-1-4 pod pod-configmaps-fd443453-0882-4f5b-8206-f1270b850fd5 container env-test: <nil>
STEP: delete the pod
Feb  6 05:18:31.698: INFO: Waiting for pod pod-configmaps-fd443453-0882-4f5b-8206-f1270b850fd5 to disappear
Feb  6 05:18:31.700: INFO: Pod pod-configmaps-fd443453-0882-4f5b-8206-f1270b850fd5 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:18:31.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2911" for this suite.
Feb  6 05:18:37.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:18:37.756: INFO: namespace configmap-2911 deletion completed in 6.05381644s

• [SLOW TEST:8.260 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:18:37.756: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4726
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 05:18:37.901: INFO: Number of nodes with available pods: 0
Feb  6 05:18:37.901: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 05:18:38.908: INFO: Number of nodes with available pods: 0
Feb  6 05:18:38.908: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 05:18:39.906: INFO: Number of nodes with available pods: 0
Feb  6 05:18:39.906: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 05:18:40.914: INFO: Number of nodes with available pods: 0
Feb  6 05:18:40.914: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 05:18:41.906: INFO: Number of nodes with available pods: 2
Feb  6 05:18:41.906: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:18:42.906: INFO: Number of nodes with available pods: 2
Feb  6 05:18:42.906: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:18:43.906: INFO: Number of nodes with available pods: 2
Feb  6 05:18:43.906: INFO: Node aks-1-3 is running more than one daemon pod
Feb  6 05:18:44.906: INFO: Number of nodes with available pods: 3
Feb  6 05:18:44.906: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb  6 05:18:44.937: INFO: Number of nodes with available pods: 2
Feb  6 05:18:44.937: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 05:18:46.097: INFO: Number of nodes with available pods: 2
Feb  6 05:18:46.097: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 05:18:46.950: INFO: Number of nodes with available pods: 2
Feb  6 05:18:46.950: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 05:18:47.945: INFO: Number of nodes with available pods: 2
Feb  6 05:18:47.945: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 05:18:48.941: INFO: Number of nodes with available pods: 2
Feb  6 05:18:48.941: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 05:18:49.941: INFO: Number of nodes with available pods: 2
Feb  6 05:18:49.941: INFO: Node aks-1-2 is running more than one daemon pod
Feb  6 05:18:50.941: INFO: Number of nodes with available pods: 3
Feb  6 05:18:50.941: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4726, will wait for the garbage collector to delete the pods
Feb  6 05:18:50.999: INFO: Deleting DaemonSet.extensions daemon-set took: 4.630687ms
Feb  6 05:18:51.300: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.215686ms
Feb  6 05:19:04.202: INFO: Number of nodes with available pods: 0
Feb  6 05:19:04.202: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 05:19:04.203: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4726/daemonsets","resourceVersion":"1807645"},"items":null}

Feb  6 05:19:04.207: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4726/pods","resourceVersion":"1807645"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:19:04.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4726" for this suite.
Feb  6 05:19:10.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:19:10.271: INFO: namespace daemonsets-4726 deletion completed in 6.057312095s

• [SLOW TEST:32.515 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:19:10.272: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8448
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-5c1c3f37-fc1f-4726-93ca-d29123f525c5
STEP: Creating a pod to test consume configMaps
Feb  6 05:19:10.404: INFO: Waiting up to 5m0s for pod "pod-configmaps-b08400da-c895-4cd0-8eed-32597dd56b22" in namespace "configmap-8448" to be "success or failure"
Feb  6 05:19:10.408: INFO: Pod "pod-configmaps-b08400da-c895-4cd0-8eed-32597dd56b22": Phase="Pending", Reason="", readiness=false. Elapsed: 3.516381ms
Feb  6 05:19:12.410: INFO: Pod "pod-configmaps-b08400da-c895-4cd0-8eed-32597dd56b22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00589833s
STEP: Saw pod success
Feb  6 05:19:12.410: INFO: Pod "pod-configmaps-b08400da-c895-4cd0-8eed-32597dd56b22" satisfied condition "success or failure"
Feb  6 05:19:12.412: INFO: Trying to get logs from node aks-1-3 pod pod-configmaps-b08400da-c895-4cd0-8eed-32597dd56b22 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 05:19:12.431: INFO: Waiting for pod pod-configmaps-b08400da-c895-4cd0-8eed-32597dd56b22 to disappear
Feb  6 05:19:12.432: INFO: Pod pod-configmaps-b08400da-c895-4cd0-8eed-32597dd56b22 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:19:12.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8448" for this suite.
Feb  6 05:19:18.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:19:18.490: INFO: namespace configmap-8448 deletion completed in 6.054741311s

• [SLOW TEST:8.218 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:19:18.490: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8327
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-eda5e4b9-1ced-462f-a89d-91f53273eb1a
STEP: Creating configMap with name cm-test-opt-upd-88db8174-af0d-489e-b13a-c5a6953bb966
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-eda5e4b9-1ced-462f-a89d-91f53273eb1a
STEP: Updating configmap cm-test-opt-upd-88db8174-af0d-489e-b13a-c5a6953bb966
STEP: Creating configMap with name cm-test-opt-create-55642c4c-0d21-4f83-b61b-0e286d2f018e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:20:36.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8327" for this suite.
Feb  6 05:20:50.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:20:51.013: INFO: namespace configmap-8327 deletion completed in 14.059034969s

• [SLOW TEST:92.523 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:20:51.013: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8992
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Feb  6 05:20:53.171: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-529150080 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb  6 05:21:03.274: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:21:03.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8992" for this suite.
Feb  6 05:21:09.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:21:09.336: INFO: namespace pods-8992 deletion completed in 6.056097452s

• [SLOW TEST:18.323 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:21:09.337: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1517
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb  6 05:21:09.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-1517'
Feb  6 05:21:09.740: INFO: stderr: ""
Feb  6 05:21:09.740: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 05:21:09.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1517'
Feb  6 05:21:09.849: INFO: stderr: ""
Feb  6 05:21:09.849: INFO: stdout: "update-demo-nautilus-4ldl8 update-demo-nautilus-t9zpj "
Feb  6 05:21:09.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-4ldl8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:09.933: INFO: stderr: ""
Feb  6 05:21:09.933: INFO: stdout: ""
Feb  6 05:21:09.933: INFO: update-demo-nautilus-4ldl8 is created but not running
Feb  6 05:21:14.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1517'
Feb  6 05:21:15.024: INFO: stderr: ""
Feb  6 05:21:15.024: INFO: stdout: "update-demo-nautilus-4ldl8 update-demo-nautilus-t9zpj "
Feb  6 05:21:15.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-4ldl8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:15.134: INFO: stderr: ""
Feb  6 05:21:15.134: INFO: stdout: "true"
Feb  6 05:21:15.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-4ldl8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:15.218: INFO: stderr: ""
Feb  6 05:21:15.218: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 05:21:15.218: INFO: validating pod update-demo-nautilus-4ldl8
Feb  6 05:21:15.222: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 05:21:15.222: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 05:21:15.222: INFO: update-demo-nautilus-4ldl8 is verified up and running
Feb  6 05:21:15.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-t9zpj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:15.306: INFO: stderr: ""
Feb  6 05:21:15.306: INFO: stdout: "true"
Feb  6 05:21:15.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-t9zpj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:15.393: INFO: stderr: ""
Feb  6 05:21:15.393: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 05:21:15.393: INFO: validating pod update-demo-nautilus-t9zpj
Feb  6 05:21:15.396: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 05:21:15.396: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 05:21:15.396: INFO: update-demo-nautilus-t9zpj is verified up and running
STEP: scaling down the replication controller
Feb  6 05:21:15.397: INFO: scanned /root for discovery docs: <nil>
Feb  6 05:21:15.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1517'
Feb  6 05:21:16.508: INFO: stderr: ""
Feb  6 05:21:16.508: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 05:21:16.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1517'
Feb  6 05:21:16.602: INFO: stderr: ""
Feb  6 05:21:16.602: INFO: stdout: "update-demo-nautilus-4ldl8 update-demo-nautilus-t9zpj "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb  6 05:21:21.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1517'
Feb  6 05:21:21.686: INFO: stderr: ""
Feb  6 05:21:21.686: INFO: stdout: "update-demo-nautilus-4ldl8 "
Feb  6 05:21:21.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-4ldl8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:21.783: INFO: stderr: ""
Feb  6 05:21:21.783: INFO: stdout: "true"
Feb  6 05:21:21.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-4ldl8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:21.881: INFO: stderr: ""
Feb  6 05:21:21.881: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 05:21:21.881: INFO: validating pod update-demo-nautilus-4ldl8
Feb  6 05:21:21.884: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 05:21:21.884: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 05:21:21.884: INFO: update-demo-nautilus-4ldl8 is verified up and running
STEP: scaling up the replication controller
Feb  6 05:21:21.885: INFO: scanned /root for discovery docs: <nil>
Feb  6 05:21:21.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1517'
Feb  6 05:21:23.005: INFO: stderr: ""
Feb  6 05:21:23.005: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 05:21:23.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1517'
Feb  6 05:21:23.097: INFO: stderr: ""
Feb  6 05:21:23.097: INFO: stdout: "update-demo-nautilus-4ldl8 update-demo-nautilus-h9dz9 "
Feb  6 05:21:23.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-4ldl8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:23.199: INFO: stderr: ""
Feb  6 05:21:23.199: INFO: stdout: "true"
Feb  6 05:21:23.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-4ldl8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:23.290: INFO: stderr: ""
Feb  6 05:21:23.290: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 05:21:23.290: INFO: validating pod update-demo-nautilus-4ldl8
Feb  6 05:21:23.292: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 05:21:23.293: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 05:21:23.293: INFO: update-demo-nautilus-4ldl8 is verified up and running
Feb  6 05:21:23.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-h9dz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:23.375: INFO: stderr: ""
Feb  6 05:21:23.375: INFO: stdout: ""
Feb  6 05:21:23.375: INFO: update-demo-nautilus-h9dz9 is created but not running
Feb  6 05:21:28.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1517'
Feb  6 05:21:28.465: INFO: stderr: ""
Feb  6 05:21:28.465: INFO: stdout: "update-demo-nautilus-4ldl8 update-demo-nautilus-h9dz9 "
Feb  6 05:21:28.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-4ldl8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:28.549: INFO: stderr: ""
Feb  6 05:21:28.549: INFO: stdout: "true"
Feb  6 05:21:28.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-4ldl8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:28.638: INFO: stderr: ""
Feb  6 05:21:28.638: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 05:21:28.638: INFO: validating pod update-demo-nautilus-4ldl8
Feb  6 05:21:28.640: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 05:21:28.640: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 05:21:28.640: INFO: update-demo-nautilus-4ldl8 is verified up and running
Feb  6 05:21:28.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-h9dz9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:28.721: INFO: stderr: ""
Feb  6 05:21:28.721: INFO: stdout: "true"
Feb  6 05:21:28.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods update-demo-nautilus-h9dz9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1517'
Feb  6 05:21:28.806: INFO: stderr: ""
Feb  6 05:21:28.806: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 05:21:28.806: INFO: validating pod update-demo-nautilus-h9dz9
Feb  6 05:21:28.809: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 05:21:28.809: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 05:21:28.809: INFO: update-demo-nautilus-h9dz9 is verified up and running
STEP: using delete to clean up resources
Feb  6 05:21:28.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete --grace-period=0 --force -f - --namespace=kubectl-1517'
Feb  6 05:21:28.896: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 05:21:28.896: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  6 05:21:28.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1517'
Feb  6 05:21:29.027: INFO: stderr: "No resources found in kubectl-1517 namespace.\n"
Feb  6 05:21:29.027: INFO: stdout: ""
Feb  6 05:21:29.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -l name=update-demo --namespace=kubectl-1517 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 05:21:29.132: INFO: stderr: ""
Feb  6 05:21:29.132: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:21:29.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1517" for this suite.
Feb  6 05:21:57.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:21:57.203: INFO: namespace kubectl-1517 deletion completed in 28.068105736s

• [SLOW TEST:47.866 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:21:57.203: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7144
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7144.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7144.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7144.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7144.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7144.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7144.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 05:22:03.368: INFO: DNS probes using dns-7144/dns-test-259176e4-a880-4509-9344-0088e1472a32 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:22:03.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7144" for this suite.
Feb  6 05:22:09.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:22:09.453: INFO: namespace dns-7144 deletion completed in 6.057337306s

• [SLOW TEST:12.250 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:22:09.453: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3557
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb  6 05:22:09.636: INFO: Waiting up to 5m0s for pod "downward-api-0c8842f5-ca34-4cc9-80b4-9056555112fc" in namespace "downward-api-3557" to be "success or failure"
Feb  6 05:22:09.638: INFO: Pod "downward-api-0c8842f5-ca34-4cc9-80b4-9056555112fc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.771542ms
Feb  6 05:22:11.640: INFO: Pod "downward-api-0c8842f5-ca34-4cc9-80b4-9056555112fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004121164s
STEP: Saw pod success
Feb  6 05:22:11.640: INFO: Pod "downward-api-0c8842f5-ca34-4cc9-80b4-9056555112fc" satisfied condition "success or failure"
Feb  6 05:22:11.642: INFO: Trying to get logs from node aks-1-4 pod downward-api-0c8842f5-ca34-4cc9-80b4-9056555112fc container dapi-container: <nil>
STEP: delete the pod
Feb  6 05:22:11.663: INFO: Waiting for pod downward-api-0c8842f5-ca34-4cc9-80b4-9056555112fc to disappear
Feb  6 05:22:11.665: INFO: Pod downward-api-0c8842f5-ca34-4cc9-80b4-9056555112fc no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:22:11.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3557" for this suite.
Feb  6 05:22:17.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:22:17.725: INFO: namespace downward-api-3557 deletion completed in 6.057236192s

• [SLOW TEST:8.271 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:22:17.725: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7288
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-be5e934e-3178-4875-b86b-dddafbaad33d
STEP: Creating a pod to test consume secrets
Feb  6 05:22:17.885: INFO: Waiting up to 5m0s for pod "pod-secrets-e761c3e1-00d1-42c2-b1d3-e7ee15f6c268" in namespace "secrets-7288" to be "success or failure"
Feb  6 05:22:17.890: INFO: Pod "pod-secrets-e761c3e1-00d1-42c2-b1d3-e7ee15f6c268": Phase="Pending", Reason="", readiness=false. Elapsed: 4.821687ms
Feb  6 05:22:19.892: INFO: Pod "pod-secrets-e761c3e1-00d1-42c2-b1d3-e7ee15f6c268": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007334456s
STEP: Saw pod success
Feb  6 05:22:19.892: INFO: Pod "pod-secrets-e761c3e1-00d1-42c2-b1d3-e7ee15f6c268" satisfied condition "success or failure"
Feb  6 05:22:19.894: INFO: Trying to get logs from node aks-1-4 pod pod-secrets-e761c3e1-00d1-42c2-b1d3-e7ee15f6c268 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 05:22:19.905: INFO: Waiting for pod pod-secrets-e761c3e1-00d1-42c2-b1d3-e7ee15f6c268 to disappear
Feb  6 05:22:19.907: INFO: Pod pod-secrets-e761c3e1-00d1-42c2-b1d3-e7ee15f6c268 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:22:19.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7288" for this suite.
Feb  6 05:22:25.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:22:25.966: INFO: namespace secrets-7288 deletion completed in 6.057278619s

• [SLOW TEST:8.242 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:22:25.966: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7159
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7159
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb  6 05:22:26.103: INFO: Found 0 stateful pods, waiting for 3
Feb  6 05:22:36.107: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 05:22:36.107: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 05:22:36.107: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb  6 05:22:46.106: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 05:22:46.106: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 05:22:46.106: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb  6 05:22:46.126: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb  6 05:22:56.151: INFO: Updating stateful set ss2
Feb  6 05:22:56.158: INFO: Waiting for Pod statefulset-7159/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Feb  6 05:23:06.203: INFO: Found 2 stateful pods, waiting for 3
Feb  6 05:23:16.206: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 05:23:16.206: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 05:23:16.206: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb  6 05:23:26.206: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 05:23:26.206: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 05:23:26.206: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb  6 05:23:26.224: INFO: Updating stateful set ss2
Feb  6 05:23:26.228: INFO: Waiting for Pod statefulset-7159/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 05:23:36.232: INFO: Waiting for Pod statefulset-7159/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 05:23:46.251: INFO: Updating stateful set ss2
Feb  6 05:23:46.256: INFO: Waiting for StatefulSet statefulset-7159/ss2 to complete update
Feb  6 05:23:46.256: INFO: Waiting for Pod statefulset-7159/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb  6 05:23:56.261: INFO: Waiting for StatefulSet statefulset-7159/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 05:24:06.261: INFO: Deleting all statefulset in ns statefulset-7159
Feb  6 05:24:06.262: INFO: Scaling statefulset ss2 to 0
Feb  6 05:24:36.272: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 05:24:36.273: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:24:36.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7159" for this suite.
Feb  6 05:24:42.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:24:42.352: INFO: namespace statefulset-7159 deletion completed in 6.069206426s

• [SLOW TEST:136.386 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:24:42.353: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9709
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0206 05:24:52.491851      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 05:24:52.491: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:24:52.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9709" for this suite.
Feb  6 05:24:58.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:24:58.562: INFO: namespace gc-9709 deletion completed in 6.06840832s

• [SLOW TEST:16.209 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:24:58.562: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6264
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Feb  6 05:24:58.689: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Feb  6 05:25:13.965: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 05:25:17.719: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:25:31.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6264" for this suite.
Feb  6 05:25:37.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:25:37.589: INFO: namespace crd-publish-openapi-6264 deletion completed in 6.081781029s

• [SLOW TEST:39.027 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:25:37.589: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-1347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb  6 05:25:49.744: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1347 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 05:25:49.744: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 05:25:50.764: INFO: Exec stderr: ""
Feb  6 05:25:50.764: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1347 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 05:25:50.765: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 05:25:50.871: INFO: Exec stderr: ""
Feb  6 05:25:50.871: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1347 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 05:25:50.871: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 05:25:50.947: INFO: Exec stderr: ""
Feb  6 05:25:50.947: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1347 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 05:25:50.947: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 05:25:51.020: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb  6 05:25:51.020: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1347 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 05:25:51.020: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 05:25:51.088: INFO: Exec stderr: ""
Feb  6 05:25:51.088: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1347 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 05:25:51.088: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 05:25:51.157: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb  6 05:25:51.157: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1347 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 05:25:51.157: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 05:25:51.248: INFO: Exec stderr: ""
Feb  6 05:25:51.248: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1347 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 05:25:51.248: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 05:25:51.321: INFO: Exec stderr: ""
Feb  6 05:25:51.321: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1347 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 05:25:51.321: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 05:25:51.405: INFO: Exec stderr: ""
Feb  6 05:25:51.405: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1347 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 05:25:51.405: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
Feb  6 05:25:51.488: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:25:51.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1347" for this suite.
Feb  6 05:26:35.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:26:35.543: INFO: namespace e2e-kubelet-etc-hosts-1347 deletion completed in 44.051389097s

• [SLOW TEST:57.953 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:26:35.543: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7762
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-51f35d7d-8b8a-4cc7-9fc0-1411ab1067ca
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:26:35.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7762" for this suite.
Feb  6 05:26:41.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:26:41.727: INFO: namespace secrets-7762 deletion completed in 6.05466048s

• [SLOW TEST:6.185 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:26:41.728: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2095
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb  6 05:26:41.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2095'
Feb  6 05:26:42.273: INFO: stderr: ""
Feb  6 05:26:42.273: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Feb  6 05:26:42.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete pods e2e-test-httpd-pod --namespace=kubectl-2095'
Feb  6 05:26:53.350: INFO: stderr: ""
Feb  6 05:26:53.350: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:26:53.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2095" for this suite.
Feb  6 05:26:59.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:26:59.415: INFO: namespace kubectl-2095 deletion completed in 6.063565775s

• [SLOW TEST:17.688 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:26:59.416: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8535
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8535
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8535
Feb  6 05:26:59.562: INFO: Found 0 stateful pods, waiting for 1
Feb  6 05:27:09.565: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb  6 05:27:09.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 05:27:09.873: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 05:27:09.873: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 05:27:09.873: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 05:27:09.875: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 05:27:09.875: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 05:27:09.901: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999572s
Feb  6 05:27:10.905: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.97884987s
Feb  6 05:27:11.908: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.975617153s
Feb  6 05:27:12.912: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.972011334s
Feb  6 05:27:13.936: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.968454344s
Feb  6 05:27:15.054: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.944325554s
Feb  6 05:27:16.058: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.826026235s
Feb  6 05:27:17.061: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.822429993s
Feb  6 05:27:18.065: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.819400513s
Feb  6 05:27:19.095: INFO: Verifying statefulset ss doesn't scale past 1 for another 814.585452ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8535
Feb  6 05:27:20.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:27:20.461: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 05:27:20.461: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 05:27:20.461: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 05:27:20.465: INFO: Found 1 stateful pods, waiting for 3
Feb  6 05:27:30.468: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 05:27:30.468: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 05:27:30.468: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb  6 05:27:30.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 05:27:30.850: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 05:27:30.850: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 05:27:30.850: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 05:27:30.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 05:27:31.321: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 05:27:31.321: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 05:27:31.321: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 05:27:31.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb  6 05:27:31.503: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb  6 05:27:31.503: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb  6 05:27:31.503: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb  6 05:27:31.503: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 05:27:31.506: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Feb  6 05:27:41.510: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 05:27:41.510: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 05:27:41.510: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 05:27:41.517: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999546s
Feb  6 05:27:42.520: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997758358s
Feb  6 05:27:43.523: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994719554s
Feb  6 05:27:44.527: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991531316s
Feb  6 05:27:45.530: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.987780628s
Feb  6 05:27:46.532: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985226699s
Feb  6 05:27:47.535: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982356476s
Feb  6 05:27:48.538: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.979273272s
Feb  6 05:27:49.541: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.976394892s
Feb  6 05:27:50.568: INFO: Verifying statefulset ss doesn't scale past 3 for another 973.265588ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8535
Feb  6 05:27:51.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:27:51.739: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 05:27:51.740: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 05:27:51.740: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 05:27:51.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:27:51.932: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb  6 05:27:51.932: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb  6 05:27:51.932: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb  6 05:27:51.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:27:52.119: INFO: rc: 126
Feb  6 05:27:52.138: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil> OCI runtime exec failed: exec failed: cannot exec a container that has stopped: unknown
 command terminated with exit code 126
 [] <nil> 0xc005f165d0 exit status 126 <nil> <nil> true [0xc004fbe1a8 0xc004fbe1c0 0xc004fbe1d8] [0xc004fbe1a8 0xc004fbe1c0 0xc004fbe1d8] [0xc004fbe1b8 0xc004fbe1d0] [0x10efe30 0x10efe30] 0xc0034ff860 <nil>}:
Command stdout:
OCI runtime exec failed: exec failed: cannot exec a container that has stopped: unknown

stderr:
command terminated with exit code 126

error:
exit status 126
Feb  6 05:28:02.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:28:02.271: INFO: rc: 1
Feb  6 05:28:02.271: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc002b47e60 exit status 1 <nil> <nil> true [0xc004f84130 0xc004f84148 0xc004f84160] [0xc004f84130 0xc004f84148 0xc004f84160] [0xc004f84140 0xc004f84158] [0x10efe30 0x10efe30] 0xc002173200 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Feb  6 05:28:12.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:28:12.366: INFO: rc: 1
Feb  6 05:28:12.366: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005f16a20 exit status 1 <nil> <nil> true [0xc004fbe1e0 0xc004fbe1f8 0xc004fbe210] [0xc004fbe1e0 0xc004fbe1f8 0xc004fbe210] [0xc004fbe1f0 0xc004fbe208] [0x10efe30 0x10efe30] 0xc0034ffbc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:28:22.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:28:22.491: INFO: rc: 1
Feb  6 05:28:22.491: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025a8240 exit status 1 <nil> <nil> true [0xc004f84168 0xc004f84180 0xc004f84198] [0xc004f84168 0xc004f84180 0xc004f84198] [0xc004f84178 0xc004f84190] [0x10efe30 0x10efe30] 0xc002173560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:28:32.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:28:32.582: INFO: rc: 1
Feb  6 05:28:32.582: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005f16e10 exit status 1 <nil> <nil> true [0xc004fbe218 0xc004fbe230 0xc004fbe248] [0xc004fbe218 0xc004fbe230 0xc004fbe248] [0xc004fbe228 0xc004fbe240] [0x10efe30 0x10efe30] 0xc0034fff20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:28:42.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:28:42.666: INFO: rc: 1
Feb  6 05:28:42.666: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005f171a0 exit status 1 <nil> <nil> true [0xc004fbe250 0xc004fbe268 0xc004fbe280] [0xc004fbe250 0xc004fbe268 0xc004fbe280] [0xc004fbe260 0xc004fbe278] [0x10efe30 0x10efe30] 0xc002845a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:28:52.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:28:52.752: INFO: rc: 1
Feb  6 05:28:52.752: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025a8840 exit status 1 <nil> <nil> true [0xc004f841a0 0xc004f841b8 0xc004f841d0] [0xc004f841a0 0xc004f841b8 0xc004f841d0] [0xc004f841b0 0xc004f841c8] [0x10efe30 0x10efe30] 0xc0021738c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:29:02.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:29:02.841: INFO: rc: 1
Feb  6 05:29:02.841: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005f17590 exit status 1 <nil> <nil> true [0xc004fbe288 0xc004fbe2a0 0xc004fbe2b8] [0xc004fbe288 0xc004fbe2a0 0xc004fbe2b8] [0xc004fbe298 0xc004fbe2b0] [0x10efe30 0x10efe30] 0xc005f183c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:29:12.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:29:12.926: INFO: rc: 1
Feb  6 05:29:12.926: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005f17920 exit status 1 <nil> <nil> true [0xc004fbe2c0 0xc004fbe2d8 0xc004fbe2f0] [0xc004fbe2c0 0xc004fbe2d8 0xc004fbe2f0] [0xc004fbe2d0 0xc004fbe2e8] [0x10efe30 0x10efe30] 0xc005f18720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:29:22.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:29:23.017: INFO: rc: 1
Feb  6 05:29:23.017: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0025a8d20 exit status 1 <nil> <nil> true [0xc004f841d8 0xc004f841f0 0xc004f84208] [0xc004f841d8 0xc004f841f0 0xc004f84208] [0xc004f841e8 0xc004f84200] [0x10efe30 0x10efe30] 0xc002173c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:29:33.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:29:33.103: INFO: rc: 1
Feb  6 05:29:33.103: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005f17cb0 exit status 1 <nil> <nil> true [0xc004fbe2f8 0xc004fbe310 0xc004fbe328] [0xc004fbe2f8 0xc004fbe310 0xc004fbe328] [0xc004fbe308 0xc004fbe320] [0x10efe30 0x10efe30] 0xc005f18ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:29:43.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:29:43.186: INFO: rc: 1
Feb  6 05:29:43.187: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b46360 exit status 1 <nil> <nil> true [0xc004f84008 0xc004f84020 0xc004f84038] [0xc004f84008 0xc004f84020 0xc004f84038] [0xc004f84018 0xc004f84030] [0x10efe30 0x10efe30] 0xc002845a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:29:53.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:29:53.274: INFO: rc: 1
Feb  6 05:29:53.274: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c8390 exit status 1 <nil> <nil> true [0xc004fbe000 0xc004fbe018 0xc004fbe030] [0xc004fbe000 0xc004fbe018 0xc004fbe030] [0xc004fbe010 0xc004fbe028] [0x10efe30 0x10efe30] 0xc0034fe420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:30:03.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:30:03.361: INFO: rc: 1
Feb  6 05:30:03.361: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c8720 exit status 1 <nil> <nil> true [0xc004fbe038 0xc004fbe050 0xc004fbe068] [0xc004fbe038 0xc004fbe050 0xc004fbe068] [0xc004fbe048 0xc004fbe060] [0x10efe30 0x10efe30] 0xc0034fe7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:30:13.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:30:13.489: INFO: rc: 1
Feb  6 05:30:13.490: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c8ab0 exit status 1 <nil> <nil> true [0xc004fbe070 0xc004fbe088 0xc004fbe0a0] [0xc004fbe070 0xc004fbe088 0xc004fbe0a0] [0xc004fbe080 0xc004fbe098] [0x10efe30 0x10efe30] 0xc0034feb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:30:23.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:30:23.577: INFO: rc: 1
Feb  6 05:30:23.577: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b46750 exit status 1 <nil> <nil> true [0xc004f84040 0xc004f84058 0xc004f84070] [0xc004f84040 0xc004f84058 0xc004f84070] [0xc004f84050 0xc004f84068] [0x10efe30 0x10efe30] 0xc002172240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:30:33.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:30:33.670: INFO: rc: 1
Feb  6 05:30:33.670: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c8e70 exit status 1 <nil> <nil> true [0xc004fbe0a8 0xc004fbe0c0 0xc004fbe0d8] [0xc004fbe0a8 0xc004fbe0c0 0xc004fbe0d8] [0xc004fbe0b8 0xc004fbe0d0] [0x10efe30 0x10efe30] 0xc0034ff080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:30:43.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:30:43.760: INFO: rc: 1
Feb  6 05:30:43.760: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c9200 exit status 1 <nil> <nil> true [0xc004fbe0e0 0xc004fbe0f8 0xc004fbe110] [0xc004fbe0e0 0xc004fbe0f8 0xc004fbe110] [0xc004fbe0f0 0xc004fbe108] [0x10efe30 0x10efe30] 0xc0034ff440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:30:53.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:30:53.845: INFO: rc: 1
Feb  6 05:30:53.845: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c9590 exit status 1 <nil> <nil> true [0xc004fbe118 0xc004fbe130 0xc004fbe148] [0xc004fbe118 0xc004fbe130 0xc004fbe148] [0xc004fbe128 0xc004fbe140] [0x10efe30 0x10efe30] 0xc0034ff7a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:31:03.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:31:03.929: INFO: rc: 1
Feb  6 05:31:03.929: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c9920 exit status 1 <nil> <nil> true [0xc004fbe150 0xc004fbe168 0xc004fbe180] [0xc004fbe150 0xc004fbe168 0xc004fbe180] [0xc004fbe160 0xc004fbe178] [0x10efe30 0x10efe30] 0xc0034ffb00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:31:13.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:31:14.014: INFO: rc: 1
Feb  6 05:31:14.014: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b46c00 exit status 1 <nil> <nil> true [0xc004f84078 0xc004f84090 0xc004f840a8] [0xc004f84078 0xc004f84090 0xc004f840a8] [0xc004f84088 0xc004f840a0] [0x10efe30 0x10efe30] 0xc0021725a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:31:24.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:31:24.112: INFO: rc: 1
Feb  6 05:31:24.112: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004f0a000 exit status 1 <nil> <nil> true [0xc004fbe188 0xc004fbe1a0 0xc004fbe1b8] [0xc004fbe188 0xc004fbe1a0 0xc004fbe1b8] [0xc004fbe198 0xc004fbe1b0] [0x10efe30 0x10efe30] 0xc0034ffe60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:31:34.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:31:34.203: INFO: rc: 1
Feb  6 05:31:34.203: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b471a0 exit status 1 <nil> <nil> true [0xc004f840b0 0xc004f840c8 0xc004f840e0] [0xc004f840b0 0xc004f840c8 0xc004f840e0] [0xc004f840c0 0xc004f840d8] [0x10efe30 0x10efe30] 0xc002172960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:31:44.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:31:44.292: INFO: rc: 1
Feb  6 05:31:44.292: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c8360 exit status 1 <nil> <nil> true [0xc004f84008 0xc004f84020 0xc004f84038] [0xc004f84008 0xc004f84020 0xc004f84038] [0xc004f84018 0xc004f84030] [0x10efe30 0x10efe30] 0xc002845a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:31:54.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:31:54.388: INFO: rc: 1
Feb  6 05:31:54.388: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c8780 exit status 1 <nil> <nil> true [0xc004f84040 0xc004f84058 0xc004f84070] [0xc004f84040 0xc004f84058 0xc004f84070] [0xc004f84050 0xc004f84068] [0x10efe30 0x10efe30] 0xc002172240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:32:04.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:32:04.473: INFO: rc: 1
Feb  6 05:32:04.473: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b46390 exit status 1 <nil> <nil> true [0xc004fbe000 0xc004fbe018 0xc004fbe030] [0xc004fbe000 0xc004fbe018 0xc004fbe030] [0xc004fbe010 0xc004fbe028] [0x10efe30 0x10efe30] 0xc0034fe420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:32:14.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:32:14.558: INFO: rc: 1
Feb  6 05:32:14.558: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002b46720 exit status 1 <nil> <nil> true [0xc004fbe038 0xc004fbe050 0xc004fbe068] [0xc004fbe038 0xc004fbe050 0xc004fbe068] [0xc004fbe048 0xc004fbe060] [0x10efe30 0x10efe30] 0xc0034fe7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:32:24.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:32:24.642: INFO: rc: 1
Feb  6 05:32:24.643: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c8ba0 exit status 1 <nil> <nil> true [0xc004f84078 0xc004f84090 0xc004f840a8] [0xc004f84078 0xc004f84090 0xc004f840a8] [0xc004f84088 0xc004f840a0] [0x10efe30 0x10efe30] 0xc0021725a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:32:34.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:32:34.726: INFO: rc: 1
Feb  6 05:32:34.727: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c8f60 exit status 1 <nil> <nil> true [0xc004f840b0 0xc004f840c8 0xc004f840e0] [0xc004f840b0 0xc004f840c8 0xc004f840e0] [0xc004f840c0 0xc004f840d8] [0x10efe30 0x10efe30] 0xc002172960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:32:44.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:32:44.812: INFO: rc: 1
Feb  6 05:32:44.812: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0057c9320 exit status 1 <nil> <nil> true [0xc004f840e8 0xc004f84100 0xc004f84118] [0xc004f840e8 0xc004f84100 0xc004f84118] [0xc004f840f8 0xc004f84110] [0x10efe30 0x10efe30] 0xc002172e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb  6 05:32:54.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 exec --namespace=statefulset-8535 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb  6 05:32:54.903: INFO: rc: 1
Feb  6 05:32:54.903: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Feb  6 05:32:54.903: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb  6 05:32:54.909: INFO: Deleting all statefulset in ns statefulset-8535
Feb  6 05:32:54.923: INFO: Scaling statefulset ss to 0
Feb  6 05:32:54.927: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 05:32:54.928: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:32:54.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8535" for this suite.
Feb  6 05:33:00.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:33:01.096: INFO: namespace statefulset-8535 deletion completed in 6.157778418s

• [SLOW TEST:361.680 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:33:01.097: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2167
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 05:33:01.251: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ac6594da-826f-408c-a0d1-83607f26e39d" in namespace "downward-api-2167" to be "success or failure"
Feb  6 05:33:01.263: INFO: Pod "downwardapi-volume-ac6594da-826f-408c-a0d1-83607f26e39d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.20776ms
Feb  6 05:33:03.266: INFO: Pod "downwardapi-volume-ac6594da-826f-408c-a0d1-83607f26e39d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014656009s
STEP: Saw pod success
Feb  6 05:33:03.266: INFO: Pod "downwardapi-volume-ac6594da-826f-408c-a0d1-83607f26e39d" satisfied condition "success or failure"
Feb  6 05:33:03.285: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-ac6594da-826f-408c-a0d1-83607f26e39d container client-container: <nil>
STEP: delete the pod
Feb  6 05:33:03.299: INFO: Waiting for pod downwardapi-volume-ac6594da-826f-408c-a0d1-83607f26e39d to disappear
Feb  6 05:33:03.302: INFO: Pod downwardapi-volume-ac6594da-826f-408c-a0d1-83607f26e39d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:33:03.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2167" for this suite.
Feb  6 05:33:09.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:33:09.376: INFO: namespace downward-api-2167 deletion completed in 6.071785626s

• [SLOW TEST:8.279 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:33:09.377: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5510
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:33:09.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5510" for this suite.
Feb  6 05:33:15.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:33:15.569: INFO: namespace services-5510 deletion completed in 6.055777206s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.192 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:33:15.569: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9636
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-a35129d5-6a2c-454d-b27b-1c0370354a69
STEP: Creating a pod to test consume secrets
Feb  6 05:33:15.723: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d93451ea-2fbd-437a-a577-c0495cf5f792" in namespace "projected-9636" to be "success or failure"
Feb  6 05:33:15.726: INFO: Pod "pod-projected-secrets-d93451ea-2fbd-437a-a577-c0495cf5f792": Phase="Pending", Reason="", readiness=false. Elapsed: 2.960878ms
Feb  6 05:33:17.729: INFO: Pod "pod-projected-secrets-d93451ea-2fbd-437a-a577-c0495cf5f792": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005413265s
STEP: Saw pod success
Feb  6 05:33:17.729: INFO: Pod "pod-projected-secrets-d93451ea-2fbd-437a-a577-c0495cf5f792" satisfied condition "success or failure"
Feb  6 05:33:17.730: INFO: Trying to get logs from node aks-1-4 pod pod-projected-secrets-d93451ea-2fbd-437a-a577-c0495cf5f792 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 05:33:17.754: INFO: Waiting for pod pod-projected-secrets-d93451ea-2fbd-437a-a577-c0495cf5f792 to disappear
Feb  6 05:33:17.756: INFO: Pod pod-projected-secrets-d93451ea-2fbd-437a-a577-c0495cf5f792 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:33:17.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9636" for this suite.
Feb  6 05:33:23.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:33:23.815: INFO: namespace projected-9636 deletion completed in 6.057291022s

• [SLOW TEST:8.246 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:33:23.816: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6127
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb  6 05:33:26.609: INFO: Successfully updated pod "labelsupdate1a0018e0-1a6e-4fe4-aee9-89a7adffd8a2"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:33:30.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6127" for this suite.
Feb  6 05:33:42.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:33:42.683: INFO: namespace downward-api-6127 deletion completed in 12.053265931s

• [SLOW TEST:18.867 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:33:42.684: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5147
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 05:33:42.836: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb  6 05:33:46.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-5147 create -f -'
Feb  6 05:33:47.320: INFO: stderr: ""
Feb  6 05:33:47.320: INFO: stdout: "e2e-test-crd-publish-openapi-3976-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb  6 05:33:47.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-5147 delete e2e-test-crd-publish-openapi-3976-crds test-cr'
Feb  6 05:33:47.421: INFO: stderr: ""
Feb  6 05:33:47.421: INFO: stdout: "e2e-test-crd-publish-openapi-3976-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Feb  6 05:33:47.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-5147 apply -f -'
Feb  6 05:33:47.629: INFO: stderr: ""
Feb  6 05:33:47.629: INFO: stdout: "e2e-test-crd-publish-openapi-3976-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb  6 05:33:47.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-5147 delete e2e-test-crd-publish-openapi-3976-crds test-cr'
Feb  6 05:33:47.725: INFO: stderr: ""
Feb  6 05:33:47.725: INFO: stdout: "e2e-test-crd-publish-openapi-3976-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb  6 05:33:47.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 explain e2e-test-crd-publish-openapi-3976-crds'
Feb  6 05:33:47.953: INFO: stderr: ""
Feb  6 05:33:47.953: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3976-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:33:52.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5147" for this suite.
Feb  6 05:33:58.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:33:58.291: INFO: namespace crd-publish-openapi-5147 deletion completed in 6.056745812s

• [SLOW TEST:15.608 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:33:58.292: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3177
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 05:34:00.464: INFO: Waiting up to 5m0s for pod "client-envvars-1703ab89-2c4d-450a-bffa-bc39bdd91374" in namespace "pods-3177" to be "success or failure"
Feb  6 05:34:00.473: INFO: Pod "client-envvars-1703ab89-2c4d-450a-bffa-bc39bdd91374": Phase="Pending", Reason="", readiness=false. Elapsed: 8.337378ms
Feb  6 05:34:02.475: INFO: Pod "client-envvars-1703ab89-2c4d-450a-bffa-bc39bdd91374": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010763601s
STEP: Saw pod success
Feb  6 05:34:02.475: INFO: Pod "client-envvars-1703ab89-2c4d-450a-bffa-bc39bdd91374" satisfied condition "success or failure"
Feb  6 05:34:02.477: INFO: Trying to get logs from node aks-1-4 pod client-envvars-1703ab89-2c4d-450a-bffa-bc39bdd91374 container env3cont: <nil>
STEP: delete the pod
Feb  6 05:34:02.488: INFO: Waiting for pod client-envvars-1703ab89-2c4d-450a-bffa-bc39bdd91374 to disappear
Feb  6 05:34:02.492: INFO: Pod client-envvars-1703ab89-2c4d-450a-bffa-bc39bdd91374 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:34:02.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3177" for this suite.
Feb  6 05:34:14.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:34:14.551: INFO: namespace pods-3177 deletion completed in 12.057082265s

• [SLOW TEST:16.259 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:34:14.551: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4600
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb  6 05:34:14.687: INFO: Waiting up to 5m0s for pod "downwardapi-volume-915f1ac4-53f6-445b-8122-704596cd6618" in namespace "downward-api-4600" to be "success or failure"
Feb  6 05:34:14.689: INFO: Pod "downwardapi-volume-915f1ac4-53f6-445b-8122-704596cd6618": Phase="Pending", Reason="", readiness=false. Elapsed: 2.127796ms
Feb  6 05:34:16.692: INFO: Pod "downwardapi-volume-915f1ac4-53f6-445b-8122-704596cd6618": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004821887s
STEP: Saw pod success
Feb  6 05:34:16.692: INFO: Pod "downwardapi-volume-915f1ac4-53f6-445b-8122-704596cd6618" satisfied condition "success or failure"
Feb  6 05:34:16.693: INFO: Trying to get logs from node aks-1-4 pod downwardapi-volume-915f1ac4-53f6-445b-8122-704596cd6618 container client-container: <nil>
STEP: delete the pod
Feb  6 05:34:16.704: INFO: Waiting for pod downwardapi-volume-915f1ac4-53f6-445b-8122-704596cd6618 to disappear
Feb  6 05:34:16.706: INFO: Pod downwardapi-volume-915f1ac4-53f6-445b-8122-704596cd6618 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:34:16.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4600" for this suite.
Feb  6 05:34:22.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:34:22.763: INFO: namespace downward-api-4600 deletion completed in 6.054855481s

• [SLOW TEST:8.211 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:34:22.764: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3327
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb  6 05:34:23.519: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb  6 05:34:25.527: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716564063, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716564063, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63716564063, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63716564063, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb  6 05:34:28.537: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 05:34:28.540: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:34:29.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3327" for this suite.
Feb  6 05:34:35.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:34:35.766: INFO: namespace webhook-3327 deletion completed in 6.058774133s
STEP: Destroying namespace "webhook-3327-markers" for this suite.
Feb  6 05:34:41.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:34:41.880: INFO: namespace webhook-3327-markers deletion completed in 6.113890655s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.124 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:34:41.887: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5459
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-4209
STEP: Creating secret with name secret-test-80aee677-53ef-4be1-aeba-603adb0fe574
STEP: Creating a pod to test consume secrets
Feb  6 05:34:42.211: INFO: Waiting up to 5m0s for pod "pod-secrets-a0500ea4-9b10-454a-9d28-452bcf241b72" in namespace "secrets-5459" to be "success or failure"
Feb  6 05:34:42.213: INFO: Pod "pod-secrets-a0500ea4-9b10-454a-9d28-452bcf241b72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.760314ms
Feb  6 05:34:44.215: INFO: Pod "pod-secrets-a0500ea4-9b10-454a-9d28-452bcf241b72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004153797s
STEP: Saw pod success
Feb  6 05:34:44.215: INFO: Pod "pod-secrets-a0500ea4-9b10-454a-9d28-452bcf241b72" satisfied condition "success or failure"
Feb  6 05:34:44.217: INFO: Trying to get logs from node aks-1-3 pod pod-secrets-a0500ea4-9b10-454a-9d28-452bcf241b72 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 05:34:44.229: INFO: Waiting for pod pod-secrets-a0500ea4-9b10-454a-9d28-452bcf241b72 to disappear
Feb  6 05:34:44.231: INFO: Pod pod-secrets-a0500ea4-9b10-454a-9d28-452bcf241b72 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:34:44.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5459" for this suite.
Feb  6 05:34:50.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:34:50.288: INFO: namespace secrets-5459 deletion completed in 6.055692016s
STEP: Destroying namespace "secret-namespace-4209" for this suite.
Feb  6 05:34:56.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:34:56.345: INFO: namespace secret-namespace-4209 deletion completed in 6.056450829s

• [SLOW TEST:14.457 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:34:56.345: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6062
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-8344b341-180f-456e-ba8f-3d1dfb21cd1d in namespace container-probe-6062
Feb  6 05:34:58.504: INFO: Started pod busybox-8344b341-180f-456e-ba8f-3d1dfb21cd1d in namespace container-probe-6062
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 05:34:58.505: INFO: Initial restart count of pod busybox-8344b341-180f-456e-ba8f-3d1dfb21cd1d is 0
Feb  6 05:35:46.572: INFO: Restart count of pod container-probe-6062/busybox-8344b341-180f-456e-ba8f-3d1dfb21cd1d is now 1 (48.066906555s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:35:46.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6062" for this suite.
Feb  6 05:35:52.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:35:52.661: INFO: namespace container-probe-6062 deletion completed in 6.081568191s

• [SLOW TEST:56.317 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:35:52.662: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7994
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb  6 05:35:52.836: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb  6 05:35:56.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-7994 create -f -'
Feb  6 05:35:57.135: INFO: stderr: ""
Feb  6 05:35:57.135: INFO: stdout: "e2e-test-crd-publish-openapi-9014-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb  6 05:35:57.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-7994 delete e2e-test-crd-publish-openapi-9014-crds test-cr'
Feb  6 05:35:57.226: INFO: stderr: ""
Feb  6 05:35:57.226: INFO: stdout: "e2e-test-crd-publish-openapi-9014-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Feb  6 05:35:57.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-7994 apply -f -'
Feb  6 05:35:57.419: INFO: stderr: ""
Feb  6 05:35:57.419: INFO: stdout: "e2e-test-crd-publish-openapi-9014-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb  6 05:35:57.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=crd-publish-openapi-7994 delete e2e-test-crd-publish-openapi-9014-crds test-cr'
Feb  6 05:35:57.516: INFO: stderr: ""
Feb  6 05:35:57.516: INFO: stdout: "e2e-test-crd-publish-openapi-9014-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Feb  6 05:35:57.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 explain e2e-test-crd-publish-openapi-9014-crds'
Feb  6 05:35:57.714: INFO: stderr: ""
Feb  6 05:35:57.714: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9014-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:36:02.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7994" for this suite.
Feb  6 05:36:08.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:36:08.143: INFO: namespace crd-publish-openapi-7994 deletion completed in 6.072759831s

• [SLOW TEST:15.481 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:36:08.144: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8008
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7c931172-c029-4caf-9cb4-abedf73ea4a3
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-7c931172-c029-4caf-9cb4-abedf73ea4a3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:37:32.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8008" for this suite.
Feb  6 05:37:54.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:37:54.713: INFO: namespace projected-8008 deletion completed in 22.056781763s

• [SLOW TEST:106.569 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:37:54.714: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3398
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Feb  6 05:37:54.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 --namespace=kubectl-3398 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb  6 05:37:56.915: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb  6 05:37:56.915: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:37:58.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3398" for this suite.
Feb  6 05:38:10.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:38:10.978: INFO: namespace kubectl-3398 deletion completed in 12.056760133s

• [SLOW TEST:16.264 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:38:10.978: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-64
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Feb  6 05:38:11.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 create -f - --namespace=kubectl-64'
Feb  6 05:38:11.378: INFO: stderr: ""
Feb  6 05:38:11.378: INFO: stdout: "pod/pause created\n"
Feb  6 05:38:11.378: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb  6 05:38:11.378: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-64" to be "running and ready"
Feb  6 05:38:11.381: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.893341ms
Feb  6 05:38:13.383: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.005455059s
Feb  6 05:38:13.383: INFO: Pod "pause" satisfied condition "running and ready"
Feb  6 05:38:13.383: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Feb  6 05:38:13.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 label pods pause testing-label=testing-label-value --namespace=kubectl-64'
Feb  6 05:38:13.481: INFO: stderr: ""
Feb  6 05:38:13.481: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb  6 05:38:13.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pod pause -L testing-label --namespace=kubectl-64'
Feb  6 05:38:13.566: INFO: stderr: ""
Feb  6 05:38:13.566: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb  6 05:38:13.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 label pods pause testing-label- --namespace=kubectl-64'
Feb  6 05:38:13.658: INFO: stderr: ""
Feb  6 05:38:13.658: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb  6 05:38:13.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pod pause -L testing-label --namespace=kubectl-64'
Feb  6 05:38:13.742: INFO: stderr: ""
Feb  6 05:38:13.742: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Feb  6 05:38:13.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 delete --grace-period=0 --force -f - --namespace=kubectl-64'
Feb  6 05:38:13.836: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 05:38:13.836: INFO: stdout: "pod \"pause\" force deleted\n"
Feb  6 05:38:13.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get rc,svc -l name=pause --no-headers --namespace=kubectl-64'
Feb  6 05:38:13.927: INFO: stderr: "No resources found in kubectl-64 namespace.\n"
Feb  6 05:38:13.927: INFO: stdout: ""
Feb  6 05:38:13.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-529150080 get pods -l name=pause --namespace=kubectl-64 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 05:38:14.009: INFO: stderr: ""
Feb  6 05:38:14.009: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:38:14.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-64" for this suite.
Feb  6 05:38:20.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:38:20.075: INFO: namespace kubectl-64 deletion completed in 6.0567588s

• [SLOW TEST:9.097 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb  6 05:38:20.076: INFO: >>> kubeConfig: /tmp/kubeconfig-529150080
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5514
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5514.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5514.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5514.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5514.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5514.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5514.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5514.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5514.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5514.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5514.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 05:38:26.247: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:26.249: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:26.251: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:26.252: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:26.258: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:26.260: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:26.262: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:26.268: INFO: Lookups using dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5514.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5514.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_udp@dns-test-service-2.dns-5514.svc.cluster.local]

Feb  6 05:38:31.271: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:31.273: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:31.283: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:31.285: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:31.293: INFO: Lookups using dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local]

Feb  6 05:38:36.271: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:36.273: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:36.283: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:36.287: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:36.295: INFO: Lookups using dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local]

Feb  6 05:38:41.271: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:41.273: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:41.284: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:41.286: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:41.293: INFO: Lookups using dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local]

Feb  6 05:38:46.271: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:46.272: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:46.282: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:46.285: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:46.293: INFO: Lookups using dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local]

Feb  6 05:38:51.271: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:51.273: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:51.282: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:51.284: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local from pod dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865: the server could not find the requested resource (get pods dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865)
Feb  6 05:38:51.294: INFO: Lookups using dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5514.svc.cluster.local]

Feb  6 05:38:56.294: INFO: DNS probes using dns-5514/dns-test-3a77c4e2-db4d-40e3-b82e-55e96f8cc865 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb  6 05:38:56.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5514" for this suite.
Feb  6 05:39:02.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 05:39:02.386: INFO: namespace dns-5514 deletion completed in 6.059822386s

• [SLOW TEST:42.310 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSFeb  6 05:39:02.388: INFO: Running AfterSuite actions on all nodes
Feb  6 05:39:02.414: INFO: Running AfterSuite actions on node 1
Feb  6 05:39:02.415: INFO: Skipping dumping logs from cluster

Ran 274 of 4732 Specs in 7817.191 seconds
SUCCESS! -- 274 Passed | 0 Failed | 0 Pending | 4458 Skipped
PASS

Ginkgo ran 1 suite in 2h10m19.780571308s
Test Suite Passed
