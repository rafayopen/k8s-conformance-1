I0309 01:24:21.481516      22 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-910735845
I0309 01:24:21.481877      22 e2e.go:92] Starting e2e run "bdcc56d9-e601-4840-ba76-c399edfb1a55" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1583717055 - Will randomize all specs
Will run 274 of 4731 specs

Mar  9 01:24:21.621: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 01:24:21.629: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar  9 01:24:21.666: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar  9 01:24:21.737: INFO: 21 / 21 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar  9 01:24:21.737: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Mar  9 01:24:21.737: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar  9 01:24:21.762: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Mar  9 01:24:21.762: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm' (0 seconds elapsed)
Mar  9 01:24:21.762: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm64' (0 seconds elapsed)
Mar  9 01:24:21.762: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-ppc64le' (0 seconds elapsed)
Mar  9 01:24:21.762: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-s390x' (0 seconds elapsed)
Mar  9 01:24:21.762: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Mar  9 01:24:21.762: INFO: e2e test version: v1.16.4
Mar  9 01:24:21.764: INFO: kube-apiserver version: v1.16.4
Mar  9 01:24:21.764: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 01:24:21.814: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:24:21.816: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename services
Mar  9 01:24:22.086: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Mar  9 01:24:22.113: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5477
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-5477
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5477
STEP: creating replication controller externalsvc in namespace services-5477
I0309 01:24:22.699890      22 runners.go:184] Created replication controller with name: externalsvc, namespace: services-5477, replica count: 2
I0309 01:24:25.750937      22 runners.go:184] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0309 01:24:28.751400      22 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Mar  9 01:24:28.931: INFO: Creating new exec pod
Mar  9 01:24:33.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-5477 execpodlhtp9 -- /bin/sh -x -c nslookup nodeport-service'
Mar  9 01:24:37.763: INFO: stderr: "+ nslookup nodeport-service\n"
Mar  9 01:24:37.763: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-5477.svc.cluster.local\tcanonical name = externalsvc.services-5477.svc.cluster.local.\nName:\texternalsvc.services-5477.svc.cluster.local\nAddress: 10.106.21.237\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5477, will wait for the garbage collector to delete the pods
Mar  9 01:24:38.034: INFO: Deleting ReplicationController externalsvc took: 211.99528ms
Mar  9 01:24:38.534: INFO: Terminating ReplicationController externalsvc pods took: 500.581024ms
Mar  9 01:24:51.291: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:24:51.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5477" for this suite.
Mar  9 01:24:59.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:24:59.841: INFO: namespace services-5477 deletion completed in 8.370757809s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:38.026 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:24:59.842: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3223
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-3223/secret-test-dd225447-308e-4c8a-a4d1-749d7e23d06d
STEP: Creating a pod to test consume secrets
Mar  9 01:25:00.399: INFO: Waiting up to 5m0s for pod "pod-configmaps-2f167da0-aca9-4bf7-a689-ca10270dba0d" in namespace "secrets-3223" to be "success or failure"
Mar  9 01:25:00.450: INFO: Pod "pod-configmaps-2f167da0-aca9-4bf7-a689-ca10270dba0d": Phase="Pending", Reason="", readiness=false. Elapsed: 50.707337ms
Mar  9 01:25:02.459: INFO: Pod "pod-configmaps-2f167da0-aca9-4bf7-a689-ca10270dba0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059715806s
Mar  9 01:25:04.466: INFO: Pod "pod-configmaps-2f167da0-aca9-4bf7-a689-ca10270dba0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066749992s
STEP: Saw pod success
Mar  9 01:25:04.466: INFO: Pod "pod-configmaps-2f167da0-aca9-4bf7-a689-ca10270dba0d" satisfied condition "success or failure"
Mar  9 01:25:04.472: INFO: Trying to get logs from node worker1 pod pod-configmaps-2f167da0-aca9-4bf7-a689-ca10270dba0d container env-test: <nil>
STEP: delete the pod
Mar  9 01:25:04.688: INFO: Waiting for pod pod-configmaps-2f167da0-aca9-4bf7-a689-ca10270dba0d to disappear
Mar  9 01:25:04.719: INFO: Pod pod-configmaps-2f167da0-aca9-4bf7-a689-ca10270dba0d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:25:04.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3223" for this suite.
Mar  9 01:25:12.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:25:13.039: INFO: namespace secrets-3223 deletion completed in 8.309891825s

• [SLOW TEST:13.197 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:25:13.040: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4299
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  9 01:25:16.680: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:25:16.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4299" for this suite.
Mar  9 01:25:24.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:25:25.011: INFO: namespace container-runtime-4299 deletion completed in 8.214079539s

• [SLOW TEST:11.971 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:25:25.013: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1850
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8041
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9994
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:25:32.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1850" for this suite.
Mar  9 01:25:38.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:25:38.701: INFO: namespace namespaces-1850 deletion completed in 6.215319384s
STEP: Destroying namespace "nsdeletetest-8041" for this suite.
Mar  9 01:25:38.704: INFO: Namespace nsdeletetest-8041 was already deleted
STEP: Destroying namespace "nsdeletetest-9994" for this suite.
Mar  9 01:25:44.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:25:45.002: INFO: namespace nsdeletetest-9994 deletion completed in 6.297429039s

• [SLOW TEST:19.989 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:25:45.002: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9267
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 01:25:45.299: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fdbe1de1-3062-44a8-b2e2-69e932c65c66" in namespace "downward-api-9267" to be "success or failure"
Mar  9 01:25:45.486: INFO: Pod "downwardapi-volume-fdbe1de1-3062-44a8-b2e2-69e932c65c66": Phase="Pending", Reason="", readiness=false. Elapsed: 187.005581ms
Mar  9 01:25:47.494: INFO: Pod "downwardapi-volume-fdbe1de1-3062-44a8-b2e2-69e932c65c66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.19455102s
Mar  9 01:25:49.499: INFO: Pod "downwardapi-volume-fdbe1de1-3062-44a8-b2e2-69e932c65c66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.200439906s
STEP: Saw pod success
Mar  9 01:25:49.500: INFO: Pod "downwardapi-volume-fdbe1de1-3062-44a8-b2e2-69e932c65c66" satisfied condition "success or failure"
Mar  9 01:25:49.635: INFO: Trying to get logs from node worker1 pod downwardapi-volume-fdbe1de1-3062-44a8-b2e2-69e932c65c66 container client-container: <nil>
STEP: delete the pod
Mar  9 01:25:49.773: INFO: Waiting for pod downwardapi-volume-fdbe1de1-3062-44a8-b2e2-69e932c65c66 to disappear
Mar  9 01:25:49.789: INFO: Pod downwardapi-volume-fdbe1de1-3062-44a8-b2e2-69e932c65c66 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:25:49.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9267" for this suite.
Mar  9 01:25:55.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:25:56.178: INFO: namespace downward-api-9267 deletion completed in 6.381799693s

• [SLOW TEST:11.176 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:25:56.178: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1734
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  9 01:26:01.248: INFO: Successfully updated pod "labelsupdate55b2d200-cdbd-4d02-a3d4-a7e256c1f4e3"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:26:03.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1734" for this suite.
Mar  9 01:26:15.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:26:15.563: INFO: namespace projected-1734 deletion completed in 12.248452151s

• [SLOW TEST:19.386 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:26:15.564: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1764
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 01:26:17.019: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719313976, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719313976, loc:(*time.Location)(0x84bfb00)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-7794d7ccd5\""}}, CollisionCount:(*int32)(nil)}
Mar  9 01:26:19.026: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719313977, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719313977, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719313977, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719313976, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 01:26:22.118: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:26:22.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1764" for this suite.
Mar  9 01:26:30.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:26:30.419: INFO: namespace webhook-1764 deletion completed in 8.262708013s
STEP: Destroying namespace "webhook-1764-markers" for this suite.
Mar  9 01:26:36.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:26:36.609: INFO: namespace webhook-1764-markers deletion completed in 6.190438285s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.090 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:26:36.655: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4037
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Mar  9 01:26:37.655: INFO: created pod pod-service-account-defaultsa
Mar  9 01:26:37.655: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar  9 01:26:37.671: INFO: created pod pod-service-account-mountsa
Mar  9 01:26:37.671: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar  9 01:26:37.746: INFO: created pod pod-service-account-nomountsa
Mar  9 01:26:37.746: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar  9 01:26:37.839: INFO: created pod pod-service-account-defaultsa-mountspec
Mar  9 01:26:37.839: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar  9 01:26:37.961: INFO: created pod pod-service-account-mountsa-mountspec
Mar  9 01:26:37.961: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar  9 01:26:38.046: INFO: created pod pod-service-account-nomountsa-mountspec
Mar  9 01:26:38.046: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar  9 01:26:38.114: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar  9 01:26:38.114: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar  9 01:26:38.274: INFO: created pod pod-service-account-mountsa-nomountspec
Mar  9 01:26:38.274: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar  9 01:26:38.336: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar  9 01:26:38.336: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:26:38.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4037" for this suite.
Mar  9 01:26:46.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:26:46.781: INFO: namespace svcaccounts-4037 deletion completed in 8.424011585s

• [SLOW TEST:10.126 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:26:46.781: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-3312
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Mar  9 01:26:49.011: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Mar  9 01:26:51.030: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314008, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314008, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314009, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314008, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-5bb99b877f\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 01:26:54.127: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 01:26:54.134: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:27:00.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3312" for this suite.
Mar  9 01:27:09.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:27:09.231: INFO: namespace crd-webhook-3312 deletion completed in 8.290992947s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:22.515 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:27:09.297: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9727
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Mar  9 01:27:09.965: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Mar  9 01:27:39.375: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 01:27:49.755: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:28:17.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9727" for this suite.
Mar  9 01:28:25.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:28:25.525: INFO: namespace crd-publish-openapi-9727 deletion completed in 8.281523903s

• [SLOW TEST:76.229 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:28:25.526: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7503
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  9 01:28:34.269: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 01:28:34.275: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 01:28:36.275: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 01:28:36.284: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 01:28:38.276: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 01:28:38.285: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 01:28:40.276: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 01:28:40.283: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  9 01:28:42.276: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  9 01:28:42.284: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:28:42.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7503" for this suite.
Mar  9 01:29:12.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:29:12.661: INFO: namespace container-lifecycle-hook-7503 deletion completed in 30.368960766s

• [SLOW TEST:47.135 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:29:12.661: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7171
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar  9 01:29:13.157: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed a6e845af-7423-4354-acb0-3ae4d5953e84 92834 0 2020-03-09 01:29:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  9 01:29:13.158: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed a6e845af-7423-4354-acb0-3ae4d5953e84 92835 0 2020-03-09 01:29:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  9 01:29:13.158: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed a6e845af-7423-4354-acb0-3ae4d5953e84 92836 0 2020-03-09 01:29:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar  9 01:29:23.303: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed a6e845af-7423-4354-acb0-3ae4d5953e84 92856 0 2020-03-09 01:29:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  9 01:29:23.304: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed a6e845af-7423-4354-acb0-3ae4d5953e84 92857 0 2020-03-09 01:29:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar  9 01:29:23.304: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed a6e845af-7423-4354-acb0-3ae4d5953e84 92858 0 2020-03-09 01:29:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:29:23.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7171" for this suite.
Mar  9 01:29:29.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:29:29.505: INFO: namespace watch-7171 deletion completed in 6.191111758s

• [SLOW TEST:16.844 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:29:29.507: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8088
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8088
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8088
STEP: creating replication controller externalsvc in namespace services-8088
I0309 01:29:30.244684      22 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8088, replica count: 2
I0309 01:29:33.295640      22 runners.go:184] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0309 01:29:36.296042      22 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Mar  9 01:29:36.469: INFO: Creating new exec pod
Mar  9 01:29:40.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-8088 execpodzf5lp -- /bin/sh -x -c nslookup clusterip-service'
Mar  9 01:29:41.066: INFO: stderr: "+ nslookup clusterip-service\n"
Mar  9 01:29:41.066: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-8088.svc.cluster.local\tcanonical name = externalsvc.services-8088.svc.cluster.local.\nName:\texternalsvc.services-8088.svc.cluster.local\nAddress: 10.102.1.60\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8088, will wait for the garbage collector to delete the pods
Mar  9 01:29:41.153: INFO: Deleting ReplicationController externalsvc took: 30.381971ms
Mar  9 01:29:41.553: INFO: Terminating ReplicationController externalsvc pods took: 400.316783ms
Mar  9 01:29:51.432: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:29:51.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8088" for this suite.
Mar  9 01:29:59.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:29:59.902: INFO: namespace services-8088 deletion completed in 8.344882839s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:30.395 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:29:59.904: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5264
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5264.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5264.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5264.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5264.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5264.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5264.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  9 01:30:04.542: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:04.548: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:04.554: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:04.560: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:04.579: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:04.584: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:04.589: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:04.602: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:04.614: INFO: Lookups using dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local]

Mar  9 01:30:09.623: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:09.630: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:09.636: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:09.657: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:09.745: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:09.752: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:09.758: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:09.782: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:09.795: INFO: Lookups using dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local]

Mar  9 01:30:14.624: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:14.631: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:14.638: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:14.644: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:14.663: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:14.669: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:14.674: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:14.681: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:14.693: INFO: Lookups using dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local]

Mar  9 01:30:19.629: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:19.688: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:19.695: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:19.701: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:19.776: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:19.782: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:19.788: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:19.794: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:19.806: INFO: Lookups using dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local]

Mar  9 01:30:24.624: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:24.631: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:24.637: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:24.644: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:24.662: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:24.668: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:24.674: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:24.680: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:24.692: INFO: Lookups using dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local]

Mar  9 01:30:29.623: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:29.638: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:29.666: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:29.673: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:29.714: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:29.742: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:29.770: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:29.776: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local from pod dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad: the server could not find the requested resource (get pods dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad)
Mar  9 01:30:29.788: INFO: Lookups using dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5264.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5264.svc.cluster.local jessie_udp@dns-test-service-2.dns-5264.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5264.svc.cluster.local]

Mar  9 01:30:34.690: INFO: DNS probes using dns-5264/dns-test-abebe2bb-89d0-489d-9719-7052aa9f78ad succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:30:35.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5264" for this suite.
Mar  9 01:30:43.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:30:43.391: INFO: namespace dns-5264 deletion completed in 8.276840147s

• [SLOW TEST:43.487 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:30:43.392: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3996
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  9 01:30:43.825: INFO: Waiting up to 5m0s for pod "pod-0d947741-0902-4934-9b9b-59732b1203cc" in namespace "emptydir-3996" to be "success or failure"
Mar  9 01:30:43.881: INFO: Pod "pod-0d947741-0902-4934-9b9b-59732b1203cc": Phase="Pending", Reason="", readiness=false. Elapsed: 55.347027ms
Mar  9 01:30:45.887: INFO: Pod "pod-0d947741-0902-4934-9b9b-59732b1203cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062103291s
Mar  9 01:30:47.894: INFO: Pod "pod-0d947741-0902-4934-9b9b-59732b1203cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068816718s
STEP: Saw pod success
Mar  9 01:30:47.894: INFO: Pod "pod-0d947741-0902-4934-9b9b-59732b1203cc" satisfied condition "success or failure"
Mar  9 01:30:47.899: INFO: Trying to get logs from node worker1 pod pod-0d947741-0902-4934-9b9b-59732b1203cc container test-container: <nil>
STEP: delete the pod
Mar  9 01:30:48.060: INFO: Waiting for pod pod-0d947741-0902-4934-9b9b-59732b1203cc to disappear
Mar  9 01:30:48.066: INFO: Pod pod-0d947741-0902-4934-9b9b-59732b1203cc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:30:48.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3996" for this suite.
Mar  9 01:30:54.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:30:54.254: INFO: namespace emptydir-3996 deletion completed in 6.179413991s

• [SLOW TEST:10.863 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:30:54.255: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-827
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-6877dd31-cbc9-47c7-abc9-5369eec73466
STEP: Creating secret with name secret-projected-all-test-volume-b81fcbe9-f947-412e-9b2e-0a2bf1e26d28
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar  9 01:30:55.037: INFO: Waiting up to 5m0s for pod "projected-volume-27623be1-ff85-4233-93a1-297cd4d5a002" in namespace "projected-827" to be "success or failure"
Mar  9 01:30:55.042: INFO: Pod "projected-volume-27623be1-ff85-4233-93a1-297cd4d5a002": Phase="Pending", Reason="", readiness=false. Elapsed: 4.880063ms
Mar  9 01:30:57.050: INFO: Pod "projected-volume-27623be1-ff85-4233-93a1-297cd4d5a002": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012264052s
Mar  9 01:30:59.058: INFO: Pod "projected-volume-27623be1-ff85-4233-93a1-297cd4d5a002": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020080089s
STEP: Saw pod success
Mar  9 01:30:59.058: INFO: Pod "projected-volume-27623be1-ff85-4233-93a1-297cd4d5a002" satisfied condition "success or failure"
Mar  9 01:30:59.062: INFO: Trying to get logs from node worker1 pod projected-volume-27623be1-ff85-4233-93a1-297cd4d5a002 container projected-all-volume-test: <nil>
STEP: delete the pod
Mar  9 01:30:59.173: INFO: Waiting for pod projected-volume-27623be1-ff85-4233-93a1-297cd4d5a002 to disappear
Mar  9 01:30:59.250: INFO: Pod projected-volume-27623be1-ff85-4233-93a1-297cd4d5a002 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:30:59.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-827" for this suite.
Mar  9 01:31:07.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:31:07.491: INFO: namespace projected-827 deletion completed in 8.231635899s

• [SLOW TEST:13.236 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:31:07.492: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Mar  9 01:31:07.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-9604'
Mar  9 01:31:09.092: INFO: stderr: ""
Mar  9 01:31:09.092: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 01:31:09.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9604'
Mar  9 01:31:09.327: INFO: stderr: ""
Mar  9 01:31:09.327: INFO: stdout: "update-demo-nautilus-6dczw update-demo-nautilus-nljzt "
Mar  9 01:31:09.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-6dczw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9604'
Mar  9 01:31:09.610: INFO: stderr: ""
Mar  9 01:31:09.611: INFO: stdout: ""
Mar  9 01:31:09.611: INFO: update-demo-nautilus-6dczw is created but not running
Mar  9 01:31:14.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9604'
Mar  9 01:31:14.816: INFO: stderr: ""
Mar  9 01:31:14.816: INFO: stdout: "update-demo-nautilus-6dczw update-demo-nautilus-nljzt "
Mar  9 01:31:14.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-6dczw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9604'
Mar  9 01:31:15.050: INFO: stderr: ""
Mar  9 01:31:15.050: INFO: stdout: "true"
Mar  9 01:31:15.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-6dczw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9604'
Mar  9 01:31:15.249: INFO: stderr: ""
Mar  9 01:31:15.249: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  9 01:31:15.249: INFO: validating pod update-demo-nautilus-6dczw
Mar  9 01:31:15.260: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 01:31:15.260: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 01:31:15.260: INFO: update-demo-nautilus-6dczw is verified up and running
Mar  9 01:31:15.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-nljzt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9604'
Mar  9 01:31:15.457: INFO: stderr: ""
Mar  9 01:31:15.457: INFO: stdout: "true"
Mar  9 01:31:15.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-nljzt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9604'
Mar  9 01:31:15.665: INFO: stderr: ""
Mar  9 01:31:15.666: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  9 01:31:15.666: INFO: validating pod update-demo-nautilus-nljzt
Mar  9 01:31:15.676: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 01:31:15.676: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 01:31:15.676: INFO: update-demo-nautilus-nljzt is verified up and running
STEP: rolling-update to new replication controller
Mar  9 01:31:15.681: INFO: scanned /root for discovery docs: <nil>
Mar  9 01:31:15.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9604'
Mar  9 01:31:39.817: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  9 01:31:39.817: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 01:31:39.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9604'
Mar  9 01:31:40.019: INFO: stderr: ""
Mar  9 01:31:40.019: INFO: stdout: "update-demo-kitten-tzcwv update-demo-kitten-xzqz8 update-demo-nautilus-nljzt "
STEP: Replicas for name=update-demo: expected=2 actual=3
Mar  9 01:31:45.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9604'
Mar  9 01:31:45.231: INFO: stderr: ""
Mar  9 01:31:45.231: INFO: stdout: "update-demo-kitten-tzcwv update-demo-kitten-xzqz8 "
Mar  9 01:31:45.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-kitten-tzcwv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9604'
Mar  9 01:31:45.434: INFO: stderr: ""
Mar  9 01:31:45.434: INFO: stdout: "true"
Mar  9 01:31:45.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-kitten-tzcwv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9604'
Mar  9 01:31:45.687: INFO: stderr: ""
Mar  9 01:31:45.687: INFO: stdout: "172.20.8.7/library/kitten:1.0"
Mar  9 01:31:45.687: INFO: validating pod update-demo-kitten-tzcwv
Mar  9 01:31:45.697: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  9 01:31:45.698: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  9 01:31:45.698: INFO: update-demo-kitten-tzcwv is verified up and running
Mar  9 01:31:45.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-kitten-xzqz8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9604'
Mar  9 01:31:45.903: INFO: stderr: ""
Mar  9 01:31:45.903: INFO: stdout: "true"
Mar  9 01:31:45.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-kitten-xzqz8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9604'
Mar  9 01:31:46.102: INFO: stderr: ""
Mar  9 01:31:46.102: INFO: stdout: "172.20.8.7/library/kitten:1.0"
Mar  9 01:31:46.102: INFO: validating pod update-demo-kitten-xzqz8
Mar  9 01:31:46.139: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  9 01:31:46.139: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  9 01:31:46.139: INFO: update-demo-kitten-xzqz8 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:31:46.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9604" for this suite.
Mar  9 01:32:16.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:32:16.353: INFO: namespace kubectl-9604 deletion completed in 30.205032416s

• [SLOW TEST:68.861 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:32:16.354: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  9 01:32:16.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 run e2e-test-httpd-pod --generator=run-pod/v1 --image=172.20.8.7/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-1277'
Mar  9 01:32:17.053: INFO: stderr: ""
Mar  9 01:32:17.053: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Mar  9 01:32:22.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pod e2e-test-httpd-pod --namespace=kubectl-1277 -o json'
Mar  9 01:32:22.309: INFO: stderr: ""
Mar  9 01:32:22.309: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-03-09T01:32:16Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1277\",\n        \"resourceVersion\": \"93532\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1277/pods/e2e-test-httpd-pod\",\n        \"uid\": \"70be866f-66eb-4495-8f6d-deda75015b51\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"172.20.8.7/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-t7w8f\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worker1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-t7w8f\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-t7w8f\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-09T01:32:17Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-09T01:32:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-09T01:32:19Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-09T01:32:16Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://3d3f147b06bfc22b7afe842c7f8f099de849c8d730e78ad46ed7ade06e992df8\",\n                \"image\": \"172.20.8.7/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-03-09T01:32:18Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.20.8.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.4.142\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.4.142\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-03-09T01:32:17Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar  9 01:32:22.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 replace -f - --namespace=kubectl-1277'
Mar  9 01:32:23.057: INFO: stderr: ""
Mar  9 01:32:23.057: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image 172.20.8.7/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Mar  9 01:32:23.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete pods e2e-test-httpd-pod --namespace=kubectl-1277'
Mar  9 01:32:25.497: INFO: stderr: ""
Mar  9 01:32:25.498: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:32:25.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1277" for this suite.
Mar  9 01:32:31.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:32:31.720: INFO: namespace kubectl-1277 deletion completed in 6.213298515s

• [SLOW TEST:15.366 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:32:31.720: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4264
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-dzxr
STEP: Creating a pod to test atomic-volume-subpath
Mar  9 01:32:32.477: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-dzxr" in namespace "subpath-4264" to be "success or failure"
Mar  9 01:32:32.483: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Pending", Reason="", readiness=false. Elapsed: 5.64153ms
Mar  9 01:32:34.490: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01267525s
Mar  9 01:32:36.497: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Running", Reason="", readiness=true. Elapsed: 4.020029693s
Mar  9 01:32:38.504: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Running", Reason="", readiness=true. Elapsed: 6.026908851s
Mar  9 01:32:40.510: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Running", Reason="", readiness=true. Elapsed: 8.032978614s
Mar  9 01:32:42.517: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Running", Reason="", readiness=true. Elapsed: 10.040071948s
Mar  9 01:32:44.524: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Running", Reason="", readiness=true. Elapsed: 12.04749661s
Mar  9 01:32:46.531: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Running", Reason="", readiness=true. Elapsed: 14.054303672s
Mar  9 01:32:48.546: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Running", Reason="", readiness=true. Elapsed: 16.069377827s
Mar  9 01:32:50.577: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Running", Reason="", readiness=true. Elapsed: 18.100199566s
Mar  9 01:32:52.584: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Running", Reason="", readiness=true. Elapsed: 20.107561151s
Mar  9 01:32:54.590: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Running", Reason="", readiness=true. Elapsed: 22.113080781s
Mar  9 01:32:56.598: INFO: Pod "pod-subpath-test-downwardapi-dzxr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.120777624s
STEP: Saw pod success
Mar  9 01:32:56.598: INFO: Pod "pod-subpath-test-downwardapi-dzxr" satisfied condition "success or failure"
Mar  9 01:32:56.634: INFO: Trying to get logs from node worker1 pod pod-subpath-test-downwardapi-dzxr container test-container-subpath-downwardapi-dzxr: <nil>
STEP: delete the pod
Mar  9 01:32:56.793: INFO: Waiting for pod pod-subpath-test-downwardapi-dzxr to disappear
Mar  9 01:32:56.811: INFO: Pod pod-subpath-test-downwardapi-dzxr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-dzxr
Mar  9 01:32:56.811: INFO: Deleting pod "pod-subpath-test-downwardapi-dzxr" in namespace "subpath-4264"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:32:56.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4264" for this suite.
Mar  9 01:33:04.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:33:05.157: INFO: namespace subpath-4264 deletion completed in 8.326476069s

• [SLOW TEST:33.437 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:33:05.158: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6713
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:33:22.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6713" for this suite.
Mar  9 01:33:30.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:33:30.352: INFO: namespace resourcequota-6713 deletion completed in 8.281332763s

• [SLOW TEST:25.194 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:33:30.353: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5633
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 01:33:32.247: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 01:33:34.267: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314412, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314412, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314412, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314412, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 01:33:37.386: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
Mar  9 01:33:37.574: INFO: Waiting for webhook configuration to be ready...
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:33:37.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5633" for this suite.
Mar  9 01:33:45.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:33:46.242: INFO: namespace webhook-5633 deletion completed in 8.429915277s
STEP: Destroying namespace "webhook-5633-markers" for this suite.
Mar  9 01:33:52.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:33:52.565: INFO: namespace webhook-5633-markers deletion completed in 6.323324704s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.251 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:33:52.605: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3814
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 01:33:53.131: INFO: (0) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 14.600209ms)
Mar  9 01:33:53.138: INFO: (1) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.470989ms)
Mar  9 01:33:53.144: INFO: (2) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.967807ms)
Mar  9 01:33:53.151: INFO: (3) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.761418ms)
Mar  9 01:33:53.158: INFO: (4) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.078319ms)
Mar  9 01:33:53.165: INFO: (5) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.263529ms)
Mar  9 01:33:53.171: INFO: (6) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.163058ms)
Mar  9 01:33:53.178: INFO: (7) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.131025ms)
Mar  9 01:33:53.184: INFO: (8) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.714259ms)
Mar  9 01:33:53.190: INFO: (9) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.629856ms)
Mar  9 01:33:53.198: INFO: (10) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.501234ms)
Mar  9 01:33:53.204: INFO: (11) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.93316ms)
Mar  9 01:33:53.210: INFO: (12) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.935937ms)
Mar  9 01:33:53.216: INFO: (13) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.087114ms)
Mar  9 01:33:53.223: INFO: (14) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.723731ms)
Mar  9 01:33:53.229: INFO: (15) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.258964ms)
Mar  9 01:33:53.236: INFO: (16) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.623437ms)
Mar  9 01:33:53.242: INFO: (17) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.958014ms)
Mar  9 01:33:53.248: INFO: (18) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.303401ms)
Mar  9 01:33:53.255: INFO: (19) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.57069ms)
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:33:53.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3814" for this suite.
Mar  9 01:33:59.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:33:59.425: INFO: namespace proxy-3814 deletion completed in 6.163490652s

• [SLOW TEST:6.821 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:33:59.428: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1015
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-4cb3c982-abf5-459d-a123-0b2895fbcf3b
STEP: Creating configMap with name cm-test-opt-upd-ce8c3fc8-3573-497e-b6e7-3e72394e2d7a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-4cb3c982-abf5-459d-a123-0b2895fbcf3b
STEP: Updating configmap cm-test-opt-upd-ce8c3fc8-3573-497e-b6e7-3e72394e2d7a
STEP: Creating configMap with name cm-test-opt-create-69145356-ebc8-4f20-994f-d9fd90bdc6e1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:35:23.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1015" for this suite.
Mar  9 01:35:53.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:35:54.009: INFO: namespace projected-1015 deletion completed in 30.173829427s

• [SLOW TEST:114.582 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:35:54.011: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6562
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 01:35:54.310: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar  9 01:36:05.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-6562 create -f -'
Mar  9 01:36:09.825: INFO: stderr: ""
Mar  9 01:36:09.825: INFO: stdout: "e2e-test-crd-publish-openapi-7716-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Mar  9 01:36:09.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-6562 delete e2e-test-crd-publish-openapi-7716-crds test-cr'
Mar  9 01:36:10.218: INFO: stderr: ""
Mar  9 01:36:10.218: INFO: stdout: "e2e-test-crd-publish-openapi-7716-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Mar  9 01:36:10.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-6562 apply -f -'
Mar  9 01:36:11.058: INFO: stderr: ""
Mar  9 01:36:11.058: INFO: stdout: "e2e-test-crd-publish-openapi-7716-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Mar  9 01:36:11.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-6562 delete e2e-test-crd-publish-openapi-7716-crds test-cr'
Mar  9 01:36:11.349: INFO: stderr: ""
Mar  9 01:36:11.349: INFO: stdout: "e2e-test-crd-publish-openapi-7716-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Mar  9 01:36:11.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 explain e2e-test-crd-publish-openapi-7716-crds'
Mar  9 01:36:12.154: INFO: stderr: ""
Mar  9 01:36:12.154: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7716-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:36:18.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6562" for this suite.
Mar  9 01:36:24.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:36:24.810: INFO: namespace crd-publish-openapi-6562 deletion completed in 6.251769995s

• [SLOW TEST:30.800 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:36:24.812: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-609
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-a9c9bfdc-f9fa-4b8f-9b14-2d91ff267b21
STEP: Creating a pod to test consume configMaps
Mar  9 01:36:25.445: INFO: Waiting up to 5m0s for pod "pod-configmaps-19fe9d71-0934-4903-8db0-e258c90aad89" in namespace "configmap-609" to be "success or failure"
Mar  9 01:36:25.450: INFO: Pod "pod-configmaps-19fe9d71-0934-4903-8db0-e258c90aad89": Phase="Pending", Reason="", readiness=false. Elapsed: 5.073894ms
Mar  9 01:36:27.457: INFO: Pod "pod-configmaps-19fe9d71-0934-4903-8db0-e258c90aad89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011978433s
Mar  9 01:36:29.464: INFO: Pod "pod-configmaps-19fe9d71-0934-4903-8db0-e258c90aad89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019005806s
STEP: Saw pod success
Mar  9 01:36:29.464: INFO: Pod "pod-configmaps-19fe9d71-0934-4903-8db0-e258c90aad89" satisfied condition "success or failure"
Mar  9 01:36:29.470: INFO: Trying to get logs from node worker1 pod pod-configmaps-19fe9d71-0934-4903-8db0-e258c90aad89 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 01:36:29.586: INFO: Waiting for pod pod-configmaps-19fe9d71-0934-4903-8db0-e258c90aad89 to disappear
Mar  9 01:36:29.599: INFO: Pod pod-configmaps-19fe9d71-0934-4903-8db0-e258c90aad89 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:36:29.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-609" for this suite.
Mar  9 01:36:35.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:36:36.155: INFO: namespace configmap-609 deletion completed in 6.546487326s

• [SLOW TEST:11.343 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:36:36.156: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8293
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 01:36:36.583: INFO: Waiting up to 5m0s for pod "downwardapi-volume-30df8f97-1531-4c25-b98b-58945c02e47a" in namespace "projected-8293" to be "success or failure"
Mar  9 01:36:36.722: INFO: Pod "downwardapi-volume-30df8f97-1531-4c25-b98b-58945c02e47a": Phase="Pending", Reason="", readiness=false. Elapsed: 139.21412ms
Mar  9 01:36:38.729: INFO: Pod "downwardapi-volume-30df8f97-1531-4c25-b98b-58945c02e47a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.146063902s
Mar  9 01:36:40.743: INFO: Pod "downwardapi-volume-30df8f97-1531-4c25-b98b-58945c02e47a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.15934527s
STEP: Saw pod success
Mar  9 01:36:40.743: INFO: Pod "downwardapi-volume-30df8f97-1531-4c25-b98b-58945c02e47a" satisfied condition "success or failure"
Mar  9 01:36:40.747: INFO: Trying to get logs from node worker1 pod downwardapi-volume-30df8f97-1531-4c25-b98b-58945c02e47a container client-container: <nil>
STEP: delete the pod
Mar  9 01:36:40.853: INFO: Waiting for pod downwardapi-volume-30df8f97-1531-4c25-b98b-58945c02e47a to disappear
Mar  9 01:36:40.883: INFO: Pod downwardapi-volume-30df8f97-1531-4c25-b98b-58945c02e47a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:36:40.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8293" for this suite.
Mar  9 01:36:47.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:36:47.216: INFO: namespace projected-8293 deletion completed in 6.32472333s

• [SLOW TEST:11.060 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:36:47.216: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-465
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  9 01:36:47.626: INFO: Waiting up to 5m0s for pod "downward-api-48959cd2-ed89-4d61-8575-8dc59a0be454" in namespace "downward-api-465" to be "success or failure"
Mar  9 01:36:47.632: INFO: Pod "downward-api-48959cd2-ed89-4d61-8575-8dc59a0be454": Phase="Pending", Reason="", readiness=false. Elapsed: 5.694823ms
Mar  9 01:36:49.639: INFO: Pod "downward-api-48959cd2-ed89-4d61-8575-8dc59a0be454": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01264833s
Mar  9 01:36:51.646: INFO: Pod "downward-api-48959cd2-ed89-4d61-8575-8dc59a0be454": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019290552s
STEP: Saw pod success
Mar  9 01:36:51.646: INFO: Pod "downward-api-48959cd2-ed89-4d61-8575-8dc59a0be454" satisfied condition "success or failure"
Mar  9 01:36:51.700: INFO: Trying to get logs from node worker1 pod downward-api-48959cd2-ed89-4d61-8575-8dc59a0be454 container dapi-container: <nil>
STEP: delete the pod
Mar  9 01:36:51.884: INFO: Waiting for pod downward-api-48959cd2-ed89-4d61-8575-8dc59a0be454 to disappear
Mar  9 01:36:51.908: INFO: Pod downward-api-48959cd2-ed89-4d61-8575-8dc59a0be454 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:36:51.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-465" for this suite.
Mar  9 01:36:57.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:36:58.185: INFO: namespace downward-api-465 deletion completed in 6.268434735s

• [SLOW TEST:10.969 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:36:58.186: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  9 01:36:58.734: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  9 01:36:58.757: INFO: Waiting for terminating namespaces to be deleted...
Mar  9 01:36:58.762: INFO: 
Logging pods the kubelet thinks is on node worker1 before test
Mar  9 01:36:58.773: INFO: sonobuoy from sonobuoy started at 2020-03-09 01:23:11 +0000 UTC (1 container statuses recorded)
Mar  9 01:36:58.773: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  9 01:36:58.773: INFO: sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-txlws from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 01:36:58.774: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  9 01:36:58.774: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  9 01:36:58.774: INFO: kube-flannel-ds-amd64-wgfqr from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 01:36:58.774: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  9 01:36:58.774: INFO: kube-proxy-94vtq from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 01:36:58.774: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 01:36:58.774: INFO: 
Logging pods the kubelet thinks is on node worker2 before test
Mar  9 01:36:58.804: INFO: kube-flannel-ds-amd64-q9s4h from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 01:36:58.805: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  9 01:36:58.805: INFO: sonobuoy-e2e-job-aaa481025fe94110 from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 01:36:58.805: INFO: 	Container e2e ready: true, restart count 0
Mar  9 01:36:58.805: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  9 01:36:58.805: INFO: kube-proxy-55qqw from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 01:36:58.805: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 01:36:58.805: INFO: sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-b49xx from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 01:36:58.805: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  9 01:36:58.805: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15fa7ef721bcf215], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:36:59.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5334" for this suite.
Mar  9 01:37:06.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:37:06.183: INFO: namespace sched-pred-5334 deletion completed in 6.306709065s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.997 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:37:06.183: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2649
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Mar  9 01:37:06.522: INFO: Waiting up to 5m0s for pod "pod-3b04306e-2d38-41c4-83df-5ae8d2b9ad7c" in namespace "emptydir-2649" to be "success or failure"
Mar  9 01:37:06.687: INFO: Pod "pod-3b04306e-2d38-41c4-83df-5ae8d2b9ad7c": Phase="Pending", Reason="", readiness=false. Elapsed: 165.315623ms
Mar  9 01:37:08.694: INFO: Pod "pod-3b04306e-2d38-41c4-83df-5ae8d2b9ad7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.172127892s
Mar  9 01:37:10.701: INFO: Pod "pod-3b04306e-2d38-41c4-83df-5ae8d2b9ad7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.178918227s
STEP: Saw pod success
Mar  9 01:37:10.701: INFO: Pod "pod-3b04306e-2d38-41c4-83df-5ae8d2b9ad7c" satisfied condition "success or failure"
Mar  9 01:37:10.706: INFO: Trying to get logs from node worker1 pod pod-3b04306e-2d38-41c4-83df-5ae8d2b9ad7c container test-container: <nil>
STEP: delete the pod
Mar  9 01:37:10.842: INFO: Waiting for pod pod-3b04306e-2d38-41c4-83df-5ae8d2b9ad7c to disappear
Mar  9 01:37:10.879: INFO: Pod pod-3b04306e-2d38-41c4-83df-5ae8d2b9ad7c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:37:10.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2649" for this suite.
Mar  9 01:37:19.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:37:19.335: INFO: namespace emptydir-2649 deletion completed in 8.445902526s

• [SLOW TEST:13.151 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:37:19.336: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8234
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 01:37:21.028: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314640, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314640, loc:(*time.Location)(0x84bfb00)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-7794d7ccd5\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314640, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314640, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Mar  9 01:37:23.050: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314640, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314640, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314641, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719314640, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 01:37:26.200: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 01:37:26.207: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3470-crds.webhook.example.com via the AdmissionRegistration API
Mar  9 01:37:31.969: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:37:32.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8234" for this suite.
Mar  9 01:37:41.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:37:41.245: INFO: namespace webhook-8234 deletion completed in 8.268559617s
STEP: Destroying namespace "webhook-8234-markers" for this suite.
Mar  9 01:37:47.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:37:47.425: INFO: namespace webhook-8234-markers deletion completed in 6.180894806s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.123 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:37:47.460: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7548
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Mar  9 01:37:47.760: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-910735845 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:37:47.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7548" for this suite.
Mar  9 01:37:54.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:37:54.187: INFO: namespace kubectl-7548 deletion completed in 6.215075416s

• [SLOW TEST:6.727 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:37:54.188: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-946
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-946.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-946.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-946.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  9 01:37:59.114: INFO: DNS probes using dns-test-527cc083-588f-407b-902c-8f9b56840a5b succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-946.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-946.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-946.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  9 01:38:03.605: INFO: File wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local from pod  dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  9 01:38:03.613: INFO: File jessie_udp@dns-test-service-3.dns-946.svc.cluster.local from pod  dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  9 01:38:03.613: INFO: Lookups using dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c failed for: [wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local jessie_udp@dns-test-service-3.dns-946.svc.cluster.local]

Mar  9 01:38:08.622: INFO: File wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local from pod  dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  9 01:38:08.629: INFO: File jessie_udp@dns-test-service-3.dns-946.svc.cluster.local from pod  dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  9 01:38:08.629: INFO: Lookups using dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c failed for: [wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local jessie_udp@dns-test-service-3.dns-946.svc.cluster.local]

Mar  9 01:38:13.623: INFO: File wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local from pod  dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  9 01:38:13.629: INFO: File jessie_udp@dns-test-service-3.dns-946.svc.cluster.local from pod  dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  9 01:38:13.629: INFO: Lookups using dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c failed for: [wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local jessie_udp@dns-test-service-3.dns-946.svc.cluster.local]

Mar  9 01:38:18.636: INFO: File wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local from pod  dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  9 01:38:18.644: INFO: File jessie_udp@dns-test-service-3.dns-946.svc.cluster.local from pod  dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  9 01:38:18.644: INFO: Lookups using dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c failed for: [wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local jessie_udp@dns-test-service-3.dns-946.svc.cluster.local]

Mar  9 01:38:23.623: INFO: File wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local from pod  dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  9 01:38:23.630: INFO: File jessie_udp@dns-test-service-3.dns-946.svc.cluster.local from pod  dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  9 01:38:23.630: INFO: Lookups using dns-946/dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c failed for: [wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local jessie_udp@dns-test-service-3.dns-946.svc.cluster.local]

Mar  9 01:38:28.630: INFO: DNS probes using dns-test-1439d741-efea-4250-83d5-98aae8eb0c5c succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-946.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-946.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-946.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-946.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  9 01:38:33.509: INFO: DNS probes using dns-test-585e0b51-b230-4040-a7cd-54f3fea4f76d succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:38:33.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-946" for this suite.
Mar  9 01:38:42.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:38:42.349: INFO: namespace dns-946 deletion completed in 8.534834606s

• [SLOW TEST:48.161 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:38:42.349: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3587
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  9 01:38:51.058: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  9 01:38:51.072: INFO: Pod pod-with-prestop-http-hook still exists
Mar  9 01:38:53.073: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  9 01:38:53.082: INFO: Pod pod-with-prestop-http-hook still exists
Mar  9 01:38:55.073: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  9 01:38:55.081: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:38:55.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3587" for this suite.
Mar  9 01:39:07.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:39:07.517: INFO: namespace container-lifecycle-hook-3587 deletion completed in 12.389184951s

• [SLOW TEST:25.168 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:39:07.519: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-259
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-a3c7d9d2-5603-4b3f-84e8-531918a77102 in namespace container-probe-259
Mar  9 01:39:11.922: INFO: Started pod test-webserver-a3c7d9d2-5603-4b3f-84e8-531918a77102 in namespace container-probe-259
STEP: checking the pod's current state and verifying that restartCount is present
Mar  9 01:39:11.928: INFO: Initial restart count of pod test-webserver-a3c7d9d2-5603-4b3f-84e8-531918a77102 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:43:13.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-259" for this suite.
Mar  9 01:43:21.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:43:21.688: INFO: namespace container-probe-259 deletion completed in 8.265767904s

• [SLOW TEST:254.169 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:43:21.689: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8268
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  9 01:43:22.079: INFO: Waiting up to 5m0s for pod "pod-a0af5811-1633-420d-a1c5-a989b49d9f62" in namespace "emptydir-8268" to be "success or failure"
Mar  9 01:43:22.084: INFO: Pod "pod-a0af5811-1633-420d-a1c5-a989b49d9f62": Phase="Pending", Reason="", readiness=false. Elapsed: 5.552035ms
Mar  9 01:43:24.092: INFO: Pod "pod-a0af5811-1633-420d-a1c5-a989b49d9f62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012779105s
Mar  9 01:43:26.099: INFO: Pod "pod-a0af5811-1633-420d-a1c5-a989b49d9f62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019610259s
STEP: Saw pod success
Mar  9 01:43:26.099: INFO: Pod "pod-a0af5811-1633-420d-a1c5-a989b49d9f62" satisfied condition "success or failure"
Mar  9 01:43:26.105: INFO: Trying to get logs from node worker1 pod pod-a0af5811-1633-420d-a1c5-a989b49d9f62 container test-container: <nil>
STEP: delete the pod
Mar  9 01:43:26.385: INFO: Waiting for pod pod-a0af5811-1633-420d-a1c5-a989b49d9f62 to disappear
Mar  9 01:43:26.392: INFO: Pod pod-a0af5811-1633-420d-a1c5-a989b49d9f62 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:43:26.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8268" for this suite.
Mar  9 01:43:32.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:43:33.002: INFO: namespace emptydir-8268 deletion completed in 6.601137699s

• [SLOW TEST:11.313 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:43:33.004: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-52
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:43:40.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-52" for this suite.
Mar  9 01:43:46.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:43:46.642: INFO: namespace resourcequota-52 deletion completed in 6.201880742s

• [SLOW TEST:13.639 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:43:46.642: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-940
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 01:43:47.136: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d5bd2c9-7cd4-41a1-8ec9-07602d9fcf3b" in namespace "projected-940" to be "success or failure"
Mar  9 01:43:47.263: INFO: Pod "downwardapi-volume-3d5bd2c9-7cd4-41a1-8ec9-07602d9fcf3b": Phase="Pending", Reason="", readiness=false. Elapsed: 126.764277ms
Mar  9 01:43:49.270: INFO: Pod "downwardapi-volume-3d5bd2c9-7cd4-41a1-8ec9-07602d9fcf3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.133748249s
Mar  9 01:43:51.278: INFO: Pod "downwardapi-volume-3d5bd2c9-7cd4-41a1-8ec9-07602d9fcf3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.141497538s
STEP: Saw pod success
Mar  9 01:43:51.278: INFO: Pod "downwardapi-volume-3d5bd2c9-7cd4-41a1-8ec9-07602d9fcf3b" satisfied condition "success or failure"
Mar  9 01:43:51.285: INFO: Trying to get logs from node worker1 pod downwardapi-volume-3d5bd2c9-7cd4-41a1-8ec9-07602d9fcf3b container client-container: <nil>
STEP: delete the pod
Mar  9 01:43:51.424: INFO: Waiting for pod downwardapi-volume-3d5bd2c9-7cd4-41a1-8ec9-07602d9fcf3b to disappear
Mar  9 01:43:51.472: INFO: Pod downwardapi-volume-3d5bd2c9-7cd4-41a1-8ec9-07602d9fcf3b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:43:51.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-940" for this suite.
Mar  9 01:43:59.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:43:59.720: INFO: namespace projected-940 deletion completed in 8.240018583s

• [SLOW TEST:13.078 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:43:59.721: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9478
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  9 01:44:00.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 run e2e-test-httpd-rc --image=172.20.8.7/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9478'
Mar  9 01:44:00.368: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  9 01:44:00.368: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Mar  9 01:44:00.597: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar  9 01:44:00.806: INFO: scanned /root for discovery docs: <nil>
Mar  9 01:44:00.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 rolling-update e2e-test-httpd-rc --update-period=1s --image=172.20.8.7/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9478'
Mar  9 01:44:17.159: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  9 01:44:17.159: INFO: stdout: "Created e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1\nScaling up e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Mar  9 01:44:17.159: INFO: stdout: "Created e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1\nScaling up e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Mar  9 01:44:17.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9478'
Mar  9 01:44:17.427: INFO: stderr: ""
Mar  9 01:44:17.427: INFO: stdout: "e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1-fvl8k "
Mar  9 01:44:17.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1-fvl8k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9478'
Mar  9 01:44:17.627: INFO: stderr: ""
Mar  9 01:44:17.627: INFO: stdout: "true"
Mar  9 01:44:17.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1-fvl8k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9478'
Mar  9 01:44:17.838: INFO: stderr: ""
Mar  9 01:44:17.838: INFO: stdout: "172.20.8.7/library/httpd:2.4.38-alpine"
Mar  9 01:44:17.838: INFO: e2e-test-httpd-rc-5e09e86fbdb5fd1fd4cf60ab91f8a0d1-fvl8k is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Mar  9 01:44:17.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete rc e2e-test-httpd-rc --namespace=kubectl-9478'
Mar  9 01:44:18.275: INFO: stderr: ""
Mar  9 01:44:18.275: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:44:18.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9478" for this suite.
Mar  9 01:44:48.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:44:48.532: INFO: namespace kubectl-9478 deletion completed in 30.242213454s

• [SLOW TEST:48.811 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:44:48.533: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9446
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9446
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  9 01:44:49.222: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  9 01:45:13.748: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.4.160:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9446 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 01:45:13.748: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 01:45:14.272: INFO: Found all expected endpoints: [netserver-0]
Mar  9 01:45:14.279: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.3.70:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9446 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 01:45:14.279: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 01:45:14.553: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:45:14.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9446" for this suite.
Mar  9 01:45:28.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:45:28.738: INFO: namespace pod-network-test-9446 deletion completed in 14.175783863s

• [SLOW TEST:40.205 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:45:28.738: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2859
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  9 01:45:29.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 run e2e-test-httpd-deployment --image=172.20.8.7/library/httpd:2.4.38-alpine --namespace=kubectl-2859'
Mar  9 01:45:29.354: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  9 01:45:29.354: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Mar  9 01:45:31.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete deployment e2e-test-httpd-deployment --namespace=kubectl-2859'
Mar  9 01:45:31.663: INFO: stderr: ""
Mar  9 01:45:31.663: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:45:31.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2859" for this suite.
Mar  9 01:45:43.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:45:43.866: INFO: namespace kubectl-2859 deletion completed in 12.194159538s

• [SLOW TEST:15.128 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:45:43.867: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7966
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 01:45:44.210: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:45:48.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7966" for this suite.
Mar  9 01:46:34.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:46:34.976: INFO: namespace pods-7966 deletion completed in 46.322866165s

• [SLOW TEST:51.109 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:46:34.976: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1496
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:47:35.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1496" for this suite.
Mar  9 01:47:47.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:47:47.648: INFO: namespace container-probe-1496 deletion completed in 12.27146931s

• [SLOW TEST:72.672 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:47:47.649: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-2540
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Mar  9 01:47:48.920: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Mar  9 01:47:50.997: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315268, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315268, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315269, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315268, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-5bb99b877f\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 01:47:54.125: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 01:47:54.132: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:48:00.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2540" for this suite.
Mar  9 01:48:08.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:48:08.741: INFO: namespace crd-webhook-2540 deletion completed in 8.183007939s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:21.135 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:48:08.784: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5768
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 01:48:09.152: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ba784d1-083d-48cd-a4c2-919a8ffec79f" in namespace "projected-5768" to be "success or failure"
Mar  9 01:48:09.227: INFO: Pod "downwardapi-volume-8ba784d1-083d-48cd-a4c2-919a8ffec79f": Phase="Pending", Reason="", readiness=false. Elapsed: 74.376221ms
Mar  9 01:48:11.261: INFO: Pod "downwardapi-volume-8ba784d1-083d-48cd-a4c2-919a8ffec79f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.108145535s
Mar  9 01:48:13.268: INFO: Pod "downwardapi-volume-8ba784d1-083d-48cd-a4c2-919a8ffec79f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.115540274s
STEP: Saw pod success
Mar  9 01:48:13.268: INFO: Pod "downwardapi-volume-8ba784d1-083d-48cd-a4c2-919a8ffec79f" satisfied condition "success or failure"
Mar  9 01:48:13.274: INFO: Trying to get logs from node worker1 pod downwardapi-volume-8ba784d1-083d-48cd-a4c2-919a8ffec79f container client-container: <nil>
STEP: delete the pod
Mar  9 01:48:13.386: INFO: Waiting for pod downwardapi-volume-8ba784d1-083d-48cd-a4c2-919a8ffec79f to disappear
Mar  9 01:48:13.391: INFO: Pod downwardapi-volume-8ba784d1-083d-48cd-a4c2-919a8ffec79f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:48:13.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5768" for this suite.
Mar  9 01:48:19.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:48:19.653: INFO: namespace projected-5768 deletion completed in 6.254682467s

• [SLOW TEST:10.869 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:48:19.654: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8677
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  9 01:48:20.380: INFO: Waiting up to 5m0s for pod "downward-api-6eb9b8b2-f293-4841-8dd7-06da07edec42" in namespace "downward-api-8677" to be "success or failure"
Mar  9 01:48:20.399: INFO: Pod "downward-api-6eb9b8b2-f293-4841-8dd7-06da07edec42": Phase="Pending", Reason="", readiness=false. Elapsed: 17.898364ms
Mar  9 01:48:22.407: INFO: Pod "downward-api-6eb9b8b2-f293-4841-8dd7-06da07edec42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02686148s
Mar  9 01:48:24.417: INFO: Pod "downward-api-6eb9b8b2-f293-4841-8dd7-06da07edec42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036857911s
STEP: Saw pod success
Mar  9 01:48:24.418: INFO: Pod "downward-api-6eb9b8b2-f293-4841-8dd7-06da07edec42" satisfied condition "success or failure"
Mar  9 01:48:24.434: INFO: Trying to get logs from node worker1 pod downward-api-6eb9b8b2-f293-4841-8dd7-06da07edec42 container dapi-container: <nil>
STEP: delete the pod
Mar  9 01:48:24.551: INFO: Waiting for pod downward-api-6eb9b8b2-f293-4841-8dd7-06da07edec42 to disappear
Mar  9 01:48:24.557: INFO: Pod downward-api-6eb9b8b2-f293-4841-8dd7-06da07edec42 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:48:24.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8677" for this suite.
Mar  9 01:48:32.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:48:32.882: INFO: namespace downward-api-8677 deletion completed in 8.303998923s

• [SLOW TEST:13.228 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:48:32.883: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4822
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Mar  9 01:48:38.170: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4822 pod-service-account-4427faa1-1cea-47d2-bbfd-adf593c64d7b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Mar  9 01:48:42.043: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4822 pod-service-account-4427faa1-1cea-47d2-bbfd-adf593c64d7b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Mar  9 01:48:42.507: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4822 pod-service-account-4427faa1-1cea-47d2-bbfd-adf593c64d7b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:48:42.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4822" for this suite.
Mar  9 01:48:51.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:48:51.302: INFO: namespace svcaccounts-4822 deletion completed in 8.232983465s

• [SLOW TEST:18.419 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:48:51.305: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-782
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 01:48:51.900: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b3145a4-2728-4031-816b-04563d9b72ce" in namespace "projected-782" to be "success or failure"
Mar  9 01:48:51.933: INFO: Pod "downwardapi-volume-2b3145a4-2728-4031-816b-04563d9b72ce": Phase="Pending", Reason="", readiness=false. Elapsed: 32.940074ms
Mar  9 01:48:53.941: INFO: Pod "downwardapi-volume-2b3145a4-2728-4031-816b-04563d9b72ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040632133s
Mar  9 01:48:55.949: INFO: Pod "downwardapi-volume-2b3145a4-2728-4031-816b-04563d9b72ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048718651s
STEP: Saw pod success
Mar  9 01:48:55.949: INFO: Pod "downwardapi-volume-2b3145a4-2728-4031-816b-04563d9b72ce" satisfied condition "success or failure"
Mar  9 01:48:55.956: INFO: Trying to get logs from node worker1 pod downwardapi-volume-2b3145a4-2728-4031-816b-04563d9b72ce container client-container: <nil>
STEP: delete the pod
Mar  9 01:48:56.073: INFO: Waiting for pod downwardapi-volume-2b3145a4-2728-4031-816b-04563d9b72ce to disappear
Mar  9 01:48:56.093: INFO: Pod downwardapi-volume-2b3145a4-2728-4031-816b-04563d9b72ce no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:48:56.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-782" for this suite.
Mar  9 01:49:02.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:49:02.352: INFO: namespace projected-782 deletion completed in 6.251393634s

• [SLOW TEST:11.047 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:49:02.352: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-7837
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar  9 01:49:06.756: INFO: &Pod{ObjectMeta:{send-events-c4ea238f-31da-4a65-ab80-429a74c4d074  events-7837 /api/v1/namespaces/events-7837/pods/send-events-c4ea238f-31da-4a65-ab80-429a74c4d074 f8caa31a-428e-4082-98eb-a2365d3023b7 96582 0 2020-03-09 01:49:02 +0000 UTC <nil> <nil> map[name:foo time:692412519] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zn8wd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zn8wd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:172.20.8.7/library/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zn8wd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 01:49:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 01:49:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 01:49:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 01:49:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.170,StartTime:2020-03-09 01:49:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 01:49:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/agnhost:2.6,ImageID:docker-pullable://172.20.8.7/library/agnhost@sha256:4273341f784390e3fd568bee1bf86efe6ef4ad4a7a1a75c0dcd01776683d669a,ContainerID:docker://951ab9c070fbe01a80b1a132777adae187a0173dadc30655a0435f1a424a60e4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.170,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Mar  9 01:49:08.766: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar  9 01:49:10.776: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:49:10.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7837" for this suite.
Mar  9 01:49:57.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:49:57.330: INFO: namespace events-7837 deletion completed in 46.434541251s

• [SLOW TEST:54.978 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:49:57.331: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3311
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3311.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3311.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  9 01:50:03.795: INFO: DNS probes using dns-3311/dns-test-832915b6-be6f-45ef-8f98-e01b956a96d3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:50:03.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3311" for this suite.
Mar  9 01:50:12.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:50:12.167: INFO: namespace dns-3311 deletion completed in 8.226426561s

• [SLOW TEST:14.836 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:50:12.168: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-230
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-899c3cae-a9d0-43cb-8f47-df2b1bd210b4
STEP: Creating a pod to test consume configMaps
Mar  9 01:50:12.873: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-15440e64-974e-4b6d-906f-d1ffe7dc3cef" in namespace "projected-230" to be "success or failure"
Mar  9 01:50:12.946: INFO: Pod "pod-projected-configmaps-15440e64-974e-4b6d-906f-d1ffe7dc3cef": Phase="Pending", Reason="", readiness=false. Elapsed: 73.398174ms
Mar  9 01:50:14.954: INFO: Pod "pod-projected-configmaps-15440e64-974e-4b6d-906f-d1ffe7dc3cef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081129134s
Mar  9 01:50:16.976: INFO: Pod "pod-projected-configmaps-15440e64-974e-4b6d-906f-d1ffe7dc3cef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.103078516s
STEP: Saw pod success
Mar  9 01:50:16.976: INFO: Pod "pod-projected-configmaps-15440e64-974e-4b6d-906f-d1ffe7dc3cef" satisfied condition "success or failure"
Mar  9 01:50:17.016: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-15440e64-974e-4b6d-906f-d1ffe7dc3cef container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 01:50:17.178: INFO: Waiting for pod pod-projected-configmaps-15440e64-974e-4b6d-906f-d1ffe7dc3cef to disappear
Mar  9 01:50:17.183: INFO: Pod pod-projected-configmaps-15440e64-974e-4b6d-906f-d1ffe7dc3cef no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:50:17.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-230" for this suite.
Mar  9 01:50:23.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:50:23.448: INFO: namespace projected-230 deletion completed in 6.255873185s

• [SLOW TEST:11.280 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:50:23.448: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1508
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 01:50:23.903: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d75ee08b-0f5e-4718-a0b5-b528a1c45eac" in namespace "downward-api-1508" to be "success or failure"
Mar  9 01:50:24.165: INFO: Pod "downwardapi-volume-d75ee08b-0f5e-4718-a0b5-b528a1c45eac": Phase="Pending", Reason="", readiness=false. Elapsed: 262.396316ms
Mar  9 01:50:26.173: INFO: Pod "downwardapi-volume-d75ee08b-0f5e-4718-a0b5-b528a1c45eac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.270846839s
Mar  9 01:50:28.182: INFO: Pod "downwardapi-volume-d75ee08b-0f5e-4718-a0b5-b528a1c45eac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.279023956s
STEP: Saw pod success
Mar  9 01:50:28.182: INFO: Pod "downwardapi-volume-d75ee08b-0f5e-4718-a0b5-b528a1c45eac" satisfied condition "success or failure"
Mar  9 01:50:28.187: INFO: Trying to get logs from node worker1 pod downwardapi-volume-d75ee08b-0f5e-4718-a0b5-b528a1c45eac container client-container: <nil>
STEP: delete the pod
Mar  9 01:50:28.258: INFO: Waiting for pod downwardapi-volume-d75ee08b-0f5e-4718-a0b5-b528a1c45eac to disappear
Mar  9 01:50:28.317: INFO: Pod downwardapi-volume-d75ee08b-0f5e-4718-a0b5-b528a1c45eac no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:50:28.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1508" for this suite.
Mar  9 01:50:34.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:50:34.545: INFO: namespace downward-api-1508 deletion completed in 6.217120573s

• [SLOW TEST:11.097 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:50:34.545: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4908
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 01:50:34.846: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:50:38.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4908" for this suite.
Mar  9 01:51:22.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:51:23.159: INFO: namespace pods-4908 deletion completed in 44.213515909s

• [SLOW TEST:48.614 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:51:23.159: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-966
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 01:51:23.678: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dde9ac8d-af8c-41b8-b810-77e37f60f468" in namespace "projected-966" to be "success or failure"
Mar  9 01:51:23.747: INFO: Pod "downwardapi-volume-dde9ac8d-af8c-41b8-b810-77e37f60f468": Phase="Pending", Reason="", readiness=false. Elapsed: 68.900995ms
Mar  9 01:51:25.757: INFO: Pod "downwardapi-volume-dde9ac8d-af8c-41b8-b810-77e37f60f468": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079120411s
Mar  9 01:51:27.765: INFO: Pod "downwardapi-volume-dde9ac8d-af8c-41b8-b810-77e37f60f468": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.086583139s
STEP: Saw pod success
Mar  9 01:51:27.765: INFO: Pod "downwardapi-volume-dde9ac8d-af8c-41b8-b810-77e37f60f468" satisfied condition "success or failure"
Mar  9 01:51:27.769: INFO: Trying to get logs from node worker1 pod downwardapi-volume-dde9ac8d-af8c-41b8-b810-77e37f60f468 container client-container: <nil>
STEP: delete the pod
Mar  9 01:51:27.850: INFO: Waiting for pod downwardapi-volume-dde9ac8d-af8c-41b8-b810-77e37f60f468 to disappear
Mar  9 01:51:27.863: INFO: Pod downwardapi-volume-dde9ac8d-af8c-41b8-b810-77e37f60f468 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:51:27.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-966" for this suite.
Mar  9 01:51:36.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:51:36.202: INFO: namespace projected-966 deletion completed in 8.214793238s

• [SLOW TEST:13.042 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:51:36.202: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2517
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Mar  9 01:51:36.817: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 01:51:48.199: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:52:15.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2517" for this suite.
Mar  9 01:52:21.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:52:21.577: INFO: namespace crd-publish-openapi-2517 deletion completed in 6.174374289s

• [SLOW TEST:45.375 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:52:21.578: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-440
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:52:22.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-440" for this suite.
Mar  9 01:52:28.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:52:28.607: INFO: namespace kubelet-test-440 deletion completed in 6.220768318s

• [SLOW TEST:7.029 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:52:28.607: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2095
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 01:52:28.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fd1b8fbe-fe95-4f12-92f6-e4195a1a885d" in namespace "downward-api-2095" to be "success or failure"
Mar  9 01:52:28.972: INFO: Pod "downwardapi-volume-fd1b8fbe-fe95-4f12-92f6-e4195a1a885d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.422052ms
Mar  9 01:52:31.159: INFO: Pod "downwardapi-volume-fd1b8fbe-fe95-4f12-92f6-e4195a1a885d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.192385308s
Mar  9 01:52:33.167: INFO: Pod "downwardapi-volume-fd1b8fbe-fe95-4f12-92f6-e4195a1a885d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.200056616s
STEP: Saw pod success
Mar  9 01:52:33.167: INFO: Pod "downwardapi-volume-fd1b8fbe-fe95-4f12-92f6-e4195a1a885d" satisfied condition "success or failure"
Mar  9 01:52:33.174: INFO: Trying to get logs from node worker1 pod downwardapi-volume-fd1b8fbe-fe95-4f12-92f6-e4195a1a885d container client-container: <nil>
STEP: delete the pod
Mar  9 01:52:33.264: INFO: Waiting for pod downwardapi-volume-fd1b8fbe-fe95-4f12-92f6-e4195a1a885d to disappear
Mar  9 01:52:33.269: INFO: Pod downwardapi-volume-fd1b8fbe-fe95-4f12-92f6-e4195a1a885d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:52:33.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2095" for this suite.
Mar  9 01:52:41.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:52:41.670: INFO: namespace downward-api-2095 deletion completed in 8.329386683s

• [SLOW TEST:13.063 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:52:41.671: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4007
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  9 01:52:42.016: INFO: Waiting up to 5m0s for pod "downward-api-65d5d386-351c-488e-8548-6bc178aa9e44" in namespace "downward-api-4007" to be "success or failure"
Mar  9 01:52:42.020: INFO: Pod "downward-api-65d5d386-351c-488e-8548-6bc178aa9e44": Phase="Pending", Reason="", readiness=false. Elapsed: 4.757676ms
Mar  9 01:52:44.028: INFO: Pod "downward-api-65d5d386-351c-488e-8548-6bc178aa9e44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012493658s
Mar  9 01:52:46.035: INFO: Pod "downward-api-65d5d386-351c-488e-8548-6bc178aa9e44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01988129s
STEP: Saw pod success
Mar  9 01:52:46.036: INFO: Pod "downward-api-65d5d386-351c-488e-8548-6bc178aa9e44" satisfied condition "success or failure"
Mar  9 01:52:46.042: INFO: Trying to get logs from node worker1 pod downward-api-65d5d386-351c-488e-8548-6bc178aa9e44 container dapi-container: <nil>
STEP: delete the pod
Mar  9 01:52:46.170: INFO: Waiting for pod downward-api-65d5d386-351c-488e-8548-6bc178aa9e44 to disappear
Mar  9 01:52:46.192: INFO: Pod downward-api-65d5d386-351c-488e-8548-6bc178aa9e44 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:52:46.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4007" for this suite.
Mar  9 01:52:52.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:52:52.386: INFO: namespace downward-api-4007 deletion completed in 6.184807807s

• [SLOW TEST:10.715 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:52:52.386: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2311
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 01:52:53.928: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 01:52:55.959: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315573, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315573, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315574, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315573, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 01:52:59.045: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Mar  9 01:53:03.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 attach --namespace=webhook-2311 to-be-attached-pod -i -c=container1'
Mar  9 01:53:03.610: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:53:03.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2311" for this suite.
Mar  9 01:53:33.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:53:33.864: INFO: namespace webhook-2311 deletion completed in 30.214254504s
STEP: Destroying namespace "webhook-2311-markers" for this suite.
Mar  9 01:53:40.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:53:40.288: INFO: namespace webhook-2311-markers deletion completed in 6.423317044s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:47.934 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:53:40.322: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1771
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Mar  9 01:53:40.670: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:54:16.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1771" for this suite.
Mar  9 01:54:22.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:54:22.677: INFO: namespace crd-publish-openapi-1771 deletion completed in 6.208966073s

• [SLOW TEST:42.355 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:54:22.677: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 01:54:23.023: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dc8b54c9-83fc-47af-9234-f81eb203db0e" in namespace "projected-7613" to be "success or failure"
Mar  9 01:54:23.051: INFO: Pod "downwardapi-volume-dc8b54c9-83fc-47af-9234-f81eb203db0e": Phase="Pending", Reason="", readiness=false. Elapsed: 27.473142ms
Mar  9 01:54:25.058: INFO: Pod "downwardapi-volume-dc8b54c9-83fc-47af-9234-f81eb203db0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03406056s
Mar  9 01:54:27.065: INFO: Pod "downwardapi-volume-dc8b54c9-83fc-47af-9234-f81eb203db0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041911876s
STEP: Saw pod success
Mar  9 01:54:27.066: INFO: Pod "downwardapi-volume-dc8b54c9-83fc-47af-9234-f81eb203db0e" satisfied condition "success or failure"
Mar  9 01:54:27.071: INFO: Trying to get logs from node worker1 pod downwardapi-volume-dc8b54c9-83fc-47af-9234-f81eb203db0e container client-container: <nil>
STEP: delete the pod
Mar  9 01:54:27.283: INFO: Waiting for pod downwardapi-volume-dc8b54c9-83fc-47af-9234-f81eb203db0e to disappear
Mar  9 01:54:27.329: INFO: Pod downwardapi-volume-dc8b54c9-83fc-47af-9234-f81eb203db0e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:54:27.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7613" for this suite.
Mar  9 01:54:35.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:54:35.603: INFO: namespace projected-7613 deletion completed in 8.266456289s

• [SLOW TEST:12.926 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:54:35.604: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7765
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-7765
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7765 to expose endpoints map[]
Mar  9 01:54:36.264: INFO: Get endpoints failed (19.836309ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar  9 01:54:37.286: INFO: successfully validated that service endpoint-test2 in namespace services-7765 exposes endpoints map[] (1.041989374s elapsed)
STEP: Creating pod pod1 in namespace services-7765
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7765 to expose endpoints map[pod1:[80]]
Mar  9 01:54:40.536: INFO: successfully validated that service endpoint-test2 in namespace services-7765 exposes endpoints map[pod1:[80]] (3.172560193s elapsed)
STEP: Creating pod pod2 in namespace services-7765
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7765 to expose endpoints map[pod1:[80] pod2:[80]]
Mar  9 01:54:44.771: INFO: successfully validated that service endpoint-test2 in namespace services-7765 exposes endpoints map[pod1:[80] pod2:[80]] (4.145150984s elapsed)
STEP: Deleting pod pod1 in namespace services-7765
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7765 to expose endpoints map[pod2:[80]]
Mar  9 01:54:45.840: INFO: successfully validated that service endpoint-test2 in namespace services-7765 exposes endpoints map[pod2:[80]] (1.042923289s elapsed)
STEP: Deleting pod pod2 in namespace services-7765
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7765 to expose endpoints map[]
Mar  9 01:54:45.951: INFO: successfully validated that service endpoint-test2 in namespace services-7765 exposes endpoints map[] (84.887423ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:54:46.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7765" for this suite.
Mar  9 01:54:54.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:54:54.399: INFO: namespace services-7765 deletion completed in 8.192674027s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.795 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:54:54.399: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-992
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  9 01:54:54.727: INFO: PodSpec: initContainers in spec.initContainers
Mar  9 01:55:46.602: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-98855ad6-bda4-4255-87ed-6689bb824fcf", GenerateName:"", Namespace:"init-container-992", SelfLink:"/api/v1/namespaces/init-container-992/pods/pod-init-98855ad6-bda4-4255-87ed-6689bb824fcf", UID:"607ba9d5-df8a-4f04-bfbe-3a7bff620c2f", ResourceVersion:"97811", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63719315694, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"727406005"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-kwkn5", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002be7780), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"172.20.8.7/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kwkn5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"172.20.8.7/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kwkn5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"172.20.8.7/library/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-kwkn5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0052c25e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003078120), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0052c2670)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0052c2690)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0052c2698), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0052c269c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315694, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315694, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315694, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719315694, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.20.8.6", PodIP:"10.244.3.73", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.3.73"}}, StartTime:(*v1.Time)(0xc003067980), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0010b3b90)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0010b3c00)}, Ready:false, RestartCount:3, Image:"172.20.8.7/library/busybox:1.29", ImageID:"docker-pullable://172.20.8.7/library/busybox@sha256:e004c2cc521c95383aebb1fb5893719aa7a8eae2e7a71f316a4410784edb00a9", ContainerID:"docker://d8c0665a37e5bf58c0616b49dfeb140d171228436af850baf394114b9960dfa8", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030679c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"172.20.8.7/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030679a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"172.20.8.7/library/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0052c271f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:55:46.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-992" for this suite.
Mar  9 01:56:14.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:56:15.002: INFO: namespace init-container-992 deletion completed in 28.288949028s

• [SLOW TEST:80.603 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:56:15.003: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-409ff338-ca69-470a-b633-edbd52c7ae47
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:56:15.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6586" for this suite.
Mar  9 01:56:21.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:56:21.559: INFO: namespace configmap-6586 deletion completed in 6.205840782s

• [SLOW TEST:6.557 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:56:21.560: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8319
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  9 01:56:21.925: INFO: Waiting up to 5m0s for pod "pod-1a01a739-2904-4729-89f0-4cf795d5ad12" in namespace "emptydir-8319" to be "success or failure"
Mar  9 01:56:21.931: INFO: Pod "pod-1a01a739-2904-4729-89f0-4cf795d5ad12": Phase="Pending", Reason="", readiness=false. Elapsed: 5.220058ms
Mar  9 01:56:23.939: INFO: Pod "pod-1a01a739-2904-4729-89f0-4cf795d5ad12": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013418538s
Mar  9 01:56:25.967: INFO: Pod "pod-1a01a739-2904-4729-89f0-4cf795d5ad12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041507836s
STEP: Saw pod success
Mar  9 01:56:25.967: INFO: Pod "pod-1a01a739-2904-4729-89f0-4cf795d5ad12" satisfied condition "success or failure"
Mar  9 01:56:25.972: INFO: Trying to get logs from node worker1 pod pod-1a01a739-2904-4729-89f0-4cf795d5ad12 container test-container: <nil>
STEP: delete the pod
Mar  9 01:56:26.251: INFO: Waiting for pod pod-1a01a739-2904-4729-89f0-4cf795d5ad12 to disappear
Mar  9 01:56:26.256: INFO: Pod pod-1a01a739-2904-4729-89f0-4cf795d5ad12 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:56:26.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8319" for this suite.
Mar  9 01:56:34.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:56:34.488: INFO: namespace emptydir-8319 deletion completed in 8.19184026s

• [SLOW TEST:12.928 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:56:34.488: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1396
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 01:56:34.871: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:56:40.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1396" for this suite.
Mar  9 01:56:49.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:56:49.213: INFO: namespace custom-resource-definition-1396 deletion completed in 8.317221538s

• [SLOW TEST:14.725 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:56:49.215: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5429
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  9 01:56:52.873: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:56:52.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5429" for this suite.
Mar  9 01:56:59.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:56:59.286: INFO: namespace container-runtime-5429 deletion completed in 6.284920651s

• [SLOW TEST:10.071 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:56:59.286: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9180
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-69fd57cd-f0f4-4eca-b574-74939f08acec
Mar  9 01:56:59.755: INFO: Pod name my-hostname-basic-69fd57cd-f0f4-4eca-b574-74939f08acec: Found 0 pods out of 1
Mar  9 01:57:04.764: INFO: Pod name my-hostname-basic-69fd57cd-f0f4-4eca-b574-74939f08acec: Found 1 pods out of 1
Mar  9 01:57:04.764: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-69fd57cd-f0f4-4eca-b574-74939f08acec" are running
Mar  9 01:57:04.768: INFO: Pod "my-hostname-basic-69fd57cd-f0f4-4eca-b574-74939f08acec-ldww4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-09 01:56:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-09 01:57:02 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-09 01:57:02 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-09 01:56:59 +0000 UTC Reason: Message:}])
Mar  9 01:57:04.769: INFO: Trying to dial the pod
Mar  9 01:57:09.862: INFO: Controller my-hostname-basic-69fd57cd-f0f4-4eca-b574-74939f08acec: Got expected result from replica 1 [my-hostname-basic-69fd57cd-f0f4-4eca-b574-74939f08acec-ldww4]: "my-hostname-basic-69fd57cd-f0f4-4eca-b574-74939f08acec-ldww4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:57:09.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9180" for this suite.
Mar  9 01:57:17.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:57:18.087: INFO: namespace replication-controller-9180 deletion completed in 8.216215414s

• [SLOW TEST:18.801 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:57:18.088: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4411
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-7e1f4fd7-28cf-4aee-b6b4-add728946426
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-7e1f4fd7-28cf-4aee-b6b4-add728946426
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:58:35.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4411" for this suite.
Mar  9 01:59:05.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:59:05.904: INFO: namespace configmap-4411 deletion completed in 30.193211051s

• [SLOW TEST:107.817 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:59:05.906: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2794
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-5d02bc8f-cd58-44d8-97cc-c131968bdc9c
STEP: Creating a pod to test consume configMaps
Mar  9 01:59:06.401: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-71c4ba15-97a5-4745-a37c-0eddaea597b2" in namespace "projected-2794" to be "success or failure"
Mar  9 01:59:06.409: INFO: Pod "pod-projected-configmaps-71c4ba15-97a5-4745-a37c-0eddaea597b2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.874059ms
Mar  9 01:59:08.416: INFO: Pod "pod-projected-configmaps-71c4ba15-97a5-4745-a37c-0eddaea597b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014920872s
Mar  9 01:59:10.423: INFO: Pod "pod-projected-configmaps-71c4ba15-97a5-4745-a37c-0eddaea597b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021924112s
STEP: Saw pod success
Mar  9 01:59:10.423: INFO: Pod "pod-projected-configmaps-71c4ba15-97a5-4745-a37c-0eddaea597b2" satisfied condition "success or failure"
Mar  9 01:59:10.428: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-71c4ba15-97a5-4745-a37c-0eddaea597b2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 01:59:10.561: INFO: Waiting for pod pod-projected-configmaps-71c4ba15-97a5-4745-a37c-0eddaea597b2 to disappear
Mar  9 01:59:10.568: INFO: Pod pod-projected-configmaps-71c4ba15-97a5-4745-a37c-0eddaea597b2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:59:10.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2794" for this suite.
Mar  9 01:59:18.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:59:18.990: INFO: namespace projected-2794 deletion completed in 8.386174755s

• [SLOW TEST:13.084 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:59:18.991: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1256
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-fb6a0dbe-3d58-49db-8bca-6e1d6213d09a
STEP: Creating a pod to test consume configMaps
Mar  9 01:59:19.471: INFO: Waiting up to 5m0s for pod "pod-configmaps-bfe7f8aa-18ac-44cf-80bc-8265e119e47e" in namespace "configmap-1256" to be "success or failure"
Mar  9 01:59:19.523: INFO: Pod "pod-configmaps-bfe7f8aa-18ac-44cf-80bc-8265e119e47e": Phase="Pending", Reason="", readiness=false. Elapsed: 52.382169ms
Mar  9 01:59:21.530: INFO: Pod "pod-configmaps-bfe7f8aa-18ac-44cf-80bc-8265e119e47e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059285496s
Mar  9 01:59:23.537: INFO: Pod "pod-configmaps-bfe7f8aa-18ac-44cf-80bc-8265e119e47e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065929085s
STEP: Saw pod success
Mar  9 01:59:23.537: INFO: Pod "pod-configmaps-bfe7f8aa-18ac-44cf-80bc-8265e119e47e" satisfied condition "success or failure"
Mar  9 01:59:23.543: INFO: Trying to get logs from node worker1 pod pod-configmaps-bfe7f8aa-18ac-44cf-80bc-8265e119e47e container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 01:59:23.618: INFO: Waiting for pod pod-configmaps-bfe7f8aa-18ac-44cf-80bc-8265e119e47e to disappear
Mar  9 01:59:23.623: INFO: Pod pod-configmaps-bfe7f8aa-18ac-44cf-80bc-8265e119e47e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:59:23.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1256" for this suite.
Mar  9 01:59:31.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:59:31.875: INFO: namespace configmap-1256 deletion completed in 8.244219246s

• [SLOW TEST:12.884 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:59:31.875: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9360
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  9 01:59:35.458: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:59:35.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9360" for this suite.
Mar  9 01:59:43.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:59:43.897: INFO: namespace container-runtime-9360 deletion completed in 8.228461306s

• [SLOW TEST:12.022 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:59:43.898: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4878
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  9 01:59:44.241: INFO: Waiting up to 5m0s for pod "pod-07f6eea0-8908-4258-bd83-ddd084ed58b4" in namespace "emptydir-4878" to be "success or failure"
Mar  9 01:59:44.502: INFO: Pod "pod-07f6eea0-8908-4258-bd83-ddd084ed58b4": Phase="Pending", Reason="", readiness=false. Elapsed: 261.061639ms
Mar  9 01:59:46.509: INFO: Pod "pod-07f6eea0-8908-4258-bd83-ddd084ed58b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.268086483s
Mar  9 01:59:48.517: INFO: Pod "pod-07f6eea0-8908-4258-bd83-ddd084ed58b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.275941916s
STEP: Saw pod success
Mar  9 01:59:48.517: INFO: Pod "pod-07f6eea0-8908-4258-bd83-ddd084ed58b4" satisfied condition "success or failure"
Mar  9 01:59:48.522: INFO: Trying to get logs from node worker1 pod pod-07f6eea0-8908-4258-bd83-ddd084ed58b4 container test-container: <nil>
STEP: delete the pod
Mar  9 01:59:48.846: INFO: Waiting for pod pod-07f6eea0-8908-4258-bd83-ddd084ed58b4 to disappear
Mar  9 01:59:48.865: INFO: Pod pod-07f6eea0-8908-4258-bd83-ddd084ed58b4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 01:59:48.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4878" for this suite.
Mar  9 01:59:54.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 01:59:55.113: INFO: namespace emptydir-4878 deletion completed in 6.239186995s

• [SLOW TEST:11.216 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 01:59:55.114: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6427
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-9f00144c-e413-4c35-b637-18b6898f92c0
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-9f00144c-e413-4c35-b637-18b6898f92c0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:01:26.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6427" for this suite.
Mar  9 02:01:38.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:01:39.166: INFO: namespace projected-6427 deletion completed in 12.365441524s

• [SLOW TEST:104.052 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:01:39.167: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2994
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  9 02:01:39.602: INFO: Waiting up to 5m0s for pod "pod-e30d6309-8896-418e-9e22-96589699fdc9" in namespace "emptydir-2994" to be "success or failure"
Mar  9 02:01:39.607: INFO: Pod "pod-e30d6309-8896-418e-9e22-96589699fdc9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.774769ms
Mar  9 02:01:41.614: INFO: Pod "pod-e30d6309-8896-418e-9e22-96589699fdc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011771015s
Mar  9 02:01:43.622: INFO: Pod "pod-e30d6309-8896-418e-9e22-96589699fdc9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019489154s
STEP: Saw pod success
Mar  9 02:01:43.622: INFO: Pod "pod-e30d6309-8896-418e-9e22-96589699fdc9" satisfied condition "success or failure"
Mar  9 02:01:43.627: INFO: Trying to get logs from node worker1 pod pod-e30d6309-8896-418e-9e22-96589699fdc9 container test-container: <nil>
STEP: delete the pod
Mar  9 02:01:43.843: INFO: Waiting for pod pod-e30d6309-8896-418e-9e22-96589699fdc9 to disappear
Mar  9 02:01:43.877: INFO: Pod pod-e30d6309-8896-418e-9e22-96589699fdc9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:01:43.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2994" for this suite.
Mar  9 02:01:49.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:01:50.449: INFO: namespace emptydir-2994 deletion completed in 6.562558127s

• [SLOW TEST:11.282 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:01:50.451: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2299
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-bdee036d-fdc4-4da9-94aa-67b7e2b2d4a7
STEP: Creating a pod to test consume configMaps
Mar  9 02:01:50.836: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-01b28a24-6e70-4ac6-a3f6-d9ec8c20519a" in namespace "projected-2299" to be "success or failure"
Mar  9 02:01:50.857: INFO: Pod "pod-projected-configmaps-01b28a24-6e70-4ac6-a3f6-d9ec8c20519a": Phase="Pending", Reason="", readiness=false. Elapsed: 21.334026ms
Mar  9 02:01:52.966: INFO: Pod "pod-projected-configmaps-01b28a24-6e70-4ac6-a3f6-d9ec8c20519a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.129985702s
Mar  9 02:01:54.973: INFO: Pod "pod-projected-configmaps-01b28a24-6e70-4ac6-a3f6-d9ec8c20519a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.137423699s
STEP: Saw pod success
Mar  9 02:01:54.973: INFO: Pod "pod-projected-configmaps-01b28a24-6e70-4ac6-a3f6-d9ec8c20519a" satisfied condition "success or failure"
Mar  9 02:01:54.979: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-01b28a24-6e70-4ac6-a3f6-d9ec8c20519a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 02:01:55.128: INFO: Waiting for pod pod-projected-configmaps-01b28a24-6e70-4ac6-a3f6-d9ec8c20519a to disappear
Mar  9 02:01:55.153: INFO: Pod pod-projected-configmaps-01b28a24-6e70-4ac6-a3f6-d9ec8c20519a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:01:55.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2299" for this suite.
Mar  9 02:02:03.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:02:03.566: INFO: namespace projected-2299 deletion completed in 8.283449607s

• [SLOW TEST:13.115 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:02:03.566: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9446
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-43130e3e-30ec-4574-ad20-e928aef375c4
STEP: Creating a pod to test consume configMaps
Mar  9 02:02:03.920: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4f23e733-b101-4d01-abe2-9e54c42dc9d3" in namespace "projected-9446" to be "success or failure"
Mar  9 02:02:03.924: INFO: Pod "pod-projected-configmaps-4f23e733-b101-4d01-abe2-9e54c42dc9d3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.282127ms
Mar  9 02:02:05.931: INFO: Pod "pod-projected-configmaps-4f23e733-b101-4d01-abe2-9e54c42dc9d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011674029s
Mar  9 02:02:07.939: INFO: Pod "pod-projected-configmaps-4f23e733-b101-4d01-abe2-9e54c42dc9d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019028286s
STEP: Saw pod success
Mar  9 02:02:07.939: INFO: Pod "pod-projected-configmaps-4f23e733-b101-4d01-abe2-9e54c42dc9d3" satisfied condition "success or failure"
Mar  9 02:02:07.966: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-4f23e733-b101-4d01-abe2-9e54c42dc9d3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 02:02:08.153: INFO: Waiting for pod pod-projected-configmaps-4f23e733-b101-4d01-abe2-9e54c42dc9d3 to disappear
Mar  9 02:02:08.158: INFO: Pod pod-projected-configmaps-4f23e733-b101-4d01-abe2-9e54c42dc9d3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:02:08.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9446" for this suite.
Mar  9 02:02:16.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:02:16.459: INFO: namespace projected-9446 deletion completed in 8.293238415s

• [SLOW TEST:12.894 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:02:16.460: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6377
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Mar  9 02:02:16.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 api-versions'
Mar  9 02:02:17.193: INFO: stderr: ""
Mar  9 02:02:17.193: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:02:17.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6377" for this suite.
Mar  9 02:02:23.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:02:23.460: INFO: namespace kubectl-6377 deletion completed in 6.222018302s

• [SLOW TEST:6.999 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:02:23.460: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3925
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Mar  9 02:02:27.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec pod-sharedvolume-399038a5-5a01-4b9a-9eb2-e9a5c1d52017 -c busybox-main-container --namespace=emptydir-3925 -- cat /usr/share/volumeshare/shareddata.txt'
Mar  9 02:02:31.858: INFO: stderr: ""
Mar  9 02:02:31.858: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:02:31.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3925" for this suite.
Mar  9 02:02:39.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:02:40.057: INFO: namespace emptydir-3925 deletion completed in 8.18766989s

• [SLOW TEST:16.597 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:02:40.058: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4025
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:02:40.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4025" for this suite.
Mar  9 02:02:46.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:02:46.794: INFO: namespace services-4025 deletion completed in 6.18967529s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.736 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:02:46.796: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5087
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  9 02:02:47.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=172.20.8.7/library/httpd:2.4.38-alpine --namespace=kubectl-5087'
Mar  9 02:02:47.729: INFO: stderr: ""
Mar  9 02:02:47.729: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Mar  9 02:02:47.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete pods e2e-test-httpd-pod --namespace=kubectl-5087'
Mar  9 02:03:01.083: INFO: stderr: ""
Mar  9 02:03:01.083: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:03:01.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5087" for this suite.
Mar  9 02:03:07.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:03:07.439: INFO: namespace kubectl-5087 deletion completed in 6.347060736s

• [SLOW TEST:20.643 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:03:07.441: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9767
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:03:08.026: INFO: Create a RollingUpdate DaemonSet
Mar  9 02:03:08.044: INFO: Check that daemon pods launch on every node of the cluster
Mar  9 02:03:08.098: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:08.098: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:08.098: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:08.142: INFO: Number of nodes with available pods: 0
Mar  9 02:03:08.142: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:03:09.154: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:09.156: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:09.156: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:09.163: INFO: Number of nodes with available pods: 0
Mar  9 02:03:09.163: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:03:10.153: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:10.153: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:10.153: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:10.160: INFO: Number of nodes with available pods: 0
Mar  9 02:03:10.160: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:03:11.152: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:11.152: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:11.152: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:11.159: INFO: Number of nodes with available pods: 1
Mar  9 02:03:11.159: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:03:12.153: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:12.153: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:12.153: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:12.159: INFO: Number of nodes with available pods: 1
Mar  9 02:03:12.159: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:03:13.152: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:13.152: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:13.152: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:13.158: INFO: Number of nodes with available pods: 2
Mar  9 02:03:13.158: INFO: Number of running nodes: 2, number of available pods: 2
Mar  9 02:03:13.158: INFO: Update the DaemonSet to trigger a rollout
Mar  9 02:03:13.192: INFO: Updating DaemonSet daemon-set
Mar  9 02:03:16.235: INFO: Roll back the DaemonSet before rollout is complete
Mar  9 02:03:16.307: INFO: Updating DaemonSet daemon-set
Mar  9 02:03:16.307: INFO: Make sure DaemonSet rollback is complete
Mar  9 02:03:16.333: INFO: Wrong image for pod: daemon-set-vtl96. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  9 02:03:16.333: INFO: Pod daemon-set-vtl96 is not available
Mar  9 02:03:16.361: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:16.361: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:16.361: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:17.369: INFO: Wrong image for pod: daemon-set-vtl96. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  9 02:03:17.369: INFO: Pod daemon-set-vtl96 is not available
Mar  9 02:03:17.377: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:17.377: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:17.377: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:18.379: INFO: Pod daemon-set-cd99m is not available
Mar  9 02:03:18.402: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:18.402: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:03:18.402: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9767, will wait for the garbage collector to delete the pods
Mar  9 02:03:18.549: INFO: Deleting DaemonSet.extensions daemon-set took: 77.511674ms
Mar  9 02:03:18.950: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.548997ms
Mar  9 02:03:21.756: INFO: Number of nodes with available pods: 0
Mar  9 02:03:21.756: INFO: Number of running nodes: 0, number of available pods: 0
Mar  9 02:03:21.766: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9767/daemonsets","resourceVersion":"99192"},"items":null}

Mar  9 02:03:21.800: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9767/pods","resourceVersion":"99192"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:03:21.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9767" for this suite.
Mar  9 02:03:29.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:03:30.029: INFO: namespace daemonsets-9767 deletion completed in 8.195054656s

• [SLOW TEST:22.588 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:03:30.030: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-6134
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:03:34.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6134" for this suite.
Mar  9 02:03:41.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:03:41.317: INFO: namespace emptydir-wrapper-6134 deletion completed in 6.337794268s

• [SLOW TEST:11.287 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:03:41.320: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8565
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-frjh
STEP: Creating a pod to test atomic-volume-subpath
Mar  9 02:03:41.736: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-frjh" in namespace "subpath-8565" to be "success or failure"
Mar  9 02:03:41.851: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Pending", Reason="", readiness=false. Elapsed: 115.284231ms
Mar  9 02:03:43.859: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123133469s
Mar  9 02:03:45.867: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Running", Reason="", readiness=true. Elapsed: 4.131181559s
Mar  9 02:03:47.875: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Running", Reason="", readiness=true. Elapsed: 6.138621347s
Mar  9 02:03:49.882: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Running", Reason="", readiness=true. Elapsed: 8.14556816s
Mar  9 02:03:51.889: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Running", Reason="", readiness=true. Elapsed: 10.153040431s
Mar  9 02:03:53.896: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Running", Reason="", readiness=true. Elapsed: 12.160351465s
Mar  9 02:03:55.904: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Running", Reason="", readiness=true. Elapsed: 14.16778105s
Mar  9 02:03:57.911: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Running", Reason="", readiness=true. Elapsed: 16.174857647s
Mar  9 02:03:59.919: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Running", Reason="", readiness=true. Elapsed: 18.182793367s
Mar  9 02:04:01.926: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Running", Reason="", readiness=true. Elapsed: 20.189724786s
Mar  9 02:04:03.933: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Running", Reason="", readiness=true. Elapsed: 22.196729506s
Mar  9 02:04:05.940: INFO: Pod "pod-subpath-test-projected-frjh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.203928356s
STEP: Saw pod success
Mar  9 02:04:05.940: INFO: Pod "pod-subpath-test-projected-frjh" satisfied condition "success or failure"
Mar  9 02:04:05.946: INFO: Trying to get logs from node worker1 pod pod-subpath-test-projected-frjh container test-container-subpath-projected-frjh: <nil>
STEP: delete the pod
Mar  9 02:04:06.219: INFO: Waiting for pod pod-subpath-test-projected-frjh to disappear
Mar  9 02:04:06.225: INFO: Pod pod-subpath-test-projected-frjh no longer exists
STEP: Deleting pod pod-subpath-test-projected-frjh
Mar  9 02:04:06.226: INFO: Deleting pod "pod-subpath-test-projected-frjh" in namespace "subpath-8565"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:04:06.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8565" for this suite.
Mar  9 02:04:14.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:04:14.476: INFO: namespace subpath-8565 deletion completed in 8.23780856s

• [SLOW TEST:33.156 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:04:14.477: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3458
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:04:15.010: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar  9 02:04:15.045: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:15.045: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:15.045: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:15.053: INFO: Number of nodes with available pods: 0
Mar  9 02:04:15.053: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:04:16.063: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:16.063: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:16.063: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:16.069: INFO: Number of nodes with available pods: 0
Mar  9 02:04:16.069: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:04:17.063: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:17.063: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:17.064: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:17.070: INFO: Number of nodes with available pods: 0
Mar  9 02:04:17.070: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:04:18.063: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:18.063: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:18.064: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:18.071: INFO: Number of nodes with available pods: 1
Mar  9 02:04:18.071: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:04:19.063: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:19.063: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:19.063: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:19.127: INFO: Number of nodes with available pods: 2
Mar  9 02:04:19.127: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar  9 02:04:19.223: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:19.223: INFO: Wrong image for pod: daemon-set-wcwlm. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:19.286: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:19.286: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:19.286: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:20.294: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:20.295: INFO: Wrong image for pod: daemon-set-wcwlm. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:20.303: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:20.303: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:20.303: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:21.294: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:21.294: INFO: Wrong image for pod: daemon-set-wcwlm. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:21.302: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:21.302: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:21.302: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:22.384: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:22.384: INFO: Wrong image for pod: daemon-set-wcwlm. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:22.446: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:22.446: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:22.446: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:23.294: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:23.295: INFO: Wrong image for pod: daemon-set-wcwlm. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:23.295: INFO: Pod daemon-set-wcwlm is not available
Mar  9 02:04:23.303: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:23.303: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:23.303: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:24.319: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:24.319: INFO: Pod daemon-set-spwgq is not available
Mar  9 02:04:24.326: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:24.327: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:24.327: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:25.294: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:25.294: INFO: Pod daemon-set-spwgq is not available
Mar  9 02:04:25.302: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:25.302: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:25.302: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:26.294: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:26.294: INFO: Pod daemon-set-spwgq is not available
Mar  9 02:04:26.303: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:26.303: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:26.303: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:27.295: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:27.305: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:27.305: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:27.305: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:28.295: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:28.295: INFO: Pod daemon-set-mcvk5 is not available
Mar  9 02:04:28.303: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:28.303: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:28.303: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:29.294: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:29.294: INFO: Pod daemon-set-mcvk5 is not available
Mar  9 02:04:29.303: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:29.303: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:29.303: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:30.294: INFO: Wrong image for pod: daemon-set-mcvk5. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  9 02:04:30.294: INFO: Pod daemon-set-mcvk5 is not available
Mar  9 02:04:30.301: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:30.301: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:30.301: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:31.293: INFO: Pod daemon-set-27l55 is not available
Mar  9 02:04:31.471: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:31.471: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:31.471: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:32.295: INFO: Pod daemon-set-27l55 is not available
Mar  9 02:04:32.304: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:32.304: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:32.304: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Mar  9 02:04:32.311: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:32.311: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:32.311: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:32.317: INFO: Number of nodes with available pods: 1
Mar  9 02:04:32.317: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:04:33.332: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:33.332: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:33.332: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:33.338: INFO: Number of nodes with available pods: 1
Mar  9 02:04:33.338: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:04:34.327: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:34.327: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:34.327: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:34.334: INFO: Number of nodes with available pods: 2
Mar  9 02:04:34.334: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3458, will wait for the garbage collector to delete the pods
Mar  9 02:04:34.439: INFO: Deleting DaemonSet.extensions daemon-set took: 21.109014ms
Mar  9 02:04:34.839: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.305738ms
Mar  9 02:04:41.246: INFO: Number of nodes with available pods: 0
Mar  9 02:04:41.246: INFO: Number of running nodes: 0, number of available pods: 0
Mar  9 02:04:41.250: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3458/daemonsets","resourceVersion":"99511"},"items":null}

Mar  9 02:04:41.254: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3458/pods","resourceVersion":"99511"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:04:41.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3458" for this suite.
Mar  9 02:04:51.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:04:51.533: INFO: namespace daemonsets-3458 deletion completed in 10.17622692s

• [SLOW TEST:37.057 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:04:51.535: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-308
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  9 02:04:52.064: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:52.065: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:52.065: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:52.075: INFO: Number of nodes with available pods: 0
Mar  9 02:04:52.075: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:04:53.084: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:53.084: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:53.084: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:53.091: INFO: Number of nodes with available pods: 0
Mar  9 02:04:53.091: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:04:54.086: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:54.086: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:54.086: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:54.092: INFO: Number of nodes with available pods: 0
Mar  9 02:04:54.092: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:04:55.084: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:55.084: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:55.084: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:55.103: INFO: Number of nodes with available pods: 1
Mar  9 02:04:55.103: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:04:56.114: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:56.114: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:56.114: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:56.120: INFO: Number of nodes with available pods: 2
Mar  9 02:04:56.120: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar  9 02:04:56.201: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:56.201: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:56.201: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:56.227: INFO: Number of nodes with available pods: 1
Mar  9 02:04:56.228: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:04:57.252: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:57.252: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:57.253: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:57.263: INFO: Number of nodes with available pods: 1
Mar  9 02:04:57.263: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:04:58.239: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:58.239: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:58.239: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:58.245: INFO: Number of nodes with available pods: 1
Mar  9 02:04:58.245: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:04:59.237: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:59.237: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:59.237: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:04:59.243: INFO: Number of nodes with available pods: 1
Mar  9 02:04:59.243: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:00.237: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:00.237: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:00.237: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:00.243: INFO: Number of nodes with available pods: 1
Mar  9 02:05:00.243: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:01.239: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:01.239: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:01.239: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:01.246: INFO: Number of nodes with available pods: 1
Mar  9 02:05:01.246: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:02.239: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:02.239: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:02.239: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:02.246: INFO: Number of nodes with available pods: 1
Mar  9 02:05:02.246: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:03.237: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:03.237: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:03.237: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:03.243: INFO: Number of nodes with available pods: 1
Mar  9 02:05:03.243: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:04.238: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:04.238: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:04.238: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:04.244: INFO: Number of nodes with available pods: 1
Mar  9 02:05:04.244: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:05.237: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:05.237: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:05.237: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:05.244: INFO: Number of nodes with available pods: 1
Mar  9 02:05:05.244: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:06.277: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:06.278: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:06.278: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:06.284: INFO: Number of nodes with available pods: 1
Mar  9 02:05:06.284: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:07.239: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:07.239: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:07.239: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:07.245: INFO: Number of nodes with available pods: 1
Mar  9 02:05:07.245: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:08.236: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:08.236: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:08.237: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:08.246: INFO: Number of nodes with available pods: 1
Mar  9 02:05:08.246: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:09.237: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:09.237: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:09.237: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:09.266: INFO: Number of nodes with available pods: 1
Mar  9 02:05:09.266: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:10.261: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:10.261: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:10.261: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:10.266: INFO: Number of nodes with available pods: 1
Mar  9 02:05:10.266: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:11.299: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:11.299: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:11.299: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:11.314: INFO: Number of nodes with available pods: 1
Mar  9 02:05:11.314: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:12.238: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:12.238: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:12.239: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:12.244: INFO: Number of nodes with available pods: 1
Mar  9 02:05:12.244: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:13.244: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:13.244: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:13.244: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:13.268: INFO: Number of nodes with available pods: 1
Mar  9 02:05:13.268: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:14.237: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:14.238: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:14.238: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:14.244: INFO: Number of nodes with available pods: 1
Mar  9 02:05:14.244: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:05:15.237: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:15.237: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:15.238: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:05:15.268: INFO: Number of nodes with available pods: 2
Mar  9 02:05:15.268: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-308, will wait for the garbage collector to delete the pods
Mar  9 02:05:15.467: INFO: Deleting DaemonSet.extensions daemon-set took: 42.415981ms
Mar  9 02:05:15.867: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.414307ms
Mar  9 02:05:21.174: INFO: Number of nodes with available pods: 0
Mar  9 02:05:21.174: INFO: Number of running nodes: 0, number of available pods: 0
Mar  9 02:05:21.179: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-308/daemonsets","resourceVersion":"99677"},"items":null}

Mar  9 02:05:21.183: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-308/pods","resourceVersion":"99677"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:05:21.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-308" for this suite.
Mar  9 02:05:29.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:05:29.393: INFO: namespace daemonsets-308 deletion completed in 8.184727898s

• [SLOW TEST:37.859 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:05:29.394: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3364
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  9 02:05:29.779: INFO: Waiting up to 5m0s for pod "pod-bd48234d-7534-4e3d-ba32-fbc44c085597" in namespace "emptydir-3364" to be "success or failure"
Mar  9 02:05:29.812: INFO: Pod "pod-bd48234d-7534-4e3d-ba32-fbc44c085597": Phase="Pending", Reason="", readiness=false. Elapsed: 33.38266ms
Mar  9 02:05:31.829: INFO: Pod "pod-bd48234d-7534-4e3d-ba32-fbc44c085597": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050495687s
Mar  9 02:05:33.837: INFO: Pod "pod-bd48234d-7534-4e3d-ba32-fbc44c085597": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057699607s
STEP: Saw pod success
Mar  9 02:05:33.837: INFO: Pod "pod-bd48234d-7534-4e3d-ba32-fbc44c085597" satisfied condition "success or failure"
Mar  9 02:05:33.842: INFO: Trying to get logs from node worker1 pod pod-bd48234d-7534-4e3d-ba32-fbc44c085597 container test-container: <nil>
STEP: delete the pod
Mar  9 02:05:33.991: INFO: Waiting for pod pod-bd48234d-7534-4e3d-ba32-fbc44c085597 to disappear
Mar  9 02:05:34.004: INFO: Pod pod-bd48234d-7534-4e3d-ba32-fbc44c085597 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:05:34.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3364" for this suite.
Mar  9 02:05:42.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:05:42.260: INFO: namespace emptydir-3364 deletion completed in 8.247564903s

• [SLOW TEST:12.866 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:05:42.261: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  9 02:05:42.591: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:05:50.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2453" for this suite.
Mar  9 02:06:02.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:06:02.911: INFO: namespace init-container-2453 deletion completed in 12.20698966s

• [SLOW TEST:20.650 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:06:02.912: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1108
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 02:06:03.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-956655a6-7850-4fa3-a211-4054693ee82b" in namespace "downward-api-1108" to be "success or failure"
Mar  9 02:06:03.397: INFO: Pod "downwardapi-volume-956655a6-7850-4fa3-a211-4054693ee82b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.216348ms
Mar  9 02:06:05.420: INFO: Pod "downwardapi-volume-956655a6-7850-4fa3-a211-4054693ee82b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0258583s
Mar  9 02:06:07.427: INFO: Pod "downwardapi-volume-956655a6-7850-4fa3-a211-4054693ee82b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033356035s
STEP: Saw pod success
Mar  9 02:06:07.427: INFO: Pod "downwardapi-volume-956655a6-7850-4fa3-a211-4054693ee82b" satisfied condition "success or failure"
Mar  9 02:06:07.433: INFO: Trying to get logs from node worker1 pod downwardapi-volume-956655a6-7850-4fa3-a211-4054693ee82b container client-container: <nil>
STEP: delete the pod
Mar  9 02:06:07.522: INFO: Waiting for pod downwardapi-volume-956655a6-7850-4fa3-a211-4054693ee82b to disappear
Mar  9 02:06:07.536: INFO: Pod downwardapi-volume-956655a6-7850-4fa3-a211-4054693ee82b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:06:07.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1108" for this suite.
Mar  9 02:06:13.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:06:13.813: INFO: namespace downward-api-1108 deletion completed in 6.269643973s

• [SLOW TEST:10.901 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:06:13.814: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3391
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:06:14.177: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar  9 02:06:24.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-3391 create -f -'
Mar  9 02:06:29.083: INFO: stderr: ""
Mar  9 02:06:29.083: INFO: stdout: "e2e-test-crd-publish-openapi-1833-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Mar  9 02:06:29.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-3391 delete e2e-test-crd-publish-openapi-1833-crds test-cr'
Mar  9 02:06:29.537: INFO: stderr: ""
Mar  9 02:06:29.537: INFO: stdout: "e2e-test-crd-publish-openapi-1833-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Mar  9 02:06:29.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-3391 apply -f -'
Mar  9 02:06:30.332: INFO: stderr: ""
Mar  9 02:06:30.332: INFO: stdout: "e2e-test-crd-publish-openapi-1833-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Mar  9 02:06:30.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-3391 delete e2e-test-crd-publish-openapi-1833-crds test-cr'
Mar  9 02:06:30.559: INFO: stderr: ""
Mar  9 02:06:30.559: INFO: stdout: "e2e-test-crd-publish-openapi-1833-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Mar  9 02:06:30.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 explain e2e-test-crd-publish-openapi-1833-crds'
Mar  9 02:06:31.208: INFO: stderr: ""
Mar  9 02:06:31.208: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1833-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:06:36.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3391" for this suite.
Mar  9 02:06:42.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:06:43.075: INFO: namespace crd-publish-openapi-3391 deletion completed in 6.283127604s

• [SLOW TEST:29.261 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:06:43.076: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8988
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-55454eb8-b870-4202-b79f-8c84bb18a34e
STEP: Creating a pod to test consume configMaps
Mar  9 02:06:43.543: INFO: Waiting up to 5m0s for pod "pod-configmaps-78cbedcc-d5fb-4efc-9cfa-76190cea2d3d" in namespace "configmap-8988" to be "success or failure"
Mar  9 02:06:43.548: INFO: Pod "pod-configmaps-78cbedcc-d5fb-4efc-9cfa-76190cea2d3d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.777443ms
Mar  9 02:06:45.556: INFO: Pod "pod-configmaps-78cbedcc-d5fb-4efc-9cfa-76190cea2d3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012945327s
Mar  9 02:06:47.564: INFO: Pod "pod-configmaps-78cbedcc-d5fb-4efc-9cfa-76190cea2d3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020853191s
STEP: Saw pod success
Mar  9 02:06:47.564: INFO: Pod "pod-configmaps-78cbedcc-d5fb-4efc-9cfa-76190cea2d3d" satisfied condition "success or failure"
Mar  9 02:06:47.569: INFO: Trying to get logs from node worker1 pod pod-configmaps-78cbedcc-d5fb-4efc-9cfa-76190cea2d3d container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 02:06:47.756: INFO: Waiting for pod pod-configmaps-78cbedcc-d5fb-4efc-9cfa-76190cea2d3d to disappear
Mar  9 02:06:47.775: INFO: Pod pod-configmaps-78cbedcc-d5fb-4efc-9cfa-76190cea2d3d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:06:47.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8988" for this suite.
Mar  9 02:06:55.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:06:56.001: INFO: namespace configmap-8988 deletion completed in 8.217836698s

• [SLOW TEST:12.925 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:06:56.002: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5266
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  9 02:06:56.380: INFO: Waiting up to 5m0s for pod "pod-b0776e52-8900-4ba0-8df9-9e0cad1d6af5" in namespace "emptydir-5266" to be "success or failure"
Mar  9 02:06:56.520: INFO: Pod "pod-b0776e52-8900-4ba0-8df9-9e0cad1d6af5": Phase="Pending", Reason="", readiness=false. Elapsed: 139.596841ms
Mar  9 02:06:58.527: INFO: Pod "pod-b0776e52-8900-4ba0-8df9-9e0cad1d6af5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.146977833s
Mar  9 02:07:00.535: INFO: Pod "pod-b0776e52-8900-4ba0-8df9-9e0cad1d6af5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.154817286s
STEP: Saw pod success
Mar  9 02:07:00.535: INFO: Pod "pod-b0776e52-8900-4ba0-8df9-9e0cad1d6af5" satisfied condition "success or failure"
Mar  9 02:07:00.540: INFO: Trying to get logs from node worker1 pod pod-b0776e52-8900-4ba0-8df9-9e0cad1d6af5 container test-container: <nil>
STEP: delete the pod
Mar  9 02:07:00.702: INFO: Waiting for pod pod-b0776e52-8900-4ba0-8df9-9e0cad1d6af5 to disappear
Mar  9 02:07:00.706: INFO: Pod pod-b0776e52-8900-4ba0-8df9-9e0cad1d6af5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:07:00.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5266" for this suite.
Mar  9 02:07:08.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:07:08.905: INFO: namespace emptydir-5266 deletion completed in 8.191294498s

• [SLOW TEST:12.903 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:07:08.905: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3831
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Mar  9 02:07:09.531: INFO: Waiting up to 5m0s for pod "client-containers-e3f14b50-83b2-49b7-979b-58ad245a919d" in namespace "containers-3831" to be "success or failure"
Mar  9 02:07:09.561: INFO: Pod "client-containers-e3f14b50-83b2-49b7-979b-58ad245a919d": Phase="Pending", Reason="", readiness=false. Elapsed: 29.836585ms
Mar  9 02:07:11.568: INFO: Pod "client-containers-e3f14b50-83b2-49b7-979b-58ad245a919d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037440647s
Mar  9 02:07:13.575: INFO: Pod "client-containers-e3f14b50-83b2-49b7-979b-58ad245a919d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04417867s
STEP: Saw pod success
Mar  9 02:07:13.575: INFO: Pod "client-containers-e3f14b50-83b2-49b7-979b-58ad245a919d" satisfied condition "success or failure"
Mar  9 02:07:13.581: INFO: Trying to get logs from node worker1 pod client-containers-e3f14b50-83b2-49b7-979b-58ad245a919d container test-container: <nil>
STEP: delete the pod
Mar  9 02:07:13.693: INFO: Waiting for pod client-containers-e3f14b50-83b2-49b7-979b-58ad245a919d to disappear
Mar  9 02:07:13.698: INFO: Pod client-containers-e3f14b50-83b2-49b7-979b-58ad245a919d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:07:13.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3831" for this suite.
Mar  9 02:07:19.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:07:19.978: INFO: namespace containers-3831 deletion completed in 6.255468699s

• [SLOW TEST:11.073 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:07:19.978: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2321
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  9 02:07:20.420: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  9 02:07:20.454: INFO: Waiting for terminating namespaces to be deleted...
Mar  9 02:07:20.460: INFO: 
Logging pods the kubelet thinks is on node worker1 before test
Mar  9 02:07:20.473: INFO: kube-proxy-94vtq from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:07:20.473: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 02:07:20.473: INFO: sonobuoy from sonobuoy started at 2020-03-09 01:23:11 +0000 UTC (1 container statuses recorded)
Mar  9 02:07:20.473: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  9 02:07:20.473: INFO: sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-txlws from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 02:07:20.473: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  9 02:07:20.473: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  9 02:07:20.473: INFO: kube-flannel-ds-amd64-wgfqr from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:07:20.473: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  9 02:07:20.473: INFO: 
Logging pods the kubelet thinks is on node worker2 before test
Mar  9 02:07:20.511: INFO: sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-b49xx from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 02:07:20.511: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  9 02:07:20.511: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  9 02:07:20.511: INFO: kube-flannel-ds-amd64-q9s4h from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:07:20.511: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  9 02:07:20.511: INFO: sonobuoy-e2e-job-aaa481025fe94110 from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 02:07:20.511: INFO: 	Container e2e ready: true, restart count 0
Mar  9 02:07:20.511: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  9 02:07:20.511: INFO: kube-proxy-55qqw from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:07:20.511: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-1d998552-1653-48b8-92f3-ea8b383e834c 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-1d998552-1653-48b8-92f3-ea8b383e834c off the node worker1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1d998552-1653-48b8-92f3-ea8b383e834c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:07:29.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2321" for this suite.
Mar  9 02:07:43.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:07:43.410: INFO: namespace sched-pred-2321 deletion completed in 14.187098067s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:23.432 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:07:43.411: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4396
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 02:07:45.365: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 02:07:47.385: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719316465, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719316465, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719316465, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719316465, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 02:07:50.528: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:07:50.536: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1327-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:07:57.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4396" for this suite.
Mar  9 02:08:05.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:08:05.465: INFO: namespace webhook-4396 deletion completed in 8.303086192s
STEP: Destroying namespace "webhook-4396-markers" for this suite.
Mar  9 02:08:11.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:08:11.707: INFO: namespace webhook-4396-markers deletion completed in 6.241849848s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.354 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:08:11.766: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-291
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-291.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-291.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-291.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-291.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-291.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-291.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  9 02:08:18.257: INFO: DNS probes using dns-291/dns-test-490e4358-43b5-4bde-8dea-ce7658e8f057 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:08:18.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-291" for this suite.
Mar  9 02:08:26.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:08:26.702: INFO: namespace dns-291 deletion completed in 8.312709471s

• [SLOW TEST:14.936 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:08:26.703: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2836
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Mar  9 02:08:31.646: INFO: Successfully updated pod "adopt-release-bhbzw"
STEP: Checking that the Job readopts the Pod
Mar  9 02:08:31.647: INFO: Waiting up to 15m0s for pod "adopt-release-bhbzw" in namespace "job-2836" to be "adopted"
Mar  9 02:08:31.652: INFO: Pod "adopt-release-bhbzw": Phase="Running", Reason="", readiness=true. Elapsed: 5.305748ms
Mar  9 02:08:33.660: INFO: Pod "adopt-release-bhbzw": Phase="Running", Reason="", readiness=true. Elapsed: 2.013214284s
Mar  9 02:08:33.660: INFO: Pod "adopt-release-bhbzw" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Mar  9 02:08:34.192: INFO: Successfully updated pod "adopt-release-bhbzw"
STEP: Checking that the Job releases the Pod
Mar  9 02:08:34.192: INFO: Waiting up to 15m0s for pod "adopt-release-bhbzw" in namespace "job-2836" to be "released"
Mar  9 02:08:34.239: INFO: Pod "adopt-release-bhbzw": Phase="Running", Reason="", readiness=true. Elapsed: 47.380919ms
Mar  9 02:08:34.239: INFO: Pod "adopt-release-bhbzw" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:08:34.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2836" for this suite.
Mar  9 02:09:22.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:09:22.480: INFO: namespace job-2836 deletion completed in 48.228930722s

• [SLOW TEST:55.777 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:09:22.481: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8041
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-6657d4ce-7a7a-4d5a-84ce-8de3a01882e5 in namespace container-probe-8041
Mar  9 02:09:27.039: INFO: Started pod liveness-6657d4ce-7a7a-4d5a-84ce-8de3a01882e5 in namespace container-probe-8041
STEP: checking the pod's current state and verifying that restartCount is present
Mar  9 02:09:27.045: INFO: Initial restart count of pod liveness-6657d4ce-7a7a-4d5a-84ce-8de3a01882e5 is 0
Mar  9 02:09:49.134: INFO: Restart count of pod container-probe-8041/liveness-6657d4ce-7a7a-4d5a-84ce-8de3a01882e5 is now 1 (22.088364739s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:09:49.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8041" for this suite.
Mar  9 02:09:57.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:09:57.546: INFO: namespace container-probe-8041 deletion completed in 8.278649794s

• [SLOW TEST:35.065 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:09:57.548: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8102
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8102
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Mar  9 02:09:57.909: INFO: Found 0 stateful pods, waiting for 3
Mar  9 02:10:07.920: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 02:10:07.920: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 02:10:07.920: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Mar  9 02:10:17.919: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 02:10:17.919: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 02:10:17.919: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 02:10:17.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-8102 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  9 02:10:18.503: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  9 02:10:18.503: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  9 02:10:18.503: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from 172.20.8.7/library/httpd:2.4.38-alpine to 172.20.8.7/library/httpd:2.4.39-alpine
Mar  9 02:10:28.575: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar  9 02:10:38.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-8102 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 02:10:39.177: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  9 02:10:39.177: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  9 02:10:39.177: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  9 02:10:49.223: INFO: Waiting for StatefulSet statefulset-8102/ss2 to complete update
Mar  9 02:10:49.223: INFO: Waiting for Pod statefulset-8102/ss2-0 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
Mar  9 02:10:49.223: INFO: Waiting for Pod statefulset-8102/ss2-1 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
Mar  9 02:10:49.223: INFO: Waiting for Pod statefulset-8102/ss2-2 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
Mar  9 02:10:59.236: INFO: Waiting for StatefulSet statefulset-8102/ss2 to complete update
Mar  9 02:10:59.236: INFO: Waiting for Pod statefulset-8102/ss2-0 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
Mar  9 02:10:59.236: INFO: Waiting for Pod statefulset-8102/ss2-1 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
Mar  9 02:11:09.237: INFO: Waiting for StatefulSet statefulset-8102/ss2 to complete update
Mar  9 02:11:09.237: INFO: Waiting for Pod statefulset-8102/ss2-0 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
STEP: Rolling back to a previous revision
Mar  9 02:11:19.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-8102 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  9 02:11:19.859: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  9 02:11:19.859: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  9 02:11:19.859: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  9 02:11:29.921: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar  9 02:11:39.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-8102 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 02:11:40.533: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  9 02:11:40.533: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  9 02:11:40.533: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  9 02:11:40.825: INFO: Waiting for StatefulSet statefulset-8102/ss2 to complete update
Mar  9 02:11:40.826: INFO: Waiting for Pod statefulset-8102/ss2-0 to have revision ss2-5f4b4c7df9 update revision ss2-95cdf5d68
Mar  9 02:11:40.826: INFO: Waiting for Pod statefulset-8102/ss2-1 to have revision ss2-5f4b4c7df9 update revision ss2-95cdf5d68
Mar  9 02:11:40.826: INFO: Waiting for Pod statefulset-8102/ss2-2 to have revision ss2-5f4b4c7df9 update revision ss2-95cdf5d68
Mar  9 02:11:50.840: INFO: Waiting for StatefulSet statefulset-8102/ss2 to complete update
Mar  9 02:11:50.840: INFO: Waiting for Pod statefulset-8102/ss2-0 to have revision ss2-5f4b4c7df9 update revision ss2-95cdf5d68
Mar  9 02:12:00.838: INFO: Waiting for StatefulSet statefulset-8102/ss2 to complete update
Mar  9 02:12:00.839: INFO: Waiting for Pod statefulset-8102/ss2-0 to have revision ss2-5f4b4c7df9 update revision ss2-95cdf5d68
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  9 02:12:10.840: INFO: Deleting all statefulset in ns statefulset-8102
Mar  9 02:12:10.849: INFO: Scaling statefulset ss2 to 0
Mar  9 02:12:40.912: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 02:12:40.956: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:12:41.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8102" for this suite.
Mar  9 02:12:51.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:12:51.351: INFO: namespace statefulset-8102 deletion completed in 10.240189776s

• [SLOW TEST:173.803 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:12:51.352: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7147
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7147.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7147.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7147.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7147.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7147.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7147.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7147.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7147.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7147.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7147.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 232.204.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.204.232_udp@PTR;check="$$(dig +tcp +noall +answer +search 232.204.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.204.232_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7147.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7147.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7147.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7147.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7147.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7147.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7147.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7147.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7147.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7147.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7147.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 232.204.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.204.232_udp@PTR;check="$$(dig +tcp +noall +answer +search 232.204.108.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.108.204.232_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  9 02:12:56.193: INFO: Unable to read wheezy_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:12:56.200: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:12:56.207: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:12:56.213: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:12:56.298: INFO: Unable to read jessie_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:12:56.304: INFO: Unable to read jessie_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:12:56.311: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:12:56.317: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:12:56.356: INFO: Lookups using dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26 failed for: [wheezy_udp@dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_udp@dns-test-service.dns-7147.svc.cluster.local jessie_tcp@dns-test-service.dns-7147.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local]

Mar  9 02:13:01.365: INFO: Unable to read wheezy_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:01.372: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:01.379: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:01.385: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:01.428: INFO: Unable to read jessie_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:01.435: INFO: Unable to read jessie_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:01.440: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:01.447: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:01.483: INFO: Lookups using dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26 failed for: [wheezy_udp@dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_udp@dns-test-service.dns-7147.svc.cluster.local jessie_tcp@dns-test-service.dns-7147.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local]

Mar  9 02:13:06.366: INFO: Unable to read wheezy_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:06.374: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:06.380: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:06.387: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:06.436: INFO: Unable to read jessie_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:06.443: INFO: Unable to read jessie_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:06.451: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:06.458: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:06.499: INFO: Lookups using dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26 failed for: [wheezy_udp@dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_udp@dns-test-service.dns-7147.svc.cluster.local jessie_tcp@dns-test-service.dns-7147.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local]

Mar  9 02:13:11.365: INFO: Unable to read wheezy_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:11.372: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:11.415: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:11.422: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:11.467: INFO: Unable to read jessie_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:11.472: INFO: Unable to read jessie_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:11.479: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:11.485: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:11.521: INFO: Lookups using dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26 failed for: [wheezy_udp@dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_udp@dns-test-service.dns-7147.svc.cluster.local jessie_tcp@dns-test-service.dns-7147.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local]

Mar  9 02:13:16.366: INFO: Unable to read wheezy_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:16.372: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:16.379: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:16.414: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:16.559: INFO: Unable to read jessie_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:16.565: INFO: Unable to read jessie_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:16.572: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:16.578: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:16.615: INFO: Lookups using dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26 failed for: [wheezy_udp@dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_udp@dns-test-service.dns-7147.svc.cluster.local jessie_tcp@dns-test-service.dns-7147.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local]

Mar  9 02:13:21.365: INFO: Unable to read wheezy_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:21.373: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:21.379: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:21.385: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:21.430: INFO: Unable to read jessie_udp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:21.436: INFO: Unable to read jessie_tcp@dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:21.443: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:21.450: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local from pod dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26: the server could not find the requested resource (get pods dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26)
Mar  9 02:13:21.495: INFO: Lookups using dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26 failed for: [wheezy_udp@dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@dns-test-service.dns-7147.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_udp@dns-test-service.dns-7147.svc.cluster.local jessie_tcp@dns-test-service.dns-7147.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7147.svc.cluster.local]

Mar  9 02:13:26.558: INFO: DNS probes using dns-7147/dns-test-0d99cd65-4eed-41cf-95d1-2ccf7a5ecf26 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:13:27.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7147" for this suite.
Mar  9 02:13:35.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:13:35.612: INFO: namespace dns-7147 deletion completed in 8.38828797s

• [SLOW TEST:44.260 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:13:35.612: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2361
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 02:13:38.820: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 02:13:40.840: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719316818, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719316818, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719316819, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719316818, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 02:13:44.039: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:13:45.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2361" for this suite.
Mar  9 02:13:53.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:13:54.190: INFO: namespace webhook-2361 deletion completed in 8.458359296s
STEP: Destroying namespace "webhook-2361-markers" for this suite.
Mar  9 02:14:02.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:14:02.452: INFO: namespace webhook-2361-markers deletion completed in 8.262054185s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.884 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:14:02.497: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8270
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-8270, will wait for the garbage collector to delete the pods
Mar  9 02:14:09.201: INFO: Deleting Job.batch foo took: 40.011877ms
Mar  9 02:14:09.702: INFO: Terminating Job.batch foo pods took: 500.472073ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:14:51.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8270" for this suite.
Mar  9 02:14:59.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:14:59.429: INFO: namespace job-8270 deletion completed in 8.197074841s

• [SLOW TEST:56.933 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:14:59.430: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5841
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5841
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Mar  9 02:14:59.902: INFO: Found 0 stateful pods, waiting for 3
Mar  9 02:15:09.934: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 02:15:09.935: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 02:15:09.935: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from 172.20.8.7/library/httpd:2.4.38-alpine to 172.20.8.7/library/httpd:2.4.39-alpine
Mar  9 02:15:10.054: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar  9 02:15:20.256: INFO: Updating stateful set ss2
Mar  9 02:15:20.282: INFO: Waiting for Pod statefulset-5841/ss2-2 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
Mar  9 02:15:30.297: INFO: Waiting for Pod statefulset-5841/ss2-2 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
STEP: Restoring Pods to the correct revision when they are deleted
Mar  9 02:15:40.928: INFO: Found 2 stateful pods, waiting for 3
Mar  9 02:15:51.016: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 02:15:51.016: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 02:15:51.016: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar  9 02:15:51.196: INFO: Updating stateful set ss2
Mar  9 02:15:51.402: INFO: Waiting for Pod statefulset-5841/ss2-1 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
Mar  9 02:16:02.495: INFO: Updating stateful set ss2
Mar  9 02:16:02.556: INFO: Waiting for StatefulSet statefulset-5841/ss2 to complete update
Mar  9 02:16:02.556: INFO: Waiting for Pod statefulset-5841/ss2-0 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
Mar  9 02:16:12.625: INFO: Waiting for StatefulSet statefulset-5841/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  9 02:16:22.574: INFO: Deleting all statefulset in ns statefulset-5841
Mar  9 02:16:22.579: INFO: Scaling statefulset ss2 to 0
Mar  9 02:16:42.694: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 02:16:42.700: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:16:42.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5841" for this suite.
Mar  9 02:16:53.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:16:53.378: INFO: namespace statefulset-5841 deletion completed in 10.384808468s

• [SLOW TEST:113.949 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:16:53.380: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7453
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  9 02:16:57.255: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:16:57.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7453" for this suite.
Mar  9 02:17:05.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:17:05.996: INFO: namespace container-runtime-7453 deletion completed in 8.582602316s

• [SLOW TEST:12.616 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:17:05.996: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2285
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 02:17:06.442: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a61510e-7be9-4d51-9156-cb35ddcb688f" in namespace "projected-2285" to be "success or failure"
Mar  9 02:17:06.447: INFO: Pod "downwardapi-volume-8a61510e-7be9-4d51-9156-cb35ddcb688f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.094364ms
Mar  9 02:17:08.464: INFO: Pod "downwardapi-volume-8a61510e-7be9-4d51-9156-cb35ddcb688f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021704118s
Mar  9 02:17:10.471: INFO: Pod "downwardapi-volume-8a61510e-7be9-4d51-9156-cb35ddcb688f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02910531s
STEP: Saw pod success
Mar  9 02:17:10.471: INFO: Pod "downwardapi-volume-8a61510e-7be9-4d51-9156-cb35ddcb688f" satisfied condition "success or failure"
Mar  9 02:17:10.477: INFO: Trying to get logs from node worker1 pod downwardapi-volume-8a61510e-7be9-4d51-9156-cb35ddcb688f container client-container: <nil>
STEP: delete the pod
Mar  9 02:17:10.585: INFO: Waiting for pod downwardapi-volume-8a61510e-7be9-4d51-9156-cb35ddcb688f to disappear
Mar  9 02:17:10.625: INFO: Pod downwardapi-volume-8a61510e-7be9-4d51-9156-cb35ddcb688f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:17:10.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2285" for this suite.
Mar  9 02:17:18.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:17:19.040: INFO: namespace projected-2285 deletion completed in 8.349556554s

• [SLOW TEST:13.044 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:17:19.042: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:17:36.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2" for this suite.
Mar  9 02:17:44.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:17:44.915: INFO: namespace resourcequota-2 deletion completed in 8.283596221s

• [SLOW TEST:25.873 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:17:44.916: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-560
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  9 02:17:45.405: INFO: Waiting up to 5m0s for pod "downward-api-b1c79fe0-aacd-4206-8db3-2ad22f01e72e" in namespace "downward-api-560" to be "success or failure"
Mar  9 02:17:45.573: INFO: Pod "downward-api-b1c79fe0-aacd-4206-8db3-2ad22f01e72e": Phase="Pending", Reason="", readiness=false. Elapsed: 167.964574ms
Mar  9 02:17:47.581: INFO: Pod "downward-api-b1c79fe0-aacd-4206-8db3-2ad22f01e72e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.176820119s
Mar  9 02:17:49.589: INFO: Pod "downward-api-b1c79fe0-aacd-4206-8db3-2ad22f01e72e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.184263164s
STEP: Saw pod success
Mar  9 02:17:49.589: INFO: Pod "downward-api-b1c79fe0-aacd-4206-8db3-2ad22f01e72e" satisfied condition "success or failure"
Mar  9 02:17:49.594: INFO: Trying to get logs from node worker1 pod downward-api-b1c79fe0-aacd-4206-8db3-2ad22f01e72e container dapi-container: <nil>
STEP: delete the pod
Mar  9 02:17:49.922: INFO: Waiting for pod downward-api-b1c79fe0-aacd-4206-8db3-2ad22f01e72e to disappear
Mar  9 02:17:49.930: INFO: Pod downward-api-b1c79fe0-aacd-4206-8db3-2ad22f01e72e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:17:49.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-560" for this suite.
Mar  9 02:17:56.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:17:57.181: INFO: namespace downward-api-560 deletion completed in 6.757194599s

• [SLOW TEST:12.266 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:17:57.183: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1959
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:18:24.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1959" for this suite.
Mar  9 02:18:32.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:18:33.048: INFO: namespace container-runtime-1959 deletion completed in 8.3434024s

• [SLOW TEST:35.866 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:18:33.050: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1753
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Mar  9 02:18:33.708: INFO: Waiting up to 5m0s for pod "var-expansion-34d62213-ee21-4fe0-9bd2-b9718771142f" in namespace "var-expansion-1753" to be "success or failure"
Mar  9 02:18:33.713: INFO: Pod "var-expansion-34d62213-ee21-4fe0-9bd2-b9718771142f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.930963ms
Mar  9 02:18:35.721: INFO: Pod "var-expansion-34d62213-ee21-4fe0-9bd2-b9718771142f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013110398s
Mar  9 02:18:37.729: INFO: Pod "var-expansion-34d62213-ee21-4fe0-9bd2-b9718771142f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020608753s
STEP: Saw pod success
Mar  9 02:18:37.729: INFO: Pod "var-expansion-34d62213-ee21-4fe0-9bd2-b9718771142f" satisfied condition "success or failure"
Mar  9 02:18:37.735: INFO: Trying to get logs from node worker1 pod var-expansion-34d62213-ee21-4fe0-9bd2-b9718771142f container dapi-container: <nil>
STEP: delete the pod
Mar  9 02:18:37.821: INFO: Waiting for pod var-expansion-34d62213-ee21-4fe0-9bd2-b9718771142f to disappear
Mar  9 02:18:37.833: INFO: Pod var-expansion-34d62213-ee21-4fe0-9bd2-b9718771142f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:18:37.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1753" for this suite.
Mar  9 02:18:46.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:18:46.830: INFO: namespace var-expansion-1753 deletion completed in 8.987639442s

• [SLOW TEST:13.780 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:18:46.830: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7468
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:18:51.612: INFO: Waiting up to 5m0s for pod "client-envvars-b462a720-6558-4746-bbad-52ab1ee722ae" in namespace "pods-7468" to be "success or failure"
Mar  9 02:18:51.661: INFO: Pod "client-envvars-b462a720-6558-4746-bbad-52ab1ee722ae": Phase="Pending", Reason="", readiness=false. Elapsed: 49.794392ms
Mar  9 02:18:53.677: INFO: Pod "client-envvars-b462a720-6558-4746-bbad-52ab1ee722ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064866255s
Mar  9 02:18:55.915: INFO: Pod "client-envvars-b462a720-6558-4746-bbad-52ab1ee722ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.303453364s
STEP: Saw pod success
Mar  9 02:18:55.915: INFO: Pod "client-envvars-b462a720-6558-4746-bbad-52ab1ee722ae" satisfied condition "success or failure"
Mar  9 02:18:55.921: INFO: Trying to get logs from node worker1 pod client-envvars-b462a720-6558-4746-bbad-52ab1ee722ae container env3cont: <nil>
STEP: delete the pod
Mar  9 02:18:56.313: INFO: Waiting for pod client-envvars-b462a720-6558-4746-bbad-52ab1ee722ae to disappear
Mar  9 02:18:56.333: INFO: Pod client-envvars-b462a720-6558-4746-bbad-52ab1ee722ae no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:18:56.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7468" for this suite.
Mar  9 02:19:12.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:19:12.570: INFO: namespace pods-7468 deletion completed in 16.204341849s

• [SLOW TEST:25.740 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:19:12.571: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7975
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-097d5482-2767-4cc5-a621-743037b1e2e9
STEP: Creating a pod to test consume secrets
Mar  9 02:19:13.140: INFO: Waiting up to 5m0s for pod "pod-secrets-c70afe17-87c8-4083-8ccf-9e52e1470a10" in namespace "secrets-7975" to be "success or failure"
Mar  9 02:19:13.146: INFO: Pod "pod-secrets-c70afe17-87c8-4083-8ccf-9e52e1470a10": Phase="Pending", Reason="", readiness=false. Elapsed: 5.346985ms
Mar  9 02:19:15.154: INFO: Pod "pod-secrets-c70afe17-87c8-4083-8ccf-9e52e1470a10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013726666s
Mar  9 02:19:17.162: INFO: Pod "pod-secrets-c70afe17-87c8-4083-8ccf-9e52e1470a10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021055434s
STEP: Saw pod success
Mar  9 02:19:17.162: INFO: Pod "pod-secrets-c70afe17-87c8-4083-8ccf-9e52e1470a10" satisfied condition "success or failure"
Mar  9 02:19:17.168: INFO: Trying to get logs from node worker1 pod pod-secrets-c70afe17-87c8-4083-8ccf-9e52e1470a10 container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 02:19:17.242: INFO: Waiting for pod pod-secrets-c70afe17-87c8-4083-8ccf-9e52e1470a10 to disappear
Mar  9 02:19:17.334: INFO: Pod pod-secrets-c70afe17-87c8-4083-8ccf-9e52e1470a10 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:19:17.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7975" for this suite.
Mar  9 02:19:25.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:19:26.612: INFO: namespace secrets-7975 deletion completed in 9.270481936s

• [SLOW TEST:14.041 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:19:26.613: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2130
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 02:19:28.421: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 02:19:30.458: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317169, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317169, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317169, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317168, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 02:19:33.537: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Mar  9 02:19:33.651: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:19:33.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2130" for this suite.
Mar  9 02:19:43.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:19:44.827: INFO: namespace webhook-2130 deletion completed in 11.103190469s
STEP: Destroying namespace "webhook-2130-markers" for this suite.
Mar  9 02:19:50.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:19:51.197: INFO: namespace webhook-2130-markers deletion completed in 6.370090791s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.632 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:19:51.246: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5891
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  9 02:19:51.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 run e2e-test-httpd-deployment --image=172.20.8.7/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-5891'
Mar  9 02:19:58.032: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  9 02:19:58.033: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Mar  9 02:20:02.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete deployment e2e-test-httpd-deployment --namespace=kubectl-5891'
Mar  9 02:20:02.401: INFO: stderr: ""
Mar  9 02:20:02.401: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:20:02.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5891" for this suite.
Mar  9 02:20:14.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:20:14.606: INFO: namespace kubectl-5891 deletion completed in 12.194822243s

• [SLOW TEST:23.360 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:20:14.607: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4458
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  9 02:20:15.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=172.20.8.7/library/httpd:2.4.38-alpine --namespace=kubectl-4458'
Mar  9 02:20:15.431: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  9 02:20:15.431: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Mar  9 02:20:15.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete jobs e2e-test-httpd-job --namespace=kubectl-4458'
Mar  9 02:20:15.757: INFO: stderr: ""
Mar  9 02:20:15.757: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:20:15.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4458" for this suite.
Mar  9 02:20:24.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:20:24.238: INFO: namespace kubectl-4458 deletion completed in 8.384509001s

• [SLOW TEST:9.631 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:20:24.239: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6548
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 02:20:26.384: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 02:20:28.403: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317226, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317226, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317226, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317226, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 02:20:31.538: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
Mar  9 02:20:31.726: INFO: Waiting for webhook configuration to be ready...
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:20:32.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6548" for this suite.
Mar  9 02:20:40.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:20:40.910: INFO: namespace webhook-6548 deletion completed in 8.244705965s
STEP: Destroying namespace "webhook-6548-markers" for this suite.
Mar  9 02:20:47.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:20:47.182: INFO: namespace webhook-6548-markers deletion completed in 6.27112086s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.979 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:20:47.219: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9590
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  9 02:20:53.390: INFO: Successfully updated pod "pod-update-2c825535-5c54-49c9-9760-c0a85a680e7b"
STEP: verifying the updated pod is in kubernetes
Mar  9 02:20:53.406: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:20:53.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9590" for this suite.
Mar  9 02:21:05.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:21:05.662: INFO: namespace pods-9590 deletion completed in 12.248803252s

• [SLOW TEST:18.444 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:21:05.663: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1115
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Mar  9 02:21:05.980: INFO: Waiting up to 5m0s for pod "client-containers-8a28e097-29f9-4967-aa01-12f32edac699" in namespace "containers-1115" to be "success or failure"
Mar  9 02:21:06.014: INFO: Pod "client-containers-8a28e097-29f9-4967-aa01-12f32edac699": Phase="Pending", Reason="", readiness=false. Elapsed: 33.228699ms
Mar  9 02:21:08.394: INFO: Pod "client-containers-8a28e097-29f9-4967-aa01-12f32edac699": Phase="Pending", Reason="", readiness=false. Elapsed: 2.41378608s
Mar  9 02:21:10.402: INFO: Pod "client-containers-8a28e097-29f9-4967-aa01-12f32edac699": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.421353186s
STEP: Saw pod success
Mar  9 02:21:10.402: INFO: Pod "client-containers-8a28e097-29f9-4967-aa01-12f32edac699" satisfied condition "success or failure"
Mar  9 02:21:10.407: INFO: Trying to get logs from node worker1 pod client-containers-8a28e097-29f9-4967-aa01-12f32edac699 container test-container: <nil>
STEP: delete the pod
Mar  9 02:21:10.551: INFO: Waiting for pod client-containers-8a28e097-29f9-4967-aa01-12f32edac699 to disappear
Mar  9 02:21:10.557: INFO: Pod client-containers-8a28e097-29f9-4967-aa01-12f32edac699 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:21:10.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1115" for this suite.
Mar  9 02:21:16.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:21:17.479: INFO: namespace containers-1115 deletion completed in 6.914608169s

• [SLOW TEST:11.816 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:21:17.481: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Mar  9 02:21:17.826: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:21:31.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5923" for this suite.
Mar  9 02:21:37.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:21:37.459: INFO: namespace pods-5923 deletion completed in 6.313919897s

• [SLOW TEST:19.979 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:21:37.460: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5083
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-dee758f9-973e-4808-94c4-2a111ebc1ee1
STEP: Creating configMap with name cm-test-opt-upd-32944af1-9fc8-4ee5-9b46-23c1329ea4ee
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-dee758f9-973e-4808-94c4-2a111ebc1ee1
STEP: Updating configmap cm-test-opt-upd-32944af1-9fc8-4ee5-9b46-23c1329ea4ee
STEP: Creating configMap with name cm-test-opt-create-9f4145b2-8585-462a-a664-e525ac7cd2e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:23:05.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5083" for this suite.
Mar  9 02:23:23.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:23:23.982: INFO: namespace configmap-5083 deletion completed in 18.225804825s

• [SLOW TEST:106.523 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:23:23.984: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2139
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:23:38.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2139" for this suite.
Mar  9 02:23:46.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:23:46.633: INFO: namespace resourcequota-2139 deletion completed in 8.225299828s

• [SLOW TEST:22.649 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:23:46.634: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9704
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:24:01.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9704" for this suite.
Mar  9 02:24:13.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:24:13.565: INFO: namespace job-9704 deletion completed in 12.366983412s

• [SLOW TEST:26.931 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:24:13.565: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3603
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:24:18.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3603" for this suite.
Mar  9 02:24:26.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:24:26.618: INFO: namespace kubelet-test-3603 deletion completed in 8.297325409s

• [SLOW TEST:13.053 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:24:26.619: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4415
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 02:24:27.018: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4dbe2659-d026-4618-90d6-d79fed8539ac" in namespace "downward-api-4415" to be "success or failure"
Mar  9 02:24:27.023: INFO: Pod "downwardapi-volume-4dbe2659-d026-4618-90d6-d79fed8539ac": Phase="Pending", Reason="", readiness=false. Elapsed: 5.783943ms
Mar  9 02:24:29.031: INFO: Pod "downwardapi-volume-4dbe2659-d026-4618-90d6-d79fed8539ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013466596s
Mar  9 02:24:31.038: INFO: Pod "downwardapi-volume-4dbe2659-d026-4618-90d6-d79fed8539ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01984674s
STEP: Saw pod success
Mar  9 02:24:31.038: INFO: Pod "downwardapi-volume-4dbe2659-d026-4618-90d6-d79fed8539ac" satisfied condition "success or failure"
Mar  9 02:24:31.077: INFO: Trying to get logs from node worker1 pod downwardapi-volume-4dbe2659-d026-4618-90d6-d79fed8539ac container client-container: <nil>
STEP: delete the pod
Mar  9 02:24:31.363: INFO: Waiting for pod downwardapi-volume-4dbe2659-d026-4618-90d6-d79fed8539ac to disappear
Mar  9 02:24:31.437: INFO: Pod downwardapi-volume-4dbe2659-d026-4618-90d6-d79fed8539ac no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:24:31.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4415" for this suite.
Mar  9 02:24:39.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:24:39.647: INFO: namespace downward-api-4415 deletion completed in 8.199802763s

• [SLOW TEST:13.028 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:24:39.648: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1249
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-ed7212a5-db47-43ea-a55e-9a21af1ec85d
STEP: Creating a pod to test consume secrets
Mar  9 02:24:40.088: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b8da51d2-842a-402c-8528-a9bf04b7d204" in namespace "projected-1249" to be "success or failure"
Mar  9 02:24:40.097: INFO: Pod "pod-projected-secrets-b8da51d2-842a-402c-8528-a9bf04b7d204": Phase="Pending", Reason="", readiness=false. Elapsed: 8.889288ms
Mar  9 02:24:42.246: INFO: Pod "pod-projected-secrets-b8da51d2-842a-402c-8528-a9bf04b7d204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.158281921s
Mar  9 02:24:44.254: INFO: Pod "pod-projected-secrets-b8da51d2-842a-402c-8528-a9bf04b7d204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.165976327s
STEP: Saw pod success
Mar  9 02:24:44.254: INFO: Pod "pod-projected-secrets-b8da51d2-842a-402c-8528-a9bf04b7d204" satisfied condition "success or failure"
Mar  9 02:24:44.259: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-b8da51d2-842a-402c-8528-a9bf04b7d204 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  9 02:24:44.971: INFO: Waiting for pod pod-projected-secrets-b8da51d2-842a-402c-8528-a9bf04b7d204 to disappear
Mar  9 02:24:44.976: INFO: Pod pod-projected-secrets-b8da51d2-842a-402c-8528-a9bf04b7d204 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:24:44.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1249" for this suite.
Mar  9 02:24:53.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:24:53.319: INFO: namespace projected-1249 deletion completed in 8.317196843s

• [SLOW TEST:13.671 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:24:53.320: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4475
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:24:54.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4475" for this suite.
Mar  9 02:25:02.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:25:03.058: INFO: namespace resourcequota-4475 deletion completed in 8.184339407s

• [SLOW TEST:9.739 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:25:03.059: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3626
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:25:04.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 version'
Mar  9 02:25:04.362: INFO: stderr: ""
Mar  9 02:25:04.362: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.4\", GitCommit:\"224be7bdce5a9dd0c2fd0d46b83865648e2fe0ba\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:47:40Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.4\", GitCommit:\"224be7bdce5a9dd0c2fd0d46b83865648e2fe0ba\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:37:43Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:25:04.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3626" for this suite.
Mar  9 02:25:12.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:25:12.564: INFO: namespace kubectl-3626 deletion completed in 8.18681148s

• [SLOW TEST:9.505 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:25:12.565: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9953
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:25:13.184: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  9 02:25:17.199: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar  9 02:25:19.208: INFO: Creating deployment "test-rollover-deployment"
Mar  9 02:25:19.242: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar  9 02:25:21.256: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar  9 02:25:21.268: INFO: Ensure that both replica sets have 1 created replica
Mar  9 02:25:21.279: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar  9 02:25:21.314: INFO: Updating deployment test-rollover-deployment
Mar  9 02:25:21.314: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar  9 02:25:23.326: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar  9 02:25:23.337: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar  9 02:25:23.349: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 02:25:23.349: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317521, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 02:25:25.808: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 02:25:25.808: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317521, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 02:25:27.363: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 02:25:27.363: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 02:25:29.363: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 02:25:29.363: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 02:25:31.365: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 02:25:31.365: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 02:25:33.363: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 02:25:33.363: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 02:25:35.460: INFO: all replica sets need to contain the pod-template-hash label
Mar  9 02:25:35.460: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317526, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 02:25:37.649: INFO: 
Mar  9 02:25:37.649: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317536, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317519, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 02:25:39.363: INFO: 
Mar  9 02:25:39.363: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  9 02:25:39.379: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9953 /apis/apps/v1/namespaces/deployment-9953/deployments/test-rollover-deployment 60c37127-7a3f-45e0-a419-e1c0d35bf442 104229 2 2020-03-09 02:25:19 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003165f78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-03-09 02:25:19 +0000 UTC,LastTransitionTime:2020-03-09 02:25:19 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6589d75b4d" has successfully progressed.,LastUpdateTime:2020-03-09 02:25:37 +0000 UTC,LastTransitionTime:2020-03-09 02:25:19 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Mar  9 02:25:39.386: INFO: New ReplicaSet "test-rollover-deployment-6589d75b4d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6589d75b4d  deployment-9953 /apis/apps/v1/namespaces/deployment-9953/replicasets/test-rollover-deployment-6589d75b4d 5655ff20-1a11-4cbf-aed2-7b83a5d44392 104217 2 2020-03-09 02:25:21 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6589d75b4d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 60c37127-7a3f-45e0-a419-e1c0d35bf442 0xc00072f127 0xc00072f128}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6589d75b4d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6589d75b4d] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00072f198 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar  9 02:25:39.386: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar  9 02:25:39.386: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9953 /apis/apps/v1/namespaces/deployment-9953/replicasets/test-rollover-controller 272805db-5b7f-4eff-9b47-894f51ce3613 104228 2 2020-03-09 02:25:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 60c37127-7a3f-45e0-a419-e1c0d35bf442 0xc00072ee47 0xc00072ee48}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd 172.20.8.7/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00072ef68 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  9 02:25:39.386: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-9953 /apis/apps/v1/namespaces/deployment-9953/replicasets/test-rollover-deployment-f6c94f66c 9f9b8fc4-1015-499c-bcfd-caa9172c4051 104170 2 2020-03-09 02:25:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 60c37127-7a3f-45e0-a419-e1c0d35bf442 0xc00072f5d0 0xc00072f5d1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00072f6b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  9 02:25:39.393: INFO: Pod "test-rollover-deployment-6589d75b4d-n985g" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6589d75b4d-n985g test-rollover-deployment-6589d75b4d- deployment-9953 /api/v1/namespaces/deployment-9953/pods/test-rollover-deployment-6589d75b4d-n985g 7cbdebc9-9a55-4d2d-8b80-747d229b341c 104194 0 2020-03-09 02:25:21 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6589d75b4d] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6589d75b4d 5655ff20-1a11-4cbf-aed2-7b83a5d44392 0xc003429157 0xc003429158}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-h5769,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-h5769,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:172.20.8.7/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-h5769,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:25:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:25:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:25:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:25:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:10.244.3.90,StartTime:2020-03-09 02:25:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 02:25:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/redis:5.0.5-alpine,ImageID:docker-pullable://172.20.8.7/library/redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c,ContainerID:docker://f71b419dc6450299aad12ec504dbaf2ef75b8ff619ec6c576643e5797af1ee6e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.90,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:25:39.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9953" for this suite.
Mar  9 02:25:49.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:25:49.906: INFO: namespace deployment-9953 deletion completed in 10.503654056s

• [SLOW TEST:37.341 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:25:49.906: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9029
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Mar  9 02:25:54.544: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-910735845 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar  9 02:25:59.828: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:25:59.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9029" for this suite.
Mar  9 02:26:07.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:26:08.079: INFO: namespace pods-9029 deletion completed in 8.20340641s

• [SLOW TEST:18.173 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:26:08.081: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-394
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 02:26:08.662: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6259e420-9c07-4ef6-8729-cada3a7444a0" in namespace "downward-api-394" to be "success or failure"
Mar  9 02:26:08.678: INFO: Pod "downwardapi-volume-6259e420-9c07-4ef6-8729-cada3a7444a0": Phase="Pending", Reason="", readiness=false. Elapsed: 15.748599ms
Mar  9 02:26:10.688: INFO: Pod "downwardapi-volume-6259e420-9c07-4ef6-8729-cada3a7444a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025858358s
Mar  9 02:26:12.695: INFO: Pod "downwardapi-volume-6259e420-9c07-4ef6-8729-cada3a7444a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033125585s
STEP: Saw pod success
Mar  9 02:26:12.695: INFO: Pod "downwardapi-volume-6259e420-9c07-4ef6-8729-cada3a7444a0" satisfied condition "success or failure"
Mar  9 02:26:12.700: INFO: Trying to get logs from node worker1 pod downwardapi-volume-6259e420-9c07-4ef6-8729-cada3a7444a0 container client-container: <nil>
STEP: delete the pod
Mar  9 02:26:13.124: INFO: Waiting for pod downwardapi-volume-6259e420-9c07-4ef6-8729-cada3a7444a0 to disappear
Mar  9 02:26:13.129: INFO: Pod downwardapi-volume-6259e420-9c07-4ef6-8729-cada3a7444a0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:26:13.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-394" for this suite.
Mar  9 02:26:21.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:26:21.717: INFO: namespace downward-api-394 deletion completed in 8.579951926s

• [SLOW TEST:13.636 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:26:21.718: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3321
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-29e5254d-2c70-4bf7-b1d1-9c4e280c330c
STEP: Creating a pod to test consume configMaps
Mar  9 02:26:22.319: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-245cf446-60d9-431c-b428-eb39dddbe4ca" in namespace "projected-3321" to be "success or failure"
Mar  9 02:26:22.326: INFO: Pod "pod-projected-configmaps-245cf446-60d9-431c-b428-eb39dddbe4ca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.752601ms
Mar  9 02:26:24.333: INFO: Pod "pod-projected-configmaps-245cf446-60d9-431c-b428-eb39dddbe4ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01439371s
Mar  9 02:26:26.444: INFO: Pod "pod-projected-configmaps-245cf446-60d9-431c-b428-eb39dddbe4ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.124889124s
STEP: Saw pod success
Mar  9 02:26:26.444: INFO: Pod "pod-projected-configmaps-245cf446-60d9-431c-b428-eb39dddbe4ca" satisfied condition "success or failure"
Mar  9 02:26:26.450: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-245cf446-60d9-431c-b428-eb39dddbe4ca container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 02:26:27.566: INFO: Waiting for pod pod-projected-configmaps-245cf446-60d9-431c-b428-eb39dddbe4ca to disappear
Mar  9 02:26:27.571: INFO: Pod pod-projected-configmaps-245cf446-60d9-431c-b428-eb39dddbe4ca no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:26:27.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3321" for this suite.
Mar  9 02:26:35.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:26:36.434: INFO: namespace projected-3321 deletion completed in 8.829939448s

• [SLOW TEST:14.716 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:26:36.435: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8794
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:26:36.822: INFO: Creating deployment "test-recreate-deployment"
Mar  9 02:26:36.846: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar  9 02:26:37.010: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Mar  9 02:26:39.056: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar  9 02:26:39.061: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317597, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317597, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317597, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719317596, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-8ffcb657f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 02:26:41.200: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar  9 02:26:41.289: INFO: Updating deployment test-recreate-deployment
Mar  9 02:26:41.289: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  9 02:26:42.890: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-8794 /apis/apps/v1/namespaces/deployment-8794/deployments/test-recreate-deployment 3da8d2e7-84de-4e6a-a438-09ffdfa57363 104515 2 2020-03-09 02:26:36 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd 172.20.8.7/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0052c3de8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-03-09 02:26:41 +0000 UTC,LastTransitionTime:2020-03-09 02:26:41 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-75f6b9b45d" is progressing.,LastUpdateTime:2020-03-09 02:26:42 +0000 UTC,LastTransitionTime:2020-03-09 02:26:36 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Mar  9 02:26:42.898: INFO: New ReplicaSet "test-recreate-deployment-75f6b9b45d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-75f6b9b45d  deployment-8794 /apis/apps/v1/namespaces/deployment-8794/replicasets/test-recreate-deployment-75f6b9b45d aba9186a-e0f0-46f6-8f8e-dc9cdecae2c5 104514 1 2020-03-09 02:26:41 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:75f6b9b45d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 3da8d2e7-84de-4e6a-a438-09ffdfa57363 0xc00535e1a7 0xc00535e1a8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 75f6b9b45d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:75f6b9b45d] map[] [] []  []} {[] [] [{httpd 172.20.8.7/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00535e208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  9 02:26:42.898: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar  9 02:26:42.898: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-8ffcb657f  deployment-8794 /apis/apps/v1/namespaces/deployment-8794/replicasets/test-recreate-deployment-8ffcb657f 5525d1b9-18c7-489b-8bdc-528c0d4c8462 104501 2 2020-03-09 02:26:36 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:8ffcb657f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 3da8d2e7-84de-4e6a-a438-09ffdfa57363 0xc00535e270 0xc00535e271}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 8ffcb657f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:8ffcb657f] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00535e2d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  9 02:26:42.905: INFO: Pod "test-recreate-deployment-75f6b9b45d-gqvzs" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-75f6b9b45d-gqvzs test-recreate-deployment-75f6b9b45d- deployment-8794 /api/v1/namespaces/deployment-8794/pods/test-recreate-deployment-75f6b9b45d-gqvzs 23517202-e16b-4465-8f30-e53b34548730 104512 0 2020-03-09 02:26:41 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:75f6b9b45d] map[] [{apps/v1 ReplicaSet test-recreate-deployment-75f6b9b45d aba9186a-e0f0-46f6-8f8e-dc9cdecae2c5 0xc005498977 0xc005498978}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qtd86,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qtd86,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qtd86,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:26:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:26:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:26:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:26:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:,StartTime:2020-03-09 02:26:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:26:42.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8794" for this suite.
Mar  9 02:26:50.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:26:51.153: INFO: namespace deployment-8794 deletion completed in 8.238659495s

• [SLOW TEST:14.718 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:26:51.154: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-196
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  9 02:26:51.693: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:51.693: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:51.693: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:51.702: INFO: Number of nodes with available pods: 0
Mar  9 02:26:51.702: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:26:52.713: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:52.713: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:52.713: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:52.720: INFO: Number of nodes with available pods: 0
Mar  9 02:26:52.720: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:26:53.712: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:53.713: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:53.713: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:53.719: INFO: Number of nodes with available pods: 0
Mar  9 02:26:53.719: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:26:54.765: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:54.765: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:54.765: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:54.771: INFO: Number of nodes with available pods: 1
Mar  9 02:26:54.771: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:26:55.762: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:55.762: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:55.762: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:55.768: INFO: Number of nodes with available pods: 1
Mar  9 02:26:55.768: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:26:56.711: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:56.711: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:56.711: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:56.721: INFO: Number of nodes with available pods: 1
Mar  9 02:26:56.721: INFO: Node worker2 is running more than one daemon pod
Mar  9 02:26:57.714: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:57.714: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:57.714: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:57.721: INFO: Number of nodes with available pods: 2
Mar  9 02:26:57.721: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar  9 02:26:57.768: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:57.768: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:57.768: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  9 02:26:58.322: INFO: Number of nodes with available pods: 2
Mar  9 02:26:58.322: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-196, will wait for the garbage collector to delete the pods
Mar  9 02:26:59.701: INFO: Deleting DaemonSet.extensions daemon-set took: 258.459207ms
Mar  9 02:27:00.101: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.502975ms
Mar  9 02:27:03.907: INFO: Number of nodes with available pods: 0
Mar  9 02:27:03.908: INFO: Number of running nodes: 0, number of available pods: 0
Mar  9 02:27:03.913: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-196/daemonsets","resourceVersion":"104639"},"items":null}

Mar  9 02:27:03.917: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-196/pods","resourceVersion":"104639"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:27:03.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-196" for this suite.
Mar  9 02:27:12.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:27:12.234: INFO: namespace daemonsets-196 deletion completed in 8.275779506s

• [SLOW TEST:21.080 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:27:12.235: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5829
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-6fb7d7d5-a19b-4607-a818-c2d90d92b4ca
STEP: Creating a pod to test consume secrets
Mar  9 02:27:12.800: INFO: Waiting up to 5m0s for pod "pod-secrets-53bc9072-b3be-4ac4-8e09-3e50800edb24" in namespace "secrets-5829" to be "success or failure"
Mar  9 02:27:12.843: INFO: Pod "pod-secrets-53bc9072-b3be-4ac4-8e09-3e50800edb24": Phase="Pending", Reason="", readiness=false. Elapsed: 43.176605ms
Mar  9 02:27:14.874: INFO: Pod "pod-secrets-53bc9072-b3be-4ac4-8e09-3e50800edb24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074100485s
Mar  9 02:27:16.881: INFO: Pod "pod-secrets-53bc9072-b3be-4ac4-8e09-3e50800edb24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.081825581s
STEP: Saw pod success
Mar  9 02:27:16.882: INFO: Pod "pod-secrets-53bc9072-b3be-4ac4-8e09-3e50800edb24" satisfied condition "success or failure"
Mar  9 02:27:17.117: INFO: Trying to get logs from node worker1 pod pod-secrets-53bc9072-b3be-4ac4-8e09-3e50800edb24 container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 02:27:17.302: INFO: Waiting for pod pod-secrets-53bc9072-b3be-4ac4-8e09-3e50800edb24 to disappear
Mar  9 02:27:17.366: INFO: Pod pod-secrets-53bc9072-b3be-4ac4-8e09-3e50800edb24 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:27:17.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5829" for this suite.
Mar  9 02:27:25.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:27:25.840: INFO: namespace secrets-5829 deletion completed in 8.464629588s

• [SLOW TEST:13.606 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:27:25.841: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-228
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Mar  9 02:27:30.792: INFO: Pod pod-hostip-5071b562-ceed-4965-ba21-501496f03679 has hostIP: 172.20.8.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:27:30.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-228" for this suite.
Mar  9 02:28:00.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:28:01.301: INFO: namespace pods-228 deletion completed in 30.501449012s

• [SLOW TEST:35.461 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:28:01.302: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4667
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Mar  9 02:28:42.839: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:28:42.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0309 02:28:42.838793      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-4667" for this suite.
Mar  9 02:28:53.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:28:53.425: INFO: namespace gc-4667 deletion completed in 10.576579221s

• [SLOW TEST:52.123 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:28:53.426: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4110
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Mar  9 02:28:56.958: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0309 02:28:56.958799      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  9 02:28:56.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4110" for this suite.
Mar  9 02:29:05.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:29:05.739: INFO: namespace gc-4110 deletion completed in 8.773035431s

• [SLOW TEST:12.313 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:29:05.741: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 02:29:06.426: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bc76a42f-fa30-4a83-89ae-080142da358b" in namespace "projected-3583" to be "success or failure"
Mar  9 02:29:06.432: INFO: Pod "downwardapi-volume-bc76a42f-fa30-4a83-89ae-080142da358b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.726216ms
Mar  9 02:29:08.439: INFO: Pod "downwardapi-volume-bc76a42f-fa30-4a83-89ae-080142da358b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013425732s
Mar  9 02:29:10.700: INFO: Pod "downwardapi-volume-bc76a42f-fa30-4a83-89ae-080142da358b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.274441054s
STEP: Saw pod success
Mar  9 02:29:10.700: INFO: Pod "downwardapi-volume-bc76a42f-fa30-4a83-89ae-080142da358b" satisfied condition "success or failure"
Mar  9 02:29:10.707: INFO: Trying to get logs from node worker1 pod downwardapi-volume-bc76a42f-fa30-4a83-89ae-080142da358b container client-container: <nil>
STEP: delete the pod
Mar  9 02:29:10.881: INFO: Waiting for pod downwardapi-volume-bc76a42f-fa30-4a83-89ae-080142da358b to disappear
Mar  9 02:29:10.886: INFO: Pod downwardapi-volume-bc76a42f-fa30-4a83-89ae-080142da358b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:29:10.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3583" for this suite.
Mar  9 02:29:18.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:29:19.119: INFO: namespace projected-3583 deletion completed in 8.224500272s

• [SLOW TEST:13.378 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:29:19.120: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-445
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:29:30.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-445" for this suite.
Mar  9 02:29:39.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:29:39.256: INFO: namespace resourcequota-445 deletion completed in 8.309146139s

• [SLOW TEST:20.136 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:29:39.257: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5366
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-6eab9315-5ac8-42a8-beab-785d2ffdf0f0
STEP: Creating a pod to test consume configMaps
Mar  9 02:29:40.092: INFO: Waiting up to 5m0s for pod "pod-configmaps-30a613b9-ec18-4181-9de2-791613aeb4d0" in namespace "configmap-5366" to be "success or failure"
Mar  9 02:29:40.230: INFO: Pod "pod-configmaps-30a613b9-ec18-4181-9de2-791613aeb4d0": Phase="Pending", Reason="", readiness=false. Elapsed: 137.937628ms
Mar  9 02:29:42.238: INFO: Pod "pod-configmaps-30a613b9-ec18-4181-9de2-791613aeb4d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.145223328s
Mar  9 02:29:44.245: INFO: Pod "pod-configmaps-30a613b9-ec18-4181-9de2-791613aeb4d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.151971987s
STEP: Saw pod success
Mar  9 02:29:44.245: INFO: Pod "pod-configmaps-30a613b9-ec18-4181-9de2-791613aeb4d0" satisfied condition "success or failure"
Mar  9 02:29:44.251: INFO: Trying to get logs from node worker1 pod pod-configmaps-30a613b9-ec18-4181-9de2-791613aeb4d0 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 02:29:44.334: INFO: Waiting for pod pod-configmaps-30a613b9-ec18-4181-9de2-791613aeb4d0 to disappear
Mar  9 02:29:44.356: INFO: Pod pod-configmaps-30a613b9-ec18-4181-9de2-791613aeb4d0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:29:44.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5366" for this suite.
Mar  9 02:29:50.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:29:52.843: INFO: namespace configmap-5366 deletion completed in 8.479887902s

• [SLOW TEST:13.586 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:29:52.844: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2763
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:29:54.078: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d8eabed6-38d9-43cc-8c3d-794769328f37", Controller:(*bool)(0xc00342805a), BlockOwnerDeletion:(*bool)(0xc00342805b)}}
Mar  9 02:29:54.114: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b53e3c6b-e393-4276-bcb6-ec1220e00e67", Controller:(*bool)(0xc0052c3e7a), BlockOwnerDeletion:(*bool)(0xc0052c3e7b)}}
Mar  9 02:29:54.279: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4a116310-7327-4ce9-bf46-52c3b8637c90", Controller:(*bool)(0xc004f320d2), BlockOwnerDeletion:(*bool)(0xc004f320d3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:29:59.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2763" for this suite.
Mar  9 02:30:07.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:30:07.985: INFO: namespace gc-2763 deletion completed in 8.329634599s

• [SLOW TEST:15.141 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:30:07.985: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4833
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar  9 02:30:08.685: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4833 /api/v1/namespaces/watch-4833/configmaps/e2e-watch-test-resource-version 2e279b37-ab76-454e-b2a4-a5244b30c24f 105432 0 2020-03-09 02:30:08 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  9 02:30:08.720: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4833 /api/v1/namespaces/watch-4833/configmaps/e2e-watch-test-resource-version 2e279b37-ab76-454e-b2a4-a5244b30c24f 105433 0 2020-03-09 02:30:08 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:30:08.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4833" for this suite.
Mar  9 02:30:16.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:30:17.098: INFO: namespace watch-4833 deletion completed in 8.369607071s

• [SLOW TEST:9.113 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:30:17.099: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5612
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:30:17.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-5612'
Mar  9 02:30:23.910: INFO: stderr: ""
Mar  9 02:30:23.910: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar  9 02:30:23.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-5612'
Mar  9 02:30:24.765: INFO: stderr: ""
Mar  9 02:30:24.765: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  9 02:30:25.790: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 02:30:25.790: INFO: Found 0 / 1
Mar  9 02:30:26.774: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 02:30:26.774: INFO: Found 1 / 1
Mar  9 02:30:26.774: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  9 02:30:26.803: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 02:30:26.803: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  9 02:30:26.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 describe pod redis-master-6h6ll --namespace=kubectl-5612'
Mar  9 02:30:27.051: INFO: stderr: ""
Mar  9 02:30:27.051: INFO: stdout: "Name:         redis-master-6h6ll\nNamespace:    kubectl-5612\nPriority:     0\nNode:         worker1/172.20.8.5\nStart Time:   Mon, 09 Mar 2020 02:30:24 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.244.4.22\nIPs:\n  IP:           10.244.4.22\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://deff180fb1972fcee03c93026abe0a5c2c561303c36427717864dbc4264a6ed7\n    Image:          172.20.8.7/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://172.20.8.7/library/redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 09 Mar 2020 02:30:25 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-trd74 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-trd74:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-trd74\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  4s    default-scheduler  Successfully assigned kubectl-5612/redis-master-6h6ll to worker1\n  Normal  Pulled     2s    kubelet, worker1   Container image \"172.20.8.7/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s    kubelet, worker1   Created container redis-master\n  Normal  Started    2s    kubelet, worker1   Started container redis-master\n"
Mar  9 02:30:27.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 describe rc redis-master --namespace=kubectl-5612'
Mar  9 02:30:27.307: INFO: stderr: ""
Mar  9 02:30:27.307: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5612\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        172.20.8.7/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-6h6ll\n"
Mar  9 02:30:27.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 describe service redis-master --namespace=kubectl-5612'
Mar  9 02:30:27.571: INFO: stderr: ""
Mar  9 02:30:27.571: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5612\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.98.121.82\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.4.22:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar  9 02:30:27.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 describe node master1'
Mar  9 02:30:27.885: INFO: stderr: ""
Mar  9 02:30:27.885: INFO: stdout: "Name:               master1\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=master1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"aa:e7:a5:1d:33:e0\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.20.8.2\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 08 Mar 2020 14:13:59 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 09 Mar 2020 02:30:14 +0000   Sun, 08 Mar 2020 14:13:53 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 09 Mar 2020 02:30:14 +0000   Sun, 08 Mar 2020 14:13:53 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 09 Mar 2020 02:30:14 +0000   Sun, 08 Mar 2020 14:13:53 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 09 Mar 2020 02:30:14 +0000   Sun, 08 Mar 2020 14:15:21 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.20.8.2\n  Hostname:    master1\nCapacity:\n cpu:                8\n ephemeral-storage:  51175Mi\n hugepages-2Mi:      0\n memory:             3878044Ki\n pods:               200\nAllocatable:\n cpu:                7\n ephemeral-storage:  46147305393\n hugepages-2Mi:      0\n memory:             2342044Ki\n pods:               200\nSystem Info:\n Machine ID:                 c1e2a7e37ea041feb133fd939fc56629\n System UUID:                564D17FA-35A3-5FA5-545D-CA0C20E0EA19\n Boot ID:                    e12c5382-3c53-4c95-b244-4eb56470166c\n Kernel Version:             3.10.0-693.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.8\n Kubelet Version:            v1.16.4\n Kube-Proxy Version:         v1.16.4\nPodCIDR:                     10.244.1.0/24\nPodCIDRs:                    10.244.1.0/24\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                coredns-74b6fc5854-b6c5m                                   100m (1%)     0 (0%)      70Mi (3%)        170Mi (7%)     12h\n  kube-system                coredns-74b6fc5854-d44pf                                   100m (1%)     0 (0%)      70Mi (3%)        170Mi (7%)     12h\n  kube-system                kube-apiserver-master1                                     250m (3%)     0 (0%)      0 (0%)           0 (0%)         12h\n  kube-system                kube-controller-manager-master1                            200m (2%)     0 (0%)      0 (0%)           0 (0%)         12h\n  kube-system                kube-flannel-ds-amd64-q5nmw                                100m (1%)     100m (1%)   50Mi (2%)        50Mi (2%)      12h\n  kube-system                kube-proxy-zfcwl                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         12h\n  kube-system                kube-scheduler-master1                                     100m (1%)     0 (0%)      0 (0%)           0 (0%)         12h\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-l6fxk    0 (0%)        0 (0%)      0 (0%)           0 (0%)         67m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                850m (12%)  100m (1%)\n  memory             190Mi (8%)  390Mi (17%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Mar  9 02:30:27.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 describe namespace kubectl-5612'
Mar  9 02:30:28.108: INFO: stderr: ""
Mar  9 02:30:28.108: INFO: stdout: "Name:         kubectl-5612\nLabels:       e2e-framework=kubectl\n              e2e-run=bdcc56d9-e601-4840-ba76-c399edfb1a55\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:30:28.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5612" for this suite.
Mar  9 02:30:58.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:30:58.294: INFO: namespace kubectl-5612 deletion completed in 30.177542562s

• [SLOW TEST:41.195 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:30:58.294: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3481
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-knw7d in namespace proxy-3481
I0309 02:30:59.221471      22 runners.go:184] Created replication controller with name: proxy-service-knw7d, namespace: proxy-3481, replica count: 1
I0309 02:31:00.272620      22 runners.go:184] proxy-service-knw7d Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0309 02:31:01.272940      22 runners.go:184] proxy-service-knw7d Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0309 02:31:02.273439      22 runners.go:184] proxy-service-knw7d Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0309 02:31:03.273861      22 runners.go:184] proxy-service-knw7d Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  9 02:31:03.280: INFO: setup took 4.327778938s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar  9 02:31:03.299: INFO: (0) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 16.58906ms)
Mar  9 02:31:03.299: INFO: (0) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 16.7458ms)
Mar  9 02:31:03.299: INFO: (0) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 16.90265ms)
Mar  9 02:31:03.299: INFO: (0) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 17.123918ms)
Mar  9 02:31:03.308: INFO: (0) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 27.515596ms)
Mar  9 02:31:03.308: INFO: (0) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 27.282102ms)
Mar  9 02:31:03.308: INFO: (0) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 26.347801ms)
Mar  9 02:31:03.308: INFO: (0) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 26.42269ms)
Mar  9 02:31:03.308: INFO: (0) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 26.444331ms)
Mar  9 02:31:03.309: INFO: (0) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 26.58415ms)
Mar  9 02:31:03.309: INFO: (0) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 26.77334ms)
Mar  9 02:31:03.313: INFO: (0) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 31.54869ms)
Mar  9 02:31:03.313: INFO: (0) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 32.877979ms)
Mar  9 02:31:03.320: INFO: (0) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 38.336357ms)
Mar  9 02:31:03.321: INFO: (0) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 38.538955ms)
Mar  9 02:31:03.323: INFO: (0) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 40.788455ms)
Mar  9 02:31:03.332: INFO: (1) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 8.566255ms)
Mar  9 02:31:03.333: INFO: (1) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 9.352769ms)
Mar  9 02:31:03.333: INFO: (1) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 9.331014ms)
Mar  9 02:31:03.333: INFO: (1) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 9.501092ms)
Mar  9 02:31:03.333: INFO: (1) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 9.576704ms)
Mar  9 02:31:03.334: INFO: (1) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 10.401505ms)
Mar  9 02:31:03.334: INFO: (1) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 10.361511ms)
Mar  9 02:31:03.334: INFO: (1) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 11.283362ms)
Mar  9 02:31:03.335: INFO: (1) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 11.564276ms)
Mar  9 02:31:03.335: INFO: (1) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 10.936738ms)
Mar  9 02:31:03.335: INFO: (1) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 11.346806ms)
Mar  9 02:31:03.335: INFO: (1) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 11.610957ms)
Mar  9 02:31:03.337: INFO: (1) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 13.292443ms)
Mar  9 02:31:03.338: INFO: (1) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 14.312633ms)
Mar  9 02:31:03.339: INFO: (1) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 15.13604ms)
Mar  9 02:31:03.339: INFO: (1) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 15.218093ms)
Mar  9 02:31:03.348: INFO: (2) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 8.953708ms)
Mar  9 02:31:03.348: INFO: (2) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 7.981285ms)
Mar  9 02:31:03.349: INFO: (2) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 9.346445ms)
Mar  9 02:31:03.350: INFO: (2) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 8.65396ms)
Mar  9 02:31:03.350: INFO: (2) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 9.972997ms)
Mar  9 02:31:03.351: INFO: (2) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 11.32273ms)
Mar  9 02:31:03.351: INFO: (2) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 10.808543ms)
Mar  9 02:31:03.351: INFO: (2) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 12.434936ms)
Mar  9 02:31:03.351: INFO: (2) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 10.413423ms)
Mar  9 02:31:03.351: INFO: (2) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 12.250896ms)
Mar  9 02:31:03.351: INFO: (2) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 12.209059ms)
Mar  9 02:31:03.352: INFO: (2) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 11.627194ms)
Mar  9 02:31:03.353: INFO: (2) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 13.287987ms)
Mar  9 02:31:03.354: INFO: (2) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 14.435578ms)
Mar  9 02:31:03.354: INFO: (2) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 13.411272ms)
Mar  9 02:31:03.354: INFO: (2) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 14.406971ms)
Mar  9 02:31:03.362: INFO: (3) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 7.477286ms)
Mar  9 02:31:03.364: INFO: (3) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 9.106027ms)
Mar  9 02:31:03.364: INFO: (3) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 9.757256ms)
Mar  9 02:31:03.364: INFO: (3) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 8.56904ms)
Mar  9 02:31:03.364: INFO: (3) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 8.826854ms)
Mar  9 02:31:03.364: INFO: (3) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 8.861339ms)
Mar  9 02:31:03.365: INFO: (3) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 9.763419ms)
Mar  9 02:31:03.365: INFO: (3) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 10.438474ms)
Mar  9 02:31:03.365: INFO: (3) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 10.443242ms)
Mar  9 02:31:03.365: INFO: (3) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 10.303495ms)
Mar  9 02:31:03.366: INFO: (3) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 10.326407ms)
Mar  9 02:31:03.367: INFO: (3) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 11.613216ms)
Mar  9 02:31:03.368: INFO: (3) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 13.229883ms)
Mar  9 02:31:03.369: INFO: (3) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 13.284009ms)
Mar  9 02:31:03.369: INFO: (3) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 14.786852ms)
Mar  9 02:31:03.369: INFO: (3) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 15.216367ms)
Mar  9 02:31:03.379: INFO: (4) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 8.33849ms)
Mar  9 02:31:03.380: INFO: (4) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 9.082446ms)
Mar  9 02:31:03.380: INFO: (4) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 9.048417ms)
Mar  9 02:31:03.380: INFO: (4) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 8.976286ms)
Mar  9 02:31:03.380: INFO: (4) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 10.059713ms)
Mar  9 02:31:03.381: INFO: (4) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 9.820013ms)
Mar  9 02:31:03.382: INFO: (4) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 11.590883ms)
Mar  9 02:31:03.382: INFO: (4) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 10.541202ms)
Mar  9 02:31:03.382: INFO: (4) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 10.823889ms)
Mar  9 02:31:03.382: INFO: (4) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 10.708607ms)
Mar  9 02:31:03.382: INFO: (4) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 10.486473ms)
Mar  9 02:31:03.382: INFO: (4) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 12.665244ms)
Mar  9 02:31:03.383: INFO: (4) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 11.431412ms)
Mar  9 02:31:03.383: INFO: (4) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 13.481747ms)
Mar  9 02:31:03.383: INFO: (4) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 13.027246ms)
Mar  9 02:31:03.384: INFO: (4) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 13.291716ms)
Mar  9 02:31:03.390: INFO: (5) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 6.066977ms)
Mar  9 02:31:03.390: INFO: (5) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 6.007684ms)
Mar  9 02:31:03.392: INFO: (5) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 6.563664ms)
Mar  9 02:31:03.393: INFO: (5) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 7.095188ms)
Mar  9 02:31:03.393: INFO: (5) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 8.108976ms)
Mar  9 02:31:03.394: INFO: (5) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 9.295047ms)
Mar  9 02:31:03.394: INFO: (5) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 9.93932ms)
Mar  9 02:31:03.394: INFO: (5) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 8.802105ms)
Mar  9 02:31:03.395: INFO: (5) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 9.84864ms)
Mar  9 02:31:03.396: INFO: (5) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 10.191937ms)
Mar  9 02:31:03.396: INFO: (5) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 11.209838ms)
Mar  9 02:31:03.397: INFO: (5) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 11.399824ms)
Mar  9 02:31:03.397: INFO: (5) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 12.094908ms)
Mar  9 02:31:03.398: INFO: (5) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 12.366432ms)
Mar  9 02:31:03.398: INFO: (5) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 12.773194ms)
Mar  9 02:31:03.400: INFO: (5) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 14.551178ms)
Mar  9 02:31:03.405: INFO: (6) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 5.570189ms)
Mar  9 02:31:03.407: INFO: (6) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 5.162346ms)
Mar  9 02:31:03.421: INFO: (6) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 21.208962ms)
Mar  9 02:31:03.421: INFO: (6) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 19.519234ms)
Mar  9 02:31:03.422: INFO: (6) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 20.713896ms)
Mar  9 02:31:03.423: INFO: (6) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 21.89556ms)
Mar  9 02:31:03.426: INFO: (6) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 25.167412ms)
Mar  9 02:31:03.426: INFO: (6) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 24.333366ms)
Mar  9 02:31:03.426: INFO: (6) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 23.92993ms)
Mar  9 02:31:03.429: INFO: (6) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 26.399726ms)
Mar  9 02:31:03.431: INFO: (6) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 29.485286ms)
Mar  9 02:31:03.432: INFO: (6) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 30.011095ms)
Mar  9 02:31:03.432: INFO: (6) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 31.167357ms)
Mar  9 02:31:03.432: INFO: (6) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 30.180042ms)
Mar  9 02:31:03.493: INFO: (6) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 90.981599ms)
Mar  9 02:31:03.499: INFO: (6) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 98.269847ms)
Mar  9 02:31:03.507: INFO: (7) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 7.215046ms)
Mar  9 02:31:03.508: INFO: (7) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 7.7593ms)
Mar  9 02:31:03.508: INFO: (7) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 7.706607ms)
Mar  9 02:31:03.509: INFO: (7) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 8.586375ms)
Mar  9 02:31:03.509: INFO: (7) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 8.747409ms)
Mar  9 02:31:03.509: INFO: (7) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 9.798442ms)
Mar  9 02:31:03.510: INFO: (7) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 9.701925ms)
Mar  9 02:31:03.510: INFO: (7) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 10.633356ms)
Mar  9 02:31:03.512: INFO: (7) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 11.608326ms)
Mar  9 02:31:03.512: INFO: (7) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 11.768139ms)
Mar  9 02:31:03.512: INFO: (7) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 11.79553ms)
Mar  9 02:31:03.512: INFO: (7) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 11.719821ms)
Mar  9 02:31:03.512: INFO: (7) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 11.834479ms)
Mar  9 02:31:03.512: INFO: (7) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 12.395198ms)
Mar  9 02:31:03.512: INFO: (7) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 12.152665ms)
Mar  9 02:31:03.513: INFO: (7) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 12.875858ms)
Mar  9 02:31:03.519: INFO: (8) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 6.248254ms)
Mar  9 02:31:03.520: INFO: (8) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 6.661338ms)
Mar  9 02:31:03.521: INFO: (8) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 7.859824ms)
Mar  9 02:31:03.521: INFO: (8) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 7.676958ms)
Mar  9 02:31:03.523: INFO: (8) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 9.624499ms)
Mar  9 02:31:03.524: INFO: (8) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 10.927305ms)
Mar  9 02:31:03.524: INFO: (8) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 10.996334ms)
Mar  9 02:31:03.525: INFO: (8) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 11.635437ms)
Mar  9 02:31:03.525: INFO: (8) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 11.846679ms)
Mar  9 02:31:03.525: INFO: (8) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 11.997653ms)
Mar  9 02:31:03.525: INFO: (8) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 12.459454ms)
Mar  9 02:31:03.526: INFO: (8) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 12.355422ms)
Mar  9 02:31:03.526: INFO: (8) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 12.474141ms)
Mar  9 02:31:03.526: INFO: (8) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 12.744021ms)
Mar  9 02:31:03.526: INFO: (8) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 12.983214ms)
Mar  9 02:31:03.527: INFO: (8) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 13.915147ms)
Mar  9 02:31:03.533: INFO: (9) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 5.561972ms)
Mar  9 02:31:03.533: INFO: (9) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 5.438299ms)
Mar  9 02:31:03.535: INFO: (9) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 7.10072ms)
Mar  9 02:31:03.535: INFO: (9) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 7.633139ms)
Mar  9 02:31:03.536: INFO: (9) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 7.501712ms)
Mar  9 02:31:03.536: INFO: (9) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 8.592556ms)
Mar  9 02:31:03.537: INFO: (9) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 8.196515ms)
Mar  9 02:31:03.537: INFO: (9) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 9.779326ms)
Mar  9 02:31:03.537: INFO: (9) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 9.339971ms)
Mar  9 02:31:03.538: INFO: (9) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 9.755984ms)
Mar  9 02:31:03.538: INFO: (9) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 9.717887ms)
Mar  9 02:31:03.539: INFO: (9) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 10.659212ms)
Mar  9 02:31:03.540: INFO: (9) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 11.522849ms)
Mar  9 02:31:03.540: INFO: (9) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 11.655168ms)
Mar  9 02:31:03.541: INFO: (9) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 13.016402ms)
Mar  9 02:31:03.541: INFO: (9) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 12.923925ms)
Mar  9 02:31:03.549: INFO: (10) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 6.926313ms)
Mar  9 02:31:03.549: INFO: (10) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 7.231379ms)
Mar  9 02:31:03.550: INFO: (10) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 8.285435ms)
Mar  9 02:31:03.550: INFO: (10) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 7.09075ms)
Mar  9 02:31:03.551: INFO: (10) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 9.668407ms)
Mar  9 02:31:03.551: INFO: (10) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 7.891134ms)
Mar  9 02:31:03.552: INFO: (10) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 8.462631ms)
Mar  9 02:31:03.553: INFO: (10) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 10.703904ms)
Mar  9 02:31:03.553: INFO: (10) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 9.407749ms)
Mar  9 02:31:03.553: INFO: (10) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 11.4533ms)
Mar  9 02:31:03.554: INFO: (10) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 11.017033ms)
Mar  9 02:31:03.554: INFO: (10) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 11.33025ms)
Mar  9 02:31:03.554: INFO: (10) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 10.573119ms)
Mar  9 02:31:03.554: INFO: (10) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 11.892973ms)
Mar  9 02:31:03.555: INFO: (10) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 12.0543ms)
Mar  9 02:31:03.556: INFO: (10) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 12.08011ms)
Mar  9 02:31:03.562: INFO: (11) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 5.662429ms)
Mar  9 02:31:03.564: INFO: (11) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 5.392854ms)
Mar  9 02:31:03.564: INFO: (11) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 7.25976ms)
Mar  9 02:31:03.565: INFO: (11) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 7.044551ms)
Mar  9 02:31:03.566: INFO: (11) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 8.36146ms)
Mar  9 02:31:03.566: INFO: (11) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 8.090346ms)
Mar  9 02:31:03.566: INFO: (11) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 9.501378ms)
Mar  9 02:31:03.566: INFO: (11) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 10.46073ms)
Mar  9 02:31:03.566: INFO: (11) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 9.027175ms)
Mar  9 02:31:03.567: INFO: (11) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 10.959989ms)
Mar  9 02:31:03.567: INFO: (11) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 9.166135ms)
Mar  9 02:31:03.568: INFO: (11) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 10.332381ms)
Mar  9 02:31:03.568: INFO: (11) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 10.721635ms)
Mar  9 02:31:03.568: INFO: (11) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 11.987312ms)
Mar  9 02:31:03.569: INFO: (11) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 12.40255ms)
Mar  9 02:31:03.765: INFO: (11) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 207.751604ms)
Mar  9 02:31:03.773: INFO: (12) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 7.790054ms)
Mar  9 02:31:03.774: INFO: (12) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 9.091679ms)
Mar  9 02:31:03.776: INFO: (12) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 10.928079ms)
Mar  9 02:31:03.776: INFO: (12) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 10.749215ms)
Mar  9 02:31:03.776: INFO: (12) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 10.816449ms)
Mar  9 02:31:03.776: INFO: (12) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 10.907824ms)
Mar  9 02:31:03.776: INFO: (12) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 10.855276ms)
Mar  9 02:31:03.776: INFO: (12) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 11.191058ms)
Mar  9 02:31:03.777: INFO: (12) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 11.702439ms)
Mar  9 02:31:03.777: INFO: (12) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 12.130428ms)
Mar  9 02:31:03.778: INFO: (12) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 13.162602ms)
Mar  9 02:31:03.779: INFO: (12) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 13.474213ms)
Mar  9 02:31:03.779: INFO: (12) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 13.510133ms)
Mar  9 02:31:03.779: INFO: (12) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 14.51712ms)
Mar  9 02:31:03.781: INFO: (12) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 15.743207ms)
Mar  9 02:31:03.781: INFO: (12) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 16.415588ms)
Mar  9 02:31:03.787: INFO: (13) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 5.82419ms)
Mar  9 02:31:03.789: INFO: (13) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 6.10226ms)
Mar  9 02:31:03.790: INFO: (13) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 7.705504ms)
Mar  9 02:31:03.790: INFO: (13) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 7.60771ms)
Mar  9 02:31:03.790: INFO: (13) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 7.969007ms)
Mar  9 02:31:03.790: INFO: (13) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 6.680332ms)
Mar  9 02:31:03.791: INFO: (13) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 8.805883ms)
Mar  9 02:31:03.791: INFO: (13) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 8.465776ms)
Mar  9 02:31:03.792: INFO: (13) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 10.852134ms)
Mar  9 02:31:03.793: INFO: (13) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 10.748799ms)
Mar  9 02:31:03.793: INFO: (13) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 10.018836ms)
Mar  9 02:31:03.793: INFO: (13) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 10.185287ms)
Mar  9 02:31:03.793: INFO: (13) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 10.549804ms)
Mar  9 02:31:03.794: INFO: (13) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 10.753724ms)
Mar  9 02:31:03.794: INFO: (13) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 11.813314ms)
Mar  9 02:31:03.795: INFO: (13) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 12.376636ms)
Mar  9 02:31:03.800: INFO: (14) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 5.005168ms)
Mar  9 02:31:03.801: INFO: (14) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 5.499497ms)
Mar  9 02:31:03.803: INFO: (14) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 6.704612ms)
Mar  9 02:31:03.803: INFO: (14) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 7.471539ms)
Mar  9 02:31:03.804: INFO: (14) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 9.359807ms)
Mar  9 02:31:03.804: INFO: (14) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 8.848376ms)
Mar  9 02:31:03.805: INFO: (14) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 9.116082ms)
Mar  9 02:31:03.805: INFO: (14) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 8.997554ms)
Mar  9 02:31:03.805: INFO: (14) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 9.237022ms)
Mar  9 02:31:03.805: INFO: (14) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 10.169552ms)
Mar  9 02:31:03.806: INFO: (14) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 10.432935ms)
Mar  9 02:31:03.807: INFO: (14) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 11.272444ms)
Mar  9 02:31:03.807: INFO: (14) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 11.063599ms)
Mar  9 02:31:03.807: INFO: (14) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 11.620425ms)
Mar  9 02:31:03.807: INFO: (14) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 11.52751ms)
Mar  9 02:31:03.808: INFO: (14) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 12.234299ms)
Mar  9 02:31:03.815: INFO: (15) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 6.248064ms)
Mar  9 02:31:03.817: INFO: (15) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 8.128415ms)
Mar  9 02:31:03.817: INFO: (15) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 7.919163ms)
Mar  9 02:31:03.818: INFO: (15) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 7.66369ms)
Mar  9 02:31:03.819: INFO: (15) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 7.943125ms)
Mar  9 02:31:03.820: INFO: (15) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 9.259314ms)
Mar  9 02:31:03.820: INFO: (15) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 10.308498ms)
Mar  9 02:31:03.820: INFO: (15) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 9.646722ms)
Mar  9 02:31:03.820: INFO: (15) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 9.768257ms)
Mar  9 02:31:03.821: INFO: (15) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 11.328171ms)
Mar  9 02:31:03.822: INFO: (15) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 10.890225ms)
Mar  9 02:31:03.822: INFO: (15) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 13.156379ms)
Mar  9 02:31:03.822: INFO: (15) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 12.161479ms)
Mar  9 02:31:03.824: INFO: (15) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 13.182652ms)
Mar  9 02:31:03.824: INFO: (15) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 13.828628ms)
Mar  9 02:31:03.825: INFO: (15) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 14.794286ms)
Mar  9 02:31:03.833: INFO: (16) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 7.802531ms)
Mar  9 02:31:03.833: INFO: (16) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 7.540533ms)
Mar  9 02:31:03.834: INFO: (16) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 7.753261ms)
Mar  9 02:31:03.834: INFO: (16) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 7.629983ms)
Mar  9 02:31:03.834: INFO: (16) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 8.066879ms)
Mar  9 02:31:03.835: INFO: (16) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 8.55861ms)
Mar  9 02:31:03.836: INFO: (16) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 9.20355ms)
Mar  9 02:31:03.836: INFO: (16) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 10.792623ms)
Mar  9 02:31:03.836: INFO: (16) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 10.209305ms)
Mar  9 02:31:03.837: INFO: (16) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 11.056388ms)
Mar  9 02:31:03.837: INFO: (16) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 10.980077ms)
Mar  9 02:31:03.837: INFO: (16) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 10.738663ms)
Mar  9 02:31:03.837: INFO: (16) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 10.96054ms)
Mar  9 02:31:03.837: INFO: (16) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 11.143474ms)
Mar  9 02:31:03.837: INFO: (16) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 11.969004ms)
Mar  9 02:31:03.838: INFO: (16) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 12.479443ms)
Mar  9 02:31:03.844: INFO: (17) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 5.717873ms)
Mar  9 02:31:03.846: INFO: (17) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 6.163591ms)
Mar  9 02:31:03.846: INFO: (17) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 6.6627ms)
Mar  9 02:31:03.847: INFO: (17) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 6.461562ms)
Mar  9 02:31:03.847: INFO: (17) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 5.949118ms)
Mar  9 02:31:03.848: INFO: (17) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 6.361053ms)
Mar  9 02:31:03.848: INFO: (17) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 7.649288ms)
Mar  9 02:31:03.848: INFO: (17) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 9.475745ms)
Mar  9 02:31:03.848: INFO: (17) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 6.475506ms)
Mar  9 02:31:03.850: INFO: (17) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 10.547548ms)
Mar  9 02:31:03.850: INFO: (17) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 8.801348ms)
Mar  9 02:31:03.850: INFO: (17) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 9.388932ms)
Mar  9 02:31:03.850: INFO: (17) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 11.453639ms)
Mar  9 02:31:03.851: INFO: (17) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 10.022034ms)
Mar  9 02:31:03.851: INFO: (17) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 10.774755ms)
Mar  9 02:31:03.852: INFO: (17) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 12.694634ms)
Mar  9 02:31:03.859: INFO: (18) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 6.96095ms)
Mar  9 02:31:03.859: INFO: (18) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 7.679608ms)
Mar  9 02:31:03.860: INFO: (18) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 7.847197ms)
Mar  9 02:31:03.862: INFO: (18) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 8.411023ms)
Mar  9 02:31:03.862: INFO: (18) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 8.054025ms)
Mar  9 02:31:03.862: INFO: (18) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 9.09607ms)
Mar  9 02:31:03.862: INFO: (18) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 9.578082ms)
Mar  9 02:31:03.862: INFO: (18) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 9.451494ms)
Mar  9 02:31:03.863: INFO: (18) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 9.466585ms)
Mar  9 02:31:03.864: INFO: (18) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 10.237311ms)
Mar  9 02:31:03.864: INFO: (18) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 10.695202ms)
Mar  9 02:31:03.864: INFO: (18) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 12.433682ms)
Mar  9 02:31:03.865: INFO: (18) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 12.09394ms)
Mar  9 02:31:03.865: INFO: (18) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 11.221818ms)
Mar  9 02:31:03.865: INFO: (18) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 11.908179ms)
Mar  9 02:31:03.866: INFO: (18) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 13.418639ms)
Mar  9 02:31:03.873: INFO: (19) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:460/proxy/: tls baz (200; 6.37291ms)
Mar  9 02:31:03.875: INFO: (19) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:443/proxy/tlsrewritem... (200; 7.774797ms)
Mar  9 02:31:03.876: INFO: (19) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:1080/proxy/rewriteme">test<... (200; 8.941781ms)
Mar  9 02:31:03.876: INFO: (19) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname1/proxy/: tls baz (200; 9.141592ms)
Mar  9 02:31:03.876: INFO: (19) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:160/proxy/: foo (200; 8.005229ms)
Mar  9 02:31:03.876: INFO: (19) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:162/proxy/: bar (200; 9.233607ms)
Mar  9 02:31:03.877: INFO: (19) /api/v1/namespaces/proxy-3481/services/https:proxy-service-knw7d:tlsportname2/proxy/: tls qux (200; 8.864257ms)
Mar  9 02:31:03.877: INFO: (19) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname1/proxy/: foo (200; 9.144893ms)
Mar  9 02:31:03.877: INFO: (19) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg/proxy/rewriteme">test</a> (200; 9.257233ms)
Mar  9 02:31:03.879: INFO: (19) /api/v1/namespaces/proxy-3481/pods/proxy-service-knw7d-2kffg:160/proxy/: foo (200; 12.496264ms)
Mar  9 02:31:03.879: INFO: (19) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname1/proxy/: foo (200; 10.99782ms)
Mar  9 02:31:03.879: INFO: (19) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:162/proxy/: bar (200; 11.698441ms)
Mar  9 02:31:03.879: INFO: (19) /api/v1/namespaces/proxy-3481/pods/https:proxy-service-knw7d-2kffg:462/proxy/: tls qux (200; 11.44931ms)
Mar  9 02:31:03.880: INFO: (19) /api/v1/namespaces/proxy-3481/services/proxy-service-knw7d:portname2/proxy/: bar (200; 11.874886ms)
Mar  9 02:31:03.881: INFO: (19) /api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/: <a href="/api/v1/namespaces/proxy-3481/pods/http:proxy-service-knw7d-2kffg:1080/proxy/rewriteme">... (200; 13.695768ms)
Mar  9 02:31:03.882: INFO: (19) /api/v1/namespaces/proxy-3481/services/http:proxy-service-knw7d:portname2/proxy/: bar (200; 14.740381ms)
STEP: deleting ReplicationController proxy-service-knw7d in namespace proxy-3481, will wait for the garbage collector to delete the pods
Mar  9 02:31:03.974: INFO: Deleting ReplicationController proxy-service-knw7d took: 36.756463ms
Mar  9 02:31:04.474: INFO: Terminating ReplicationController proxy-service-knw7d pods took: 500.453948ms
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:31:07.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3481" for this suite.
Mar  9 02:31:15.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:31:15.648: INFO: namespace proxy-3481 deletion completed in 8.263745135s

• [SLOW TEST:17.354 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:31:15.649: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8054
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:31:16.039: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:32:17.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8054" for this suite.
Mar  9 02:32:23.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:32:23.828: INFO: namespace custom-resource-definition-8054 deletion completed in 6.179775864s

• [SLOW TEST:68.179 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:32:23.828: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6864
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-9r7x
STEP: Creating a pod to test atomic-volume-subpath
Mar  9 02:32:24.222: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9r7x" in namespace "subpath-6864" to be "success or failure"
Mar  9 02:32:24.235: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Pending", Reason="", readiness=false. Elapsed: 13.005931ms
Mar  9 02:32:26.243: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020546125s
Mar  9 02:32:28.262: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Running", Reason="", readiness=true. Elapsed: 4.039389737s
Mar  9 02:32:30.269: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Running", Reason="", readiness=true. Elapsed: 6.046941073s
Mar  9 02:32:32.276: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Running", Reason="", readiness=true. Elapsed: 8.053804162s
Mar  9 02:32:34.284: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Running", Reason="", readiness=true. Elapsed: 10.0619801s
Mar  9 02:32:36.292: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Running", Reason="", readiness=true. Elapsed: 12.069995267s
Mar  9 02:32:38.301: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Running", Reason="", readiness=true. Elapsed: 14.078442683s
Mar  9 02:32:40.311: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Running", Reason="", readiness=true. Elapsed: 16.089180907s
Mar  9 02:32:42.320: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Running", Reason="", readiness=true. Elapsed: 18.097684013s
Mar  9 02:32:44.327: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Running", Reason="", readiness=true. Elapsed: 20.104762377s
Mar  9 02:32:46.337: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Running", Reason="", readiness=true. Elapsed: 22.114789142s
Mar  9 02:32:48.353: INFO: Pod "pod-subpath-test-configmap-9r7x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.130749402s
STEP: Saw pod success
Mar  9 02:32:48.353: INFO: Pod "pod-subpath-test-configmap-9r7x" satisfied condition "success or failure"
Mar  9 02:32:48.358: INFO: Trying to get logs from node worker1 pod pod-subpath-test-configmap-9r7x container test-container-subpath-configmap-9r7x: <nil>
STEP: delete the pod
Mar  9 02:32:48.516: INFO: Waiting for pod pod-subpath-test-configmap-9r7x to disappear
Mar  9 02:32:48.522: INFO: Pod pod-subpath-test-configmap-9r7x no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9r7x
Mar  9 02:32:48.522: INFO: Deleting pod "pod-subpath-test-configmap-9r7x" in namespace "subpath-6864"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:32:48.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6864" for this suite.
Mar  9 02:32:56.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:32:56.801: INFO: namespace subpath-6864 deletion completed in 8.2491544s

• [SLOW TEST:32.973 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:32:56.802: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:32:57.234: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar  9 02:32:57.257: INFO: Number of nodes with available pods: 0
Mar  9 02:32:57.257: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar  9 02:32:57.811: INFO: Number of nodes with available pods: 0
Mar  9 02:32:57.811: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:32:58.818: INFO: Number of nodes with available pods: 0
Mar  9 02:32:58.818: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:32:59.819: INFO: Number of nodes with available pods: 0
Mar  9 02:32:59.819: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:00.819: INFO: Number of nodes with available pods: 1
Mar  9 02:33:00.819: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar  9 02:33:00.878: INFO: Number of nodes with available pods: 1
Mar  9 02:33:00.878: INFO: Number of running nodes: 0, number of available pods: 1
Mar  9 02:33:01.885: INFO: Number of nodes with available pods: 0
Mar  9 02:33:01.885: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar  9 02:33:01.950: INFO: Number of nodes with available pods: 0
Mar  9 02:33:01.950: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:02.959: INFO: Number of nodes with available pods: 0
Mar  9 02:33:02.959: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:03.959: INFO: Number of nodes with available pods: 0
Mar  9 02:33:03.959: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:04.958: INFO: Number of nodes with available pods: 0
Mar  9 02:33:04.958: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:05.957: INFO: Number of nodes with available pods: 0
Mar  9 02:33:05.958: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:06.958: INFO: Number of nodes with available pods: 0
Mar  9 02:33:06.958: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:07.958: INFO: Number of nodes with available pods: 0
Mar  9 02:33:07.958: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:08.957: INFO: Number of nodes with available pods: 0
Mar  9 02:33:08.958: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:09.958: INFO: Number of nodes with available pods: 0
Mar  9 02:33:09.958: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:10.965: INFO: Number of nodes with available pods: 0
Mar  9 02:33:10.965: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:11.959: INFO: Number of nodes with available pods: 0
Mar  9 02:33:11.959: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:12.959: INFO: Number of nodes with available pods: 0
Mar  9 02:33:12.959: INFO: Node worker1 is running more than one daemon pod
Mar  9 02:33:13.958: INFO: Number of nodes with available pods: 1
Mar  9 02:33:13.958: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3727, will wait for the garbage collector to delete the pods
Mar  9 02:33:14.075: INFO: Deleting DaemonSet.extensions daemon-set took: 50.883096ms
Mar  9 02:33:14.476: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.578512ms
Mar  9 02:33:17.815: INFO: Number of nodes with available pods: 0
Mar  9 02:33:17.815: INFO: Number of running nodes: 0, number of available pods: 0
Mar  9 02:33:17.820: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3727/daemonsets","resourceVersion":"106022"},"items":null}

Mar  9 02:33:17.826: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3727/pods","resourceVersion":"106022"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:33:17.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3727" for this suite.
Mar  9 02:33:26.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:33:26.465: INFO: namespace daemonsets-3727 deletion completed in 8.521816812s

• [SLOW TEST:29.663 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:33:26.467: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8202
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8202
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-8202
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8202
Mar  9 02:33:26.804: INFO: Found 0 stateful pods, waiting for 1
Mar  9 02:33:36.813: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar  9 02:33:36.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-8202 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  9 02:33:37.336: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  9 02:33:37.336: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  9 02:33:37.336: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  9 02:33:37.344: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  9 02:33:47.354: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 02:33:47.355: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 02:33:47.443: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  9 02:33:47.443: INFO: ss-0  worker1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:26 +0000 UTC  }]
Mar  9 02:33:47.443: INFO: ss-1           Pending         []
Mar  9 02:33:47.443: INFO: 
Mar  9 02:33:47.443: INFO: StatefulSet ss has not reached scale 3, at 2
Mar  9 02:33:48.454: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.959627365s
Mar  9 02:33:49.462: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.949032335s
Mar  9 02:33:50.473: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.940371067s
Mar  9 02:33:51.483: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.929285065s
Mar  9 02:33:52.491: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.919927672s
Mar  9 02:33:53.501: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.911756429s
Mar  9 02:33:54.510: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.902016932s
Mar  9 02:33:55.536: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.892690937s
Mar  9 02:33:56.545: INFO: Verifying statefulset ss doesn't scale past 3 for another 866.903529ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8202
Mar  9 02:33:57.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-8202 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 02:33:58.043: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  9 02:33:58.043: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  9 02:33:58.044: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  9 02:33:58.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-8202 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 02:33:58.573: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar  9 02:33:58.573: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  9 02:33:58.573: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  9 02:33:58.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-8202 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 02:33:59.052: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar  9 02:33:59.052: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  9 02:33:59.053: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  9 02:33:59.060: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 02:33:59.060: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 02:33:59.060: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar  9 02:33:59.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-8202 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  9 02:33:59.542: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  9 02:33:59.542: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  9 02:33:59.542: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  9 02:33:59.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-8202 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  9 02:34:00.085: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  9 02:34:00.086: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  9 02:34:00.086: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  9 02:34:00.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-8202 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  9 02:34:00.605: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  9 02:34:00.606: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  9 02:34:00.606: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  9 02:34:00.606: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 02:34:00.614: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Mar  9 02:34:10.631: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 02:34:10.631: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 02:34:10.631: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 02:34:10.669: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  9 02:34:10.669: INFO: ss-0  worker1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:26 +0000 UTC  }]
Mar  9 02:34:10.669: INFO: ss-1  worker2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  }]
Mar  9 02:34:10.669: INFO: ss-2  worker1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  }]
Mar  9 02:34:10.670: INFO: 
Mar  9 02:34:10.670: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 02:34:11.678: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  9 02:34:11.678: INFO: ss-0  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:26 +0000 UTC  }]
Mar  9 02:34:11.678: INFO: ss-1  worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  }]
Mar  9 02:34:11.678: INFO: ss-2  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  }]
Mar  9 02:34:11.679: INFO: 
Mar  9 02:34:11.679: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 02:34:12.701: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  9 02:34:12.701: INFO: ss-0  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:26 +0000 UTC  }]
Mar  9 02:34:12.701: INFO: ss-1  worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  }]
Mar  9 02:34:12.701: INFO: ss-2  worker1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:34:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:47 +0000 UTC  }]
Mar  9 02:34:12.701: INFO: 
Mar  9 02:34:12.701: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  9 02:34:13.716: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  9 02:34:13.716: INFO: ss-0  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-09 02:33:26 +0000 UTC  }]
Mar  9 02:34:13.716: INFO: 
Mar  9 02:34:13.716: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  9 02:34:14.741: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.946211184s
Mar  9 02:34:15.750: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.921251664s
Mar  9 02:34:16.782: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.912877596s
Mar  9 02:34:17.789: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.880404422s
Mar  9 02:34:18.819: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.87367324s
Mar  9 02:34:19.827: INFO: Verifying statefulset ss doesn't scale past 0 for another 843.656554ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8202
Mar  9 02:34:20.835: INFO: Scaling statefulset ss to 0
Mar  9 02:34:20.854: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  9 02:34:20.859: INFO: Deleting all statefulset in ns statefulset-8202
Mar  9 02:34:20.866: INFO: Scaling statefulset ss to 0
Mar  9 02:34:20.882: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 02:34:20.888: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:34:20.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8202" for this suite.
Mar  9 02:34:29.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:34:29.247: INFO: namespace statefulset-8202 deletion completed in 8.25347755s

• [SLOW TEST:62.780 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:34:29.247: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5123
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 02:34:30.770: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 02:34:32.792: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318070, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318070, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318071, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318070, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 02:34:36.029: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:34:36.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5123" for this suite.
Mar  9 02:34:44.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:34:44.445: INFO: namespace webhook-5123 deletion completed in 8.194327061s
STEP: Destroying namespace "webhook-5123-markers" for this suite.
Mar  9 02:34:50.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:34:50.630: INFO: namespace webhook-5123-markers deletion completed in 6.184211625s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.416 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:34:50.665: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-791
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar  9 02:34:56.131: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:34:57.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-791" for this suite.
Mar  9 02:35:25.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:35:25.583: INFO: namespace replicaset-791 deletion completed in 28.387893017s

• [SLOW TEST:34.918 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:35:25.584: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9528
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Mar  9 02:35:25.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 run logs-generator --generator=run-pod/v1 --image=172.20.8.7/library/agnhost:2.6 --namespace=kubectl-9528 -- logs-generator --log-lines-total 100 --run-duration 20s'
Mar  9 02:35:26.232: INFO: stderr: ""
Mar  9 02:35:26.232: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Mar  9 02:35:26.232: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Mar  9 02:35:26.233: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-9528" to be "running and ready, or succeeded"
Mar  9 02:35:26.250: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 17.322793ms
Mar  9 02:35:28.259: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026060673s
Mar  9 02:35:30.266: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.033466768s
Mar  9 02:35:30.266: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Mar  9 02:35:30.266: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Mar  9 02:35:30.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 logs logs-generator logs-generator --namespace=kubectl-9528'
Mar  9 02:35:30.525: INFO: stderr: ""
Mar  9 02:35:30.525: INFO: stdout: "I0309 02:35:28.164129       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/k898 398\nI0309 02:35:28.364356       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/d2mz 236\nI0309 02:35:28.564412       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/smg 326\nI0309 02:35:28.764338       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/vh9 275\nI0309 02:35:28.964322       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/8vmp 504\nI0309 02:35:29.164359       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/d4h 499\nI0309 02:35:29.364338       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/6hd 523\nI0309 02:35:29.564358       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/qbmg 328\nI0309 02:35:29.764316       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/p7kw 387\nI0309 02:35:29.964349       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/lxw 314\nI0309 02:35:30.164326       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/2k2v 287\nI0309 02:35:30.364401       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/nccd 287\n"
STEP: limiting log lines
Mar  9 02:35:30.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 logs logs-generator logs-generator --namespace=kubectl-9528 --tail=1'
Mar  9 02:35:30.786: INFO: stderr: ""
Mar  9 02:35:30.786: INFO: stdout: "I0309 02:35:30.764361       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/zsx 397\n"
STEP: limiting log bytes
Mar  9 02:35:30.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 logs logs-generator logs-generator --namespace=kubectl-9528 --limit-bytes=1'
Mar  9 02:35:31.132: INFO: stderr: ""
Mar  9 02:35:31.132: INFO: stdout: "I"
STEP: exposing timestamps
Mar  9 02:35:31.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 logs logs-generator logs-generator --namespace=kubectl-9528 --tail=1 --timestamps'
Mar  9 02:35:31.366: INFO: stderr: ""
Mar  9 02:35:31.366: INFO: stdout: "2020-03-09T02:35:31.164656979Z I0309 02:35:31.164317       1 logs_generator.go:76] 15 POST /api/v1/namespaces/ns/pods/67x 245\n"
STEP: restricting to a time range
Mar  9 02:35:33.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 logs logs-generator logs-generator --namespace=kubectl-9528 --since=1s'
Mar  9 02:35:34.060: INFO: stderr: ""
Mar  9 02:35:34.060: INFO: stdout: "I0309 02:35:33.164424       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/kube-system/pods/nk7f 325\nI0309 02:35:33.364365       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/ns/pods/7mt7 368\nI0309 02:35:33.564408       1 logs_generator.go:76] 27 POST /api/v1/namespaces/ns/pods/qbct 350\nI0309 02:35:33.764340       1 logs_generator.go:76] 28 POST /api/v1/namespaces/ns/pods/drtk 543\nI0309 02:35:33.964321       1 logs_generator.go:76] 29 GET /api/v1/namespaces/ns/pods/84f2 348\n"
Mar  9 02:35:34.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 logs logs-generator logs-generator --namespace=kubectl-9528 --since=24h'
Mar  9 02:35:34.252: INFO: stderr: ""
Mar  9 02:35:34.253: INFO: stdout: "I0309 02:35:28.164129       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/k898 398\nI0309 02:35:28.364356       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/d2mz 236\nI0309 02:35:28.564412       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/smg 326\nI0309 02:35:28.764338       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/vh9 275\nI0309 02:35:28.964322       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/8vmp 504\nI0309 02:35:29.164359       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/d4h 499\nI0309 02:35:29.364338       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/6hd 523\nI0309 02:35:29.564358       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/qbmg 328\nI0309 02:35:29.764316       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/p7kw 387\nI0309 02:35:29.964349       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/lxw 314\nI0309 02:35:30.164326       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/2k2v 287\nI0309 02:35:30.364401       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/nccd 287\nI0309 02:35:30.564346       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/dqcd 456\nI0309 02:35:30.764361       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/zsx 397\nI0309 02:35:30.964357       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/vrk 592\nI0309 02:35:31.164317       1 logs_generator.go:76] 15 POST /api/v1/namespaces/ns/pods/67x 245\nI0309 02:35:31.364289       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/ns/pods/fcj 535\nI0309 02:35:31.564402       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/txr 317\nI0309 02:35:31.764361       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/d7sx 208\nI0309 02:35:31.964422       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/48gz 206\nI0309 02:35:32.164391       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/f5vg 228\nI0309 02:35:32.364406       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/7zr6 243\nI0309 02:35:32.564384       1 logs_generator.go:76] 22 POST /api/v1/namespaces/kube-system/pods/x9w 551\nI0309 02:35:32.764452       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/sg4 475\nI0309 02:35:32.964386       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/kube-system/pods/pp7 413\nI0309 02:35:33.164424       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/kube-system/pods/nk7f 325\nI0309 02:35:33.364365       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/ns/pods/7mt7 368\nI0309 02:35:33.564408       1 logs_generator.go:76] 27 POST /api/v1/namespaces/ns/pods/qbct 350\nI0309 02:35:33.764340       1 logs_generator.go:76] 28 POST /api/v1/namespaces/ns/pods/drtk 543\nI0309 02:35:33.964321       1 logs_generator.go:76] 29 GET /api/v1/namespaces/ns/pods/84f2 348\nI0309 02:35:34.164375       1 logs_generator.go:76] 30 POST /api/v1/namespaces/default/pods/vqv 575\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Mar  9 02:35:34.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete pod logs-generator --namespace=kubectl-9528'
Mar  9 02:35:41.121: INFO: stderr: ""
Mar  9 02:35:41.121: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:35:41.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9528" for this suite.
Mar  9 02:35:47.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:35:47.396: INFO: namespace kubectl-9528 deletion completed in 6.264734834s

• [SLOW TEST:21.813 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:35:47.397: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8910
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:35:58.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8910" for this suite.
Mar  9 02:36:04.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:36:05.050: INFO: namespace resourcequota-8910 deletion completed in 6.208277738s

• [SLOW TEST:17.653 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:36:05.051: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-260d6cf5-93fa-4cce-9d6e-ef61847998fd
STEP: Creating a pod to test consume secrets
Mar  9 02:36:05.429: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f4c7b189-6da4-49e4-8466-6b48f626559c" in namespace "projected-9653" to be "success or failure"
Mar  9 02:36:05.434: INFO: Pod "pod-projected-secrets-f4c7b189-6da4-49e4-8466-6b48f626559c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.745009ms
Mar  9 02:36:07.472: INFO: Pod "pod-projected-secrets-f4c7b189-6da4-49e4-8466-6b48f626559c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042958059s
Mar  9 02:36:09.496: INFO: Pod "pod-projected-secrets-f4c7b189-6da4-49e4-8466-6b48f626559c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067392763s
STEP: Saw pod success
Mar  9 02:36:09.497: INFO: Pod "pod-projected-secrets-f4c7b189-6da4-49e4-8466-6b48f626559c" satisfied condition "success or failure"
Mar  9 02:36:09.517: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-f4c7b189-6da4-49e4-8466-6b48f626559c container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  9 02:36:09.633: INFO: Waiting for pod pod-projected-secrets-f4c7b189-6da4-49e4-8466-6b48f626559c to disappear
Mar  9 02:36:09.643: INFO: Pod pod-projected-secrets-f4c7b189-6da4-49e4-8466-6b48f626559c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:36:09.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9653" for this suite.
Mar  9 02:36:17.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:36:17.924: INFO: namespace projected-9653 deletion completed in 8.272939445s

• [SLOW TEST:12.873 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:36:17.924: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2448
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-6699f69f-e66a-4ab4-8890-f80fdc6b4362 in namespace container-probe-2448
Mar  9 02:36:22.576: INFO: Started pod busybox-6699f69f-e66a-4ab4-8890-f80fdc6b4362 in namespace container-probe-2448
STEP: checking the pod's current state and verifying that restartCount is present
Mar  9 02:36:22.581: INFO: Initial restart count of pod busybox-6699f69f-e66a-4ab4-8890-f80fdc6b4362 is 0
Mar  9 02:37:08.977: INFO: Restart count of pod container-probe-2448/busybox-6699f69f-e66a-4ab4-8890-f80fdc6b4362 is now 1 (46.396474914s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:37:09.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2448" for this suite.
Mar  9 02:37:15.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:37:15.400: INFO: namespace container-probe-2448 deletion completed in 6.268707673s

• [SLOW TEST:57.476 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:37:15.401: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Mar  9 02:37:16.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-8909'
Mar  9 02:37:16.800: INFO: stderr: ""
Mar  9 02:37:16.800: INFO: stdout: "pod/pause created\n"
Mar  9 02:37:16.801: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar  9 02:37:16.801: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8909" to be "running and ready"
Mar  9 02:37:16.806: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.521799ms
Mar  9 02:37:18.815: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013963078s
Mar  9 02:37:20.823: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.021897838s
Mar  9 02:37:20.823: INFO: Pod "pause" satisfied condition "running and ready"
Mar  9 02:37:20.823: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Mar  9 02:37:20.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 label pods pause testing-label=testing-label-value --namespace=kubectl-8909'
Mar  9 02:37:21.180: INFO: stderr: ""
Mar  9 02:37:21.180: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar  9 02:37:21.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pod pause -L testing-label --namespace=kubectl-8909'
Mar  9 02:37:21.403: INFO: stderr: ""
Mar  9 02:37:21.403: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar  9 02:37:21.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 label pods pause testing-label- --namespace=kubectl-8909'
Mar  9 02:37:21.638: INFO: stderr: ""
Mar  9 02:37:21.638: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar  9 02:37:21.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pod pause -L testing-label --namespace=kubectl-8909'
Mar  9 02:37:21.849: INFO: stderr: ""
Mar  9 02:37:21.849: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Mar  9 02:37:21.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete --grace-period=0 --force -f - --namespace=kubectl-8909'
Mar  9 02:37:22.107: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 02:37:22.108: INFO: stdout: "pod \"pause\" force deleted\n"
Mar  9 02:37:22.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get rc,svc -l name=pause --no-headers --namespace=kubectl-8909'
Mar  9 02:37:22.273: INFO: stderr: "No resources found in kubectl-8909 namespace.\n"
Mar  9 02:37:22.273: INFO: stdout: ""
Mar  9 02:37:22.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -l name=pause --namespace=kubectl-8909 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  9 02:37:22.423: INFO: stderr: ""
Mar  9 02:37:22.423: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:37:22.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8909" for this suite.
Mar  9 02:37:30.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:37:30.747: INFO: namespace kubectl-8909 deletion completed in 8.31413644s

• [SLOW TEST:15.346 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:37:30.747: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 02:37:32.787: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 02:37:34.831: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318252, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318252, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318253, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318252, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 02:37:37.928: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:37:37.935: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9817-crds.webhook.example.com via the AdmissionRegistration API
Mar  9 02:37:43.671: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:37:44.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2591" for this suite.
Mar  9 02:37:52.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:37:52.851: INFO: namespace webhook-2591 deletion completed in 8.23399683s
STEP: Destroying namespace "webhook-2591-markers" for this suite.
Mar  9 02:37:58.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:37:59.054: INFO: namespace webhook-2591-markers deletion completed in 6.202516188s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.342 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:37:59.091: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  9 02:38:04.228: INFO: Successfully updated pod "annotationupdate916707af-a306-4ae8-9e5c-d776ba760717"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:38:06.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2480" for this suite.
Mar  9 02:38:18.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:38:18.862: INFO: namespace projected-2480 deletion completed in 12.505709452s

• [SLOW TEST:19.772 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:38:18.864: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-576/configmap-test-fc7f6906-f0b5-47bc-ac1c-676a3c0b09d2
STEP: Creating a pod to test consume configMaps
Mar  9 02:38:19.461: INFO: Waiting up to 5m0s for pod "pod-configmaps-c659e4be-ad69-46dd-8e7a-4d2a1c57953d" in namespace "configmap-576" to be "success or failure"
Mar  9 02:38:19.535: INFO: Pod "pod-configmaps-c659e4be-ad69-46dd-8e7a-4d2a1c57953d": Phase="Pending", Reason="", readiness=false. Elapsed: 74.360264ms
Mar  9 02:38:21.544: INFO: Pod "pod-configmaps-c659e4be-ad69-46dd-8e7a-4d2a1c57953d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083282552s
Mar  9 02:38:23.553: INFO: Pod "pod-configmaps-c659e4be-ad69-46dd-8e7a-4d2a1c57953d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.091601981s
STEP: Saw pod success
Mar  9 02:38:23.553: INFO: Pod "pod-configmaps-c659e4be-ad69-46dd-8e7a-4d2a1c57953d" satisfied condition "success or failure"
Mar  9 02:38:23.558: INFO: Trying to get logs from node worker1 pod pod-configmaps-c659e4be-ad69-46dd-8e7a-4d2a1c57953d container env-test: <nil>
STEP: delete the pod
Mar  9 02:38:23.637: INFO: Waiting for pod pod-configmaps-c659e4be-ad69-46dd-8e7a-4d2a1c57953d to disappear
Mar  9 02:38:23.642: INFO: Pod pod-configmaps-c659e4be-ad69-46dd-8e7a-4d2a1c57953d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:38:23.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-576" for this suite.
Mar  9 02:38:31.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:38:31.902: INFO: namespace configmap-576 deletion completed in 8.230760899s

• [SLOW TEST:13.039 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:38:31.903: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7582
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7582
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-7582
I0309 02:38:32.611195      22 runners.go:184] Created replication controller with name: externalname-service, namespace: services-7582, replica count: 2
I0309 02:38:35.662270      22 runners.go:184] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  9 02:38:38.662: INFO: Creating new exec pod
I0309 02:38:38.662685      22 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  9 02:38:43.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-7582 execpod6lwp8 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Mar  9 02:38:44.153: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Mar  9 02:38:44.153: INFO: stdout: ""
Mar  9 02:38:44.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-7582 execpod6lwp8 -- /bin/sh -x -c nc -zv -t -w 2 10.101.232.227 80'
Mar  9 02:38:44.570: INFO: stderr: "+ nc -zv -t -w 2 10.101.232.227 80\nConnection to 10.101.232.227 80 port [tcp/http] succeeded!\n"
Mar  9 02:38:44.570: INFO: stdout: ""
Mar  9 02:38:44.570: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:38:44.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7582" for this suite.
Mar  9 02:38:52.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:38:53.116: INFO: namespace services-7582 deletion completed in 8.325118195s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:21.214 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:38:53.118: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-2592
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Mar  9 02:38:53.483: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2592" to be "success or failure"
Mar  9 02:38:53.488: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.306788ms
Mar  9 02:38:55.496: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013243192s
Mar  9 02:38:57.504: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02073831s
STEP: Saw pod success
Mar  9 02:38:57.504: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar  9 02:38:57.552: INFO: Trying to get logs from node worker1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar  9 02:38:57.743: INFO: Waiting for pod pod-host-path-test to disappear
Mar  9 02:38:57.811: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:38:57.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2592" for this suite.
Mar  9 02:39:05.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:39:06.084: INFO: namespace hostpath-2592 deletion completed in 8.264626082s

• [SLOW TEST:12.966 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:39:06.086: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-624
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-c2610083-4428-4d32-b991-910bdde5a26a
STEP: Creating a pod to test consume secrets
Mar  9 02:39:06.504: INFO: Waiting up to 5m0s for pod "pod-secrets-8e1120e0-ddd6-47fd-8332-bbc0b9b1e524" in namespace "secrets-624" to be "success or failure"
Mar  9 02:39:06.511: INFO: Pod "pod-secrets-8e1120e0-ddd6-47fd-8332-bbc0b9b1e524": Phase="Pending", Reason="", readiness=false. Elapsed: 6.842828ms
Mar  9 02:39:08.519: INFO: Pod "pod-secrets-8e1120e0-ddd6-47fd-8332-bbc0b9b1e524": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015351423s
Mar  9 02:39:10.527: INFO: Pod "pod-secrets-8e1120e0-ddd6-47fd-8332-bbc0b9b1e524": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022913526s
STEP: Saw pod success
Mar  9 02:39:10.527: INFO: Pod "pod-secrets-8e1120e0-ddd6-47fd-8332-bbc0b9b1e524" satisfied condition "success or failure"
Mar  9 02:39:10.531: INFO: Trying to get logs from node worker1 pod pod-secrets-8e1120e0-ddd6-47fd-8332-bbc0b9b1e524 container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 02:39:10.698: INFO: Waiting for pod pod-secrets-8e1120e0-ddd6-47fd-8332-bbc0b9b1e524 to disappear
Mar  9 02:39:10.703: INFO: Pod pod-secrets-8e1120e0-ddd6-47fd-8332-bbc0b9b1e524 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:39:10.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-624" for this suite.
Mar  9 02:39:16.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:39:16.951: INFO: namespace secrets-624 deletion completed in 6.181441551s

• [SLOW TEST:10.865 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:39:16.951: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7797
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Mar  9 02:39:17.332: INFO: Waiting up to 5m0s for pod "var-expansion-0d9c1474-075b-40ad-a886-45b5fe89874e" in namespace "var-expansion-7797" to be "success or failure"
Mar  9 02:39:17.337: INFO: Pod "var-expansion-0d9c1474-075b-40ad-a886-45b5fe89874e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.811797ms
Mar  9 02:39:19.346: INFO: Pod "var-expansion-0d9c1474-075b-40ad-a886-45b5fe89874e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01402991s
Mar  9 02:39:21.353: INFO: Pod "var-expansion-0d9c1474-075b-40ad-a886-45b5fe89874e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021323143s
STEP: Saw pod success
Mar  9 02:39:21.354: INFO: Pod "var-expansion-0d9c1474-075b-40ad-a886-45b5fe89874e" satisfied condition "success or failure"
Mar  9 02:39:21.359: INFO: Trying to get logs from node worker1 pod var-expansion-0d9c1474-075b-40ad-a886-45b5fe89874e container dapi-container: <nil>
STEP: delete the pod
Mar  9 02:39:21.513: INFO: Waiting for pod var-expansion-0d9c1474-075b-40ad-a886-45b5fe89874e to disappear
Mar  9 02:39:21.519: INFO: Pod var-expansion-0d9c1474-075b-40ad-a886-45b5fe89874e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:39:21.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7797" for this suite.
Mar  9 02:39:27.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:39:27.696: INFO: namespace var-expansion-7797 deletion completed in 6.168540022s

• [SLOW TEST:10.745 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:39:27.697: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3189
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-e2e581d8-fc7b-4929-8cf8-1131dde03ddd
STEP: Creating a pod to test consume secrets
Mar  9 02:39:28.091: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cfaf71f6-b629-4f07-ae89-cd5b7e83e7e9" in namespace "projected-3189" to be "success or failure"
Mar  9 02:39:28.096: INFO: Pod "pod-projected-secrets-cfaf71f6-b629-4f07-ae89-cd5b7e83e7e9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.987997ms
Mar  9 02:39:30.104: INFO: Pod "pod-projected-secrets-cfaf71f6-b629-4f07-ae89-cd5b7e83e7e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012626613s
Mar  9 02:39:32.117: INFO: Pod "pod-projected-secrets-cfaf71f6-b629-4f07-ae89-cd5b7e83e7e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0255278s
STEP: Saw pod success
Mar  9 02:39:32.117: INFO: Pod "pod-projected-secrets-cfaf71f6-b629-4f07-ae89-cd5b7e83e7e9" satisfied condition "success or failure"
Mar  9 02:39:32.123: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-cfaf71f6-b629-4f07-ae89-cd5b7e83e7e9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  9 02:39:32.289: INFO: Waiting for pod pod-projected-secrets-cfaf71f6-b629-4f07-ae89-cd5b7e83e7e9 to disappear
Mar  9 02:39:32.319: INFO: Pod pod-projected-secrets-cfaf71f6-b629-4f07-ae89-cd5b7e83e7e9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:39:32.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3189" for this suite.
Mar  9 02:39:38.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:39:38.614: INFO: namespace projected-3189 deletion completed in 6.286917386s

• [SLOW TEST:10.918 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:39:38.615: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1048
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:39:43.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1048" for this suite.
Mar  9 02:40:32.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:40:32.411: INFO: namespace kubelet-test-1048 deletion completed in 48.462796369s

• [SLOW TEST:53.796 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:40:32.412: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5757
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Mar  9 02:40:32.977: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-910735845 proxy --unix-socket=/tmp/kubectl-proxy-unix266249968/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:40:33.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5757" for this suite.
Mar  9 02:40:39.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:40:39.508: INFO: namespace kubectl-5757 deletion completed in 6.331281114s

• [SLOW TEST:7.096 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:40:39.509: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3351
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  9 02:40:39.805: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:40:44.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3351" for this suite.
Mar  9 02:40:52.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:40:52.869: INFO: namespace init-container-3351 deletion completed in 8.370448977s

• [SLOW TEST:13.361 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:40:52.872: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-613
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-4389330b-75b4-4cf1-a836-4ff8a2eebc0a
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:40:57.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-613" for this suite.
Mar  9 02:41:09.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:41:09.893: INFO: namespace configmap-613 deletion completed in 12.313174511s

• [SLOW TEST:17.021 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:41:09.894: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-xnc4
STEP: Creating a pod to test atomic-volume-subpath
Mar  9 02:41:10.519: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-xnc4" in namespace "subpath-5453" to be "success or failure"
Mar  9 02:41:10.550: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Pending", Reason="", readiness=false. Elapsed: 30.65011ms
Mar  9 02:41:12.559: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040164966s
Mar  9 02:41:14.566: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Running", Reason="", readiness=true. Elapsed: 4.047173559s
Mar  9 02:41:16.574: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Running", Reason="", readiness=true. Elapsed: 6.054645934s
Mar  9 02:41:18.583: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Running", Reason="", readiness=true. Elapsed: 8.063838525s
Mar  9 02:41:20.590: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Running", Reason="", readiness=true. Elapsed: 10.070891231s
Mar  9 02:41:22.598: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Running", Reason="", readiness=true. Elapsed: 12.078538751s
Mar  9 02:41:24.605: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Running", Reason="", readiness=true. Elapsed: 14.085774611s
Mar  9 02:41:26.613: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Running", Reason="", readiness=true. Elapsed: 16.093794315s
Mar  9 02:41:28.622: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Running", Reason="", readiness=true. Elapsed: 18.102428001s
Mar  9 02:41:30.629: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Running", Reason="", readiness=true. Elapsed: 20.109957093s
Mar  9 02:41:32.637: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Running", Reason="", readiness=true. Elapsed: 22.118074499s
Mar  9 02:41:34.645: INFO: Pod "pod-subpath-test-secret-xnc4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.125804106s
STEP: Saw pod success
Mar  9 02:41:34.645: INFO: Pod "pod-subpath-test-secret-xnc4" satisfied condition "success or failure"
Mar  9 02:41:34.650: INFO: Trying to get logs from node worker1 pod pod-subpath-test-secret-xnc4 container test-container-subpath-secret-xnc4: <nil>
STEP: delete the pod
Mar  9 02:41:34.738: INFO: Waiting for pod pod-subpath-test-secret-xnc4 to disappear
Mar  9 02:41:34.750: INFO: Pod pod-subpath-test-secret-xnc4 no longer exists
STEP: Deleting pod pod-subpath-test-secret-xnc4
Mar  9 02:41:34.750: INFO: Deleting pod "pod-subpath-test-secret-xnc4" in namespace "subpath-5453"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:41:34.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5453" for this suite.
Mar  9 02:41:42.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:41:43.031: INFO: namespace subpath-5453 deletion completed in 8.267062548s

• [SLOW TEST:33.137 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:41:43.032: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3284
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  9 02:41:43.386: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  9 02:41:43.430: INFO: Waiting for terminating namespaces to be deleted...
Mar  9 02:41:43.437: INFO: 
Logging pods the kubelet thinks is on node worker1 before test
Mar  9 02:41:43.450: INFO: sonobuoy from sonobuoy started at 2020-03-09 01:23:11 +0000 UTC (1 container statuses recorded)
Mar  9 02:41:43.450: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  9 02:41:43.450: INFO: sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-txlws from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 02:41:43.450: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  9 02:41:43.450: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  9 02:41:43.450: INFO: kube-flannel-ds-amd64-wgfqr from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:41:43.450: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  9 02:41:43.450: INFO: kube-proxy-94vtq from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:41:43.450: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 02:41:43.450: INFO: 
Logging pods the kubelet thinks is on node worker2 before test
Mar  9 02:41:43.487: INFO: sonobuoy-e2e-job-aaa481025fe94110 from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 02:41:43.487: INFO: 	Container e2e ready: true, restart count 0
Mar  9 02:41:43.487: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  9 02:41:43.487: INFO: kube-flannel-ds-amd64-q9s4h from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:41:43.487: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  9 02:41:43.487: INFO: kube-proxy-55qqw from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:41:43.487: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 02:41:43.487: INFO: sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-b49xx from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 02:41:43.487: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  9 02:41:43.487: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-2c66944b-c29b-4d76-933e-ac878a549728 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-2c66944b-c29b-4d76-933e-ac878a549728 off the node worker1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-2c66944b-c29b-4d76-933e-ac878a549728
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:42:00.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3284" for this suite.
Mar  9 02:42:12.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:42:12.550: INFO: namespace sched-pred-3284 deletion completed in 12.231044529s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:29.519 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:42:12.551: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3561
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-04704084-7e7b-4559-962c-e0f2070017f4
STEP: Creating a pod to test consume configMaps
Mar  9 02:42:13.006: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b80f8a0e-4ea7-4d5e-8945-19c224697677" in namespace "projected-3561" to be "success or failure"
Mar  9 02:42:13.018: INFO: Pod "pod-projected-configmaps-b80f8a0e-4ea7-4d5e-8945-19c224697677": Phase="Pending", Reason="", readiness=false. Elapsed: 12.604814ms
Mar  9 02:42:15.050: INFO: Pod "pod-projected-configmaps-b80f8a0e-4ea7-4d5e-8945-19c224697677": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044391176s
Mar  9 02:42:17.058: INFO: Pod "pod-projected-configmaps-b80f8a0e-4ea7-4d5e-8945-19c224697677": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051892714s
STEP: Saw pod success
Mar  9 02:42:17.058: INFO: Pod "pod-projected-configmaps-b80f8a0e-4ea7-4d5e-8945-19c224697677" satisfied condition "success or failure"
Mar  9 02:42:17.062: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-b80f8a0e-4ea7-4d5e-8945-19c224697677 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 02:42:17.179: INFO: Waiting for pod pod-projected-configmaps-b80f8a0e-4ea7-4d5e-8945-19c224697677 to disappear
Mar  9 02:42:17.184: INFO: Pod pod-projected-configmaps-b80f8a0e-4ea7-4d5e-8945-19c224697677 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:42:17.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3561" for this suite.
Mar  9 02:42:23.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:42:23.471: INFO: namespace projected-3561 deletion completed in 6.279216457s

• [SLOW TEST:10.920 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:42:23.472: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5274
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:42:40.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5274" for this suite.
Mar  9 02:42:48.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:42:49.082: INFO: namespace resourcequota-5274 deletion completed in 8.316218338s

• [SLOW TEST:25.610 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:42:49.083: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3312
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  9 02:42:49.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 run e2e-test-httpd-rc --image=172.20.8.7/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3312'
Mar  9 02:42:53.220: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  9 02:42:53.220: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Mar  9 02:42:55.242: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-7p5vx]
Mar  9 02:42:55.243: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-7p5vx" in namespace "kubectl-3312" to be "running and ready"
Mar  9 02:42:55.249: INFO: Pod "e2e-test-httpd-rc-7p5vx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.428456ms
Mar  9 02:42:57.258: INFO: Pod "e2e-test-httpd-rc-7p5vx": Phase="Running", Reason="", readiness=true. Elapsed: 2.015552441s
Mar  9 02:42:57.258: INFO: Pod "e2e-test-httpd-rc-7p5vx" satisfied condition "running and ready"
Mar  9 02:42:57.258: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-7p5vx]
Mar  9 02:42:57.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 logs rc/e2e-test-httpd-rc --namespace=kubectl-3312'
Mar  9 02:42:57.552: INFO: stderr: ""
Mar  9 02:42:57.553: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.4.56. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.4.56. Set the 'ServerName' directive globally to suppress this message\n[Mon Mar 09 02:42:55.237088 2020] [mpm_event:notice] [pid 1:tid 140063801740136] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Mar 09 02:42:55.237170 2020] [core:notice] [pid 1:tid 140063801740136] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Mar  9 02:42:57.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete rc e2e-test-httpd-rc --namespace=kubectl-3312'
Mar  9 02:42:57.777: INFO: stderr: ""
Mar  9 02:42:57.777: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:42:57.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3312" for this suite.
Mar  9 02:43:03.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:43:04.111: INFO: namespace kubectl-3312 deletion completed in 6.325021097s

• [SLOW TEST:15.028 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:43:04.113: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Mar  9 02:43:11.094: INFO: 1 pods remaining
Mar  9 02:43:11.094: INFO: 0 pods has nil DeletionTimestamp
Mar  9 02:43:11.094: INFO: 
STEP: Gathering metrics
Mar  9 02:43:11.984: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:43:11.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0309 02:43:11.983732      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-4855" for this suite.
Mar  9 02:43:24.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:43:24.267: INFO: namespace gc-4855 deletion completed in 12.276271283s

• [SLOW TEST:20.154 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:43:24.268: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4659
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar  9 02:43:24.982: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4659 /api/v1/namespaces/watch-4659/configmaps/e2e-watch-test-watch-closed 7f978099-310f-45ed-bea4-3ddbc67a50f8 108486 0 2020-03-09 02:43:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  9 02:43:24.983: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4659 /api/v1/namespaces/watch-4659/configmaps/e2e-watch-test-watch-closed 7f978099-310f-45ed-bea4-3ddbc67a50f8 108487 0 2020-03-09 02:43:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar  9 02:43:25.154: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4659 /api/v1/namespaces/watch-4659/configmaps/e2e-watch-test-watch-closed 7f978099-310f-45ed-bea4-3ddbc67a50f8 108488 0 2020-03-09 02:43:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  9 02:43:25.155: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4659 /api/v1/namespaces/watch-4659/configmaps/e2e-watch-test-watch-closed 7f978099-310f-45ed-bea4-3ddbc67a50f8 108489 0 2020-03-09 02:43:24 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:43:25.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4659" for this suite.
Mar  9 02:43:31.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:43:31.422: INFO: namespace watch-4659 deletion completed in 6.257403167s

• [SLOW TEST:7.154 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:43:31.422: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2013
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-dc1b2eae-f63e-42ac-8d34-cdf7d6091c17
STEP: Creating a pod to test consume configMaps
Mar  9 02:43:31.899: INFO: Waiting up to 5m0s for pod "pod-configmaps-ab9a79b0-db27-4ba9-8d51-7fa100d86387" in namespace "configmap-2013" to be "success or failure"
Mar  9 02:43:31.911: INFO: Pod "pod-configmaps-ab9a79b0-db27-4ba9-8d51-7fa100d86387": Phase="Pending", Reason="", readiness=false. Elapsed: 11.78913ms
Mar  9 02:43:34.149: INFO: Pod "pod-configmaps-ab9a79b0-db27-4ba9-8d51-7fa100d86387": Phase="Pending", Reason="", readiness=false. Elapsed: 2.250425454s
Mar  9 02:43:36.157: INFO: Pod "pod-configmaps-ab9a79b0-db27-4ba9-8d51-7fa100d86387": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.258309254s
STEP: Saw pod success
Mar  9 02:43:36.157: INFO: Pod "pod-configmaps-ab9a79b0-db27-4ba9-8d51-7fa100d86387" satisfied condition "success or failure"
Mar  9 02:43:36.190: INFO: Trying to get logs from node worker1 pod pod-configmaps-ab9a79b0-db27-4ba9-8d51-7fa100d86387 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 02:43:36.622: INFO: Waiting for pod pod-configmaps-ab9a79b0-db27-4ba9-8d51-7fa100d86387 to disappear
Mar  9 02:43:36.647: INFO: Pod pod-configmaps-ab9a79b0-db27-4ba9-8d51-7fa100d86387 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:43:36.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2013" for this suite.
Mar  9 02:43:44.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:43:45.222: INFO: namespace configmap-2013 deletion completed in 8.566424541s

• [SLOW TEST:13.800 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:43:45.223: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-698
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:43:45.616: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar  9 02:43:50.625: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  9 02:43:50.626: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  9 02:43:54.723: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-698 /apis/apps/v1/namespaces/deployment-698/deployments/test-cleanup-deployment 253da543-03d1-405b-a2d9-93a5abd62a3c 108626 1 2020-03-09 02:43:50 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0052a0888 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-03-09 02:43:50 +0000 UTC,LastTransitionTime:2020-03-09 02:43:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-658687d769" has successfully progressed.,LastUpdateTime:2020-03-09 02:43:54 +0000 UTC,LastTransitionTime:2020-03-09 02:43:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Mar  9 02:43:54.730: INFO: New ReplicaSet "test-cleanup-deployment-658687d769" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-658687d769  deployment-698 /apis/apps/v1/namespaces/deployment-698/replicasets/test-cleanup-deployment-658687d769 2df0d95f-ba71-487d-aa89-7a5b75b501b3 108615 1 2020-03-09 02:43:50 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:658687d769] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 253da543-03d1-405b-a2d9-93a5abd62a3c 0xc0052a0ca7 0xc0052a0ca8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 658687d769,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:658687d769] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0052a0d08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar  9 02:43:54.738: INFO: Pod "test-cleanup-deployment-658687d769-qs2gl" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-658687d769-qs2gl test-cleanup-deployment-658687d769- deployment-698 /api/v1/namespaces/deployment-698/pods/test-cleanup-deployment-658687d769-qs2gl 0bed96c1-9869-45e8-b187-73fc8134eeca 108614 0 2020-03-09 02:43:50 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:658687d769] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-658687d769 2df0d95f-ba71-487d-aa89-7a5b75b501b3 0xc0052a10a7 0xc0052a10a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-xhdnx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-xhdnx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:172.20.8.7/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-xhdnx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:43:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:43:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:43:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 02:43:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:10.244.3.106,StartTime:2020-03-09 02:43:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 02:43:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/redis:5.0.5-alpine,ImageID:docker-pullable://172.20.8.7/library/redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c,ContainerID:docker://0ee7b42ab69e153c351248d59a9d81f94bff83d872a34919498786487c4b8343,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.106,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:43:54.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-698" for this suite.
Mar  9 02:44:02.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:44:03.005: INFO: namespace deployment-698 deletion completed in 8.257332888s

• [SLOW TEST:17.782 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:44:03.006: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6751
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:44:03.342: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-27721cc6-767e-4778-976a-16a487eb0644" in namespace "security-context-test-6751" to be "success or failure"
Mar  9 02:44:03.500: INFO: Pod "busybox-readonly-false-27721cc6-767e-4778-976a-16a487eb0644": Phase="Pending", Reason="", readiness=false. Elapsed: 157.961997ms
Mar  9 02:44:05.539: INFO: Pod "busybox-readonly-false-27721cc6-767e-4778-976a-16a487eb0644": Phase="Pending", Reason="", readiness=false. Elapsed: 2.197150068s
Mar  9 02:44:07.547: INFO: Pod "busybox-readonly-false-27721cc6-767e-4778-976a-16a487eb0644": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.205337023s
Mar  9 02:44:07.547: INFO: Pod "busybox-readonly-false-27721cc6-767e-4778-976a-16a487eb0644" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:44:07.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6751" for this suite.
Mar  9 02:44:15.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:44:15.878: INFO: namespace security-context-test-6751 deletion completed in 8.30946771s

• [SLOW TEST:12.873 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:44:15.879: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3870
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:44:20.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3870" for this suite.
Mar  9 02:45:06.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:45:06.560: INFO: namespace kubelet-test-3870 deletion completed in 46.230423355s

• [SLOW TEST:50.681 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:45:06.561: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1725
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-e005f4d8-a784-422b-98c5-a9f411cd0792 in namespace container-probe-1725
Mar  9 02:45:10.997: INFO: Started pod busybox-e005f4d8-a784-422b-98c5-a9f411cd0792 in namespace container-probe-1725
STEP: checking the pod's current state and verifying that restartCount is present
Mar  9 02:45:11.003: INFO: Initial restart count of pod busybox-e005f4d8-a784-422b-98c5-a9f411cd0792 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:49:12.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1725" for this suite.
Mar  9 02:49:18.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:49:19.053: INFO: namespace container-probe-1725 deletion completed in 6.282364264s

• [SLOW TEST:252.492 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:49:19.054: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7004
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 02:49:21.576: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 02:49:23.605: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318961, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318961, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318961, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719318961, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 02:49:26.796: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:49:26.802: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:49:33.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7004" for this suite.
Mar  9 02:49:41.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:49:41.727: INFO: namespace webhook-7004 deletion completed in 8.279876972s
STEP: Destroying namespace "webhook-7004-markers" for this suite.
Mar  9 02:49:47.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:49:47.969: INFO: namespace webhook-7004-markers deletion completed in 6.241887828s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.965 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:49:48.020: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9632
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  9 02:49:58.633: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 02:49:58.638: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 02:50:00.639: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 02:50:00.646: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 02:50:02.639: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 02:50:02.647: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  9 02:50:04.639: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  9 02:50:04.648: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:50:04.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9632" for this suite.
Mar  9 02:50:34.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:50:34.993: INFO: namespace container-lifecycle-hook-9632 deletion completed in 30.290622852s

• [SLOW TEST:46.974 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:50:34.995: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3103
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-aca63b66-9de4-4d91-96b0-e6bff39dbc52
STEP: Creating a pod to test consume configMaps
Mar  9 02:50:35.407: INFO: Waiting up to 5m0s for pod "pod-configmaps-e68d15d5-8643-4087-965e-074e2b2747ff" in namespace "configmap-3103" to be "success or failure"
Mar  9 02:50:35.413: INFO: Pod "pod-configmaps-e68d15d5-8643-4087-965e-074e2b2747ff": Phase="Pending", Reason="", readiness=false. Elapsed: 5.170954ms
Mar  9 02:50:37.421: INFO: Pod "pod-configmaps-e68d15d5-8643-4087-965e-074e2b2747ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013411101s
Mar  9 02:50:39.428: INFO: Pod "pod-configmaps-e68d15d5-8643-4087-965e-074e2b2747ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02019506s
STEP: Saw pod success
Mar  9 02:50:39.428: INFO: Pod "pod-configmaps-e68d15d5-8643-4087-965e-074e2b2747ff" satisfied condition "success or failure"
Mar  9 02:50:39.435: INFO: Trying to get logs from node worker1 pod pod-configmaps-e68d15d5-8643-4087-965e-074e2b2747ff container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 02:50:39.579: INFO: Waiting for pod pod-configmaps-e68d15d5-8643-4087-965e-074e2b2747ff to disappear
Mar  9 02:50:39.595: INFO: Pod pod-configmaps-e68d15d5-8643-4087-965e-074e2b2747ff no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:50:39.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3103" for this suite.
Mar  9 02:50:45.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:50:45.861: INFO: namespace configmap-3103 deletion completed in 6.246760718s

• [SLOW TEST:10.867 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:50:45.862: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9399
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Mar  9 02:50:46.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-9399'
Mar  9 02:50:47.025: INFO: stderr: ""
Mar  9 02:50:47.026: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 02:50:47.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9399'
Mar  9 02:50:47.252: INFO: stderr: ""
Mar  9 02:50:47.252: INFO: stdout: "update-demo-nautilus-44trl update-demo-nautilus-gvfsf "
Mar  9 02:50:47.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-44trl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:50:47.570: INFO: stderr: ""
Mar  9 02:50:47.570: INFO: stdout: ""
Mar  9 02:50:47.570: INFO: update-demo-nautilus-44trl is created but not running
Mar  9 02:50:52.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9399'
Mar  9 02:50:52.784: INFO: stderr: ""
Mar  9 02:50:52.784: INFO: stdout: "update-demo-nautilus-44trl update-demo-nautilus-gvfsf "
Mar  9 02:50:52.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-44trl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:50:52.988: INFO: stderr: ""
Mar  9 02:50:52.988: INFO: stdout: "true"
Mar  9 02:50:52.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-44trl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:50:53.201: INFO: stderr: ""
Mar  9 02:50:53.201: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  9 02:50:53.202: INFO: validating pod update-demo-nautilus-44trl
Mar  9 02:50:53.213: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 02:50:53.213: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 02:50:53.213: INFO: update-demo-nautilus-44trl is verified up and running
Mar  9 02:50:53.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-gvfsf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:50:53.411: INFO: stderr: ""
Mar  9 02:50:53.411: INFO: stdout: "true"
Mar  9 02:50:53.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-gvfsf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:50:53.622: INFO: stderr: ""
Mar  9 02:50:53.622: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  9 02:50:53.622: INFO: validating pod update-demo-nautilus-gvfsf
Mar  9 02:50:53.633: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 02:50:53.633: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 02:50:53.633: INFO: update-demo-nautilus-gvfsf is verified up and running
STEP: scaling down the replication controller
Mar  9 02:50:53.639: INFO: scanned /root for discovery docs: <nil>
Mar  9 02:50:53.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9399'
Mar  9 02:50:55.132: INFO: stderr: ""
Mar  9 02:50:55.132: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 02:50:55.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9399'
Mar  9 02:50:55.344: INFO: stderr: ""
Mar  9 02:50:55.344: INFO: stdout: "update-demo-nautilus-44trl update-demo-nautilus-gvfsf "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  9 02:51:00.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9399'
Mar  9 02:51:00.562: INFO: stderr: ""
Mar  9 02:51:00.562: INFO: stdout: "update-demo-nautilus-gvfsf "
Mar  9 02:51:00.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-gvfsf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:51:00.774: INFO: stderr: ""
Mar  9 02:51:00.774: INFO: stdout: "true"
Mar  9 02:51:00.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-gvfsf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:51:00.992: INFO: stderr: ""
Mar  9 02:51:00.993: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  9 02:51:00.993: INFO: validating pod update-demo-nautilus-gvfsf
Mar  9 02:51:01.001: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 02:51:01.002: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 02:51:01.002: INFO: update-demo-nautilus-gvfsf is verified up and running
STEP: scaling up the replication controller
Mar  9 02:51:01.006: INFO: scanned /root for discovery docs: <nil>
Mar  9 02:51:01.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9399'
Mar  9 02:51:02.280: INFO: stderr: ""
Mar  9 02:51:02.280: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 02:51:02.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9399'
Mar  9 02:51:02.500: INFO: stderr: ""
Mar  9 02:51:02.500: INFO: stdout: "update-demo-nautilus-g8bkm update-demo-nautilus-gvfsf "
Mar  9 02:51:02.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-g8bkm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:51:02.742: INFO: stderr: ""
Mar  9 02:51:02.742: INFO: stdout: ""
Mar  9 02:51:02.742: INFO: update-demo-nautilus-g8bkm is created but not running
Mar  9 02:51:07.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9399'
Mar  9 02:51:07.958: INFO: stderr: ""
Mar  9 02:51:07.958: INFO: stdout: "update-demo-nautilus-g8bkm update-demo-nautilus-gvfsf "
Mar  9 02:51:07.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-g8bkm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:51:08.159: INFO: stderr: ""
Mar  9 02:51:08.159: INFO: stdout: "true"
Mar  9 02:51:08.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-g8bkm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:51:08.364: INFO: stderr: ""
Mar  9 02:51:08.364: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  9 02:51:08.364: INFO: validating pod update-demo-nautilus-g8bkm
Mar  9 02:51:08.375: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 02:51:08.375: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 02:51:08.375: INFO: update-demo-nautilus-g8bkm is verified up and running
Mar  9 02:51:08.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-gvfsf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:51:08.573: INFO: stderr: ""
Mar  9 02:51:08.574: INFO: stdout: "true"
Mar  9 02:51:08.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-gvfsf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9399'
Mar  9 02:51:08.911: INFO: stderr: ""
Mar  9 02:51:08.911: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  9 02:51:08.911: INFO: validating pod update-demo-nautilus-gvfsf
Mar  9 02:51:08.969: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 02:51:08.969: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 02:51:08.969: INFO: update-demo-nautilus-gvfsf is verified up and running
STEP: using delete to clean up resources
Mar  9 02:51:08.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete --grace-period=0 --force -f - --namespace=kubectl-9399'
Mar  9 02:51:09.227: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 02:51:09.227: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  9 02:51:09.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9399'
Mar  9 02:51:09.436: INFO: stderr: "No resources found in kubectl-9399 namespace.\n"
Mar  9 02:51:09.436: INFO: stdout: ""
Mar  9 02:51:09.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -l name=update-demo --namespace=kubectl-9399 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  9 02:51:09.644: INFO: stderr: ""
Mar  9 02:51:09.645: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:51:09.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9399" for this suite.
Mar  9 02:51:23.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:51:23.954: INFO: namespace kubectl-9399 deletion completed in 14.258038179s

• [SLOW TEST:38.092 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:51:23.955: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6850
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:51:40.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6850" for this suite.
Mar  9 02:51:48.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:51:49.024: INFO: namespace resourcequota-6850 deletion completed in 8.315562171s

• [SLOW TEST:25.069 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:51:49.025: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1580
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  9 02:51:49.441: INFO: Waiting up to 5m0s for pod "pod-1dcc525c-a31c-48d4-9261-a75cb82403f4" in namespace "emptydir-1580" to be "success or failure"
Mar  9 02:51:49.446: INFO: Pod "pod-1dcc525c-a31c-48d4-9261-a75cb82403f4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.182994ms
Mar  9 02:51:51.454: INFO: Pod "pod-1dcc525c-a31c-48d4-9261-a75cb82403f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013180111s
Mar  9 02:51:53.461: INFO: Pod "pod-1dcc525c-a31c-48d4-9261-a75cb82403f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020505373s
STEP: Saw pod success
Mar  9 02:51:53.461: INFO: Pod "pod-1dcc525c-a31c-48d4-9261-a75cb82403f4" satisfied condition "success or failure"
Mar  9 02:51:53.467: INFO: Trying to get logs from node worker1 pod pod-1dcc525c-a31c-48d4-9261-a75cb82403f4 container test-container: <nil>
STEP: delete the pod
Mar  9 02:51:53.548: INFO: Waiting for pod pod-1dcc525c-a31c-48d4-9261-a75cb82403f4 to disappear
Mar  9 02:51:53.556: INFO: Pod pod-1dcc525c-a31c-48d4-9261-a75cb82403f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:51:53.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1580" for this suite.
Mar  9 02:52:01.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:52:01.760: INFO: namespace emptydir-1580 deletion completed in 8.191636596s

• [SLOW TEST:12.735 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:52:01.761: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5685
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Mar  9 02:52:02.427: INFO: Waiting up to 5m0s for pod "var-expansion-a43c8226-b748-4ad3-b667-b956de3cab52" in namespace "var-expansion-5685" to be "success or failure"
Mar  9 02:52:02.625: INFO: Pod "var-expansion-a43c8226-b748-4ad3-b667-b956de3cab52": Phase="Pending", Reason="", readiness=false. Elapsed: 197.859127ms
Mar  9 02:52:04.670: INFO: Pod "var-expansion-a43c8226-b748-4ad3-b667-b956de3cab52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.242780446s
Mar  9 02:52:06.679: INFO: Pod "var-expansion-a43c8226-b748-4ad3-b667-b956de3cab52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.251606211s
STEP: Saw pod success
Mar  9 02:52:06.679: INFO: Pod "var-expansion-a43c8226-b748-4ad3-b667-b956de3cab52" satisfied condition "success or failure"
Mar  9 02:52:06.684: INFO: Trying to get logs from node worker1 pod var-expansion-a43c8226-b748-4ad3-b667-b956de3cab52 container dapi-container: <nil>
STEP: delete the pod
Mar  9 02:52:06.817: INFO: Waiting for pod var-expansion-a43c8226-b748-4ad3-b667-b956de3cab52 to disappear
Mar  9 02:52:06.822: INFO: Pod var-expansion-a43c8226-b748-4ad3-b667-b956de3cab52 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:52:06.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5685" for this suite.
Mar  9 02:52:14.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:52:15.058: INFO: namespace var-expansion-5685 deletion completed in 8.226479359s

• [SLOW TEST:13.298 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:52:15.059: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3816
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3816
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-3816
Mar  9 02:52:15.901: INFO: Found 0 stateful pods, waiting for 1
Mar  9 02:52:25.910: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  9 02:52:25.955: INFO: Deleting all statefulset in ns statefulset-3816
Mar  9 02:52:26.251: INFO: Scaling statefulset ss to 0
Mar  9 02:52:36.294: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 02:52:36.299: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:52:36.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3816" for this suite.
Mar  9 02:52:46.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:52:46.634: INFO: namespace statefulset-3816 deletion completed in 10.207360964s

• [SLOW TEST:31.575 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:52:46.637: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-9708
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:52:47.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9708" for this suite.
Mar  9 02:52:55.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:52:55.682: INFO: namespace tables-9708 deletion completed in 8.352728924s

• [SLOW TEST:9.044 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:52:55.683: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-65
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:52:56.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-65" for this suite.
Mar  9 02:53:24.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:53:24.732: INFO: namespace pods-65 deletion completed in 28.359401099s

• [SLOW TEST:29.049 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:53:24.733: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-515
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  9 02:53:30.222: INFO: Successfully updated pod "labelsupdatea477da9f-e7fb-4d92-8b96-50f715d91a93"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:53:32.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-515" for this suite.
Mar  9 02:54:04.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:54:04.703: INFO: namespace downward-api-515 deletion completed in 32.181107633s

• [SLOW TEST:39.970 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:54:04.705: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1241
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  9 02:54:09.811: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a3545fb4-720d-47fd-a027-ffbd6174e213"
Mar  9 02:54:09.811: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a3545fb4-720d-47fd-a027-ffbd6174e213" in namespace "pods-1241" to be "terminated due to deadline exceeded"
Mar  9 02:54:09.817: INFO: Pod "pod-update-activedeadlineseconds-a3545fb4-720d-47fd-a027-ffbd6174e213": Phase="Running", Reason="", readiness=true. Elapsed: 5.82375ms
Mar  9 02:54:11.851: INFO: Pod "pod-update-activedeadlineseconds-a3545fb4-720d-47fd-a027-ffbd6174e213": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.040129275s
Mar  9 02:54:11.851: INFO: Pod "pod-update-activedeadlineseconds-a3545fb4-720d-47fd-a027-ffbd6174e213" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:54:11.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1241" for this suite.
Mar  9 02:54:19.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:54:20.096: INFO: namespace pods-1241 deletion completed in 8.186720416s

• [SLOW TEST:15.391 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:54:20.097: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2255
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  9 02:54:20.823: INFO: Waiting up to 5m0s for pod "downward-api-f79e8235-05d5-4c19-acd3-7f8510d30626" in namespace "downward-api-2255" to be "success or failure"
Mar  9 02:54:20.854: INFO: Pod "downward-api-f79e8235-05d5-4c19-acd3-7f8510d30626": Phase="Pending", Reason="", readiness=false. Elapsed: 31.317957ms
Mar  9 02:54:22.861: INFO: Pod "downward-api-f79e8235-05d5-4c19-acd3-7f8510d30626": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038043766s
Mar  9 02:54:24.869: INFO: Pod "downward-api-f79e8235-05d5-4c19-acd3-7f8510d30626": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046558806s
STEP: Saw pod success
Mar  9 02:54:24.869: INFO: Pod "downward-api-f79e8235-05d5-4c19-acd3-7f8510d30626" satisfied condition "success or failure"
Mar  9 02:54:24.875: INFO: Trying to get logs from node worker1 pod downward-api-f79e8235-05d5-4c19-acd3-7f8510d30626 container dapi-container: <nil>
STEP: delete the pod
Mar  9 02:54:25.165: INFO: Waiting for pod downward-api-f79e8235-05d5-4c19-acd3-7f8510d30626 to disappear
Mar  9 02:54:25.180: INFO: Pod downward-api-f79e8235-05d5-4c19-acd3-7f8510d30626 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:54:25.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2255" for this suite.
Mar  9 02:54:33.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:54:33.384: INFO: namespace downward-api-2255 deletion completed in 8.195107443s

• [SLOW TEST:13.287 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:54:33.387: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7286
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 02:54:33.776: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6fdf5a0-dbd8-494c-a03a-19b2db8a8936" in namespace "downward-api-7286" to be "success or failure"
Mar  9 02:54:33.812: INFO: Pod "downwardapi-volume-c6fdf5a0-dbd8-494c-a03a-19b2db8a8936": Phase="Pending", Reason="", readiness=false. Elapsed: 34.962558ms
Mar  9 02:54:35.819: INFO: Pod "downwardapi-volume-c6fdf5a0-dbd8-494c-a03a-19b2db8a8936": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042873424s
Mar  9 02:54:37.828: INFO: Pod "downwardapi-volume-c6fdf5a0-dbd8-494c-a03a-19b2db8a8936": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051530091s
STEP: Saw pod success
Mar  9 02:54:37.828: INFO: Pod "downwardapi-volume-c6fdf5a0-dbd8-494c-a03a-19b2db8a8936" satisfied condition "success or failure"
Mar  9 02:54:37.833: INFO: Trying to get logs from node worker1 pod downwardapi-volume-c6fdf5a0-dbd8-494c-a03a-19b2db8a8936 container client-container: <nil>
STEP: delete the pod
Mar  9 02:54:37.967: INFO: Waiting for pod downwardapi-volume-c6fdf5a0-dbd8-494c-a03a-19b2db8a8936 to disappear
Mar  9 02:54:38.006: INFO: Pod downwardapi-volume-c6fdf5a0-dbd8-494c-a03a-19b2db8a8936 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:54:38.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7286" for this suite.
Mar  9 02:54:44.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:54:44.291: INFO: namespace downward-api-7286 deletion completed in 6.27621181s

• [SLOW TEST:10.904 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:54:44.293: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4375
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Mar  9 02:54:44.619: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 02:54:55.378: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:55:21.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4375" for this suite.
Mar  9 02:55:30.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:55:30.295: INFO: namespace crd-publish-openapi-4375 deletion completed in 8.291814707s

• [SLOW TEST:46.001 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:55:30.295: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-3158
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 02:55:30.681: INFO: Waiting up to 5m0s for pod "busybox-user-65534-95a82bc6-7c76-4325-a21c-7449cb8a7633" in namespace "security-context-test-3158" to be "success or failure"
Mar  9 02:55:30.735: INFO: Pod "busybox-user-65534-95a82bc6-7c76-4325-a21c-7449cb8a7633": Phase="Pending", Reason="", readiness=false. Elapsed: 53.831485ms
Mar  9 02:55:32.741: INFO: Pod "busybox-user-65534-95a82bc6-7c76-4325-a21c-7449cb8a7633": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060421466s
Mar  9 02:55:34.751: INFO: Pod "busybox-user-65534-95a82bc6-7c76-4325-a21c-7449cb8a7633": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069629454s
Mar  9 02:55:34.751: INFO: Pod "busybox-user-65534-95a82bc6-7c76-4325-a21c-7449cb8a7633" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:55:34.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3158" for this suite.
Mar  9 02:55:42.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:55:42.959: INFO: namespace security-context-test-3158 deletion completed in 8.199029659s

• [SLOW TEST:12.664 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:55:42.960: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2982
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Mar  9 02:55:43.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 cluster-info'
Mar  9 02:55:51.147: INFO: stderr: ""
Mar  9 02:55:51.147: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:55:51.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2982" for this suite.
Mar  9 02:55:57.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:55:57.362: INFO: namespace kubectl-2982 deletion completed in 6.204427645s

• [SLOW TEST:14.403 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:55:57.363: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7931
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-bddc9514-68f6-4fac-951d-4c11f1f1a4bd
STEP: Creating a pod to test consume secrets
Mar  9 02:55:57.814: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-48b0e05c-1e6e-4904-9142-8ac86d7aa25e" in namespace "projected-7931" to be "success or failure"
Mar  9 02:55:57.819: INFO: Pod "pod-projected-secrets-48b0e05c-1e6e-4904-9142-8ac86d7aa25e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.279755ms
Mar  9 02:55:59.831: INFO: Pod "pod-projected-secrets-48b0e05c-1e6e-4904-9142-8ac86d7aa25e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017052662s
Mar  9 02:56:01.839: INFO: Pod "pod-projected-secrets-48b0e05c-1e6e-4904-9142-8ac86d7aa25e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024806369s
STEP: Saw pod success
Mar  9 02:56:01.839: INFO: Pod "pod-projected-secrets-48b0e05c-1e6e-4904-9142-8ac86d7aa25e" satisfied condition "success or failure"
Mar  9 02:56:01.844: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-48b0e05c-1e6e-4904-9142-8ac86d7aa25e container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 02:56:02.019: INFO: Waiting for pod pod-projected-secrets-48b0e05c-1e6e-4904-9142-8ac86d7aa25e to disappear
Mar  9 02:56:02.069: INFO: Pod pod-projected-secrets-48b0e05c-1e6e-4904-9142-8ac86d7aa25e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:56:02.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7931" for this suite.
Mar  9 02:56:10.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:56:10.380: INFO: namespace projected-7931 deletion completed in 8.302879508s

• [SLOW TEST:13.018 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:56:10.384: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-4125
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar  9 02:56:23.548: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4125 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 02:56:23.548: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 02:56:23.802: INFO: Exec stderr: ""
Mar  9 02:56:23.802: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4125 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 02:56:23.802: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 02:56:24.045: INFO: Exec stderr: ""
Mar  9 02:56:24.045: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4125 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 02:56:24.045: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 02:56:24.351: INFO: Exec stderr: ""
Mar  9 02:56:24.351: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4125 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 02:56:24.351: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 02:56:24.603: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar  9 02:56:24.604: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4125 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 02:56:24.604: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 02:56:24.852: INFO: Exec stderr: ""
Mar  9 02:56:24.852: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4125 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 02:56:24.852: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 02:56:25.109: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar  9 02:56:25.109: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4125 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 02:56:25.109: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 02:56:25.435: INFO: Exec stderr: ""
Mar  9 02:56:25.435: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4125 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 02:56:25.435: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 02:56:25.675: INFO: Exec stderr: ""
Mar  9 02:56:25.675: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4125 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 02:56:25.675: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 02:56:26.756: INFO: Exec stderr: ""
Mar  9 02:56:26.756: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4125 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 02:56:26.756: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 02:56:27.228: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:56:27.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4125" for this suite.
Mar  9 02:57:13.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:57:13.895: INFO: namespace e2e-kubelet-etc-hosts-4125 deletion completed in 46.656381937s

• [SLOW TEST:63.512 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:57:13.896: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-717
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-51923b02-3169-42af-adc5-316061cf96fe
STEP: Creating a pod to test consume secrets
Mar  9 02:57:14.289: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-55df1703-b22b-4bb6-92ba-f39a45063d29" in namespace "projected-717" to be "success or failure"
Mar  9 02:57:14.319: INFO: Pod "pod-projected-secrets-55df1703-b22b-4bb6-92ba-f39a45063d29": Phase="Pending", Reason="", readiness=false. Elapsed: 29.563831ms
Mar  9 02:57:16.328: INFO: Pod "pod-projected-secrets-55df1703-b22b-4bb6-92ba-f39a45063d29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038389278s
Mar  9 02:57:18.336: INFO: Pod "pod-projected-secrets-55df1703-b22b-4bb6-92ba-f39a45063d29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046505934s
STEP: Saw pod success
Mar  9 02:57:18.336: INFO: Pod "pod-projected-secrets-55df1703-b22b-4bb6-92ba-f39a45063d29" satisfied condition "success or failure"
Mar  9 02:57:18.341: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-55df1703-b22b-4bb6-92ba-f39a45063d29 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  9 02:57:18.600: INFO: Waiting for pod pod-projected-secrets-55df1703-b22b-4bb6-92ba-f39a45063d29 to disappear
Mar  9 02:57:18.605: INFO: Pod pod-projected-secrets-55df1703-b22b-4bb6-92ba-f39a45063d29 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 02:57:18.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-717" for this suite.
Mar  9 02:57:26.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 02:57:27.348: INFO: namespace projected-717 deletion completed in 8.735073079s

• [SLOW TEST:13.453 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 02:57:27.350: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1308
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  9 02:57:27.766: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  9 02:57:27.877: INFO: Waiting for terminating namespaces to be deleted...
Mar  9 02:57:27.883: INFO: 
Logging pods the kubelet thinks is on node worker1 before test
Mar  9 02:57:27.896: INFO: kube-flannel-ds-amd64-wgfqr from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:57:27.896: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  9 02:57:27.896: INFO: kube-proxy-94vtq from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:57:27.896: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 02:57:27.896: INFO: sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-txlws from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 02:57:27.896: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  9 02:57:27.896: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  9 02:57:27.896: INFO: sonobuoy from sonobuoy started at 2020-03-09 01:23:11 +0000 UTC (1 container statuses recorded)
Mar  9 02:57:27.896: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  9 02:57:27.896: INFO: 
Logging pods the kubelet thinks is on node worker2 before test
Mar  9 02:57:27.934: INFO: kube-flannel-ds-amd64-q9s4h from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:57:27.934: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  9 02:57:27.934: INFO: sonobuoy-e2e-job-aaa481025fe94110 from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 02:57:27.934: INFO: 	Container e2e ready: true, restart count 0
Mar  9 02:57:27.934: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  9 02:57:27.934: INFO: kube-proxy-55qqw from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 02:57:27.934: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 02:57:27.934: INFO: sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-b49xx from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 02:57:27.934: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  9 02:57:27.934: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-72f0eb05-5f4f-41db-b0fe-5c7563a562b7 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-72f0eb05-5f4f-41db-b0fe-5c7563a562b7 off the node worker1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-72f0eb05-5f4f-41db-b0fe-5c7563a562b7
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:02:36.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1308" for this suite.
Mar  9 03:02:46.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:02:47.158: INFO: namespace sched-pred-1308 deletion completed in 10.348477665s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:319.808 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:02:47.159: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4207
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-fd89288f-0188-4b6e-9df6-131e4a3e6f6f
STEP: Creating a pod to test consume configMaps
Mar  9 03:02:47.665: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-751a6c70-f868-4446-b17d-e21ce0580154" in namespace "projected-4207" to be "success or failure"
Mar  9 03:02:47.682: INFO: Pod "pod-projected-configmaps-751a6c70-f868-4446-b17d-e21ce0580154": Phase="Pending", Reason="", readiness=false. Elapsed: 17.5946ms
Mar  9 03:02:49.691: INFO: Pod "pod-projected-configmaps-751a6c70-f868-4446-b17d-e21ce0580154": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02603031s
Mar  9 03:02:51.699: INFO: Pod "pod-projected-configmaps-751a6c70-f868-4446-b17d-e21ce0580154": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034366823s
STEP: Saw pod success
Mar  9 03:02:51.699: INFO: Pod "pod-projected-configmaps-751a6c70-f868-4446-b17d-e21ce0580154" satisfied condition "success or failure"
Mar  9 03:02:51.704: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-751a6c70-f868-4446-b17d-e21ce0580154 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 03:02:51.916: INFO: Waiting for pod pod-projected-configmaps-751a6c70-f868-4446-b17d-e21ce0580154 to disappear
Mar  9 03:02:51.922: INFO: Pod pod-projected-configmaps-751a6c70-f868-4446-b17d-e21ce0580154 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:02:51.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4207" for this suite.
Mar  9 03:02:58.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:02:58.552: INFO: namespace projected-4207 deletion completed in 6.621931448s

• [SLOW TEST:11.393 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:02:58.553: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-2135
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:02:59.062: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Creating first CR 
Mar  9 03:03:04.838: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-09T03:03:04Z generation:1 name:name1 resourceVersion:111675 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:aa4e3910-d7c2-4e36-91ca-f7dd26873f89] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Mar  9 03:03:14.859: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-09T03:03:14Z generation:1 name:name2 resourceVersion:111693 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:07c787db-6bcb-493b-a0db-0dc2478cc2f6] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Mar  9 03:03:24.894: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-09T03:03:04Z generation:2 name:name1 resourceVersion:111714 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:aa4e3910-d7c2-4e36-91ca-f7dd26873f89] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Mar  9 03:03:34.933: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-09T03:03:14Z generation:2 name:name2 resourceVersion:111733 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:07c787db-6bcb-493b-a0db-0dc2478cc2f6] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Mar  9 03:03:44.997: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-09T03:03:04Z generation:2 name:name1 resourceVersion:111752 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:aa4e3910-d7c2-4e36-91ca-f7dd26873f89] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Mar  9 03:03:55.239: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-09T03:03:14Z generation:2 name:name2 resourceVersion:111773 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:07c787db-6bcb-493b-a0db-0dc2478cc2f6] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:04:05.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-2135" for this suite.
Mar  9 03:04:11.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:04:12.122: INFO: namespace crd-watch-2135 deletion completed in 6.341670842s

• [SLOW TEST:73.570 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:04:12.123: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-758
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-4497
STEP: Creating secret with name secret-test-2ff03fab-2650-40b3-9481-acee999e3a25
STEP: Creating a pod to test consume secrets
Mar  9 03:04:12.948: INFO: Waiting up to 5m0s for pod "pod-secrets-0168c83e-a376-4b80-9320-156c85539ddc" in namespace "secrets-758" to be "success or failure"
Mar  9 03:04:12.973: INFO: Pod "pod-secrets-0168c83e-a376-4b80-9320-156c85539ddc": Phase="Pending", Reason="", readiness=false. Elapsed: 24.772637ms
Mar  9 03:04:14.981: INFO: Pod "pod-secrets-0168c83e-a376-4b80-9320-156c85539ddc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032910821s
Mar  9 03:04:16.989: INFO: Pod "pod-secrets-0168c83e-a376-4b80-9320-156c85539ddc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040949148s
STEP: Saw pod success
Mar  9 03:04:16.990: INFO: Pod "pod-secrets-0168c83e-a376-4b80-9320-156c85539ddc" satisfied condition "success or failure"
Mar  9 03:04:16.995: INFO: Trying to get logs from node worker1 pod pod-secrets-0168c83e-a376-4b80-9320-156c85539ddc container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 03:04:17.076: INFO: Waiting for pod pod-secrets-0168c83e-a376-4b80-9320-156c85539ddc to disappear
Mar  9 03:04:17.081: INFO: Pod pod-secrets-0168c83e-a376-4b80-9320-156c85539ddc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:04:17.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-758" for this suite.
Mar  9 03:04:25.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:04:25.357: INFO: namespace secrets-758 deletion completed in 8.206145007s
STEP: Destroying namespace "secret-namespace-4497" for this suite.
Mar  9 03:04:31.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:04:31.558: INFO: namespace secret-namespace-4497 deletion completed in 6.20076897s

• [SLOW TEST:19.435 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:04:31.559: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2580
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-3779ee72-3a02-47f5-836e-fc7be2ad66cf in namespace container-probe-2580
Mar  9 03:04:35.988: INFO: Started pod liveness-3779ee72-3a02-47f5-836e-fc7be2ad66cf in namespace container-probe-2580
STEP: checking the pod's current state and verifying that restartCount is present
Mar  9 03:04:35.993: INFO: Initial restart count of pod liveness-3779ee72-3a02-47f5-836e-fc7be2ad66cf is 0
Mar  9 03:04:52.061: INFO: Restart count of pod container-probe-2580/liveness-3779ee72-3a02-47f5-836e-fc7be2ad66cf is now 1 (16.067402455s elapsed)
Mar  9 03:05:12.138: INFO: Restart count of pod container-probe-2580/liveness-3779ee72-3a02-47f5-836e-fc7be2ad66cf is now 2 (36.144670551s elapsed)
Mar  9 03:05:32.453: INFO: Restart count of pod container-probe-2580/liveness-3779ee72-3a02-47f5-836e-fc7be2ad66cf is now 3 (56.460082677s elapsed)
Mar  9 03:05:52.532: INFO: Restart count of pod container-probe-2580/liveness-3779ee72-3a02-47f5-836e-fc7be2ad66cf is now 4 (1m16.538314142s elapsed)
Mar  9 03:06:54.918: INFO: Restart count of pod container-probe-2580/liveness-3779ee72-3a02-47f5-836e-fc7be2ad66cf is now 5 (2m18.925142198s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:06:55.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2580" for this suite.
Mar  9 03:07:03.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:07:03.261: INFO: namespace container-probe-2580 deletion completed in 8.223553644s

• [SLOW TEST:151.702 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:07:03.262: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3297
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Mar  9 03:07:03.607: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:07:42.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3297" for this suite.
Mar  9 03:07:48.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:07:48.343: INFO: namespace crd-publish-openapi-3297 deletion completed in 6.269149021s

• [SLOW TEST:45.081 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:07:48.343: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1454
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-1454
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1454 to expose endpoints map[]
Mar  9 03:07:48.778: INFO: Get endpoints failed (34.214443ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar  9 03:07:49.789: INFO: successfully validated that service multi-endpoint-test in namespace services-1454 exposes endpoints map[] (1.044937927s elapsed)
STEP: Creating pod pod1 in namespace services-1454
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1454 to expose endpoints map[pod1:[100]]
Mar  9 03:07:52.964: INFO: successfully validated that service multi-endpoint-test in namespace services-1454 exposes endpoints map[pod1:[100]] (3.061065544s elapsed)
STEP: Creating pod pod2 in namespace services-1454
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1454 to expose endpoints map[pod1:[100] pod2:[101]]
Mar  9 03:07:56.232: INFO: successfully validated that service multi-endpoint-test in namespace services-1454 exposes endpoints map[pod1:[100] pod2:[101]] (3.24727283s elapsed)
STEP: Deleting pod pod1 in namespace services-1454
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1454 to expose endpoints map[pod2:[101]]
Mar  9 03:07:57.397: INFO: successfully validated that service multi-endpoint-test in namespace services-1454 exposes endpoints map[pod2:[101]] (1.146418093s elapsed)
STEP: Deleting pod pod2 in namespace services-1454
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1454 to expose endpoints map[]
Mar  9 03:07:57.596: INFO: successfully validated that service multi-endpoint-test in namespace services-1454 exposes endpoints map[] (7.687658ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:07:57.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1454" for this suite.
Mar  9 03:08:05.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:08:06.148: INFO: namespace services-1454 deletion completed in 8.281549793s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:17.805 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:08:06.149: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5527
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5527
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5527
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5527
Mar  9 03:08:06.562: INFO: Found 0 stateful pods, waiting for 1
Mar  9 03:08:16.573: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar  9 03:08:16.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  9 03:08:20.399: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  9 03:08:20.399: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  9 03:08:20.399: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  9 03:08:20.408: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  9 03:08:30.417: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 03:08:30.417: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 03:08:30.501: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999333s
Mar  9 03:08:31.511: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990893277s
Mar  9 03:08:32.519: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.981371862s
Mar  9 03:08:33.527: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.97298322s
Mar  9 03:08:34.536: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.964443895s
Mar  9 03:08:35.545: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.955804931s
Mar  9 03:08:36.573: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.947048832s
Mar  9 03:08:37.582: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.919150841s
Mar  9 03:08:38.589: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.90999093s
Mar  9 03:08:39.598: INFO: Verifying statefulset ss doesn't scale past 1 for another 902.986921ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5527
Mar  9 03:08:40.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:08:41.071: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  9 03:08:41.071: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  9 03:08:41.071: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  9 03:08:41.079: INFO: Found 1 stateful pods, waiting for 3
Mar  9 03:08:51.087: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 03:08:51.087: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  9 03:08:51.087: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar  9 03:08:51.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  9 03:08:51.536: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  9 03:08:51.537: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  9 03:08:51.537: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  9 03:08:51.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  9 03:08:52.000: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  9 03:08:52.000: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  9 03:08:52.000: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  9 03:08:52.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  9 03:08:52.604: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  9 03:08:52.604: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  9 03:08:52.604: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  9 03:08:52.604: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 03:08:52.611: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Mar  9 03:09:02.628: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 03:09:02.628: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 03:09:02.628: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  9 03:09:02.672: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999876s
Mar  9 03:09:03.681: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98208652s
Mar  9 03:09:04.690: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.973347694s
Mar  9 03:09:05.698: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.964264903s
Mar  9 03:09:06.706: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.955913074s
Mar  9 03:09:07.715: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.94831183s
Mar  9 03:09:08.724: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.938924328s
Mar  9 03:09:09.733: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.930083232s
Mar  9 03:09:10.744: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.921560171s
Mar  9 03:09:11.753: INFO: Verifying statefulset ss doesn't scale past 3 for another 910.404544ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5527
Mar  9 03:09:12.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:09:13.320: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  9 03:09:13.320: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  9 03:09:13.320: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  9 03:09:13.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:09:13.855: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  9 03:09:13.855: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  9 03:09:13.856: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  9 03:09:13.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:09:14.307: INFO: rc: 1
Mar  9 03:09:14.307: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server: 
 [] <nil> 0xc007d317d0 exit status 1 <nil> <nil> true [0xc001de6470 0xc001de6488 0xc001de64a0] [0xc001de6470 0xc001de6488 0xc001de64a0] [0xc001de6480 0xc001de6498] [0x10efe30 0x10efe30] 0xc001303140 <nil>}:
Command stdout:

stderr:
Error from server: 

error:
exit status 1
Mar  9 03:09:24.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:09:24.520: INFO: rc: 1
Mar  9 03:09:24.521: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0045f6120 exit status 1 <nil> <nil> true [0xc002f041b8 0xc002f04218 0xc002f04230] [0xc002f041b8 0xc002f04218 0xc002f04230] [0xc002f04200 0xc002f04228] [0x10efe30 0x10efe30] 0xc00350e9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:09:34.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:09:34.737: INFO: rc: 1
Mar  9 03:09:34.738: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc007d31b60 exit status 1 <nil> <nil> true [0xc001de64a8 0xc001de64c0 0xc001de64d8] [0xc001de64a8 0xc001de64c0 0xc001de64d8] [0xc001de64b8 0xc001de64d0] [0x10efe30 0x10efe30] 0xc0013035c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:09:44.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:09:44.962: INFO: rc: 1
Mar  9 03:09:44.962: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004696360 exit status 1 <nil> <nil> true [0xc000542fd8 0xc0005434e8 0xc000543a58] [0xc000542fd8 0xc0005434e8 0xc000543a58] [0xc000543448 0xc000543658] [0x10efe30 0x10efe30] 0xc002a2a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:09:54.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:09:55.178: INFO: rc: 1
Mar  9 03:09:55.178: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0038da360 exit status 1 <nil> <nil> true [0xc0009722e0 0xc000972748 0xc0009730e8] [0xc0009722e0 0xc000972748 0xc0009730e8] [0xc0009726b0 0xc000972d70] [0x10efe30 0x10efe30] 0xc001548660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:10:05.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:10:05.439: INFO: rc: 1
Mar  9 03:10:05.439: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0046966f0 exit status 1 <nil> <nil> true [0xc000543e00 0xc000543fd8 0xc003084010] [0xc000543e00 0xc000543fd8 0xc003084010] [0xc000543fc8 0xc003084008] [0x10efe30 0x10efe30] 0xc002a2a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:10:15.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:10:15.640: INFO: rc: 1
Mar  9 03:10:15.641: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004696a80 exit status 1 <nil> <nil> true [0xc003084018 0xc003084030 0xc003084090] [0xc003084018 0xc003084030 0xc003084090] [0xc003084028 0xc003084080] [0x10efe30 0x10efe30] 0xc002a2aa20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:10:25.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:10:25.858: INFO: rc: 1
Mar  9 03:10:25.859: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004696e10 exit status 1 <nil> <nil> true [0xc0030840a0 0xc0030840c8 0xc0030840e0] [0xc0030840a0 0xc0030840c8 0xc0030840e0] [0xc0030840c0 0xc0030840d8] [0x10efe30 0x10efe30] 0xc002a2ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:10:35.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:10:36.086: INFO: rc: 1
Mar  9 03:10:36.087: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004697140 exit status 1 <nil> <nil> true [0xc000a2a040 0xc000a2a140 0xc000a2a2e0] [0xc000a2a040 0xc000a2a140 0xc000a2a2e0] [0xc000a2a108 0xc000a2a2b0] [0x10efe30 0x10efe30] 0xc002a2af00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:10:46.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:10:46.291: INFO: rc: 1
Mar  9 03:10:46.291: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0046974d0 exit status 1 <nil> <nil> true [0xc0030840f0 0xc003084140 0xc003084170] [0xc0030840f0 0xc003084140 0xc003084170] [0xc003084120 0xc003084160] [0x10efe30 0x10efe30] 0xc002a2b2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:10:56.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:10:56.492: INFO: rc: 1
Mar  9 03:10:56.492: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0038da750 exit status 1 <nil> <nil> true [0xc000973258 0xc0009736a0 0xc000973908] [0xc000973258 0xc0009736a0 0xc000973908] [0xc000973488 0xc000973878] [0x10efe30 0x10efe30] 0xc001548c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:11:06.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:11:06.704: INFO: rc: 1
Mar  9 03:11:06.705: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004697890 exit status 1 <nil> <nil> true [0xc003084180 0xc0030841a0 0xc0030841b8] [0xc003084180 0xc0030841a0 0xc0030841b8] [0xc003084198 0xc0030841b0] [0x10efe30 0x10efe30] 0xc002a2b800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:11:16.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:11:16.926: INFO: rc: 1
Mar  9 03:11:16.927: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004697d10 exit status 1 <nil> <nil> true [0xc0030841c0 0xc0030841e8 0xc003084220] [0xc0030841c0 0xc0030841e8 0xc003084220] [0xc0030841d8 0xc003084208] [0x10efe30 0x10efe30] 0xc002a2bf20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:11:26.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:11:27.148: INFO: rc: 1
Mar  9 03:11:27.148: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0053a4450 exit status 1 <nil> <nil> true [0xc000a2a300 0xc000a2a3f8 0xc000a2a480] [0xc000a2a300 0xc000a2a3f8 0xc000a2a480] [0xc000a2a388 0xc000a2a440] [0x10efe30 0x10efe30] 0xc0033046c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:11:37.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:11:37.367: INFO: rc: 1
Mar  9 03:11:37.367: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0053a4810 exit status 1 <nil> <nil> true [0xc000a2a4d0 0xc000a2a590 0xc000a2a6d0] [0xc000a2a4d0 0xc000a2a590 0xc000a2a6d0] [0xc000a2a548 0xc000a2a680] [0x10efe30 0x10efe30] 0xc003304ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:11:47.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:11:47.520: INFO: rc: 1
Mar  9 03:11:47.520: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004696390 exit status 1 <nil> <nil> true [0xc000542fd8 0xc0005434e8 0xc000543a58] [0xc000542fd8 0xc0005434e8 0xc000543a58] [0xc000543448 0xc000543658] [0x10efe30 0x10efe30] 0xc002a2a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:11:57.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:11:57.737: INFO: rc: 1
Mar  9 03:11:57.737: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004696750 exit status 1 <nil> <nil> true [0xc000543e00 0xc000543fd8 0xc003084010] [0xc000543e00 0xc000543fd8 0xc003084010] [0xc000543fc8 0xc003084008] [0x10efe30 0x10efe30] 0xc002a2a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:12:07.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:12:07.900: INFO: rc: 1
Mar  9 03:12:07.901: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004696b40 exit status 1 <nil> <nil> true [0xc003084018 0xc003084030 0xc003084090] [0xc003084018 0xc003084030 0xc003084090] [0xc003084028 0xc003084080] [0x10efe30 0x10efe30] 0xc002a2aa20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:12:17.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:12:18.116: INFO: rc: 1
Mar  9 03:12:18.116: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004696f00 exit status 1 <nil> <nil> true [0xc0030840a0 0xc0030840c8 0xc0030840e0] [0xc0030840a0 0xc0030840c8 0xc0030840e0] [0xc0030840c0 0xc0030840d8] [0x10efe30 0x10efe30] 0xc002a2ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:12:28.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:12:28.342: INFO: rc: 1
Mar  9 03:12:28.343: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0046972c0 exit status 1 <nil> <nil> true [0xc0030840f0 0xc003084140 0xc003084170] [0xc0030840f0 0xc003084140 0xc003084170] [0xc003084120 0xc003084160] [0x10efe30 0x10efe30] 0xc002a2b1a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:12:38.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:12:38.562: INFO: rc: 1
Mar  9 03:12:38.562: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005d8a390 exit status 1 <nil> <nil> true [0xc000a2a040 0xc000a2a140 0xc000a2a2e0] [0xc000a2a040 0xc000a2a140 0xc000a2a2e0] [0xc000a2a108 0xc000a2a2b0] [0x10efe30 0x10efe30] 0xc003304420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:12:48.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:12:48.798: INFO: rc: 1
Mar  9 03:12:48.798: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005d8a990 exit status 1 <nil> <nil> true [0xc000a2a300 0xc000a2a3f8 0xc000a2a480] [0xc000a2a300 0xc000a2a3f8 0xc000a2a480] [0xc000a2a388 0xc000a2a440] [0x10efe30 0x10efe30] 0xc0033048a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:12:58.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:12:59.027: INFO: rc: 1
Mar  9 03:12:59.027: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004697680 exit status 1 <nil> <nil> true [0xc003084180 0xc0030841a0 0xc0030841b8] [0xc003084180 0xc0030841a0 0xc0030841b8] [0xc003084198 0xc0030841b0] [0x10efe30 0x10efe30] 0xc002a2b560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:13:09.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:13:09.270: INFO: rc: 1
Mar  9 03:13:09.270: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004697ad0 exit status 1 <nil> <nil> true [0xc0030841c0 0xc0030841e8 0xc003084220] [0xc0030841c0 0xc0030841e8 0xc003084220] [0xc0030841d8 0xc003084208] [0x10efe30 0x10efe30] 0xc002a2bce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:13:19.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:13:19.489: INFO: rc: 1
Mar  9 03:13:19.490: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004697ef0 exit status 1 <nil> <nil> true [0xc003084230 0xc003084280 0xc0030842a8] [0xc003084230 0xc003084280 0xc0030842a8] [0xc003084268 0xc003084298] [0x10efe30 0x10efe30] 0xc001548300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:13:29.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:13:29.705: INFO: rc: 1
Mar  9 03:13:29.705: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0038da2a0 exit status 1 <nil> <nil> true [0xc0030842b8 0xc0030842e0 0xc003084300] [0xc0030842b8 0xc0030842e0 0xc003084300] [0xc0030842d8 0xc0030842f8] [0x10efe30 0x10efe30] 0xc0015489c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:13:39.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:13:39.939: INFO: rc: 1
Mar  9 03:13:39.939: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0038da660 exit status 1 <nil> <nil> true [0xc003084308 0xc003084350 0xc003084380] [0xc003084308 0xc003084350 0xc003084380] [0xc003084330 0xc003084370] [0x10efe30 0x10efe30] 0xc001548ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:13:49.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:13:50.158: INFO: rc: 1
Mar  9 03:13:50.158: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004696360 exit status 1 <nil> <nil> true [0xc000542fd8 0xc0005434e8 0xc000543a58] [0xc000542fd8 0xc0005434e8 0xc000543a58] [0xc000543448 0xc000543658] [0x10efe30 0x10efe30] 0xc002a2a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:14:00.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:14:00.381: INFO: rc: 1
Mar  9 03:14:00.381: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0038da3c0 exit status 1 <nil> <nil> true [0xc003084000 0xc003084018 0xc003084030] [0xc003084000 0xc003084018 0xc003084030] [0xc003084010 0xc003084028] [0x10efe30 0x10efe30] 0xc001548660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:14:10.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:14:10.604: INFO: rc: 1
Mar  9 03:14:10.604: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004696720 exit status 1 <nil> <nil> true [0xc000543e00 0xc000543fd8 0xc000a2a108] [0xc000543e00 0xc000543fd8 0xc000a2a108] [0xc000543fc8 0xc000a2a0c0] [0x10efe30 0x10efe30] 0xc002a2a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Mar  9 03:14:20.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=statefulset-5527 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  9 03:14:20.825: INFO: rc: 1
Mar  9 03:14:20.825: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Mar  9 03:14:20.825: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  9 03:14:20.872: INFO: Deleting all statefulset in ns statefulset-5527
Mar  9 03:14:20.878: INFO: Scaling statefulset ss to 0
Mar  9 03:14:20.920: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 03:14:20.980: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:14:21.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5527" for this suite.
Mar  9 03:14:29.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:14:29.309: INFO: namespace statefulset-5527 deletion completed in 8.232801881s

• [SLOW TEST:383.160 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:14:29.310: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7564
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7564
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  9 03:14:29.791: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  9 03:14:50.275: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.92:8080/dial?request=hostName&protocol=http&host=10.244.3.112&port=8080&tries=1'] Namespace:pod-network-test-7564 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 03:14:50.275: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 03:14:50.564: INFO: Waiting for endpoints: map[]
Mar  9 03:14:50.571: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.92:8080/dial?request=hostName&protocol=http&host=10.244.4.91&port=8080&tries=1'] Namespace:pod-network-test-7564 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 03:14:50.571: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 03:14:50.838: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:14:50.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7564" for this suite.
Mar  9 03:15:04.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:15:05.126: INFO: namespace pod-network-test-7564 deletion completed in 14.276031257s

• [SLOW TEST:35.816 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:15:05.128: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7635
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Mar  9 03:15:05.933: INFO: namespace kubectl-7635
Mar  9 03:15:05.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-7635'
Mar  9 03:15:06.824: INFO: stderr: ""
Mar  9 03:15:06.824: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  9 03:15:07.833: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 03:15:07.833: INFO: Found 0 / 1
Mar  9 03:15:08.834: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 03:15:08.834: INFO: Found 0 / 1
Mar  9 03:15:09.832: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 03:15:09.832: INFO: Found 1 / 1
Mar  9 03:15:09.832: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  9 03:15:09.839: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 03:15:09.839: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  9 03:15:09.839: INFO: wait on redis-master startup in kubectl-7635 
Mar  9 03:15:09.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 logs redis-master-b46fv redis-master --namespace=kubectl-7635'
Mar  9 03:15:10.106: INFO: stderr: ""
Mar  9 03:15:10.106: INFO: stdout: "1:C 09 Mar 2020 03:15:09.050 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 09 Mar 2020 03:15:09.050 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 09 Mar 2020 03:15:09.050 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 09 Mar 2020 03:15:09.053 * Running mode=standalone, port=6379.\n1:M 09 Mar 2020 03:15:09.054 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Mar 2020 03:15:09.054 # Server initialized\n1:M 09 Mar 2020 03:15:09.054 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Mar 2020 03:15:09.054 * Ready to accept connections\n"
STEP: exposing RC
Mar  9 03:15:10.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7635'
Mar  9 03:15:10.489: INFO: stderr: ""
Mar  9 03:15:10.489: INFO: stdout: "service/rm2 exposed\n"
Mar  9 03:15:10.583: INFO: Service rm2 in namespace kubectl-7635 found.
STEP: exposing service
Mar  9 03:15:12.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7635'
Mar  9 03:15:12.889: INFO: stderr: ""
Mar  9 03:15:12.889: INFO: stdout: "service/rm3 exposed\n"
Mar  9 03:15:12.977: INFO: Service rm3 in namespace kubectl-7635 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:15:14.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7635" for this suite.
Mar  9 03:15:45.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:15:45.226: INFO: namespace kubectl-7635 deletion completed in 30.195516761s

• [SLOW TEST:40.098 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:15:45.227: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6222
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Mar  9 03:15:55.763: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:15:55.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0309 03:15:55.762813      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-6222" for this suite.
Mar  9 03:16:03.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:16:03.957: INFO: namespace gc-6222 deletion completed in 8.18650394s

• [SLOW TEST:18.730 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:16:03.958: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7851
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:16:32.399: INFO: Container started at 2020-03-09 03:16:06 +0000 UTC, pod became ready at 2020-03-09 03:16:30 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:16:32.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7851" for this suite.
Mar  9 03:17:02.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:17:02.655: INFO: namespace container-probe-7851 deletion completed in 30.243351648s

• [SLOW TEST:58.697 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:17:02.656: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-2240
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  9 03:17:03.063: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  9 03:17:29.402: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.97:8080/dial?request=hostName&protocol=udp&host=10.244.3.114&port=8081&tries=1'] Namespace:pod-network-test-2240 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 03:17:29.402: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 03:17:29.656: INFO: Waiting for endpoints: map[]
Mar  9 03:17:29.663: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.97:8080/dial?request=hostName&protocol=udp&host=10.244.4.96&port=8081&tries=1'] Namespace:pod-network-test-2240 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 03:17:29.663: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 03:17:29.959: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:17:29.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2240" for this suite.
Mar  9 03:17:44.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:17:44.275: INFO: namespace pod-network-test-2240 deletion completed in 14.304251884s

• [SLOW TEST:41.619 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:17:44.275: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3085
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3085
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3085
STEP: Creating statefulset with conflicting port in namespace statefulset-3085
STEP: Waiting until pod test-pod will start running in namespace statefulset-3085
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3085
Mar  9 03:17:49.131: INFO: Observed stateful pod in namespace: statefulset-3085, name: ss-0, uid: 2f96c0b8-1c68-4eac-b6d5-88f0ab506490, status phase: Pending. Waiting for statefulset controller to delete.
Mar  9 03:17:49.508: INFO: Observed stateful pod in namespace: statefulset-3085, name: ss-0, uid: 2f96c0b8-1c68-4eac-b6d5-88f0ab506490, status phase: Failed. Waiting for statefulset controller to delete.
Mar  9 03:17:49.533: INFO: Observed stateful pod in namespace: statefulset-3085, name: ss-0, uid: 2f96c0b8-1c68-4eac-b6d5-88f0ab506490, status phase: Failed. Waiting for statefulset controller to delete.
Mar  9 03:17:49.603: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3085
STEP: Removing pod with conflicting port in namespace statefulset-3085
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3085 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  9 03:17:53.831: INFO: Deleting all statefulset in ns statefulset-3085
Mar  9 03:17:53.838: INFO: Scaling statefulset ss to 0
Mar  9 03:18:03.888: INFO: Waiting for statefulset status.replicas updated to 0
Mar  9 03:18:03.894: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:18:03.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3085" for this suite.
Mar  9 03:18:12.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:18:12.186: INFO: namespace statefulset-3085 deletion completed in 8.247426197s

• [SLOW TEST:27.911 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:18:12.187: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-8718
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:18:12.551: INFO: Creating ReplicaSet my-hostname-basic-a3f88c5b-6ef8-4951-9677-2da1d15aae83
Mar  9 03:18:12.662: INFO: Pod name my-hostname-basic-a3f88c5b-6ef8-4951-9677-2da1d15aae83: Found 1 pods out of 1
Mar  9 03:18:12.662: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-a3f88c5b-6ef8-4951-9677-2da1d15aae83" is running
Mar  9 03:18:16.702: INFO: Pod "my-hostname-basic-a3f88c5b-6ef8-4951-9677-2da1d15aae83-v4wtw" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-09 03:18:12 +0000 UTC Reason: Message:}])
Mar  9 03:18:16.702: INFO: Trying to dial the pod
Mar  9 03:18:21.726: INFO: Controller my-hostname-basic-a3f88c5b-6ef8-4951-9677-2da1d15aae83: Got expected result from replica 1 [my-hostname-basic-a3f88c5b-6ef8-4951-9677-2da1d15aae83-v4wtw]: "my-hostname-basic-a3f88c5b-6ef8-4951-9677-2da1d15aae83-v4wtw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:18:21.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8718" for this suite.
Mar  9 03:18:29.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:18:30.302: INFO: namespace replicaset-8718 deletion completed in 8.567879246s

• [SLOW TEST:18.115 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:18:30.303: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4863
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Mar  9 03:18:30.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=kubectl-4863 run e2e-test-rm-busybox-job --image=172.20.8.7/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar  9 03:18:36.953: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar  9 03:18:36.953: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:18:39.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4863" for this suite.
Mar  9 03:18:45.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:18:45.425: INFO: namespace kubectl-4863 deletion completed in 6.331830363s

• [SLOW TEST:15.122 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:18:45.425: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8940
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 03:18:47.750: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 03:18:49.800: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320727, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320727, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320728, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320727, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 03:18:52.903: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:18:54.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8940" for this suite.
Mar  9 03:19:02.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:19:02.760: INFO: namespace webhook-8940 deletion completed in 8.262446947s
STEP: Destroying namespace "webhook-8940-markers" for this suite.
Mar  9 03:19:08.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:19:08.968: INFO: namespace webhook-8940-markers deletion completed in 6.20759135s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.769 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:19:09.195: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7467
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:19:14.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7467" for this suite.
Mar  9 03:19:28.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:19:28.923: INFO: namespace replication-controller-7467 deletion completed in 14.227922108s

• [SLOW TEST:19.728 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:19:28.924: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2060
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:19:29.220: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Mar  9 03:19:30.358: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:19:31.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2060" for this suite.
Mar  9 03:19:39.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:19:39.804: INFO: namespace replication-controller-2060 deletion completed in 8.390395306s

• [SLOW TEST:10.881 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:19:39.805: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8283
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:19:51.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8283" for this suite.
Mar  9 03:19:57.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:19:58.230: INFO: namespace resourcequota-8283 deletion completed in 6.378540198s

• [SLOW TEST:18.425 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:19:58.230: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-7195
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-7195
I0309 03:19:58.698907      22 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7195, replica count: 1
I0309 03:19:59.750015      22 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0309 03:20:00.750420      22 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0309 03:20:01.750917      22 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  9 03:20:01.936: INFO: Created: latency-svc-nxgkz
Mar  9 03:20:01.981: INFO: Got endpoints: latency-svc-nxgkz [129.915781ms]
Mar  9 03:20:02.102: INFO: Created: latency-svc-gtccd
Mar  9 03:20:02.160: INFO: Got endpoints: latency-svc-gtccd [178.469957ms]
Mar  9 03:20:02.271: INFO: Created: latency-svc-kgppp
Mar  9 03:20:02.392: INFO: Created: latency-svc-bjhn7
Mar  9 03:20:02.408: INFO: Got endpoints: latency-svc-kgppp [425.405877ms]
Mar  9 03:20:02.429: INFO: Got endpoints: latency-svc-bjhn7 [445.721011ms]
Mar  9 03:20:02.701: INFO: Created: latency-svc-qjg8t
Mar  9 03:20:02.712: INFO: Got endpoints: latency-svc-qjg8t [729.716511ms]
Mar  9 03:20:02.863: INFO: Created: latency-svc-c2h2g
Mar  9 03:20:02.901: INFO: Got endpoints: latency-svc-c2h2g [919.377641ms]
Mar  9 03:20:02.913: INFO: Created: latency-svc-xzlgw
Mar  9 03:20:02.984: INFO: Got endpoints: latency-svc-xzlgw [1.002756545s]
Mar  9 03:20:03.255: INFO: Created: latency-svc-kgzzf
Mar  9 03:20:03.268: INFO: Got endpoints: latency-svc-kgzzf [1.286084269s]
Mar  9 03:20:03.390: INFO: Created: latency-svc-svc8b
Mar  9 03:20:03.420: INFO: Got endpoints: latency-svc-svc8b [1.436853816s]
Mar  9 03:20:03.464: INFO: Created: latency-svc-6rdnn
Mar  9 03:20:03.540: INFO: Got endpoints: latency-svc-6rdnn [1.557321181s]
Mar  9 03:20:03.845: INFO: Created: latency-svc-m58p7
Mar  9 03:20:03.849: INFO: Got endpoints: latency-svc-m58p7 [1.866198422s]
Mar  9 03:20:03.873: INFO: Created: latency-svc-2kqnv
Mar  9 03:20:03.929: INFO: Got endpoints: latency-svc-2kqnv [1.946205502s]
Mar  9 03:20:03.943: INFO: Created: latency-svc-mmpq2
Mar  9 03:20:03.992: INFO: Got endpoints: latency-svc-mmpq2 [2.00889256s]
Mar  9 03:20:04.168: INFO: Created: latency-svc-hhtk8
Mar  9 03:20:04.219: INFO: Got endpoints: latency-svc-hhtk8 [2.235802201s]
Mar  9 03:20:04.266: INFO: Created: latency-svc-9vqpc
Mar  9 03:20:04.346: INFO: Got endpoints: latency-svc-9vqpc [2.362601536s]
Mar  9 03:20:04.379: INFO: Created: latency-svc-4vzzx
Mar  9 03:20:04.442: INFO: Got endpoints: latency-svc-4vzzx [2.45936923s]
Mar  9 03:20:04.846: INFO: Created: latency-svc-jgnvh
Mar  9 03:20:04.869: INFO: Got endpoints: latency-svc-jgnvh [2.709279807s]
Mar  9 03:20:04.997: INFO: Created: latency-svc-h8t9r
Mar  9 03:20:05.235: INFO: Got endpoints: latency-svc-h8t9r [2.827349443s]
Mar  9 03:20:05.295: INFO: Created: latency-svc-wlr62
Mar  9 03:20:05.328: INFO: Got endpoints: latency-svc-wlr62 [2.899593366s]
Mar  9 03:20:05.496: INFO: Created: latency-svc-9xgvn
Mar  9 03:20:05.524: INFO: Got endpoints: latency-svc-9xgvn [2.812186873s]
Mar  9 03:20:05.582: INFO: Created: latency-svc-cvwff
Mar  9 03:20:05.660: INFO: Got endpoints: latency-svc-cvwff [2.758017706s]
Mar  9 03:20:05.740: INFO: Created: latency-svc-pf6xv
Mar  9 03:20:05.771: INFO: Got endpoints: latency-svc-pf6xv [2.786976715s]
Mar  9 03:20:05.989: INFO: Created: latency-svc-xtkl6
Mar  9 03:20:06.010: INFO: Got endpoints: latency-svc-xtkl6 [2.741309378s]
Mar  9 03:20:06.017: INFO: Created: latency-svc-zfdjf
Mar  9 03:20:06.082: INFO: Got endpoints: latency-svc-zfdjf [2.662455153s]
Mar  9 03:20:06.098: INFO: Created: latency-svc-4pft5
Mar  9 03:20:06.177: INFO: Got endpoints: latency-svc-4pft5 [2.636730533s]
Mar  9 03:20:06.276: INFO: Created: latency-svc-sndj7
Mar  9 03:20:06.308: INFO: Got endpoints: latency-svc-sndj7 [2.459677935s]
Mar  9 03:20:06.534: INFO: Created: latency-svc-mrf82
Mar  9 03:20:06.608: INFO: Got endpoints: latency-svc-mrf82 [2.678734365s]
Mar  9 03:20:06.634: INFO: Created: latency-svc-ghb7d
Mar  9 03:20:06.740: INFO: Got endpoints: latency-svc-ghb7d [2.748108273s]
Mar  9 03:20:06.907: INFO: Created: latency-svc-t2fn6
Mar  9 03:20:06.939: INFO: Got endpoints: latency-svc-t2fn6 [2.720074577s]
Mar  9 03:20:06.940: INFO: Created: latency-svc-n2ppb
Mar  9 03:20:07.032: INFO: Created: latency-svc-q27fz
Mar  9 03:20:07.033: INFO: Got endpoints: latency-svc-n2ppb [2.686917894s]
Mar  9 03:20:07.084: INFO: Got endpoints: latency-svc-q27fz [2.641460349s]
Mar  9 03:20:07.457: INFO: Created: latency-svc-ngzgz
Mar  9 03:20:07.502: INFO: Got endpoints: latency-svc-ngzgz [2.63249189s]
Mar  9 03:20:07.574: INFO: Created: latency-svc-kwxmt
Mar  9 03:20:07.618: INFO: Got endpoints: latency-svc-kwxmt [2.383253409s]
Mar  9 03:20:07.686: INFO: Created: latency-svc-c8lr4
Mar  9 03:20:07.788: INFO: Got endpoints: latency-svc-c8lr4 [2.459132762s]
Mar  9 03:20:07.951: INFO: Created: latency-svc-rd5rf
Mar  9 03:20:07.986: INFO: Got endpoints: latency-svc-rd5rf [2.462094058s]
Mar  9 03:20:08.161: INFO: Created: latency-svc-psqk8
Mar  9 03:20:08.258: INFO: Created: latency-svc-4bnl7
Mar  9 03:20:08.274: INFO: Got endpoints: latency-svc-psqk8 [2.614524667s]
Mar  9 03:20:08.301: INFO: Got endpoints: latency-svc-4bnl7 [2.529159306s]
Mar  9 03:20:08.533: INFO: Created: latency-svc-2nbp5
Mar  9 03:20:08.568: INFO: Got endpoints: latency-svc-2nbp5 [2.557993189s]
Mar  9 03:20:08.582: INFO: Created: latency-svc-kmbrj
Mar  9 03:20:08.734: INFO: Got endpoints: latency-svc-kmbrj [2.651306428s]
Mar  9 03:20:08.773: INFO: Created: latency-svc-mxqdx
Mar  9 03:20:08.884: INFO: Got endpoints: latency-svc-mxqdx [2.706626766s]
Mar  9 03:20:09.066: INFO: Created: latency-svc-q9p7f
Mar  9 03:20:09.066: INFO: Got endpoints: latency-svc-q9p7f [2.757143185s]
Mar  9 03:20:09.087: INFO: Created: latency-svc-nhdlf
Mar  9 03:20:09.175: INFO: Created: latency-svc-8nfsf
Mar  9 03:20:09.250: INFO: Got endpoints: latency-svc-nhdlf [2.641795087s]
Mar  9 03:20:09.265: INFO: Got endpoints: latency-svc-8nfsf [2.524786892s]
Mar  9 03:20:09.413: INFO: Created: latency-svc-5f7gt
Mar  9 03:20:09.485: INFO: Got endpoints: latency-svc-5f7gt [2.5458995s]
Mar  9 03:20:09.509: INFO: Created: latency-svc-sf6jb
Mar  9 03:20:09.611: INFO: Created: latency-svc-gxwpc
Mar  9 03:20:09.631: INFO: Got endpoints: latency-svc-gxwpc [2.546569876s]
Mar  9 03:20:09.664: INFO: Got endpoints: latency-svc-sf6jb [2.63082873s]
Mar  9 03:20:09.964: INFO: Created: latency-svc-8vsgz
Mar  9 03:20:09.965: INFO: Got endpoints: latency-svc-8vsgz [2.462427189s]
Mar  9 03:20:10.011: INFO: Created: latency-svc-n8977
Mar  9 03:20:10.084: INFO: Got endpoints: latency-svc-n8977 [2.465137033s]
Mar  9 03:20:10.084: INFO: Created: latency-svc-cwssf
Mar  9 03:20:10.161: INFO: Got endpoints: latency-svc-cwssf [2.372974187s]
Mar  9 03:20:10.321: INFO: Created: latency-svc-p669r
Mar  9 03:20:10.360: INFO: Got endpoints: latency-svc-p669r [2.373408715s]
Mar  9 03:20:10.360: INFO: Created: latency-svc-g2pbx
Mar  9 03:20:10.444: INFO: Got endpoints: latency-svc-g2pbx [2.169571919s]
Mar  9 03:20:10.486: INFO: Created: latency-svc-vmv9b
Mar  9 03:20:10.522: INFO: Got endpoints: latency-svc-vmv9b [2.221462534s]
Mar  9 03:20:10.695: INFO: Created: latency-svc-chfrl
Mar  9 03:20:10.775: INFO: Got endpoints: latency-svc-chfrl [2.207137137s]
Mar  9 03:20:10.801: INFO: Created: latency-svc-gs24g
Mar  9 03:20:10.884: INFO: Got endpoints: latency-svc-gs24g [2.150361759s]
Mar  9 03:20:10.900: INFO: Created: latency-svc-l5qlw
Mar  9 03:20:10.941: INFO: Got endpoints: latency-svc-l5qlw [2.056849235s]
Mar  9 03:20:11.089: INFO: Created: latency-svc-xgzkt
Mar  9 03:20:11.117: INFO: Got endpoints: latency-svc-xgzkt [2.051203442s]
Mar  9 03:20:11.211: INFO: Created: latency-svc-4zffb
Mar  9 03:20:11.248: INFO: Got endpoints: latency-svc-4zffb [1.998083003s]
Mar  9 03:20:11.485: INFO: Created: latency-svc-9qqnt
Mar  9 03:20:11.485: INFO: Got endpoints: latency-svc-9qqnt [2.220001941s]
Mar  9 03:20:11.538: INFO: Created: latency-svc-6tgk6
Mar  9 03:20:11.553: INFO: Got endpoints: latency-svc-6tgk6 [2.068168957s]
Mar  9 03:20:11.785: INFO: Created: latency-svc-px8wm
Mar  9 03:20:11.809: INFO: Got endpoints: latency-svc-px8wm [2.178013573s]
Mar  9 03:20:11.920: INFO: Created: latency-svc-lwqgz
Mar  9 03:20:11.933: INFO: Got endpoints: latency-svc-lwqgz [2.26950692s]
Mar  9 03:20:12.036: INFO: Created: latency-svc-lgrlx
Mar  9 03:20:12.072: INFO: Got endpoints: latency-svc-lgrlx [2.107686259s]
Mar  9 03:20:12.327: INFO: Created: latency-svc-4pcxd
Mar  9 03:20:12.379: INFO: Got endpoints: latency-svc-4pcxd [2.295614471s]
Mar  9 03:20:12.479: INFO: Created: latency-svc-2c6df
Mar  9 03:20:12.479: INFO: Got endpoints: latency-svc-2c6df [2.318625826s]
Mar  9 03:20:12.647: INFO: Created: latency-svc-6sd2g
Mar  9 03:20:12.755: INFO: Got endpoints: latency-svc-6sd2g [2.395032839s]
Mar  9 03:20:12.827: INFO: Created: latency-svc-dl2ql
Mar  9 03:20:12.902: INFO: Got endpoints: latency-svc-dl2ql [2.45775142s]
Mar  9 03:20:12.989: INFO: Created: latency-svc-s9tnm
Mar  9 03:20:13.019: INFO: Got endpoints: latency-svc-s9tnm [2.496691862s]
Mar  9 03:20:13.077: INFO: Created: latency-svc-qrkpt
Mar  9 03:20:13.155: INFO: Got endpoints: latency-svc-qrkpt [2.379628001s]
Mar  9 03:20:13.441: INFO: Created: latency-svc-fxkdq
Mar  9 03:20:13.501: INFO: Got endpoints: latency-svc-fxkdq [2.617345256s]
Mar  9 03:20:13.574: INFO: Created: latency-svc-2fgxf
Mar  9 03:20:13.639: INFO: Created: latency-svc-gntbg
Mar  9 03:20:13.792: INFO: Got endpoints: latency-svc-gntbg [2.675220841s]
Mar  9 03:20:13.810: INFO: Created: latency-svc-kr5mw
Mar  9 03:20:13.818: INFO: Got endpoints: latency-svc-2fgxf [2.876989715s]
Mar  9 03:20:13.843: INFO: Got endpoints: latency-svc-kr5mw [2.594793262s]
Mar  9 03:20:14.040: INFO: Created: latency-svc-gfvsz
Mar  9 03:20:14.078: INFO: Got endpoints: latency-svc-gfvsz [2.592542383s]
Mar  9 03:20:14.118: INFO: Created: latency-svc-gh4xg
Mar  9 03:20:14.134: INFO: Got endpoints: latency-svc-gh4xg [2.581013587s]
Mar  9 03:20:14.357: INFO: Created: latency-svc-f2dqn
Mar  9 03:20:14.412: INFO: Got endpoints: latency-svc-f2dqn [2.602764228s]
Mar  9 03:20:14.571: INFO: Created: latency-svc-8z98h
Mar  9 03:20:14.630: INFO: Got endpoints: latency-svc-8z98h [2.696283762s]
Mar  9 03:20:14.671: INFO: Created: latency-svc-s8s2m
Mar  9 03:20:14.770: INFO: Got endpoints: latency-svc-s8s2m [2.697818705s]
Mar  9 03:20:14.821: INFO: Created: latency-svc-hzx4r
Mar  9 03:20:14.937: INFO: Got endpoints: latency-svc-hzx4r [2.557622206s]
Mar  9 03:20:14.965: INFO: Created: latency-svc-4wws7
Mar  9 03:20:14.973: INFO: Got endpoints: latency-svc-4wws7 [2.493009161s]
Mar  9 03:20:15.099: INFO: Created: latency-svc-7frfl
Mar  9 03:20:15.197: INFO: Got endpoints: latency-svc-7frfl [2.442117981s]
Mar  9 03:20:15.430: INFO: Created: latency-svc-kq669
Mar  9 03:20:15.561: INFO: Got endpoints: latency-svc-kq669 [2.659418634s]
Mar  9 03:20:15.600: INFO: Created: latency-svc-cc6xl
Mar  9 03:20:15.712: INFO: Got endpoints: latency-svc-cc6xl [2.692678454s]
Mar  9 03:20:15.834: INFO: Created: latency-svc-zn85n
Mar  9 03:20:15.884: INFO: Got endpoints: latency-svc-zn85n [2.729288197s]
Mar  9 03:20:16.012: INFO: Created: latency-svc-w5hvf
Mar  9 03:20:16.109: INFO: Got endpoints: latency-svc-w5hvf [2.607858261s]
Mar  9 03:20:16.156: INFO: Created: latency-svc-97l7f
Mar  9 03:20:16.156: INFO: Got endpoints: latency-svc-97l7f [2.363230855s]
Mar  9 03:20:16.254: INFO: Created: latency-svc-txvw7
Mar  9 03:20:16.300: INFO: Got endpoints: latency-svc-txvw7 [2.482095631s]
Mar  9 03:20:16.319: INFO: Created: latency-svc-spz97
Mar  9 03:20:16.420: INFO: Got endpoints: latency-svc-spz97 [2.576994888s]
Mar  9 03:20:16.488: INFO: Created: latency-svc-lh8zq
Mar  9 03:20:16.488: INFO: Got endpoints: latency-svc-lh8zq [2.410700108s]
Mar  9 03:20:16.578: INFO: Created: latency-svc-dptjk
Mar  9 03:20:16.765: INFO: Got endpoints: latency-svc-dptjk [2.63009141s]
Mar  9 03:20:16.772: INFO: Created: latency-svc-9nq9c
Mar  9 03:20:16.844: INFO: Got endpoints: latency-svc-9nq9c [2.432033757s]
Mar  9 03:20:16.997: INFO: Created: latency-svc-qsdc7
Mar  9 03:20:16.998: INFO: Got endpoints: latency-svc-qsdc7 [2.367890877s]
Mar  9 03:20:17.110: INFO: Created: latency-svc-wrvg5
Mar  9 03:20:17.167: INFO: Got endpoints: latency-svc-wrvg5 [2.39625758s]
Mar  9 03:20:17.173: INFO: Created: latency-svc-656ll
Mar  9 03:20:17.260: INFO: Got endpoints: latency-svc-656ll [2.32215019s]
Mar  9 03:20:17.309: INFO: Created: latency-svc-7jtkx
Mar  9 03:20:17.317: INFO: Got endpoints: latency-svc-7jtkx [2.343882387s]
Mar  9 03:20:17.404: INFO: Created: latency-svc-5s74x
Mar  9 03:20:17.537: INFO: Got endpoints: latency-svc-5s74x [2.340116996s]
Mar  9 03:20:17.551: INFO: Created: latency-svc-7q7kb
Mar  9 03:20:17.579: INFO: Got endpoints: latency-svc-7q7kb [2.017465044s]
Mar  9 03:20:17.727: INFO: Created: latency-svc-r9wk8
Mar  9 03:20:17.734: INFO: Got endpoints: latency-svc-r9wk8 [2.021573017s]
Mar  9 03:20:17.846: INFO: Created: latency-svc-7bvqv
Mar  9 03:20:18.051: INFO: Got endpoints: latency-svc-7bvqv [2.166697495s]
Mar  9 03:20:18.283: INFO: Created: latency-svc-mwf8s
Mar  9 03:20:18.283: INFO: Got endpoints: latency-svc-mwf8s [2.173713772s]
Mar  9 03:20:18.321: INFO: Created: latency-svc-v9sbm
Mar  9 03:20:18.337: INFO: Got endpoints: latency-svc-v9sbm [2.181054862s]
Mar  9 03:20:18.554: INFO: Created: latency-svc-8bsgr
Mar  9 03:20:18.778: INFO: Got endpoints: latency-svc-8bsgr [2.478054564s]
Mar  9 03:20:18.805: INFO: Created: latency-svc-ntlc2
Mar  9 03:20:18.871: INFO: Got endpoints: latency-svc-ntlc2 [2.451012506s]
Mar  9 03:20:18.913: INFO: Created: latency-svc-jqrnj
Mar  9 03:20:19.000: INFO: Got endpoints: latency-svc-jqrnj [2.511311721s]
Mar  9 03:20:19.001: INFO: Created: latency-svc-dkh4n
Mar  9 03:20:19.046: INFO: Got endpoints: latency-svc-dkh4n [2.281766292s]
Mar  9 03:20:19.189: INFO: Created: latency-svc-x2kmx
Mar  9 03:20:19.255: INFO: Created: latency-svc-rh96p
Mar  9 03:20:19.255: INFO: Got endpoints: latency-svc-x2kmx [2.410970093s]
Mar  9 03:20:19.301: INFO: Got endpoints: latency-svc-rh96p [2.303508986s]
Mar  9 03:20:19.378: INFO: Created: latency-svc-c5qqq
Mar  9 03:20:19.410: INFO: Got endpoints: latency-svc-c5qqq [2.243440409s]
Mar  9 03:20:19.634: INFO: Created: latency-svc-cjsbd
Mar  9 03:20:19.644: INFO: Got endpoints: latency-svc-cjsbd [2.384227739s]
Mar  9 03:20:19.645: INFO: Created: latency-svc-6p985
Mar  9 03:20:19.678: INFO: Got endpoints: latency-svc-6p985 [2.361487761s]
Mar  9 03:20:19.825: INFO: Created: latency-svc-c8xmc
Mar  9 03:20:19.825: INFO: Got endpoints: latency-svc-c8xmc [2.287929997s]
Mar  9 03:20:20.237: INFO: Created: latency-svc-lfvz5
Mar  9 03:20:20.264: INFO: Created: latency-svc-xzfv6
Mar  9 03:20:20.264: INFO: Got endpoints: latency-svc-xzfv6 [2.684810656s]
Mar  9 03:20:20.356: INFO: Got endpoints: latency-svc-lfvz5 [2.622631587s]
Mar  9 03:20:20.506: INFO: Created: latency-svc-ltksd
Mar  9 03:20:20.557: INFO: Got endpoints: latency-svc-ltksd [2.505347658s]
Mar  9 03:20:20.648: INFO: Created: latency-svc-v45zd
Mar  9 03:20:20.695: INFO: Created: latency-svc-wfc5b
Mar  9 03:20:20.755: INFO: Got endpoints: latency-svc-wfc5b [2.418195669s]
Mar  9 03:20:20.799: INFO: Got endpoints: latency-svc-v45zd [2.515624655s]
Mar  9 03:20:20.994: INFO: Created: latency-svc-ks72p
Mar  9 03:20:21.070: INFO: Got endpoints: latency-svc-ks72p [2.29214145s]
Mar  9 03:20:21.111: INFO: Created: latency-svc-22fmd
Mar  9 03:20:21.188: INFO: Created: latency-svc-fkzkx
Mar  9 03:20:21.195: INFO: Got endpoints: latency-svc-22fmd [2.323284271s]
Mar  9 03:20:21.248: INFO: Got endpoints: latency-svc-fkzkx [2.247625569s]
Mar  9 03:20:21.590: INFO: Created: latency-svc-4vnhb
Mar  9 03:20:21.632: INFO: Got endpoints: latency-svc-4vnhb [2.585133993s]
Mar  9 03:20:21.729: INFO: Created: latency-svc-tkrzr
Mar  9 03:20:21.845: INFO: Created: latency-svc-7kg4l
Mar  9 03:20:21.863: INFO: Got endpoints: latency-svc-tkrzr [2.607550937s]
Mar  9 03:20:21.916: INFO: Got endpoints: latency-svc-7kg4l [2.615155404s]
Mar  9 03:20:21.973: INFO: Created: latency-svc-kd6zf
Mar  9 03:20:22.046: INFO: Got endpoints: latency-svc-kd6zf [2.635203084s]
Mar  9 03:20:22.047: INFO: Created: latency-svc-cs55j
Mar  9 03:20:22.322: INFO: Got endpoints: latency-svc-cs55j [2.677907771s]
Mar  9 03:20:22.352: INFO: Created: latency-svc-tmq8h
Mar  9 03:20:22.376: INFO: Got endpoints: latency-svc-tmq8h [2.697650177s]
Mar  9 03:20:22.467: INFO: Created: latency-svc-mps9c
Mar  9 03:20:22.511: INFO: Got endpoints: latency-svc-mps9c [2.686007694s]
Mar  9 03:20:22.606: INFO: Created: latency-svc-j9s6f
Mar  9 03:20:22.632: INFO: Got endpoints: latency-svc-j9s6f [2.368332368s]
Mar  9 03:20:22.702: INFO: Created: latency-svc-p5h5s
Mar  9 03:20:22.737: INFO: Got endpoints: latency-svc-p5h5s [2.379939519s]
Mar  9 03:20:22.985: INFO: Created: latency-svc-jsskq
Mar  9 03:20:23.028: INFO: Got endpoints: latency-svc-jsskq [2.471244827s]
Mar  9 03:20:23.112: INFO: Created: latency-svc-wxk2p
Mar  9 03:20:23.170: INFO: Got endpoints: latency-svc-wxk2p [2.41440235s]
Mar  9 03:20:23.213: INFO: Created: latency-svc-tp8mk
Mar  9 03:20:23.213: INFO: Got endpoints: latency-svc-tp8mk [2.413989069s]
Mar  9 03:20:23.535: INFO: Created: latency-svc-75z7q
Mar  9 03:20:23.535: INFO: Got endpoints: latency-svc-75z7q [2.464638147s]
Mar  9 03:20:23.546: INFO: Created: latency-svc-rx2ms
Mar  9 03:20:23.596: INFO: Got endpoints: latency-svc-rx2ms [2.401182751s]
Mar  9 03:20:23.851: INFO: Created: latency-svc-wcr4p
Mar  9 03:20:23.939: INFO: Got endpoints: latency-svc-wcr4p [2.691260548s]
Mar  9 03:20:23.993: INFO: Created: latency-svc-vd2bm
Mar  9 03:20:23.996: INFO: Got endpoints: latency-svc-vd2bm [2.364542017s]
Mar  9 03:20:24.198: INFO: Created: latency-svc-q4rts
Mar  9 03:20:24.263: INFO: Got endpoints: latency-svc-q4rts [2.400272743s]
Mar  9 03:20:24.324: INFO: Created: latency-svc-rwrz7
Mar  9 03:20:24.442: INFO: Got endpoints: latency-svc-rwrz7 [2.525387571s]
Mar  9 03:20:24.524: INFO: Created: latency-svc-5mblz
Mar  9 03:20:24.602: INFO: Got endpoints: latency-svc-5mblz [2.555875056s]
Mar  9 03:20:24.714: INFO: Created: latency-svc-kwv7f
Mar  9 03:20:24.744: INFO: Created: latency-svc-rtbxx
Mar  9 03:20:24.773: INFO: Got endpoints: latency-svc-kwv7f [2.451256081s]
Mar  9 03:20:24.898: INFO: Got endpoints: latency-svc-rtbxx [2.522453343s]
Mar  9 03:20:25.031: INFO: Created: latency-svc-h94hv
Mar  9 03:20:25.061: INFO: Got endpoints: latency-svc-h94hv [2.549265867s]
Mar  9 03:20:25.081: INFO: Created: latency-svc-hn9gp
Mar  9 03:20:25.168: INFO: Got endpoints: latency-svc-hn9gp [2.536043023s]
Mar  9 03:20:25.169: INFO: Created: latency-svc-kmgns
Mar  9 03:20:25.289: INFO: Got endpoints: latency-svc-kmgns [2.552273515s]
Mar  9 03:20:25.444: INFO: Created: latency-svc-xftld
Mar  9 03:20:25.489: INFO: Got endpoints: latency-svc-xftld [2.460760369s]
Mar  9 03:20:25.523: INFO: Created: latency-svc-ll47q
Mar  9 03:20:25.608: INFO: Got endpoints: latency-svc-ll47q [2.437829407s]
Mar  9 03:20:25.623: INFO: Created: latency-svc-kl5pr
Mar  9 03:20:25.741: INFO: Got endpoints: latency-svc-kl5pr [2.527919871s]
Mar  9 03:20:25.939: INFO: Created: latency-svc-x7ffz
Mar  9 03:20:25.939: INFO: Got endpoints: latency-svc-x7ffz [2.404130482s]
Mar  9 03:20:26.173: INFO: Created: latency-svc-hr6t8
Mar  9 03:20:26.264: INFO: Got endpoints: latency-svc-hr6t8 [2.668405243s]
Mar  9 03:20:26.293: INFO: Created: latency-svc-98kr2
Mar  9 03:20:26.314: INFO: Got endpoints: latency-svc-98kr2 [2.374534407s]
Mar  9 03:20:26.468: INFO: Created: latency-svc-jl62r
Mar  9 03:20:26.544: INFO: Got endpoints: latency-svc-jl62r [2.547405212s]
Mar  9 03:20:26.570: INFO: Created: latency-svc-qdws9
Mar  9 03:20:26.704: INFO: Created: latency-svc-29m58
Mar  9 03:20:26.745: INFO: Got endpoints: latency-svc-29m58 [2.303161471s]
Mar  9 03:20:26.771: INFO: Got endpoints: latency-svc-qdws9 [2.507946391s]
Mar  9 03:20:27.152: INFO: Created: latency-svc-lkc22
Mar  9 03:20:27.152: INFO: Got endpoints: latency-svc-lkc22 [2.550320174s]
Mar  9 03:20:27.256: INFO: Created: latency-svc-h4s6w
Mar  9 03:20:27.330: INFO: Created: latency-svc-v94w9
Mar  9 03:20:27.371: INFO: Got endpoints: latency-svc-h4s6w [2.597628674s]
Mar  9 03:20:27.373: INFO: Got endpoints: latency-svc-v94w9 [2.473957472s]
Mar  9 03:20:27.941: INFO: Created: latency-svc-9zpgr
Mar  9 03:20:27.941: INFO: Got endpoints: latency-svc-9zpgr [2.880435216s]
Mar  9 03:20:27.956: INFO: Created: latency-svc-qhmbm
Mar  9 03:20:28.013: INFO: Created: latency-svc-2h76d
Mar  9 03:20:28.057: INFO: Got endpoints: latency-svc-2h76d [2.768130783s]
Mar  9 03:20:28.192: INFO: Got endpoints: latency-svc-qhmbm [3.023211644s]
Mar  9 03:20:28.336: INFO: Created: latency-svc-x75sp
Mar  9 03:20:28.458: INFO: Got endpoints: latency-svc-x75sp [2.969016911s]
Mar  9 03:20:28.475: INFO: Created: latency-svc-sjrxv
Mar  9 03:20:28.579: INFO: Got endpoints: latency-svc-sjrxv [2.970591796s]
Mar  9 03:20:28.693: INFO: Created: latency-svc-78rtj
Mar  9 03:20:28.693: INFO: Got endpoints: latency-svc-78rtj [2.951632908s]
Mar  9 03:20:28.734: INFO: Created: latency-svc-m4htp
Mar  9 03:20:28.769: INFO: Got endpoints: latency-svc-m4htp [2.829573089s]
Mar  9 03:20:28.868: INFO: Created: latency-svc-7f22g
Mar  9 03:20:29.137: INFO: Got endpoints: latency-svc-7f22g [2.871944345s]
Mar  9 03:20:29.178: INFO: Created: latency-svc-5nzlh
Mar  9 03:20:29.178: INFO: Got endpoints: latency-svc-5nzlh [2.86402142s]
Mar  9 03:20:29.388: INFO: Created: latency-svc-72gkf
Mar  9 03:20:29.420: INFO: Created: latency-svc-x5g7w
Mar  9 03:20:29.473: INFO: Got endpoints: latency-svc-72gkf [2.92881872s]
Mar  9 03:20:29.612: INFO: Got endpoints: latency-svc-x5g7w [2.866780708s]
Mar  9 03:20:29.666: INFO: Created: latency-svc-prd45
Mar  9 03:20:29.666: INFO: Got endpoints: latency-svc-prd45 [2.894223995s]
Mar  9 03:20:29.848: INFO: Created: latency-svc-q6bw6
Mar  9 03:20:29.899: INFO: Got endpoints: latency-svc-q6bw6 [2.747312826s]
Mar  9 03:20:30.029: INFO: Created: latency-svc-z772m
Mar  9 03:20:30.127: INFO: Got endpoints: latency-svc-z772m [2.755414728s]
Mar  9 03:20:30.179: INFO: Created: latency-svc-dnkg7
Mar  9 03:20:30.197: INFO: Got endpoints: latency-svc-dnkg7 [2.823965166s]
Mar  9 03:20:30.243: INFO: Created: latency-svc-wxdv6
Mar  9 03:20:30.372: INFO: Got endpoints: latency-svc-wxdv6 [2.430422501s]
Mar  9 03:20:30.391: INFO: Created: latency-svc-4qz2x
Mar  9 03:20:30.492: INFO: Got endpoints: latency-svc-4qz2x [2.43445215s]
Mar  9 03:20:30.519: INFO: Created: latency-svc-9qmvw
Mar  9 03:20:30.590: INFO: Got endpoints: latency-svc-9qmvw [2.397621853s]
Mar  9 03:20:30.663: INFO: Created: latency-svc-7scdn
Mar  9 03:20:30.717: INFO: Got endpoints: latency-svc-7scdn [2.259165179s]
Mar  9 03:20:30.791: INFO: Created: latency-svc-n5mqc
Mar  9 03:20:30.841: INFO: Got endpoints: latency-svc-n5mqc [2.262600846s]
Mar  9 03:20:30.928: INFO: Created: latency-svc-dntw2
Mar  9 03:20:30.969: INFO: Got endpoints: latency-svc-dntw2 [2.27629001s]
Mar  9 03:20:31.092: INFO: Created: latency-svc-f62r5
Mar  9 03:20:31.103: INFO: Got endpoints: latency-svc-f62r5 [2.334344129s]
Mar  9 03:20:31.309: INFO: Created: latency-svc-lskhm
Mar  9 03:20:31.391: INFO: Got endpoints: latency-svc-lskhm [2.212926127s]
Mar  9 03:20:31.395: INFO: Created: latency-svc-7dkdv
Mar  9 03:20:31.425: INFO: Got endpoints: latency-svc-7dkdv [2.288671889s]
Mar  9 03:20:31.483: INFO: Created: latency-svc-q7rjf
Mar  9 03:20:31.532: INFO: Got endpoints: latency-svc-q7rjf [2.058553985s]
Mar  9 03:20:31.747: INFO: Created: latency-svc-z8b2d
Mar  9 03:20:31.844: INFO: Got endpoints: latency-svc-z8b2d [2.231855632s]
Mar  9 03:20:31.861: INFO: Created: latency-svc-2s4xr
Mar  9 03:20:31.963: INFO: Got endpoints: latency-svc-2s4xr [2.297042293s]
Mar  9 03:20:31.982: INFO: Created: latency-svc-hp4rr
Mar  9 03:20:31.997: INFO: Got endpoints: latency-svc-hp4rr [2.096919335s]
Mar  9 03:20:32.114: INFO: Created: latency-svc-crb87
Mar  9 03:20:32.141: INFO: Got endpoints: latency-svc-crb87 [2.014406185s]
Mar  9 03:20:32.240: INFO: Created: latency-svc-d9v97
Mar  9 03:20:32.374: INFO: Got endpoints: latency-svc-d9v97 [2.177171504s]
Mar  9 03:20:32.456: INFO: Created: latency-svc-qttkl
Mar  9 03:20:32.532: INFO: Got endpoints: latency-svc-qttkl [2.159859371s]
Mar  9 03:20:32.594: INFO: Created: latency-svc-4dpzg
Mar  9 03:20:32.683: INFO: Got endpoints: latency-svc-4dpzg [2.190941836s]
Mar  9 03:20:32.683: INFO: Created: latency-svc-dx7c2
Mar  9 03:20:32.773: INFO: Got endpoints: latency-svc-dx7c2 [2.183500075s]
Mar  9 03:20:32.900: INFO: Created: latency-svc-jlwll
Mar  9 03:20:32.903: INFO: Got endpoints: latency-svc-jlwll [2.185118812s]
Mar  9 03:20:33.180: INFO: Created: latency-svc-xmnbr
Mar  9 03:20:33.211: INFO: Got endpoints: latency-svc-xmnbr [2.369012605s]
Mar  9 03:20:33.272: INFO: Created: latency-svc-nfhx5
Mar  9 03:20:33.377: INFO: Created: latency-svc-tpvzs
Mar  9 03:20:33.414: INFO: Got endpoints: latency-svc-nfhx5 [2.444194262s]
Mar  9 03:20:33.430: INFO: Got endpoints: latency-svc-tpvzs [2.326821356s]
Mar  9 03:20:33.554: INFO: Created: latency-svc-cfnlb
Mar  9 03:20:33.650: INFO: Got endpoints: latency-svc-cfnlb [2.259050707s]
Mar  9 03:20:33.650: INFO: Created: latency-svc-tw49h
Mar  9 03:20:33.707: INFO: Got endpoints: latency-svc-tw49h [2.281682392s]
Mar  9 03:20:33.784: INFO: Created: latency-svc-xxtjn
Mar  9 03:20:33.838: INFO: Got endpoints: latency-svc-xxtjn [2.306300473s]
Mar  9 03:20:34.032: INFO: Created: latency-svc-2v4dd
Mar  9 03:20:34.122: INFO: Created: latency-svc-rfj74
Mar  9 03:20:34.144: INFO: Got endpoints: latency-svc-rfj74 [2.180671854s]
Mar  9 03:20:34.247: INFO: Got endpoints: latency-svc-2v4dd [2.403037841s]
Mar  9 03:20:34.408: INFO: Created: latency-svc-gfdjn
Mar  9 03:20:34.408: INFO: Got endpoints: latency-svc-gfdjn [2.411566705s]
Mar  9 03:20:34.520: INFO: Created: latency-svc-8lbb2
Mar  9 03:20:34.650: INFO: Got endpoints: latency-svc-8lbb2 [2.508528087s]
Mar  9 03:20:34.650: INFO: Created: latency-svc-trk25
Mar  9 03:20:34.703: INFO: Got endpoints: latency-svc-trk25 [2.329257569s]
Mar  9 03:20:34.889: INFO: Created: latency-svc-wnkgx
Mar  9 03:20:34.986: INFO: Got endpoints: latency-svc-wnkgx [2.453541006s]
Mar  9 03:20:35.046: INFO: Created: latency-svc-g7nkr
Mar  9 03:20:35.065: INFO: Got endpoints: latency-svc-g7nkr [2.382326785s]
Mar  9 03:20:35.066: INFO: Latencies: [178.469957ms 425.405877ms 445.721011ms 729.716511ms 919.377641ms 1.002756545s 1.286084269s 1.436853816s 1.557321181s 1.866198422s 1.946205502s 1.998083003s 2.00889256s 2.014406185s 2.017465044s 2.021573017s 2.051203442s 2.056849235s 2.058553985s 2.068168957s 2.096919335s 2.107686259s 2.150361759s 2.159859371s 2.166697495s 2.169571919s 2.173713772s 2.177171504s 2.178013573s 2.180671854s 2.181054862s 2.183500075s 2.185118812s 2.190941836s 2.207137137s 2.212926127s 2.220001941s 2.221462534s 2.231855632s 2.235802201s 2.243440409s 2.247625569s 2.259050707s 2.259165179s 2.262600846s 2.26950692s 2.27629001s 2.281682392s 2.281766292s 2.287929997s 2.288671889s 2.29214145s 2.295614471s 2.297042293s 2.303161471s 2.303508986s 2.306300473s 2.318625826s 2.32215019s 2.323284271s 2.326821356s 2.329257569s 2.334344129s 2.340116996s 2.343882387s 2.361487761s 2.362601536s 2.363230855s 2.364542017s 2.367890877s 2.368332368s 2.369012605s 2.372974187s 2.373408715s 2.374534407s 2.379628001s 2.379939519s 2.382326785s 2.383253409s 2.384227739s 2.395032839s 2.39625758s 2.397621853s 2.400272743s 2.401182751s 2.403037841s 2.404130482s 2.410700108s 2.410970093s 2.411566705s 2.413989069s 2.41440235s 2.418195669s 2.430422501s 2.432033757s 2.43445215s 2.437829407s 2.442117981s 2.444194262s 2.451012506s 2.451256081s 2.453541006s 2.45775142s 2.459132762s 2.45936923s 2.459677935s 2.460760369s 2.462094058s 2.462427189s 2.464638147s 2.465137033s 2.471244827s 2.473957472s 2.478054564s 2.482095631s 2.493009161s 2.496691862s 2.505347658s 2.507946391s 2.508528087s 2.511311721s 2.515624655s 2.522453343s 2.524786892s 2.525387571s 2.527919871s 2.529159306s 2.536043023s 2.5458995s 2.546569876s 2.547405212s 2.549265867s 2.550320174s 2.552273515s 2.555875056s 2.557622206s 2.557993189s 2.576994888s 2.581013587s 2.585133993s 2.592542383s 2.594793262s 2.597628674s 2.602764228s 2.607550937s 2.607858261s 2.614524667s 2.615155404s 2.617345256s 2.622631587s 2.63009141s 2.63082873s 2.63249189s 2.635203084s 2.636730533s 2.641460349s 2.641795087s 2.651306428s 2.659418634s 2.662455153s 2.668405243s 2.675220841s 2.677907771s 2.678734365s 2.684810656s 2.686007694s 2.686917894s 2.691260548s 2.692678454s 2.696283762s 2.697650177s 2.697818705s 2.706626766s 2.709279807s 2.720074577s 2.729288197s 2.741309378s 2.747312826s 2.748108273s 2.755414728s 2.757143185s 2.758017706s 2.768130783s 2.786976715s 2.812186873s 2.823965166s 2.827349443s 2.829573089s 2.86402142s 2.866780708s 2.871944345s 2.876989715s 2.880435216s 2.894223995s 2.899593366s 2.92881872s 2.951632908s 2.969016911s 2.970591796s 3.023211644s]
Mar  9 03:20:35.066: INFO: 50 %ile: 2.451256081s
Mar  9 03:20:35.066: INFO: 90 %ile: 2.757143185s
Mar  9 03:20:35.066: INFO: 99 %ile: 2.970591796s
Mar  9 03:20:35.066: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:20:35.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-7195" for this suite.
Mar  9 03:21:45.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:21:45.897: INFO: namespace svc-latency-7195 deletion completed in 1m10.819933742s

• [SLOW TEST:107.667 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:21:45.898: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  9 03:21:46.606: INFO: Waiting up to 5m0s for pod "pod-0a72b7d7-25d5-46d2-b357-618348ff2038" in namespace "emptydir-2576" to be "success or failure"
Mar  9 03:21:46.675: INFO: Pod "pod-0a72b7d7-25d5-46d2-b357-618348ff2038": Phase="Pending", Reason="", readiness=false. Elapsed: 68.974201ms
Mar  9 03:21:48.685: INFO: Pod "pod-0a72b7d7-25d5-46d2-b357-618348ff2038": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078816643s
Mar  9 03:21:50.712: INFO: Pod "pod-0a72b7d7-25d5-46d2-b357-618348ff2038": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106410125s
STEP: Saw pod success
Mar  9 03:21:50.712: INFO: Pod "pod-0a72b7d7-25d5-46d2-b357-618348ff2038" satisfied condition "success or failure"
Mar  9 03:21:50.718: INFO: Trying to get logs from node worker1 pod pod-0a72b7d7-25d5-46d2-b357-618348ff2038 container test-container: <nil>
STEP: delete the pod
Mar  9 03:21:50.960: INFO: Waiting for pod pod-0a72b7d7-25d5-46d2-b357-618348ff2038 to disappear
Mar  9 03:21:50.999: INFO: Pod pod-0a72b7d7-25d5-46d2-b357-618348ff2038 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:21:50.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2576" for this suite.
Mar  9 03:21:59.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:21:59.790: INFO: namespace emptydir-2576 deletion completed in 8.759730368s

• [SLOW TEST:13.892 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:21:59.791: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1548
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  9 03:22:00.260: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:22:07.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1548" for this suite.
Mar  9 03:22:15.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:22:16.139: INFO: namespace init-container-1548 deletion completed in 8.406392313s

• [SLOW TEST:16.348 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:22:16.140: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-4768
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Mar  9 03:22:16.505: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Mar  9 03:22:17.925: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Mar  9 03:22:20.485: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320938, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5c59b48dc4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:22:22.525: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320938, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5c59b48dc4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:22:24.506: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320938, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5c59b48dc4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:22:26.494: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320938, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5c59b48dc4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:22:28.494: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320938, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5c59b48dc4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:22:30.493: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320938, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5c59b48dc4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:22:32.493: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320938, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5c59b48dc4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:22:34.493: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320938, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5c59b48dc4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:22:36.493: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320938, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5c59b48dc4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:22:38.493: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320938, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719320937, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5c59b48dc4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:22:42.411: INFO: Waited 1.865412519s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:22:43.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4768" for this suite.
Mar  9 03:22:51.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:22:52.024: INFO: namespace aggregator-4768 deletion completed in 8.253227562s

• [SLOW TEST:35.884 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:22:52.025: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7936
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 03:22:52.458: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2f5d77a9-bc4f-4486-a31d-4f9401f1e2c3" in namespace "downward-api-7936" to be "success or failure"
Mar  9 03:22:52.464: INFO: Pod "downwardapi-volume-2f5d77a9-bc4f-4486-a31d-4f9401f1e2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.325966ms
Mar  9 03:22:54.491: INFO: Pod "downwardapi-volume-2f5d77a9-bc4f-4486-a31d-4f9401f1e2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033397414s
Mar  9 03:22:56.558: INFO: Pod "downwardapi-volume-2f5d77a9-bc4f-4486-a31d-4f9401f1e2c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.100004635s
STEP: Saw pod success
Mar  9 03:22:56.558: INFO: Pod "downwardapi-volume-2f5d77a9-bc4f-4486-a31d-4f9401f1e2c3" satisfied condition "success or failure"
Mar  9 03:22:56.565: INFO: Trying to get logs from node worker1 pod downwardapi-volume-2f5d77a9-bc4f-4486-a31d-4f9401f1e2c3 container client-container: <nil>
STEP: delete the pod
Mar  9 03:22:56.742: INFO: Waiting for pod downwardapi-volume-2f5d77a9-bc4f-4486-a31d-4f9401f1e2c3 to disappear
Mar  9 03:22:56.746: INFO: Pod downwardapi-volume-2f5d77a9-bc4f-4486-a31d-4f9401f1e2c3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:22:56.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7936" for this suite.
Mar  9 03:23:02.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:23:03.251: INFO: namespace downward-api-7936 deletion completed in 6.496672441s

• [SLOW TEST:11.226 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:23:03.252: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7521
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:23:03.910: INFO: Creating deployment "webserver-deployment"
Mar  9 03:23:03.940: INFO: Waiting for observed generation 1
Mar  9 03:23:05.954: INFO: Waiting for all required pods to come up
Mar  9 03:23:05.964: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar  9 03:23:10.062: INFO: Waiting for deployment "webserver-deployment" to complete
Mar  9 03:23:10.075: INFO: Updating deployment "webserver-deployment" with a non-existent image
Mar  9 03:23:10.119: INFO: Updating deployment webserver-deployment
Mar  9 03:23:10.119: INFO: Waiting for observed generation 2
Mar  9 03:23:12.151: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar  9 03:23:12.157: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar  9 03:23:12.161: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Mar  9 03:23:12.190: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar  9 03:23:12.190: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar  9 03:23:12.205: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Mar  9 03:23:12.232: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Mar  9 03:23:12.232: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Mar  9 03:23:12.258: INFO: Updating deployment webserver-deployment
Mar  9 03:23:12.258: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Mar  9 03:23:12.279: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar  9 03:23:12.337: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  9 03:23:12.920: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-7521 /apis/apps/v1/namespaces/deployment-7521/deployments/webserver-deployment c1977824-d08f-4d40-a505-fb2d77070a44 117398 3 2020-03-09 03:23:03 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0010f3558 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-03-09 03:23:11 +0000 UTC,LastTransitionTime:2020-03-09 03:23:03 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-03-09 03:23:12 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Mar  9 03:23:12.979: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-7521 /apis/apps/v1/namespaces/deployment-7521/replicasets/webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 117378 3 2020-03-09 03:23:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment c1977824-d08f-4d40-a505-fb2d77070a44 0xc0010f3a87 0xc0010f3a88}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0010f3af8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  9 03:23:12.979: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Mar  9 03:23:12.980: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-68df7476b  deployment-7521 /apis/apps/v1/namespaces/deployment-7521/replicasets/webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 117373 3 2020-03-09 03:23:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment c1977824-d08f-4d40-a505-fb2d77070a44 0xc0010f39c7 0xc0010f39c8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 68df7476b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [] []  []} {[] [] [{httpd 172.20.8.7/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0010f3a28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Mar  9 03:23:13.604: INFO: Pod "webserver-deployment-68df7476b-4crr9" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-4crr9 webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-4crr9 1a8e6740-81b5-49eb-8b49-b72ffbabc368 117428 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008046007 0xc008046008}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:,StartTime:2020-03-09 03:23:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.605: INFO: Pod "webserver-deployment-68df7476b-5hfkj" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-5hfkj webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-5hfkj ebbd660a-de3b-49c1-989b-7d88ebce8019 117308 0 2020-03-09 03:23:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008046160 0xc008046161}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:10.244.3.120,StartTime:2020-03-09 03:23:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 03:23:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://7a403cec4037c7744223d3b2b784aba3d2b717f44b30a5ae8c3d21c5103ae131,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.120,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.605: INFO: Pod "webserver-deployment-68df7476b-7wc54" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-7wc54 webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-7wc54 0e27bfae-c520-4571-8f76-64b0a8c2db96 117435 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc0080462d0 0xc0080462d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:,StartTime:2020-03-09 03:23:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.606: INFO: Pod "webserver-deployment-68df7476b-82lc6" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-82lc6 webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-82lc6 cd6e490d-86c3-41bb-abea-2c225fa63fe3 117409 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008046440 0xc008046441}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.606: INFO: Pod "webserver-deployment-68df7476b-8cd6l" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-8cd6l webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-8cd6l d0e2e69e-1f3a-4e62-ac54-29e1bae6af6b 117418 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008046550 0xc008046551}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.606: INFO: Pod "webserver-deployment-68df7476b-cnm2g" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-cnm2g webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-cnm2g f59ad1bb-14b3-4832-9938-7db16d77a73e 117399 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008046660 0xc008046661}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.607: INFO: Pod "webserver-deployment-68df7476b-ddggm" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-ddggm webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-ddggm 923ae23f-c2bb-4d1e-9d7a-c05febcab07b 117300 0 2020-03-09 03:23:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008046770 0xc008046771}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:10.244.3.119,StartTime:2020-03-09 03:23:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 03:23:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://2b8f93ffaa98135290a0bd7976fa2ccf108a3230511b4c9ca5101b2d45b2f248,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.119,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.607: INFO: Pod "webserver-deployment-68df7476b-fj49v" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-fj49v webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-fj49v 8f3ad1bc-f1f0-4d92-abe5-40276b900fa1 117310 0 2020-03-09 03:23:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc0080468e0 0xc0080468e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:10.244.3.117,StartTime:2020-03-09 03:23:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 03:23:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://d9d34e6e582eb7b58d1b4bf2810cd29ac112828bfd8f5364db34cbd6024ca93a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.117,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.608: INFO: Pod "webserver-deployment-68df7476b-ft5xq" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-ft5xq webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-ft5xq 8f814a38-3b4c-427c-84da-9116e4b2471e 117289 0 2020-03-09 03:23:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008046a50 0xc008046a51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.111,StartTime:2020-03-09 03:23:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 03:23:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://4e145cc631ae23a9f25e9ea1d791a4f0d29f413893c0a91b21277ff63da3b1fa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.111,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.608: INFO: Pod "webserver-deployment-68df7476b-gnjd8" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-gnjd8 webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-gnjd8 448c4c96-fb25-4578-be92-7cbb8b27851e 117396 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008046bc0 0xc008046bc1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.609: INFO: Pod "webserver-deployment-68df7476b-hdcsz" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-hdcsz webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-hdcsz d5538183-53ea-4ff6-ade1-8e4e8ac9d053 117291 0 2020-03-09 03:23:03 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008046cd0 0xc008046cd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.109,StartTime:2020-03-09 03:23:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 03:23:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://5924153533a30ee1daee82ba0555f9105349da0fd639699231c573296ca6f33d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.109,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.609: INFO: Pod "webserver-deployment-68df7476b-jk4bp" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-jk4bp webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-jk4bp e36afbff-e025-4bc2-9c34-8e61100e4222 117422 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008046e40 0xc008046e41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.609: INFO: Pod "webserver-deployment-68df7476b-jn875" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-jn875 webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-jn875 b224a765-2243-4203-944e-de2a0d7e90a6 117279 0 2020-03-09 03:23:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008046f50 0xc008046f51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.112,StartTime:2020-03-09 03:23:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 03:23:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://013deea5128814b5d090c29f27b377ffb6bfeba60b7ed66ee60023472764a454,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.610: INFO: Pod "webserver-deployment-68df7476b-kdqq7" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-kdqq7 webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-kdqq7 5d95c48d-8b38-490c-a2d4-f45cfdc45fff 117397 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc0080470c0 0xc0080470c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:,StartTime:2020-03-09 03:23:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.610: INFO: Pod "webserver-deployment-68df7476b-lgkbj" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-lgkbj webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-lgkbj 435d38b3-f58e-41d6-a180-927165644e57 117416 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008047210 0xc008047211}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.611: INFO: Pod "webserver-deployment-68df7476b-lr7jb" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-lr7jb webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-lr7jb bd6414cf-09b5-43b7-b629-727c4de6e0c4 117415 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008047320 0xc008047321}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.611: INFO: Pod "webserver-deployment-68df7476b-s994q" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-s994q webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-s994q 744364a5-efa9-4d04-8b5a-c0756f1694e0 117424 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008047430 0xc008047431}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.612: INFO: Pod "webserver-deployment-68df7476b-tr4f7" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-tr4f7 webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-tr4f7 62df984c-e3f1-4a8b-9500-740e50b77ea4 117275 0 2020-03-09 03:23:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc008047540 0xc008047541}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.110,StartTime:2020-03-09 03:23:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 03:23:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://2deaa0d6be1f3bad1c84d9b6611dbd95029647a9994247cce02a2efa53a80fa2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.110,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.612: INFO: Pod "webserver-deployment-68df7476b-xlsn4" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-xlsn4 webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-xlsn4 58f317d7-6f08-4e22-968f-1c050c616d87 117411 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc0080476b0 0xc0080476b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.613: INFO: Pod "webserver-deployment-68df7476b-zrtz2" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-zrtz2 webserver-deployment-68df7476b- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-68df7476b-zrtz2 6eeed2fa-a7c9-4622-a073-16fe38f52a4a 117284 0 2020-03-09 03:23:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b 47f6adfa-d00c-4a74-9361-8fa7353877eb 0xc0080477c0 0xc0080477c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.113,StartTime:2020-03-09 03:23:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 03:23:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://0e2979281ad13c63d3c3ccbc99bf3224a3be0cc3b5890dbb2f31926f97b0fd42,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.613: INFO: Pod "webserver-deployment-c7997dcc8-42k8d" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-42k8d webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-42k8d 2a7f42a1-9d85-44d8-8a4c-4b15fe598314 117423 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc008047940 0xc008047941}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.613: INFO: Pod "webserver-deployment-c7997dcc8-66k6n" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-66k6n webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-66k6n 6c4771a6-5c94-4ebf-89b9-fcea1eb269b6 117405 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc008047a60 0xc008047a61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.614: INFO: Pod "webserver-deployment-c7997dcc8-6vd9z" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-6vd9z webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-6vd9z 1fee71f3-46f6-4738-adc8-6ae473c1ef46 117432 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc008047b80 0xc008047b81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:,StartTime:2020-03-09 03:23:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.614: INFO: Pod "webserver-deployment-c7997dcc8-8w8qb" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8w8qb webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-8w8qb 62fc81b5-c977-47a1-9655-4aaa0bdef4a3 117369 0 2020-03-09 03:23:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc008047cf0 0xc008047cf1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:,StartTime:2020-03-09 03:23:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.615: INFO: Pod "webserver-deployment-c7997dcc8-c4zs4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-c4zs4 webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-c4zs4 8b2bd3b4-8dd2-4a7f-88e0-a37466826419 117417 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc008047e60 0xc008047e61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.615: INFO: Pod "webserver-deployment-c7997dcc8-ckclt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ckclt webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-ckclt 5b78c62b-4b75-4c35-a37e-bfc5afa44a95 117420 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc008047f80 0xc008047f81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.616: INFO: Pod "webserver-deployment-c7997dcc8-fbmlt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fbmlt webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-fbmlt 64d8b685-eaa4-43ec-ac9f-fe50e75df4f4 117331 0 2020-03-09 03:23:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc002124100 0xc002124101}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:,StartTime:2020-03-09 03:23:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.616: INFO: Pod "webserver-deployment-c7997dcc8-h7djc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-h7djc webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-h7djc 19a47165-32f2-4df3-90bc-6dbdf8432313 117419 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc002124270 0xc002124271}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.616: INFO: Pod "webserver-deployment-c7997dcc8-j8fq5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-j8fq5 webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-j8fq5 709f110b-dd1a-47ef-9f4e-4288945e8b5d 117429 0 2020-03-09 03:23:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc002124530 0xc002124531}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.617: INFO: Pod "webserver-deployment-c7997dcc8-kx5v6" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kx5v6 webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-kx5v6 b7d21a9b-e2b9-4448-9594-7db00d07b860 117330 0 2020-03-09 03:23:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc002124650 0xc002124651}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:,StartTime:2020-03-09 03:23:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.618: INFO: Pod "webserver-deployment-c7997dcc8-pqlxc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-pqlxc webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-pqlxc 83856cf1-4844-4927-80a1-fbea6145fcd9 117366 0 2020-03-09 03:23:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc0021247c0 0xc0021247c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:,StartTime:2020-03-09 03:23:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.618: INFO: Pod "webserver-deployment-c7997dcc8-rrrcj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rrrcj webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-rrrcj 35cf4cf5-a5eb-45ee-aff9-e782a45d06f1 117340 0 2020-03-09 03:23:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc002124960 0xc002124961}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:,StartTime:2020-03-09 03:23:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  9 03:23:13.618: INFO: Pod "webserver-deployment-c7997dcc8-wzgnd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wzgnd webserver-deployment-c7997dcc8- deployment-7521 /api/v1/namespaces/deployment-7521/pods/webserver-deployment-c7997dcc8-wzgnd 292b17c4-dc5e-49aa-aba2-8435c2463d6b 117400 0 2020-03-09 03:23:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f087b9f2-e5dc-4fe6-af4e-55013d299251 0xc002124ad0 0xc002124ad1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gnh2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gnh2r,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gnh2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:23:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:23:13.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7521" for this suite.
Mar  9 03:23:34.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:23:34.505: INFO: namespace deployment-7521 deletion completed in 20.715218061s

• [SLOW TEST:31.253 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:23:34.506: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2507
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2507
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-2507
I0309 03:23:35.218505      22 runners.go:184] Created replication controller with name: externalname-service, namespace: services-2507, replica count: 2
I0309 03:23:38.270670      22 runners.go:184] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  9 03:23:41.271: INFO: Creating new exec pod
I0309 03:23:41.271093      22 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  9 03:23:46.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-2507 execpodgj5np -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Mar  9 03:23:46.863: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Mar  9 03:23:46.864: INFO: stdout: ""
Mar  9 03:23:46.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-2507 execpodgj5np -- /bin/sh -x -c nc -zv -t -w 2 10.102.202.70 80'
Mar  9 03:23:47.480: INFO: stderr: "+ nc -zv -t -w 2 10.102.202.70 80\nConnection to 10.102.202.70 80 port [tcp/http] succeeded!\n"
Mar  9 03:23:47.480: INFO: stdout: ""
Mar  9 03:23:47.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-2507 execpodgj5np -- /bin/sh -x -c nc -zv -t -w 2 172.20.8.5 31845'
Mar  9 03:23:47.945: INFO: stderr: "+ nc -zv -t -w 2 172.20.8.5 31845\nConnection to 172.20.8.5 31845 port [tcp/31845] succeeded!\n"
Mar  9 03:23:47.945: INFO: stdout: ""
Mar  9 03:23:47.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-2507 execpodgj5np -- /bin/sh -x -c nc -zv -t -w 2 172.20.8.6 31845'
Mar  9 03:23:48.409: INFO: stderr: "+ nc -zv -t -w 2 172.20.8.6 31845\nConnection to 172.20.8.6 31845 port [tcp/31845] succeeded!\n"
Mar  9 03:23:48.409: INFO: stdout: ""
Mar  9 03:23:48.409: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:23:48.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2507" for this suite.
Mar  9 03:23:56.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:23:56.998: INFO: namespace services-2507 deletion completed in 8.252921709s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:22.492 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:23:56.999: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5003
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Mar  9 03:23:57.581: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar  9 03:23:57.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-5003'
Mar  9 03:23:58.482: INFO: stderr: ""
Mar  9 03:23:58.482: INFO: stdout: "service/redis-slave created\n"
Mar  9 03:23:58.483: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar  9 03:23:58.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-5003'
Mar  9 03:23:59.271: INFO: stderr: ""
Mar  9 03:23:59.271: INFO: stdout: "service/redis-master created\n"
Mar  9 03:23:59.271: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar  9 03:23:59.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-5003'
Mar  9 03:24:00.046: INFO: stderr: ""
Mar  9 03:24:00.046: INFO: stdout: "service/frontend created\n"
Mar  9 03:24:00.047: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: 172.20.8.7/library/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar  9 03:24:00.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-5003'
Mar  9 03:24:00.775: INFO: stderr: ""
Mar  9 03:24:00.775: INFO: stdout: "deployment.apps/frontend created\n"
Mar  9 03:24:00.776: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: 172.20.8.7/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar  9 03:24:00.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-5003'
Mar  9 03:24:01.481: INFO: stderr: ""
Mar  9 03:24:01.481: INFO: stdout: "deployment.apps/redis-master created\n"
Mar  9 03:24:01.482: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: 172.20.8.7/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar  9 03:24:01.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-5003'
Mar  9 03:24:02.260: INFO: stderr: ""
Mar  9 03:24:02.260: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Mar  9 03:24:02.260: INFO: Waiting for all frontend pods to be Running.
Mar  9 03:24:07.311: INFO: Waiting for frontend to serve content.
Mar  9 03:24:07.345: INFO: Trying to add a new entry to the guestbook.
Mar  9 03:24:07.381: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar  9 03:24:07.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete --grace-period=0 --force -f - --namespace=kubectl-5003'
Mar  9 03:24:07.811: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 03:24:07.812: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar  9 03:24:07.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete --grace-period=0 --force -f - --namespace=kubectl-5003'
Mar  9 03:24:08.207: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 03:24:08.207: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  9 03:24:08.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete --grace-period=0 --force -f - --namespace=kubectl-5003'
Mar  9 03:24:08.712: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 03:24:08.712: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  9 03:24:08.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete --grace-period=0 --force -f - --namespace=kubectl-5003'
Mar  9 03:24:08.930: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 03:24:08.930: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  9 03:24:08.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete --grace-period=0 --force -f - --namespace=kubectl-5003'
Mar  9 03:24:09.370: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 03:24:09.370: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  9 03:24:09.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete --grace-period=0 --force -f - --namespace=kubectl-5003'
Mar  9 03:24:09.658: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 03:24:09.658: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:24:09.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5003" for this suite.
Mar  9 03:24:23.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:24:23.945: INFO: namespace kubectl-5003 deletion completed in 14.277095964s

• [SLOW TEST:26.946 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:24:23.947: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6224
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar  9 03:24:24.439: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-a 1ab505ba-7571-4cd9-a0a4-9e027c0e8c20 118122 0 2020-03-09 03:24:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  9 03:24:24.439: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-a 1ab505ba-7571-4cd9-a0a4-9e027c0e8c20 118122 0 2020-03-09 03:24:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar  9 03:24:34.504: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-a 1ab505ba-7571-4cd9-a0a4-9e027c0e8c20 118141 0 2020-03-09 03:24:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  9 03:24:34.504: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-a 1ab505ba-7571-4cd9-a0a4-9e027c0e8c20 118141 0 2020-03-09 03:24:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar  9 03:24:44.546: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-a 1ab505ba-7571-4cd9-a0a4-9e027c0e8c20 118160 0 2020-03-09 03:24:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  9 03:24:44.546: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-a 1ab505ba-7571-4cd9-a0a4-9e027c0e8c20 118160 0 2020-03-09 03:24:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar  9 03:24:54.610: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-a 1ab505ba-7571-4cd9-a0a4-9e027c0e8c20 118181 0 2020-03-09 03:24:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  9 03:24:54.610: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-a 1ab505ba-7571-4cd9-a0a4-9e027c0e8c20 118181 0 2020-03-09 03:24:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar  9 03:25:04.659: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-b 940149d8-5abc-44f7-9223-e14627899b4e 118200 0 2020-03-09 03:25:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  9 03:25:04.659: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-b 940149d8-5abc-44f7-9223-e14627899b4e 118200 0 2020-03-09 03:25:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar  9 03:25:14.698: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-b 940149d8-5abc-44f7-9223-e14627899b4e 118219 0 2020-03-09 03:25:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  9 03:25:14.699: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6224 /api/v1/namespaces/watch-6224/configmaps/e2e-watch-test-configmap-b 940149d8-5abc-44f7-9223-e14627899b4e 118219 0 2020-03-09 03:25:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:25:24.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6224" for this suite.
Mar  9 03:25:30.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:25:31.069: INFO: namespace watch-6224 deletion completed in 6.334985018s

• [SLOW TEST:67.123 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:25:31.070: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6558
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-6558
STEP: creating replication controller nodeport-test in namespace services-6558
I0309 03:25:31.675887      22 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-6558, replica count: 2
I0309 03:25:34.726885      22 runners.go:184] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  9 03:25:37.727: INFO: Creating new exec pod
I0309 03:25:37.727384      22 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  9 03:25:42.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-6558 execpodgx2pc -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Mar  9 03:25:43.519: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Mar  9 03:25:43.519: INFO: stdout: ""
Mar  9 03:25:43.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-6558 execpodgx2pc -- /bin/sh -x -c nc -zv -t -w 2 10.102.157.0 80'
Mar  9 03:25:44.033: INFO: stderr: "+ nc -zv -t -w 2 10.102.157.0 80\nConnection to 10.102.157.0 80 port [tcp/http] succeeded!\n"
Mar  9 03:25:44.033: INFO: stdout: ""
Mar  9 03:25:44.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-6558 execpodgx2pc -- /bin/sh -x -c nc -zv -t -w 2 172.20.8.5 31994'
Mar  9 03:25:44.559: INFO: stderr: "+ nc -zv -t -w 2 172.20.8.5 31994\nConnection to 172.20.8.5 31994 port [tcp/31994] succeeded!\n"
Mar  9 03:25:44.559: INFO: stdout: ""
Mar  9 03:25:44.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 exec --namespace=services-6558 execpodgx2pc -- /bin/sh -x -c nc -zv -t -w 2 172.20.8.6 31994'
Mar  9 03:25:45.050: INFO: stderr: "+ nc -zv -t -w 2 172.20.8.6 31994\nConnection to 172.20.8.6 31994 port [tcp/31994] succeeded!\n"
Mar  9 03:25:45.050: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:25:45.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6558" for this suite.
Mar  9 03:25:55.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:25:55.300: INFO: namespace services-6558 deletion completed in 10.240258259s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:24.231 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:25:55.301: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:25:59.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2270" for this suite.
Mar  9 03:26:45.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:26:45.933: INFO: namespace kubelet-test-2270 deletion completed in 46.242638302s

• [SLOW TEST:50.632 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:26:45.933: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7105
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-6d0f875c-0b9d-43bf-91e3-851eaf5bb76e
STEP: Creating secret with name s-test-opt-upd-d5958f59-d004-476b-8f22-00672d4944a7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6d0f875c-0b9d-43bf-91e3-851eaf5bb76e
STEP: Updating secret s-test-opt-upd-d5958f59-d004-476b-8f22-00672d4944a7
STEP: Creating secret with name s-test-opt-create-48a93e9c-cfcc-43e0-b573-f4a3617c052b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:26:56.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7105" for this suite.
Mar  9 03:27:10.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:27:11.244: INFO: namespace projected-7105 deletion completed in 14.320396811s

• [SLOW TEST:25.311 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:27:11.247: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5174
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:27:17.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5174" for this suite.
Mar  9 03:27:25.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:27:26.075: INFO: namespace watch-5174 deletion completed in 8.22922922s

• [SLOW TEST:14.828 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:27:26.076: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9880
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-0afc52ab-935c-4733-80fc-097e88633594
STEP: Creating secret with name s-test-opt-upd-22473e93-8013-401d-a0b4-37a467cb0d24
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-0afc52ab-935c-4733-80fc-097e88633594
STEP: Updating secret s-test-opt-upd-22473e93-8013-401d-a0b4-37a467cb0d24
STEP: Creating secret with name s-test-opt-create-510f9b11-6085-49dc-8bee-24e42e7583d7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:27:35.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9880" for this suite.
Mar  9 03:27:49.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:27:49.401: INFO: namespace secrets-9880 deletion completed in 14.256556132s

• [SLOW TEST:23.325 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:27:49.403: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9774
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-9774/configmap-test-f09a3ed9-d2a2-4112-8a7c-6d7b59da1181
STEP: Creating a pod to test consume configMaps
Mar  9 03:27:49.884: INFO: Waiting up to 5m0s for pod "pod-configmaps-52754087-faf4-45fc-bdff-a361de224261" in namespace "configmap-9774" to be "success or failure"
Mar  9 03:27:49.888: INFO: Pod "pod-configmaps-52754087-faf4-45fc-bdff-a361de224261": Phase="Pending", Reason="", readiness=false. Elapsed: 4.470594ms
Mar  9 03:27:51.934: INFO: Pod "pod-configmaps-52754087-faf4-45fc-bdff-a361de224261": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050367601s
Mar  9 03:27:53.943: INFO: Pod "pod-configmaps-52754087-faf4-45fc-bdff-a361de224261": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058679419s
STEP: Saw pod success
Mar  9 03:27:53.943: INFO: Pod "pod-configmaps-52754087-faf4-45fc-bdff-a361de224261" satisfied condition "success or failure"
Mar  9 03:27:53.957: INFO: Trying to get logs from node worker1 pod pod-configmaps-52754087-faf4-45fc-bdff-a361de224261 container env-test: <nil>
STEP: delete the pod
Mar  9 03:27:54.063: INFO: Waiting for pod pod-configmaps-52754087-faf4-45fc-bdff-a361de224261 to disappear
Mar  9 03:27:54.082: INFO: Pod pod-configmaps-52754087-faf4-45fc-bdff-a361de224261 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:27:54.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9774" for this suite.
Mar  9 03:28:02.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:28:02.312: INFO: namespace configmap-9774 deletion completed in 8.220005087s

• [SLOW TEST:12.909 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:28:02.313: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9256
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 03:28:04.450: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321284, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321284, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321284, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321284, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:28:06.456: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321284, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321284, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321284, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321284, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 03:28:09.623: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:28:10.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9256" for this suite.
Mar  9 03:28:18.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:28:18.415: INFO: namespace webhook-9256 deletion completed in 8.246714117s
STEP: Destroying namespace "webhook-9256-markers" for this suite.
Mar  9 03:28:24.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:28:24.610: INFO: namespace webhook-9256-markers deletion completed in 6.194864176s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.365 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:28:24.680: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7048
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar  9 03:28:25.051: INFO: Waiting up to 5m0s for pod "pod-ca4e012a-0660-43d6-9fe7-7d8a87407b25" in namespace "emptydir-7048" to be "success or failure"
Mar  9 03:28:25.141: INFO: Pod "pod-ca4e012a-0660-43d6-9fe7-7d8a87407b25": Phase="Pending", Reason="", readiness=false. Elapsed: 89.944354ms
Mar  9 03:28:27.148: INFO: Pod "pod-ca4e012a-0660-43d6-9fe7-7d8a87407b25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.096763192s
Mar  9 03:28:29.156: INFO: Pod "pod-ca4e012a-0660-43d6-9fe7-7d8a87407b25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.104785552s
STEP: Saw pod success
Mar  9 03:28:29.156: INFO: Pod "pod-ca4e012a-0660-43d6-9fe7-7d8a87407b25" satisfied condition "success or failure"
Mar  9 03:28:29.162: INFO: Trying to get logs from node worker1 pod pod-ca4e012a-0660-43d6-9fe7-7d8a87407b25 container test-container: <nil>
STEP: delete the pod
Mar  9 03:28:29.309: INFO: Waiting for pod pod-ca4e012a-0660-43d6-9fe7-7d8a87407b25 to disappear
Mar  9 03:28:29.334: INFO: Pod pod-ca4e012a-0660-43d6-9fe7-7d8a87407b25 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:28:29.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7048" for this suite.
Mar  9 03:28:37.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:28:37.537: INFO: namespace emptydir-7048 deletion completed in 8.193890412s

• [SLOW TEST:12.857 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:28:37.538: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7647
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:28:37.878: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Mar  9 03:28:48.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-7647 create -f -'
Mar  9 03:28:52.941: INFO: stderr: ""
Mar  9 03:28:52.941: INFO: stdout: "e2e-test-crd-publish-openapi-2686-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Mar  9 03:28:52.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-7647 delete e2e-test-crd-publish-openapi-2686-crds test-foo'
Mar  9 03:28:53.238: INFO: stderr: ""
Mar  9 03:28:53.238: INFO: stdout: "e2e-test-crd-publish-openapi-2686-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Mar  9 03:28:53.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-7647 apply -f -'
Mar  9 03:28:54.142: INFO: stderr: ""
Mar  9 03:28:54.142: INFO: stdout: "e2e-test-crd-publish-openapi-2686-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Mar  9 03:28:54.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-7647 delete e2e-test-crd-publish-openapi-2686-crds test-foo'
Mar  9 03:28:54.381: INFO: stderr: ""
Mar  9 03:28:54.381: INFO: stdout: "e2e-test-crd-publish-openapi-2686-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Mar  9 03:28:54.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-7647 create -f -'
Mar  9 03:28:54.996: INFO: rc: 1
Mar  9 03:28:54.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-7647 apply -f -'
Mar  9 03:28:55.708: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Mar  9 03:28:55.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-7647 create -f -'
Mar  9 03:28:56.397: INFO: rc: 1
Mar  9 03:28:56.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-7647 apply -f -'
Mar  9 03:28:57.103: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Mar  9 03:28:57.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 explain e2e-test-crd-publish-openapi-2686-crds'
Mar  9 03:28:57.751: INFO: stderr: ""
Mar  9 03:28:57.751: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2686-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Mar  9 03:28:57.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 explain e2e-test-crd-publish-openapi-2686-crds.metadata'
Mar  9 03:28:58.388: INFO: stderr: ""
Mar  9 03:28:58.388: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2686-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Mar  9 03:28:58.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 explain e2e-test-crd-publish-openapi-2686-crds.spec'
Mar  9 03:28:59.037: INFO: stderr: ""
Mar  9 03:28:59.038: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2686-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Mar  9 03:28:59.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 explain e2e-test-crd-publish-openapi-2686-crds.spec.bars'
Mar  9 03:28:59.752: INFO: stderr: ""
Mar  9 03:28:59.752: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2686-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Mar  9 03:28:59.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 explain e2e-test-crd-publish-openapi-2686-crds.spec.bars2'
Mar  9 03:29:00.397: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:29:06.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7647" for this suite.
Mar  9 03:29:12.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:29:12.785: INFO: namespace crd-publish-openapi-7647 deletion completed in 6.183841568s

• [SLOW TEST:35.247 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:29:12.786: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1832
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Mar  9 03:29:13.541: INFO: Waiting up to 5m0s for pod "client-containers-17f8fb94-534c-4a0e-9259-0051134b96a0" in namespace "containers-1832" to be "success or failure"
Mar  9 03:29:13.547: INFO: Pod "client-containers-17f8fb94-534c-4a0e-9259-0051134b96a0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.12746ms
Mar  9 03:29:15.567: INFO: Pod "client-containers-17f8fb94-534c-4a0e-9259-0051134b96a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02577203s
Mar  9 03:29:17.575: INFO: Pod "client-containers-17f8fb94-534c-4a0e-9259-0051134b96a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033447795s
STEP: Saw pod success
Mar  9 03:29:17.575: INFO: Pod "client-containers-17f8fb94-534c-4a0e-9259-0051134b96a0" satisfied condition "success or failure"
Mar  9 03:29:17.582: INFO: Trying to get logs from node worker1 pod client-containers-17f8fb94-534c-4a0e-9259-0051134b96a0 container test-container: <nil>
STEP: delete the pod
Mar  9 03:29:17.674: INFO: Waiting for pod client-containers-17f8fb94-534c-4a0e-9259-0051134b96a0 to disappear
Mar  9 03:29:17.706: INFO: Pod client-containers-17f8fb94-534c-4a0e-9259-0051134b96a0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:29:17.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1832" for this suite.
Mar  9 03:29:25.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:29:25.930: INFO: namespace containers-1832 deletion completed in 8.188676059s

• [SLOW TEST:13.144 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:29:25.931: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 03:29:26.354: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4636fe17-984f-4b14-a489-32d1a1fb6de0" in namespace "projected-6699" to be "success or failure"
Mar  9 03:29:26.375: INFO: Pod "downwardapi-volume-4636fe17-984f-4b14-a489-32d1a1fb6de0": Phase="Pending", Reason="", readiness=false. Elapsed: 21.17422ms
Mar  9 03:29:28.401: INFO: Pod "downwardapi-volume-4636fe17-984f-4b14-a489-32d1a1fb6de0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047196528s
Mar  9 03:29:30.409: INFO: Pod "downwardapi-volume-4636fe17-984f-4b14-a489-32d1a1fb6de0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054608939s
STEP: Saw pod success
Mar  9 03:29:30.409: INFO: Pod "downwardapi-volume-4636fe17-984f-4b14-a489-32d1a1fb6de0" satisfied condition "success or failure"
Mar  9 03:29:30.414: INFO: Trying to get logs from node worker1 pod downwardapi-volume-4636fe17-984f-4b14-a489-32d1a1fb6de0 container client-container: <nil>
STEP: delete the pod
Mar  9 03:29:30.525: INFO: Waiting for pod downwardapi-volume-4636fe17-984f-4b14-a489-32d1a1fb6de0 to disappear
Mar  9 03:29:30.545: INFO: Pod downwardapi-volume-4636fe17-984f-4b14-a489-32d1a1fb6de0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:29:30.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6699" for this suite.
Mar  9 03:29:38.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:29:38.826: INFO: namespace projected-6699 deletion completed in 8.204925667s

• [SLOW TEST:12.895 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:29:38.827: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5110
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-77c6d6c0-fea5-4ab4-b26d-4245d670a2ed
STEP: Creating a pod to test consume secrets
Mar  9 03:29:39.234: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-94fdb4a6-b3c1-4502-9f1b-0ee6755e073a" in namespace "projected-5110" to be "success or failure"
Mar  9 03:29:39.240: INFO: Pod "pod-projected-secrets-94fdb4a6-b3c1-4502-9f1b-0ee6755e073a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.344192ms
Mar  9 03:29:41.249: INFO: Pod "pod-projected-secrets-94fdb4a6-b3c1-4502-9f1b-0ee6755e073a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014505512s
Mar  9 03:29:43.256: INFO: Pod "pod-projected-secrets-94fdb4a6-b3c1-4502-9f1b-0ee6755e073a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021928729s
STEP: Saw pod success
Mar  9 03:29:43.256: INFO: Pod "pod-projected-secrets-94fdb4a6-b3c1-4502-9f1b-0ee6755e073a" satisfied condition "success or failure"
Mar  9 03:29:43.263: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-94fdb4a6-b3c1-4502-9f1b-0ee6755e073a container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  9 03:29:43.333: INFO: Waiting for pod pod-projected-secrets-94fdb4a6-b3c1-4502-9f1b-0ee6755e073a to disappear
Mar  9 03:29:43.377: INFO: Pod pod-projected-secrets-94fdb4a6-b3c1-4502-9f1b-0ee6755e073a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:29:43.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5110" for this suite.
Mar  9 03:29:49.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:29:50.137: INFO: namespace projected-5110 deletion completed in 6.7496448s

• [SLOW TEST:11.310 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:29:50.139: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3575
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Mar  9 03:30:01.291: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0309 03:30:01.291621      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  9 03:30:01.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3575" for this suite.
Mar  9 03:30:11.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:30:11.515: INFO: namespace gc-3575 deletion completed in 10.214507772s

• [SLOW TEST:21.376 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:30:11.517: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1092
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:30:15.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1092" for this suite.
Mar  9 03:30:26.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:30:26.324: INFO: namespace containers-1092 deletion completed in 10.338483698s

• [SLOW TEST:14.807 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:30:26.325: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5827
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-71f82543-d4e0-4c7e-84c2-c769df8e629e
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:30:26.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5827" for this suite.
Mar  9 03:30:32.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:30:32.975: INFO: namespace secrets-5827 deletion completed in 6.208620815s

• [SLOW TEST:6.649 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:30:32.976: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7576
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  9 03:30:37.907: INFO: Successfully updated pod "annotationupdate99f7c075-3ade-471a-b31b-cce9af57c4eb"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:30:39.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7576" for this suite.
Mar  9 03:30:54.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:30:54.156: INFO: namespace downward-api-7576 deletion completed in 14.196536535s

• [SLOW TEST:21.180 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:30:54.158: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-2852
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-2852
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2852
STEP: Deleting pre-stop pod
Mar  9 03:31:07.977: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:31:08.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2852" for this suite.
Mar  9 03:31:52.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:31:52.361: INFO: namespace prestop-2852 deletion completed in 44.340083268s

• [SLOW TEST:58.204 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:31:52.362: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  9 03:31:53.010: INFO: Waiting up to 5m0s for pod "pod-11b7b20d-0f1b-4e28-9093-372a12ab45bb" in namespace "emptydir-4443" to be "success or failure"
Mar  9 03:31:53.026: INFO: Pod "pod-11b7b20d-0f1b-4e28-9093-372a12ab45bb": Phase="Pending", Reason="", readiness=false. Elapsed: 15.453923ms
Mar  9 03:31:55.033: INFO: Pod "pod-11b7b20d-0f1b-4e28-9093-372a12ab45bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022300377s
Mar  9 03:31:57.042: INFO: Pod "pod-11b7b20d-0f1b-4e28-9093-372a12ab45bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031471095s
STEP: Saw pod success
Mar  9 03:31:57.042: INFO: Pod "pod-11b7b20d-0f1b-4e28-9093-372a12ab45bb" satisfied condition "success or failure"
Mar  9 03:31:57.047: INFO: Trying to get logs from node worker1 pod pod-11b7b20d-0f1b-4e28-9093-372a12ab45bb container test-container: <nil>
STEP: delete the pod
Mar  9 03:31:57.180: INFO: Waiting for pod pod-11b7b20d-0f1b-4e28-9093-372a12ab45bb to disappear
Mar  9 03:31:57.200: INFO: Pod pod-11b7b20d-0f1b-4e28-9093-372a12ab45bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:31:57.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4443" for this suite.
Mar  9 03:32:03.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:32:03.486: INFO: namespace emptydir-4443 deletion completed in 6.277869811s

• [SLOW TEST:11.124 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:32:03.488: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1749
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:32:03.893: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar  9 03:32:14.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-1749 create -f -'
Mar  9 03:32:19.373: INFO: stderr: ""
Mar  9 03:32:19.373: INFO: stdout: "e2e-test-crd-publish-openapi-9277-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Mar  9 03:32:19.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-1749 delete e2e-test-crd-publish-openapi-9277-crds test-cr'
Mar  9 03:32:19.676: INFO: stderr: ""
Mar  9 03:32:19.676: INFO: stdout: "e2e-test-crd-publish-openapi-9277-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Mar  9 03:32:19.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-1749 apply -f -'
Mar  9 03:32:20.652: INFO: stderr: ""
Mar  9 03:32:20.653: INFO: stdout: "e2e-test-crd-publish-openapi-9277-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Mar  9 03:32:20.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 --namespace=crd-publish-openapi-1749 delete e2e-test-crd-publish-openapi-9277-crds test-cr'
Mar  9 03:32:20.919: INFO: stderr: ""
Mar  9 03:32:20.919: INFO: stdout: "e2e-test-crd-publish-openapi-9277-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Mar  9 03:32:20.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 explain e2e-test-crd-publish-openapi-9277-crds'
Mar  9 03:32:21.649: INFO: stderr: ""
Mar  9 03:32:21.649: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9277-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:32:27.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1749" for this suite.
Mar  9 03:32:33.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:32:33.641: INFO: namespace crd-publish-openapi-1749 deletion completed in 6.227050026s

• [SLOW TEST:30.153 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:32:33.642: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3054
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-2ffdecbc-7a7b-43ca-95bc-bf042d68e807
STEP: Creating a pod to test consume configMaps
Mar  9 03:32:34.209: INFO: Waiting up to 5m0s for pod "pod-configmaps-62b97359-e459-431e-81d7-a9b86939d7c3" in namespace "configmap-3054" to be "success or failure"
Mar  9 03:32:34.218: INFO: Pod "pod-configmaps-62b97359-e459-431e-81d7-a9b86939d7c3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.233393ms
Mar  9 03:32:36.227: INFO: Pod "pod-configmaps-62b97359-e459-431e-81d7-a9b86939d7c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017106294s
Mar  9 03:32:38.235: INFO: Pod "pod-configmaps-62b97359-e459-431e-81d7-a9b86939d7c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025579259s
STEP: Saw pod success
Mar  9 03:32:38.235: INFO: Pod "pod-configmaps-62b97359-e459-431e-81d7-a9b86939d7c3" satisfied condition "success or failure"
Mar  9 03:32:38.241: INFO: Trying to get logs from node worker1 pod pod-configmaps-62b97359-e459-431e-81d7-a9b86939d7c3 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  9 03:32:38.360: INFO: Waiting for pod pod-configmaps-62b97359-e459-431e-81d7-a9b86939d7c3 to disappear
Mar  9 03:32:38.367: INFO: Pod pod-configmaps-62b97359-e459-431e-81d7-a9b86939d7c3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:32:38.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3054" for this suite.
Mar  9 03:32:46.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:32:46.745: INFO: namespace configmap-3054 deletion completed in 8.369887916s

• [SLOW TEST:13.103 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:32:46.745: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8710
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 03:32:48.651: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 03:32:50.673: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321568, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321568, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321568, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321568, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 03:32:53.756: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
Mar  9 03:32:53.982: INFO: Waiting for webhook configuration to be ready...
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:32:54.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8710" for this suite.
Mar  9 03:33:02.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:33:02.710: INFO: namespace webhook-8710 deletion completed in 8.219821178s
STEP: Destroying namespace "webhook-8710-markers" for this suite.
Mar  9 03:33:08.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:33:09.093: INFO: namespace webhook-8710-markers deletion completed in 6.382936875s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.389 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:33:09.135: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-5549
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:33:09.425: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:33:15.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5549" for this suite.
Mar  9 03:33:23.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:33:23.855: INFO: namespace custom-resource-definition-5549 deletion completed in 8.280552565s

• [SLOW TEST:14.720 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:33:23.855: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-243
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3296
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3093
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:33:41.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-243" for this suite.
Mar  9 03:33:47.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:33:47.374: INFO: namespace namespaces-243 deletion completed in 6.328732523s
STEP: Destroying namespace "nsdeletetest-3296" for this suite.
Mar  9 03:33:47.378: INFO: Namespace nsdeletetest-3296 was already deleted
STEP: Destroying namespace "nsdeletetest-3093" for this suite.
Mar  9 03:33:53.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:33:53.685: INFO: namespace nsdeletetest-3093 deletion completed in 6.307265295s

• [SLOW TEST:29.830 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:33:53.686: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1231
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:33:54.130: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-5b5c5e14-1c85-424f-8b2b-cfe52a1b69e6" in namespace "security-context-test-1231" to be "success or failure"
Mar  9 03:33:54.139: INFO: Pod "alpine-nnp-false-5b5c5e14-1c85-424f-8b2b-cfe52a1b69e6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.052304ms
Mar  9 03:33:56.147: INFO: Pod "alpine-nnp-false-5b5c5e14-1c85-424f-8b2b-cfe52a1b69e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016763175s
Mar  9 03:33:58.154: INFO: Pod "alpine-nnp-false-5b5c5e14-1c85-424f-8b2b-cfe52a1b69e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024569815s
Mar  9 03:33:58.154: INFO: Pod "alpine-nnp-false-5b5c5e14-1c85-424f-8b2b-cfe52a1b69e6" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:33:58.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1231" for this suite.
Mar  9 03:34:06.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:34:06.413: INFO: namespace security-context-test-1231 deletion completed in 8.234903925s

• [SLOW TEST:12.728 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:34:06.415: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-c5ce1a9a-9425-4323-bbf0-35ac2264206d
STEP: Creating a pod to test consume secrets
Mar  9 03:34:06.979: INFO: Waiting up to 5m0s for pod "pod-secrets-070575dd-144c-4ad1-873d-868b9ca60b29" in namespace "secrets-5548" to be "success or failure"
Mar  9 03:34:06.985: INFO: Pod "pod-secrets-070575dd-144c-4ad1-873d-868b9ca60b29": Phase="Pending", Reason="", readiness=false. Elapsed: 5.655362ms
Mar  9 03:34:09.007: INFO: Pod "pod-secrets-070575dd-144c-4ad1-873d-868b9ca60b29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028061462s
Mar  9 03:34:11.015: INFO: Pod "pod-secrets-070575dd-144c-4ad1-873d-868b9ca60b29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035864301s
STEP: Saw pod success
Mar  9 03:34:11.015: INFO: Pod "pod-secrets-070575dd-144c-4ad1-873d-868b9ca60b29" satisfied condition "success or failure"
Mar  9 03:34:11.021: INFO: Trying to get logs from node worker1 pod pod-secrets-070575dd-144c-4ad1-873d-868b9ca60b29 container secret-env-test: <nil>
STEP: delete the pod
Mar  9 03:34:11.200: INFO: Waiting for pod pod-secrets-070575dd-144c-4ad1-873d-868b9ca60b29 to disappear
Mar  9 03:34:11.207: INFO: Pod pod-secrets-070575dd-144c-4ad1-873d-868b9ca60b29 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:34:11.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5548" for this suite.
Mar  9 03:34:19.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:34:19.539: INFO: namespace secrets-5548 deletion completed in 8.295476212s

• [SLOW TEST:13.124 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:34:19.540: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1536
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  9 03:34:19.962: INFO: Waiting up to 5m0s for pod "pod-ea11b7cb-f395-474b-86da-ca17da2d1851" in namespace "emptydir-1536" to be "success or failure"
Mar  9 03:34:19.992: INFO: Pod "pod-ea11b7cb-f395-474b-86da-ca17da2d1851": Phase="Pending", Reason="", readiness=false. Elapsed: 29.982199ms
Mar  9 03:34:22.029: INFO: Pod "pod-ea11b7cb-f395-474b-86da-ca17da2d1851": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067349508s
Mar  9 03:34:24.037: INFO: Pod "pod-ea11b7cb-f395-474b-86da-ca17da2d1851": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07506104s
STEP: Saw pod success
Mar  9 03:34:24.037: INFO: Pod "pod-ea11b7cb-f395-474b-86da-ca17da2d1851" satisfied condition "success or failure"
Mar  9 03:34:24.042: INFO: Trying to get logs from node worker1 pod pod-ea11b7cb-f395-474b-86da-ca17da2d1851 container test-container: <nil>
STEP: delete the pod
Mar  9 03:34:24.125: INFO: Waiting for pod pod-ea11b7cb-f395-474b-86da-ca17da2d1851 to disappear
Mar  9 03:34:24.166: INFO: Pod pod-ea11b7cb-f395-474b-86da-ca17da2d1851 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:34:24.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1536" for this suite.
Mar  9 03:34:30.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:34:30.600: INFO: namespace emptydir-1536 deletion completed in 6.424040073s

• [SLOW TEST:11.061 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:34:30.601: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7022
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7022.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7022.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7022.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7022.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7022.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7022.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  9 03:34:37.608: INFO: Unable to read jessie_hosts@dns-querier-2 from pod dns-7022/dns-test-7f1de709-cece-40eb-9178-25e951c12f34: the server could not find the requested resource (get pods dns-test-7f1de709-cece-40eb-9178-25e951c12f34)
Mar  9 03:34:37.614: INFO: Unable to read jessie_udp@PodARecord from pod dns-7022/dns-test-7f1de709-cece-40eb-9178-25e951c12f34: the server could not find the requested resource (get pods dns-test-7f1de709-cece-40eb-9178-25e951c12f34)
Mar  9 03:34:37.622: INFO: Unable to read jessie_tcp@PodARecord from pod dns-7022/dns-test-7f1de709-cece-40eb-9178-25e951c12f34: the server could not find the requested resource (get pods dns-test-7f1de709-cece-40eb-9178-25e951c12f34)
Mar  9 03:34:37.622: INFO: Lookups using dns-7022/dns-test-7f1de709-cece-40eb-9178-25e951c12f34 failed for: [jessie_hosts@dns-querier-2 jessie_udp@PodARecord jessie_tcp@PodARecord]

Mar  9 03:34:42.677: INFO: DNS probes using dns-7022/dns-test-7f1de709-cece-40eb-9178-25e951c12f34 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:34:43.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7022" for this suite.
Mar  9 03:34:51.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:34:51.479: INFO: namespace dns-7022 deletion completed in 8.291186586s

• [SLOW TEST:20.878 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:34:51.480: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8238
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Mar  9 03:35:22.226: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:35:22.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0309 03:35:22.226035      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-8238" for this suite.
Mar  9 03:35:30.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:35:30.515: INFO: namespace gc-8238 deletion completed in 8.281193845s

• [SLOW TEST:39.036 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:35:30.517: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4005
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  9 03:35:30.911: INFO: Waiting up to 5m0s for pod "pod-2bbf1578-2331-4506-a1e6-60887e6fc591" in namespace "emptydir-4005" to be "success or failure"
Mar  9 03:35:30.917: INFO: Pod "pod-2bbf1578-2331-4506-a1e6-60887e6fc591": Phase="Pending", Reason="", readiness=false. Elapsed: 5.509847ms
Mar  9 03:35:32.926: INFO: Pod "pod-2bbf1578-2331-4506-a1e6-60887e6fc591": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014417675s
Mar  9 03:35:34.944: INFO: Pod "pod-2bbf1578-2331-4506-a1e6-60887e6fc591": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032822234s
STEP: Saw pod success
Mar  9 03:35:34.944: INFO: Pod "pod-2bbf1578-2331-4506-a1e6-60887e6fc591" satisfied condition "success or failure"
Mar  9 03:35:35.037: INFO: Trying to get logs from node worker1 pod pod-2bbf1578-2331-4506-a1e6-60887e6fc591 container test-container: <nil>
STEP: delete the pod
Mar  9 03:35:35.117: INFO: Waiting for pod pod-2bbf1578-2331-4506-a1e6-60887e6fc591 to disappear
Mar  9 03:35:35.187: INFO: Pod pod-2bbf1578-2331-4506-a1e6-60887e6fc591 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:35:35.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4005" for this suite.
Mar  9 03:35:43.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:35:43.454: INFO: namespace emptydir-4005 deletion completed in 8.257975109s

• [SLOW TEST:12.937 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:35:43.456: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8670
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 03:35:45.543: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 03:35:47.566: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321745, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321745, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321745, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321745, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 03:35:50.665: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:36:01.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8670" for this suite.
Mar  9 03:36:09.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:36:09.539: INFO: namespace webhook-8670 deletion completed in 8.273273414s
STEP: Destroying namespace "webhook-8670-markers" for this suite.
Mar  9 03:36:15.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:36:15.782: INFO: namespace webhook-8670-markers deletion completed in 6.243129456s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:32.377 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:36:15.833: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2383
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-2383
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  9 03:36:16.201: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  9 03:36:36.694: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.4.161 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2383 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 03:36:36.694: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 03:36:38.098: INFO: Found all expected endpoints: [netserver-0]
Mar  9 03:36:38.105: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.3.148 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2383 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  9 03:36:38.105: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
Mar  9 03:36:39.419: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:36:39.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2383" for this suite.
Mar  9 03:36:53.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:36:53.867: INFO: namespace pod-network-test-2383 deletion completed in 14.438220851s

• [SLOW TEST:38.034 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:36:53.867: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1209
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  9 03:36:54.338: INFO: Waiting up to 5m0s for pod "downwardapi-volume-68b409f0-8f30-455f-9ea9-68112aa6f985" in namespace "downward-api-1209" to be "success or failure"
Mar  9 03:36:54.345: INFO: Pod "downwardapi-volume-68b409f0-8f30-455f-9ea9-68112aa6f985": Phase="Pending", Reason="", readiness=false. Elapsed: 7.156442ms
Mar  9 03:36:56.353: INFO: Pod "downwardapi-volume-68b409f0-8f30-455f-9ea9-68112aa6f985": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015059848s
Mar  9 03:36:58.360: INFO: Pod "downwardapi-volume-68b409f0-8f30-455f-9ea9-68112aa6f985": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022864017s
STEP: Saw pod success
Mar  9 03:36:58.361: INFO: Pod "downwardapi-volume-68b409f0-8f30-455f-9ea9-68112aa6f985" satisfied condition "success or failure"
Mar  9 03:36:58.367: INFO: Trying to get logs from node worker1 pod downwardapi-volume-68b409f0-8f30-455f-9ea9-68112aa6f985 container client-container: <nil>
STEP: delete the pod
Mar  9 03:36:58.451: INFO: Waiting for pod downwardapi-volume-68b409f0-8f30-455f-9ea9-68112aa6f985 to disappear
Mar  9 03:36:58.468: INFO: Pod downwardapi-volume-68b409f0-8f30-455f-9ea9-68112aa6f985 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:36:58.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1209" for this suite.
Mar  9 03:37:06.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:37:06.767: INFO: namespace downward-api-1209 deletion completed in 8.276898146s

• [SLOW TEST:12.900 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:37:06.768: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7106
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  9 03:37:15.360: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  9 03:37:15.366: INFO: Pod pod-with-poststart-http-hook still exists
Mar  9 03:37:17.366: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  9 03:37:17.376: INFO: Pod pod-with-poststart-http-hook still exists
Mar  9 03:37:19.366: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  9 03:37:19.375: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:37:19.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7106" for this suite.
Mar  9 03:37:49.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:37:49.573: INFO: namespace container-lifecycle-hook-7106 deletion completed in 30.185908624s

• [SLOW TEST:42.805 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:37:49.573: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4045
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 03:37:51.332: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 03:37:53.353: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321871, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321871, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321871, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719321871, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 03:37:56.665: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
Mar  9 03:37:56.859: INFO: Waiting for webhook configuration to be ready...
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:38:09.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4045" for this suite.
Mar  9 03:38:17.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:38:18.154: INFO: namespace webhook-4045 deletion completed in 8.31245964s
STEP: Destroying namespace "webhook-4045-markers" for this suite.
Mar  9 03:38:24.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:38:24.345: INFO: namespace webhook-4045-markers deletion completed in 6.191008899s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:34.836 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:38:24.414: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2270
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar  9 03:38:27.145: INFO: Pod name wrapped-volume-race-c8c6fc04-7d8d-4120-93a6-f9a12cb51a44: Found 0 pods out of 5
Mar  9 03:38:32.166: INFO: Pod name wrapped-volume-race-c8c6fc04-7d8d-4120-93a6-f9a12cb51a44: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c8c6fc04-7d8d-4120-93a6-f9a12cb51a44 in namespace emptydir-wrapper-2270, will wait for the garbage collector to delete the pods
Mar  9 03:38:44.458: INFO: Deleting ReplicationController wrapped-volume-race-c8c6fc04-7d8d-4120-93a6-f9a12cb51a44 took: 76.085931ms
Mar  9 03:38:44.958: INFO: Terminating ReplicationController wrapped-volume-race-c8c6fc04-7d8d-4120-93a6-f9a12cb51a44 pods took: 500.384244ms
STEP: Creating RC which spawns configmap-volume pods
Mar  9 03:39:22.318: INFO: Pod name wrapped-volume-race-76165ef6-4d6d-4e11-a01f-0323171a4585: Found 0 pods out of 5
Mar  9 03:39:27.512: INFO: Pod name wrapped-volume-race-76165ef6-4d6d-4e11-a01f-0323171a4585: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-76165ef6-4d6d-4e11-a01f-0323171a4585 in namespace emptydir-wrapper-2270, will wait for the garbage collector to delete the pods
Mar  9 03:39:39.903: INFO: Deleting ReplicationController wrapped-volume-race-76165ef6-4d6d-4e11-a01f-0323171a4585 took: 92.751616ms
Mar  9 03:39:40.804: INFO: Terminating ReplicationController wrapped-volume-race-76165ef6-4d6d-4e11-a01f-0323171a4585 pods took: 900.480141ms
STEP: Creating RC which spawns configmap-volume pods
Mar  9 03:40:22.166: INFO: Pod name wrapped-volume-race-41bfcd49-1fb2-49ee-a471-d0b9886393eb: Found 0 pods out of 5
Mar  9 03:40:27.272: INFO: Pod name wrapped-volume-race-41bfcd49-1fb2-49ee-a471-d0b9886393eb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-41bfcd49-1fb2-49ee-a471-d0b9886393eb in namespace emptydir-wrapper-2270, will wait for the garbage collector to delete the pods
Mar  9 03:40:39.662: INFO: Deleting ReplicationController wrapped-volume-race-41bfcd49-1fb2-49ee-a471-d0b9886393eb took: 252.086715ms
Mar  9 03:40:40.263: INFO: Terminating ReplicationController wrapped-volume-race-41bfcd49-1fb2-49ee-a471-d0b9886393eb pods took: 600.646448ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:41:25.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2270" for this suite.
Mar  9 03:41:43.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:41:43.305: INFO: namespace emptydir-wrapper-2270 deletion completed in 18.235051271s

• [SLOW TEST:198.892 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:41:43.306: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6920
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar  9 03:41:43.682: INFO: Pod name pod-release: Found 0 pods out of 1
Mar  9 03:41:48.691: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:41:49.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6920" for this suite.
Mar  9 03:41:57.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:41:57.985: INFO: namespace replication-controller-6920 deletion completed in 8.21820943s

• [SLOW TEST:14.679 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:41:57.986: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2811
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:41:58.335: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar  9 03:41:58.370: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar  9 03:42:03.379: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  9 03:42:03.379: INFO: Creating deployment "test-rolling-update-deployment"
Mar  9 03:42:03.415: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar  9 03:42:03.428: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar  9 03:42:05.444: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar  9 03:42:05.448: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719322123, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719322123, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719322123, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719322123, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-5cb9fc687f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  9 03:42:07.456: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  9 03:42:07.473: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2811 /apis/apps/v1/namespaces/deployment-2811/deployments/test-rolling-update-deployment 35ad4cab-e13f-4e76-8005-b4772d35ea2b 122670 1 2020-03-09 03:42:03 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004434f88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-03-09 03:42:03 +0000 UTC,LastTransitionTime:2020-03-09 03:42:03 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-5cb9fc687f" has successfully progressed.,LastUpdateTime:2020-03-09 03:42:06 +0000 UTC,LastTransitionTime:2020-03-09 03:42:03 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Mar  9 03:42:07.480: INFO: New ReplicaSet "test-rolling-update-deployment-5cb9fc687f" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-5cb9fc687f  deployment-2811 /apis/apps/v1/namespaces/deployment-2811/replicasets/test-rolling-update-deployment-5cb9fc687f 25a123f4-7c1b-4c7c-8a52-edb65bb560ed 122659 1 2020-03-09 03:42:03 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5cb9fc687f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 35ad4cab-e13f-4e76-8005-b4772d35ea2b 0xc004435657 0xc004435658}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 5cb9fc687f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5cb9fc687f] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0044356b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar  9 03:42:07.480: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar  9 03:42:07.480: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2811 /apis/apps/v1/namespaces/deployment-2811/replicasets/test-rolling-update-controller 1874894b-5929-4c3c-94bb-82b36d9ff16c 122669 2 2020-03-09 03:41:58 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 35ad4cab-e13f-4e76-8005-b4772d35ea2b 0xc004435587 0xc004435588}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd 172.20.8.7/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0044355e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  9 03:42:07.488: INFO: Pod "test-rolling-update-deployment-5cb9fc687f-lmp5k" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-5cb9fc687f-lmp5k test-rolling-update-deployment-5cb9fc687f- deployment-2811 /api/v1/namespaces/deployment-2811/pods/test-rolling-update-deployment-5cb9fc687f-lmp5k 30c8f89d-dc39-4503-b1ff-9f23968aba95 122658 0 2020-03-09 03:42:03 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5cb9fc687f] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-5cb9fc687f 25a123f4-7c1b-4c7c-8a52-edb65bb560ed 0xc004435b17 0xc004435b18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-vl9h7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-vl9h7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:172.20.8.7/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-vl9h7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:42:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:42:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:42:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-09 03:42:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.185,StartTime:2020-03-09 03:42:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-09 03:42:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/redis:5.0.5-alpine,ImageID:docker-pullable://172.20.8.7/library/redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c,ContainerID:docker://6d9aef5ee720eac0afbefbc151d9c9289ed9041ffc22d3554bd0ef04438214af,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.185,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:42:07.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2811" for this suite.
Mar  9 03:42:15.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:42:15.756: INFO: namespace deployment-2811 deletion completed in 8.259764953s

• [SLOW TEST:17.771 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:42:15.757: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4297
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-5lch
STEP: Creating a pod to test atomic-volume-subpath
Mar  9 03:42:16.154: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5lch" in namespace "subpath-4297" to be "success or failure"
Mar  9 03:42:16.285: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Pending", Reason="", readiness=false. Elapsed: 130.384307ms
Mar  9 03:42:18.292: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Pending", Reason="", readiness=false. Elapsed: 2.13736346s
Mar  9 03:42:20.333: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Running", Reason="", readiness=true. Elapsed: 4.178038126s
Mar  9 03:42:22.340: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Running", Reason="", readiness=true. Elapsed: 6.185696938s
Mar  9 03:42:24.347: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Running", Reason="", readiness=true. Elapsed: 8.192150162s
Mar  9 03:42:26.356: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Running", Reason="", readiness=true. Elapsed: 10.201298248s
Mar  9 03:42:28.364: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Running", Reason="", readiness=true. Elapsed: 12.209266199s
Mar  9 03:42:30.371: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Running", Reason="", readiness=true. Elapsed: 14.216518313s
Mar  9 03:42:32.379: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Running", Reason="", readiness=true. Elapsed: 16.224843131s
Mar  9 03:42:34.387: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Running", Reason="", readiness=true. Elapsed: 18.232079222s
Mar  9 03:42:36.394: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Running", Reason="", readiness=true. Elapsed: 20.239619031s
Mar  9 03:42:38.402: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Running", Reason="", readiness=true. Elapsed: 22.247266401s
Mar  9 03:42:40.410: INFO: Pod "pod-subpath-test-configmap-5lch": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.255413319s
STEP: Saw pod success
Mar  9 03:42:40.410: INFO: Pod "pod-subpath-test-configmap-5lch" satisfied condition "success or failure"
Mar  9 03:42:40.415: INFO: Trying to get logs from node worker1 pod pod-subpath-test-configmap-5lch container test-container-subpath-configmap-5lch: <nil>
STEP: delete the pod
Mar  9 03:42:41.293: INFO: Waiting for pod pod-subpath-test-configmap-5lch to disappear
Mar  9 03:42:41.299: INFO: Pod pod-subpath-test-configmap-5lch no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5lch
Mar  9 03:42:41.299: INFO: Deleting pod "pod-subpath-test-configmap-5lch" in namespace "subpath-4297"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:42:41.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4297" for this suite.
Mar  9 03:42:47.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:42:48.015: INFO: namespace subpath-4297 deletion completed in 6.442247567s

• [SLOW TEST:32.258 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:42:48.015: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4601
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-37f806bd-aafe-43d5-ad15-016d51adb0dd
STEP: Creating a pod to test consume secrets
Mar  9 03:42:48.755: INFO: Waiting up to 5m0s for pod "pod-secrets-ca153cae-3881-479b-bd38-a135aa354fcd" in namespace "secrets-4601" to be "success or failure"
Mar  9 03:42:48.761: INFO: Pod "pod-secrets-ca153cae-3881-479b-bd38-a135aa354fcd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167022ms
Mar  9 03:42:50.774: INFO: Pod "pod-secrets-ca153cae-3881-479b-bd38-a135aa354fcd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019620251s
Mar  9 03:42:52.783: INFO: Pod "pod-secrets-ca153cae-3881-479b-bd38-a135aa354fcd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028308711s
STEP: Saw pod success
Mar  9 03:42:52.783: INFO: Pod "pod-secrets-ca153cae-3881-479b-bd38-a135aa354fcd" satisfied condition "success or failure"
Mar  9 03:42:52.788: INFO: Trying to get logs from node worker1 pod pod-secrets-ca153cae-3881-479b-bd38-a135aa354fcd container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 03:42:52.914: INFO: Waiting for pod pod-secrets-ca153cae-3881-479b-bd38-a135aa354fcd to disappear
Mar  9 03:42:52.928: INFO: Pod pod-secrets-ca153cae-3881-479b-bd38-a135aa354fcd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:42:52.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4601" for this suite.
Mar  9 03:43:01.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:43:01.276: INFO: namespace secrets-4601 deletion completed in 8.265061174s

• [SLOW TEST:13.261 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:43:01.277: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3322
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  9 03:43:01.565: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  9 03:43:01.590: INFO: Waiting for terminating namespaces to be deleted...
Mar  9 03:43:01.594: INFO: 
Logging pods the kubelet thinks is on node worker1 before test
Mar  9 03:43:01.607: INFO: sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-txlws from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 03:43:01.607: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Mar  9 03:43:01.607: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  9 03:43:01.607: INFO: sonobuoy from sonobuoy started at 2020-03-09 01:23:11 +0000 UTC (1 container statuses recorded)
Mar  9 03:43:01.607: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  9 03:43:01.607: INFO: kube-flannel-ds-amd64-wgfqr from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 03:43:01.607: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  9 03:43:01.607: INFO: kube-proxy-94vtq from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 03:43:01.607: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 03:43:01.607: INFO: 
Logging pods the kubelet thinks is on node worker2 before test
Mar  9 03:43:01.647: INFO: kube-flannel-ds-amd64-q9s4h from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 03:43:01.647: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  9 03:43:01.647: INFO: sonobuoy-e2e-job-aaa481025fe94110 from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 03:43:01.647: INFO: 	Container e2e ready: true, restart count 0
Mar  9 03:43:01.647: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  9 03:43:01.647: INFO: kube-proxy-55qqw from kube-system started at 2020-03-08 14:16:17 +0000 UTC (1 container statuses recorded)
Mar  9 03:43:01.647: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  9 03:43:01.647: INFO: sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-b49xx from sonobuoy started at 2020-03-09 01:23:14 +0000 UTC (2 container statuses recorded)
Mar  9 03:43:01.647: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Mar  9 03:43:01.647: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node worker1
STEP: verifying the node has the label node worker2
Mar  9 03:43:01.873: INFO: Pod kube-flannel-ds-amd64-q9s4h requesting resource cpu=100m on Node worker2
Mar  9 03:43:01.873: INFO: Pod kube-flannel-ds-amd64-wgfqr requesting resource cpu=100m on Node worker1
Mar  9 03:43:01.873: INFO: Pod kube-proxy-55qqw requesting resource cpu=0m on Node worker2
Mar  9 03:43:01.873: INFO: Pod kube-proxy-94vtq requesting resource cpu=0m on Node worker1
Mar  9 03:43:01.873: INFO: Pod sonobuoy requesting resource cpu=0m on Node worker1
Mar  9 03:43:01.873: INFO: Pod sonobuoy-e2e-job-aaa481025fe94110 requesting resource cpu=0m on Node worker2
Mar  9 03:43:01.873: INFO: Pod sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-b49xx requesting resource cpu=0m on Node worker2
Mar  9 03:43:01.873: INFO: Pod sonobuoy-systemd-logs-daemon-set-3d6540eb1a3540fe-txlws requesting resource cpu=0m on Node worker1
STEP: Starting Pods to consume most of the cluster CPU.
Mar  9 03:43:01.873: INFO: Creating a pod which consumes cpu=4830m on Node worker1
Mar  9 03:43:01.906: INFO: Creating a pod which consumes cpu=4830m on Node worker2
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-288a87e9-568b-4bd2-a97f-c169cd6902dd.15fa85d80bf4fb63], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3322/filler-pod-288a87e9-568b-4bd2-a97f-c169cd6902dd to worker1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-288a87e9-568b-4bd2-a97f-c169cd6902dd.15fa85d85bbc02dd], Reason = [Pulled], Message = [Container image "172.20.8.7/library/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-288a87e9-568b-4bd2-a97f-c169cd6902dd.15fa85d863dd41ff], Reason = [Created], Message = [Created container filler-pod-288a87e9-568b-4bd2-a97f-c169cd6902dd]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-288a87e9-568b-4bd2-a97f-c169cd6902dd.15fa85d87ae4fe07], Reason = [Started], Message = [Started container filler-pod-288a87e9-568b-4bd2-a97f-c169cd6902dd]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-609a5a6c-54d2-4635-86e5-d668fd1f6a55.15fa85d80e030dc0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3322/filler-pod-609a5a6c-54d2-4635-86e5-d668fd1f6a55 to worker2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-609a5a6c-54d2-4635-86e5-d668fd1f6a55.15fa85d886e153bb], Reason = [Pulled], Message = [Container image "172.20.8.7/library/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-609a5a6c-54d2-4635-86e5-d668fd1f6a55.15fa85d89929bbc4], Reason = [Created], Message = [Created container filler-pod-609a5a6c-54d2-4635-86e5-d668fd1f6a55]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-609a5a6c-54d2-4635-86e5-d668fd1f6a55.15fa85d8b9d10382], Reason = [Started], Message = [Started container filler-pod-609a5a6c-54d2-4635-86e5-d668fd1f6a55]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15fa85d904a99984], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node worker1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worker2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:43:07.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3322" for this suite.
Mar  9 03:43:15.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:43:15.636: INFO: namespace sched-pred-3322 deletion completed in 8.315996785s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:14.359 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:43:15.640: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-3599
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:43:16.044: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-e10dc0b9-badf-4a28-8744-b7a92161f014" in namespace "security-context-test-3599" to be "success or failure"
Mar  9 03:43:16.065: INFO: Pod "busybox-privileged-false-e10dc0b9-badf-4a28-8744-b7a92161f014": Phase="Pending", Reason="", readiness=false. Elapsed: 20.638569ms
Mar  9 03:43:18.072: INFO: Pod "busybox-privileged-false-e10dc0b9-badf-4a28-8744-b7a92161f014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027973578s
Mar  9 03:43:20.081: INFO: Pod "busybox-privileged-false-e10dc0b9-badf-4a28-8744-b7a92161f014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036869944s
Mar  9 03:43:20.081: INFO: Pod "busybox-privileged-false-e10dc0b9-badf-4a28-8744-b7a92161f014" satisfied condition "success or failure"
Mar  9 03:43:20.097: INFO: Got logs for pod "busybox-privileged-false-e10dc0b9-badf-4a28-8744-b7a92161f014": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:43:20.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3599" for this suite.
Mar  9 03:43:28.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:43:28.319: INFO: namespace security-context-test-3599 deletion completed in 8.213237064s

• [SLOW TEST:12.679 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:43:28.319: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-829
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  9 03:43:30.950: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  9 03:43:32.970: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719322211, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719322211, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63719322211, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63719322211, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  9 03:43:36.148: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:43:36.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-829" for this suite.
Mar  9 03:43:50.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:43:50.721: INFO: namespace webhook-829 deletion completed in 14.251558256s
STEP: Destroying namespace "webhook-829-markers" for this suite.
Mar  9 03:43:56.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:43:56.911: INFO: namespace webhook-829-markers deletion completed in 6.190795742s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.841 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:43:57.161: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6930
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-83e5d4d2-9a52-4391-9e60-9146efa1bba8
STEP: Creating a pod to test consume secrets
Mar  9 03:43:57.621: INFO: Waiting up to 5m0s for pod "pod-secrets-a605836a-dc66-4f37-a17c-5ba06080e4d1" in namespace "secrets-6930" to be "success or failure"
Mar  9 03:43:57.630: INFO: Pod "pod-secrets-a605836a-dc66-4f37-a17c-5ba06080e4d1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.331681ms
Mar  9 03:43:59.639: INFO: Pod "pod-secrets-a605836a-dc66-4f37-a17c-5ba06080e4d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018776434s
Mar  9 03:44:01.649: INFO: Pod "pod-secrets-a605836a-dc66-4f37-a17c-5ba06080e4d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028120497s
STEP: Saw pod success
Mar  9 03:44:01.649: INFO: Pod "pod-secrets-a605836a-dc66-4f37-a17c-5ba06080e4d1" satisfied condition "success or failure"
Mar  9 03:44:01.655: INFO: Trying to get logs from node worker1 pod pod-secrets-a605836a-dc66-4f37-a17c-5ba06080e4d1 container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 03:44:01.763: INFO: Waiting for pod pod-secrets-a605836a-dc66-4f37-a17c-5ba06080e4d1 to disappear
Mar  9 03:44:01.767: INFO: Pod pod-secrets-a605836a-dc66-4f37-a17c-5ba06080e4d1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:44:01.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6930" for this suite.
Mar  9 03:44:09.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:44:10.085: INFO: namespace secrets-6930 deletion completed in 8.310059781s

• [SLOW TEST:12.924 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:44:10.087: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2100
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  9 03:44:10.483: INFO: (0) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 13.852195ms)
Mar  9 03:44:10.490: INFO: (1) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.047025ms)
Mar  9 03:44:10.516: INFO: (2) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 25.766643ms)
Mar  9 03:44:10.573: INFO: (3) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 57.034584ms)
Mar  9 03:44:10.580: INFO: (4) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.459196ms)
Mar  9 03:44:10.586: INFO: (5) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.088714ms)
Mar  9 03:44:10.594: INFO: (6) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.589591ms)
Mar  9 03:44:10.607: INFO: (7) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.904878ms)
Mar  9 03:44:10.614: INFO: (8) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.454292ms)
Mar  9 03:44:10.621: INFO: (9) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.057815ms)
Mar  9 03:44:10.627: INFO: (10) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.362179ms)
Mar  9 03:44:10.655: INFO: (11) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 27.70823ms)
Mar  9 03:44:10.664: INFO: (12) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.752611ms)
Mar  9 03:44:10.671: INFO: (13) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.446087ms)
Mar  9 03:44:10.678: INFO: (14) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.069801ms)
Mar  9 03:44:10.736: INFO: (15) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 56.966458ms)
Mar  9 03:44:10.744: INFO: (16) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.054782ms)
Mar  9 03:44:10.750: INFO: (17) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.086328ms)
Mar  9 03:44:10.757: INFO: (18) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.188809ms)
Mar  9 03:44:10.764: INFO: (19) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.263972ms)
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:44:10.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2100" for this suite.
Mar  9 03:44:16.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:44:17.143: INFO: namespace proxy-2100 deletion completed in 6.368998621s

• [SLOW TEST:7.056 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:44:17.144: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9131
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Mar  9 03:44:17.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-9131'
Mar  9 03:44:22.036: INFO: stderr: ""
Mar  9 03:44:22.036: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  9 03:44:22.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9131'
Mar  9 03:44:22.319: INFO: stderr: ""
Mar  9 03:44:22.319: INFO: stdout: "update-demo-nautilus-bkfh4 "
STEP: Replicas for name=update-demo: expected=2 actual=1
Mar  9 03:44:27.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9131'
Mar  9 03:44:27.549: INFO: stderr: ""
Mar  9 03:44:27.549: INFO: stdout: "update-demo-nautilus-bkfh4 update-demo-nautilus-hv2nc "
Mar  9 03:44:27.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-bkfh4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9131'
Mar  9 03:44:27.764: INFO: stderr: ""
Mar  9 03:44:27.764: INFO: stdout: "true"
Mar  9 03:44:27.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-bkfh4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9131'
Mar  9 03:44:27.972: INFO: stderr: ""
Mar  9 03:44:27.972: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  9 03:44:27.972: INFO: validating pod update-demo-nautilus-bkfh4
Mar  9 03:44:27.983: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 03:44:27.983: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 03:44:27.983: INFO: update-demo-nautilus-bkfh4 is verified up and running
Mar  9 03:44:27.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-hv2nc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9131'
Mar  9 03:44:28.190: INFO: stderr: ""
Mar  9 03:44:28.190: INFO: stdout: "true"
Mar  9 03:44:28.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods update-demo-nautilus-hv2nc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9131'
Mar  9 03:44:28.440: INFO: stderr: ""
Mar  9 03:44:28.440: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  9 03:44:28.440: INFO: validating pod update-demo-nautilus-hv2nc
Mar  9 03:44:28.452: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  9 03:44:28.452: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  9 03:44:28.452: INFO: update-demo-nautilus-hv2nc is verified up and running
STEP: using delete to clean up resources
Mar  9 03:44:28.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 delete --grace-period=0 --force -f - --namespace=kubectl-9131'
Mar  9 03:44:28.681: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  9 03:44:28.681: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  9 03:44:28.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9131'
Mar  9 03:44:28.900: INFO: stderr: "No resources found in kubectl-9131 namespace.\n"
Mar  9 03:44:28.900: INFO: stdout: ""
Mar  9 03:44:28.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 get pods -l name=update-demo --namespace=kubectl-9131 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  9 03:44:29.112: INFO: stderr: ""
Mar  9 03:44:29.112: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:44:29.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9131" for this suite.
Mar  9 03:44:37.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:44:37.479: INFO: namespace kubectl-9131 deletion completed in 8.287520214s

• [SLOW TEST:20.336 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:44:37.482: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9922
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Mar  9 03:44:37.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 create -f - --namespace=kubectl-9922'
Mar  9 03:44:38.596: INFO: stderr: ""
Mar  9 03:44:38.596: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  9 03:44:39.605: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 03:44:39.605: INFO: Found 0 / 1
Mar  9 03:44:40.605: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 03:44:40.605: INFO: Found 0 / 1
Mar  9 03:44:41.604: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 03:44:41.605: INFO: Found 1 / 1
Mar  9 03:44:41.605: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar  9 03:44:41.610: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 03:44:41.610: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  9 03:44:41.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-910735845 patch pod redis-master-5sw5c --namespace=kubectl-9922 -p {"metadata":{"annotations":{"x":"y"}}}'
Mar  9 03:44:41.845: INFO: stderr: ""
Mar  9 03:44:41.845: INFO: stdout: "pod/redis-master-5sw5c patched\n"
STEP: checking annotations
Mar  9 03:44:41.851: INFO: Selector matched 1 pods for map[app:redis]
Mar  9 03:44:41.851: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:44:41.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9922" for this suite.
Mar  9 03:45:09.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:45:10.461: INFO: namespace kubectl-9922 deletion completed in 28.601743118s

• [SLOW TEST:32.980 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:45:10.462: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4085
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:45:10.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4085" for this suite.
Mar  9 03:45:16.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:45:17.259: INFO: namespace custom-resource-definition-4085 deletion completed in 6.459685407s

• [SLOW TEST:6.798 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  9 03:45:17.260: INFO: >>> kubeConfig: /tmp/kubeconfig-910735845
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3994
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-e23517c1-ea10-49bd-a491-66b05896a4b2
STEP: Creating a pod to test consume secrets
Mar  9 03:45:17.604: INFO: Waiting up to 5m0s for pod "pod-secrets-3446fd36-1b1b-476c-b31c-eb363abeb4d8" in namespace "secrets-3994" to be "success or failure"
Mar  9 03:45:17.622: INFO: Pod "pod-secrets-3446fd36-1b1b-476c-b31c-eb363abeb4d8": Phase="Pending", Reason="", readiness=false. Elapsed: 18.560701ms
Mar  9 03:45:19.650: INFO: Pod "pod-secrets-3446fd36-1b1b-476c-b31c-eb363abeb4d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046203107s
Mar  9 03:45:21.659: INFO: Pod "pod-secrets-3446fd36-1b1b-476c-b31c-eb363abeb4d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05473903s
STEP: Saw pod success
Mar  9 03:45:21.659: INFO: Pod "pod-secrets-3446fd36-1b1b-476c-b31c-eb363abeb4d8" satisfied condition "success or failure"
Mar  9 03:45:21.664: INFO: Trying to get logs from node worker1 pod pod-secrets-3446fd36-1b1b-476c-b31c-eb363abeb4d8 container secret-volume-test: <nil>
STEP: delete the pod
Mar  9 03:45:21.796: INFO: Waiting for pod pod-secrets-3446fd36-1b1b-476c-b31c-eb363abeb4d8 to disappear
Mar  9 03:45:21.801: INFO: Pod pod-secrets-3446fd36-1b1b-476c-b31c-eb363abeb4d8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  9 03:45:21.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3994" for this suite.
Mar  9 03:45:29.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  9 03:45:30.065: INFO: namespace secrets-3994 deletion completed in 8.256395397s

• [SLOW TEST:12.805 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSMar  9 03:45:30.067: INFO: Running AfterSuite actions on all nodes
Mar  9 03:45:30.067: INFO: Running AfterSuite actions on node 1
Mar  9 03:45:30.067: INFO: Skipping dumping logs from cluster

Ran 274 of 4731 Specs in 8468.458 seconds
SUCCESS! -- 274 Passed | 0 Failed | 0 Pending | 4457 Skipped
PASS

Ginkgo ran 1 suite in 2h21m14.44791076s
Test Suite Passed
