I1228 04:15:43.735759      22 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-505712781
I1228 04:15:43.735897      22 e2e.go:92] Starting e2e run "535d0e95-1b92-4b2b-bc7e-376d8e5e7513" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1577506542 - Will randomize all specs
Will run 276 of 4732 specs

Dec 28 04:15:43.749: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 04:15:43.753: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 28 04:15:43.765: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 28 04:15:43.785: INFO: 13 / 13 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 28 04:15:43.785: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Dec 28 04:15:43.785: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 28 04:15:43.790: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel' (0 seconds elapsed)
Dec 28 04:15:43.791: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec 28 04:15:43.791: INFO: e2e test version: v1.16.3
Dec 28 04:15:43.791: INFO: kube-apiserver version: v1.16.3
Dec 28 04:15:43.791: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 04:15:43.794: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:15:43.795: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
Dec 28 04:15:43.813: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:15:43.817: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92ae6422-18e0-4d60-8531-3ac02278c39b" in namespace "projected-3299" to be "success or failure"
Dec 28 04:15:43.819: INFO: Pod "downwardapi-volume-92ae6422-18e0-4d60-8531-3ac02278c39b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.70503ms
Dec 28 04:15:45.821: INFO: Pod "downwardapi-volume-92ae6422-18e0-4d60-8531-3ac02278c39b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004070553s
STEP: Saw pod success
Dec 28 04:15:45.821: INFO: Pod "downwardapi-volume-92ae6422-18e0-4d60-8531-3ac02278c39b" satisfied condition "success or failure"
Dec 28 04:15:45.823: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-92ae6422-18e0-4d60-8531-3ac02278c39b container client-container: <nil>
STEP: delete the pod
Dec 28 04:15:45.841: INFO: Waiting for pod downwardapi-volume-92ae6422-18e0-4d60-8531-3ac02278c39b to disappear
Dec 28 04:15:45.842: INFO: Pod downwardapi-volume-92ae6422-18e0-4d60-8531-3ac02278c39b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:15:45.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3299" for this suite.
Dec 28 04:15:51.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:15:51.917: INFO: namespace projected-3299 deletion completed in 6.072824029s

• [SLOW TEST:8.123 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:15:51.918: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:15:51.937: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84baf77c-6f46-4ae0-b419-28bbdef4bf19" in namespace "projected-9998" to be "success or failure"
Dec 28 04:15:51.939: INFO: Pod "downwardapi-volume-84baf77c-6f46-4ae0-b419-28bbdef4bf19": Phase="Pending", Reason="", readiness=false. Elapsed: 1.65178ms
Dec 28 04:15:53.941: INFO: Pod "downwardapi-volume-84baf77c-6f46-4ae0-b419-28bbdef4bf19": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003943256s
STEP: Saw pod success
Dec 28 04:15:53.941: INFO: Pod "downwardapi-volume-84baf77c-6f46-4ae0-b419-28bbdef4bf19" satisfied condition "success or failure"
Dec 28 04:15:53.943: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-84baf77c-6f46-4ae0-b419-28bbdef4bf19 container client-container: <nil>
STEP: delete the pod
Dec 28 04:15:53.954: INFO: Waiting for pod downwardapi-volume-84baf77c-6f46-4ae0-b419-28bbdef4bf19 to disappear
Dec 28 04:15:53.955: INFO: Pod downwardapi-volume-84baf77c-6f46-4ae0-b419-28bbdef4bf19 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:15:53.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9998" for this suite.
Dec 28 04:15:59.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:16:00.024: INFO: namespace projected-9998 deletion completed in 6.066427842s

• [SLOW TEST:8.106 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:16:00.024: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Dec 28 04:16:00.043: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-5850" to be "success or failure"
Dec 28 04:16:00.045: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.877636ms
Dec 28 04:16:02.047: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004179446s
STEP: Saw pod success
Dec 28 04:16:02.047: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 28 04:16:02.049: INFO: Trying to get logs from node hxx-m-2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 28 04:16:02.058: INFO: Waiting for pod pod-host-path-test to disappear
Dec 28 04:16:02.060: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:16:02.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-5850" for this suite.
Dec 28 04:16:08.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:16:08.133: INFO: namespace hostpath-5850 deletion completed in 6.070706132s

• [SLOW TEST:8.109 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:16:08.133: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec 28 04:16:08.149: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec 28 04:16:21.618: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 04:16:25.321: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:16:39.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3383" for this suite.
Dec 28 04:16:45.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:16:45.680: INFO: namespace crd-publish-openapi-3383 deletion completed in 6.066916018s

• [SLOW TEST:37.547 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:16:45.681: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 28 04:16:45.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-4904'
Dec 28 04:16:45.842: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 28 04:16:45.842: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Dec 28 04:16:47.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete deployment e2e-test-httpd-deployment --namespace=kubectl-4904'
Dec 28 04:16:47.926: INFO: stderr: ""
Dec 28 04:16:47.926: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:16:47.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4904" for this suite.
Dec 28 04:16:53.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:16:53.995: INFO: namespace kubectl-4904 deletion completed in 6.066051944s

• [SLOW TEST:8.314 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:16:53.995: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:17:00.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2863" for this suite.
Dec 28 04:17:06.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:17:06.125: INFO: namespace namespaces-2863 deletion completed in 6.064811514s
STEP: Destroying namespace "nsdeletetest-1862" for this suite.
Dec 28 04:17:06.126: INFO: Namespace nsdeletetest-1862 was already deleted
STEP: Destroying namespace "nsdeletetest-3478" for this suite.
Dec 28 04:17:12.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:17:12.196: INFO: namespace nsdeletetest-3478 deletion completed in 6.069340588s

• [SLOW TEST:18.201 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:17:12.196: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-bec31512-e24f-44e3-8d54-98b315817b9e
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:17:12.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7469" for this suite.
Dec 28 04:17:18.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:17:18.288: INFO: namespace secrets-7469 deletion completed in 6.070013798s

• [SLOW TEST:6.092 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:17:18.288: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-1257753d-256e-4aad-add1-96d01e00b95c
STEP: Creating a pod to test consume secrets
Dec 28 04:17:18.309: INFO: Waiting up to 5m0s for pod "pod-secrets-19e5e3c9-9ae8-48fb-ad5a-fbf87ac0a562" in namespace "secrets-9441" to be "success or failure"
Dec 28 04:17:18.311: INFO: Pod "pod-secrets-19e5e3c9-9ae8-48fb-ad5a-fbf87ac0a562": Phase="Pending", Reason="", readiness=false. Elapsed: 1.837492ms
Dec 28 04:17:20.313: INFO: Pod "pod-secrets-19e5e3c9-9ae8-48fb-ad5a-fbf87ac0a562": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00419326s
STEP: Saw pod success
Dec 28 04:17:20.313: INFO: Pod "pod-secrets-19e5e3c9-9ae8-48fb-ad5a-fbf87ac0a562" satisfied condition "success or failure"
Dec 28 04:17:20.314: INFO: Trying to get logs from node hxx-m-2 pod pod-secrets-19e5e3c9-9ae8-48fb-ad5a-fbf87ac0a562 container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 04:17:20.325: INFO: Waiting for pod pod-secrets-19e5e3c9-9ae8-48fb-ad5a-fbf87ac0a562 to disappear
Dec 28 04:17:20.326: INFO: Pod pod-secrets-19e5e3c9-9ae8-48fb-ad5a-fbf87ac0a562 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:17:20.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9441" for this suite.
Dec 28 04:17:26.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:17:26.394: INFO: namespace secrets-9441 deletion completed in 6.06567168s

• [SLOW TEST:8.106 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:17:26.394: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:17:26.414: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bff423d1-ec28-44b9-9b71-18a7da18ef9f" in namespace "downward-api-6150" to be "success or failure"
Dec 28 04:17:26.416: INFO: Pod "downwardapi-volume-bff423d1-ec28-44b9-9b71-18a7da18ef9f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.479578ms
Dec 28 04:17:28.418: INFO: Pod "downwardapi-volume-bff423d1-ec28-44b9-9b71-18a7da18ef9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003438225s
STEP: Saw pod success
Dec 28 04:17:28.418: INFO: Pod "downwardapi-volume-bff423d1-ec28-44b9-9b71-18a7da18ef9f" satisfied condition "success or failure"
Dec 28 04:17:28.419: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-bff423d1-ec28-44b9-9b71-18a7da18ef9f container client-container: <nil>
STEP: delete the pod
Dec 28 04:17:28.430: INFO: Waiting for pod downwardapi-volume-bff423d1-ec28-44b9-9b71-18a7da18ef9f to disappear
Dec 28 04:17:28.431: INFO: Pod downwardapi-volume-bff423d1-ec28-44b9-9b71-18a7da18ef9f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:17:28.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6150" for this suite.
Dec 28 04:17:34.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:17:34.499: INFO: namespace downward-api-6150 deletion completed in 6.065258204s

• [SLOW TEST:8.105 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:17:34.499: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:17:34.520: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5e9d597-ccd0-4d41-b322-3f7c5e0e2f02" in namespace "projected-5337" to be "success or failure"
Dec 28 04:17:34.521: INFO: Pod "downwardapi-volume-d5e9d597-ccd0-4d41-b322-3f7c5e0e2f02": Phase="Pending", Reason="", readiness=false. Elapsed: 1.429996ms
Dec 28 04:17:36.524: INFO: Pod "downwardapi-volume-d5e9d597-ccd0-4d41-b322-3f7c5e0e2f02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003884048s
STEP: Saw pod success
Dec 28 04:17:36.524: INFO: Pod "downwardapi-volume-d5e9d597-ccd0-4d41-b322-3f7c5e0e2f02" satisfied condition "success or failure"
Dec 28 04:17:36.525: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-d5e9d597-ccd0-4d41-b322-3f7c5e0e2f02 container client-container: <nil>
STEP: delete the pod
Dec 28 04:17:36.534: INFO: Waiting for pod downwardapi-volume-d5e9d597-ccd0-4d41-b322-3f7c5e0e2f02 to disappear
Dec 28 04:17:36.536: INFO: Pod downwardapi-volume-d5e9d597-ccd0-4d41-b322-3f7c5e0e2f02 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:17:36.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5337" for this suite.
Dec 28 04:17:42.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:17:42.603: INFO: namespace projected-5337 deletion completed in 6.064737219s

• [SLOW TEST:8.104 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:17:42.603: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 04:17:43.118: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 28 04:17:45.123: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713103463, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713103463, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713103463, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713103463, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 04:17:48.131: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:17:48.133: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3711-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:17:49.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2487" for this suite.
Dec 28 04:17:55.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:17:55.269: INFO: namespace webhook-2487 deletion completed in 6.070632231s
STEP: Destroying namespace "webhook-2487-markers" for this suite.
Dec 28 04:18:01.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:18:01.335: INFO: namespace webhook-2487-markers deletion completed in 6.065794489s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.739 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:18:01.342: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 04:18:01.718: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 04:18:04.729: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:18:04.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7922" for this suite.
Dec 28 04:18:10.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:18:10.825: INFO: namespace webhook-7922 deletion completed in 6.066933324s
STEP: Destroying namespace "webhook-7922-markers" for this suite.
Dec 28 04:18:16.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:18:16.890: INFO: namespace webhook-7922-markers deletion completed in 6.064922414s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.554 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:18:16.896: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 28 04:18:16.911: INFO: namespace kubectl-7929
Dec 28 04:18:16.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-7929'
Dec 28 04:18:17.102: INFO: stderr: ""
Dec 28 04:18:17.102: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 28 04:18:18.104: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:18:18.104: INFO: Found 0 / 1
Dec 28 04:18:19.104: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:18:19.104: INFO: Found 1 / 1
Dec 28 04:18:19.104: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 28 04:18:19.106: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:18:19.106: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 28 04:18:19.106: INFO: wait on redis-master startup in kubectl-7929 
Dec 28 04:18:19.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 logs redis-master-wl6vw redis-master --namespace=kubectl-7929'
Dec 28 04:18:19.202: INFO: stderr: ""
Dec 28 04:18:19.202: INFO: stdout: "1:C 28 Dec 2019 04:18:17.921 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 28 Dec 2019 04:18:17.921 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 28 Dec 2019 04:18:17.921 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 28 Dec 2019 04:18:17.922 * Running mode=standalone, port=6379.\n1:M 28 Dec 2019 04:18:17.922 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Dec 2019 04:18:17.922 # Server initialized\n1:M 28 Dec 2019 04:18:17.922 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Dec 2019 04:18:17.922 * Ready to accept connections\n"
STEP: exposing RC
Dec 28 04:18:19.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7929'
Dec 28 04:18:19.292: INFO: stderr: ""
Dec 28 04:18:19.292: INFO: stdout: "service/rm2 exposed\n"
Dec 28 04:18:19.294: INFO: Service rm2 in namespace kubectl-7929 found.
STEP: exposing service
Dec 28 04:18:21.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7929'
Dec 28 04:18:21.384: INFO: stderr: ""
Dec 28 04:18:21.385: INFO: stdout: "service/rm3 exposed\n"
Dec 28 04:18:21.388: INFO: Service rm3 in namespace kubectl-7929 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:18:23.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7929" for this suite.
Dec 28 04:18:51.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:18:51.460: INFO: namespace kubectl-7929 deletion completed in 28.066638235s

• [SLOW TEST:34.565 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:18:51.461: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:18:51.476: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:18:51.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9652" for this suite.
Dec 28 04:18:58.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:18:58.080: INFO: namespace custom-resource-definition-9652 deletion completed in 6.08198159s

• [SLOW TEST:6.619 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:18:58.080: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 28 04:18:58.100: INFO: Waiting up to 5m0s for pod "pod-0906cd76-c033-4908-ae9e-688684baaa56" in namespace "emptydir-2058" to be "success or failure"
Dec 28 04:18:58.101: INFO: Pod "pod-0906cd76-c033-4908-ae9e-688684baaa56": Phase="Pending", Reason="", readiness=false. Elapsed: 1.667083ms
Dec 28 04:19:00.104: INFO: Pod "pod-0906cd76-c033-4908-ae9e-688684baaa56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00403586s
STEP: Saw pod success
Dec 28 04:19:00.104: INFO: Pod "pod-0906cd76-c033-4908-ae9e-688684baaa56" satisfied condition "success or failure"
Dec 28 04:19:00.105: INFO: Trying to get logs from node hxx-m-2 pod pod-0906cd76-c033-4908-ae9e-688684baaa56 container test-container: <nil>
STEP: delete the pod
Dec 28 04:19:00.114: INFO: Waiting for pod pod-0906cd76-c033-4908-ae9e-688684baaa56 to disappear
Dec 28 04:19:00.116: INFO: Pod pod-0906cd76-c033-4908-ae9e-688684baaa56 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:19:00.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2058" for this suite.
Dec 28 04:19:06.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:19:06.185: INFO: namespace emptydir-2058 deletion completed in 6.067383539s

• [SLOW TEST:8.105 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:19:06.186: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 28 04:19:06.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2587'
Dec 28 04:19:06.286: INFO: stderr: ""
Dec 28 04:19:06.286: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Dec 28 04:19:06.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete pods e2e-test-httpd-pod --namespace=kubectl-2587'
Dec 28 04:19:09.162: INFO: stderr: ""
Dec 28 04:19:09.162: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:19:09.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2587" for this suite.
Dec 28 04:19:15.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:19:15.233: INFO: namespace kubectl-2587 deletion completed in 6.067903273s

• [SLOW TEST:9.048 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:19:15.233: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:19:15.253: INFO: Waiting up to 5m0s for pod "downwardapi-volume-334a4e31-bd82-442c-8dde-bf3f46a22b18" in namespace "projected-4709" to be "success or failure"
Dec 28 04:19:15.255: INFO: Pod "downwardapi-volume-334a4e31-bd82-442c-8dde-bf3f46a22b18": Phase="Pending", Reason="", readiness=false. Elapsed: 1.644775ms
Dec 28 04:19:17.257: INFO: Pod "downwardapi-volume-334a4e31-bd82-442c-8dde-bf3f46a22b18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003924472s
STEP: Saw pod success
Dec 28 04:19:17.257: INFO: Pod "downwardapi-volume-334a4e31-bd82-442c-8dde-bf3f46a22b18" satisfied condition "success or failure"
Dec 28 04:19:17.259: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-334a4e31-bd82-442c-8dde-bf3f46a22b18 container client-container: <nil>
STEP: delete the pod
Dec 28 04:19:17.268: INFO: Waiting for pod downwardapi-volume-334a4e31-bd82-442c-8dde-bf3f46a22b18 to disappear
Dec 28 04:19:17.269: INFO: Pod downwardapi-volume-334a4e31-bd82-442c-8dde-bf3f46a22b18 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:19:17.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4709" for this suite.
Dec 28 04:19:23.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:19:23.341: INFO: namespace projected-4709 deletion completed in 6.069068099s

• [SLOW TEST:8.107 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:19:23.341: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-528acfb5-8c83-44a0-8ddd-970a400e469e
STEP: Creating a pod to test consume secrets
Dec 28 04:19:23.362: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7516ee25-d5fe-4d66-bb9e-261b7ac3479b" in namespace "projected-1689" to be "success or failure"
Dec 28 04:19:23.363: INFO: Pod "pod-projected-secrets-7516ee25-d5fe-4d66-bb9e-261b7ac3479b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.359215ms
Dec 28 04:19:25.366: INFO: Pod "pod-projected-secrets-7516ee25-d5fe-4d66-bb9e-261b7ac3479b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003773569s
STEP: Saw pod success
Dec 28 04:19:25.366: INFO: Pod "pod-projected-secrets-7516ee25-d5fe-4d66-bb9e-261b7ac3479b" satisfied condition "success or failure"
Dec 28 04:19:25.367: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-secrets-7516ee25-d5fe-4d66-bb9e-261b7ac3479b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 28 04:19:25.378: INFO: Waiting for pod pod-projected-secrets-7516ee25-d5fe-4d66-bb9e-261b7ac3479b to disappear
Dec 28 04:19:25.379: INFO: Pod pod-projected-secrets-7516ee25-d5fe-4d66-bb9e-261b7ac3479b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:19:25.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1689" for this suite.
Dec 28 04:19:31.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:19:31.453: INFO: namespace projected-1689 deletion completed in 6.071903195s

• [SLOW TEST:8.112 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:19:31.454: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 04:19:31.805: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 04:19:34.816: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:19:34.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7920" for this suite.
Dec 28 04:19:40.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:19:40.890: INFO: namespace webhook-7920 deletion completed in 6.066858034s
STEP: Destroying namespace "webhook-7920-markers" for this suite.
Dec 28 04:19:46.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:19:46.957: INFO: namespace webhook-7920-markers deletion completed in 6.067261518s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.510 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:19:46.964: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 28 04:19:46.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-1111'
Dec 28 04:19:47.176: INFO: stderr: ""
Dec 28 04:19:47.176: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 04:19:47.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1111'
Dec 28 04:19:47.250: INFO: stderr: ""
Dec 28 04:19:47.250: INFO: stdout: "update-demo-nautilus-7kqbl update-demo-nautilus-kvn95 "
Dec 28 04:19:47.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-7kqbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:19:47.320: INFO: stderr: ""
Dec 28 04:19:47.320: INFO: stdout: ""
Dec 28 04:19:47.320: INFO: update-demo-nautilus-7kqbl is created but not running
Dec 28 04:19:52.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1111'
Dec 28 04:19:52.393: INFO: stderr: ""
Dec 28 04:19:52.393: INFO: stdout: "update-demo-nautilus-7kqbl update-demo-nautilus-kvn95 "
Dec 28 04:19:52.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-7kqbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:19:52.463: INFO: stderr: ""
Dec 28 04:19:52.463: INFO: stdout: "true"
Dec 28 04:19:52.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-7kqbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:19:52.532: INFO: stderr: ""
Dec 28 04:19:52.532: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 04:19:52.532: INFO: validating pod update-demo-nautilus-7kqbl
Dec 28 04:19:52.535: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 04:19:52.535: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 04:19:52.535: INFO: update-demo-nautilus-7kqbl is verified up and running
Dec 28 04:19:52.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-kvn95 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:19:52.603: INFO: stderr: ""
Dec 28 04:19:52.603: INFO: stdout: "true"
Dec 28 04:19:52.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-kvn95 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:19:52.677: INFO: stderr: ""
Dec 28 04:19:52.677: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 04:19:52.677: INFO: validating pod update-demo-nautilus-kvn95
Dec 28 04:19:52.680: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 04:19:52.680: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 04:19:52.680: INFO: update-demo-nautilus-kvn95 is verified up and running
STEP: scaling down the replication controller
Dec 28 04:19:52.684: INFO: scanned /root for discovery docs: <nil>
Dec 28 04:19:52.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1111'
Dec 28 04:19:53.781: INFO: stderr: ""
Dec 28 04:19:53.781: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 04:19:53.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1111'
Dec 28 04:19:53.857: INFO: stderr: ""
Dec 28 04:19:53.857: INFO: stdout: "update-demo-nautilus-7kqbl update-demo-nautilus-kvn95 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 28 04:19:58.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1111'
Dec 28 04:19:58.944: INFO: stderr: ""
Dec 28 04:19:58.944: INFO: stdout: "update-demo-nautilus-7kqbl update-demo-nautilus-kvn95 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 28 04:20:03.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1111'
Dec 28 04:20:04.022: INFO: stderr: ""
Dec 28 04:20:04.022: INFO: stdout: "update-demo-nautilus-kvn95 "
Dec 28 04:20:04.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-kvn95 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:20:04.097: INFO: stderr: ""
Dec 28 04:20:04.097: INFO: stdout: "true"
Dec 28 04:20:04.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-kvn95 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:20:04.172: INFO: stderr: ""
Dec 28 04:20:04.172: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 04:20:04.172: INFO: validating pod update-demo-nautilus-kvn95
Dec 28 04:20:04.175: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 04:20:04.175: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 04:20:04.175: INFO: update-demo-nautilus-kvn95 is verified up and running
STEP: scaling up the replication controller
Dec 28 04:20:04.176: INFO: scanned /root for discovery docs: <nil>
Dec 28 04:20:04.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1111'
Dec 28 04:20:04.269: INFO: stderr: ""
Dec 28 04:20:04.269: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 04:20:04.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1111'
Dec 28 04:20:04.341: INFO: stderr: ""
Dec 28 04:20:04.341: INFO: stdout: "update-demo-nautilus-kvn95 update-demo-nautilus-rlgjt "
Dec 28 04:20:04.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-kvn95 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:20:04.415: INFO: stderr: ""
Dec 28 04:20:04.415: INFO: stdout: "true"
Dec 28 04:20:04.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-kvn95 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:20:04.483: INFO: stderr: ""
Dec 28 04:20:04.483: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 04:20:04.483: INFO: validating pod update-demo-nautilus-kvn95
Dec 28 04:20:04.485: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 04:20:04.485: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 04:20:04.485: INFO: update-demo-nautilus-kvn95 is verified up and running
Dec 28 04:20:04.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-rlgjt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:20:04.554: INFO: stderr: ""
Dec 28 04:20:04.554: INFO: stdout: ""
Dec 28 04:20:04.554: INFO: update-demo-nautilus-rlgjt is created but not running
Dec 28 04:20:09.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1111'
Dec 28 04:20:09.630: INFO: stderr: ""
Dec 28 04:20:09.630: INFO: stdout: "update-demo-nautilus-kvn95 update-demo-nautilus-rlgjt "
Dec 28 04:20:09.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-kvn95 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:20:09.697: INFO: stderr: ""
Dec 28 04:20:09.697: INFO: stdout: "true"
Dec 28 04:20:09.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-kvn95 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:20:09.765: INFO: stderr: ""
Dec 28 04:20:09.765: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 04:20:09.765: INFO: validating pod update-demo-nautilus-kvn95
Dec 28 04:20:09.768: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 04:20:09.768: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 04:20:09.768: INFO: update-demo-nautilus-kvn95 is verified up and running
Dec 28 04:20:09.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-rlgjt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:20:09.840: INFO: stderr: ""
Dec 28 04:20:09.840: INFO: stdout: "true"
Dec 28 04:20:09.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-rlgjt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1111'
Dec 28 04:20:09.912: INFO: stderr: ""
Dec 28 04:20:09.912: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 04:20:09.912: INFO: validating pod update-demo-nautilus-rlgjt
Dec 28 04:20:09.915: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 04:20:09.915: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 04:20:09.915: INFO: update-demo-nautilus-rlgjt is verified up and running
STEP: using delete to clean up resources
Dec 28 04:20:09.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete --grace-period=0 --force -f - --namespace=kubectl-1111'
Dec 28 04:20:09.984: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 04:20:09.984: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 28 04:20:09.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1111'
Dec 28 04:20:10.064: INFO: stderr: "No resources found in kubectl-1111 namespace.\n"
Dec 28 04:20:10.064: INFO: stdout: ""
Dec 28 04:20:10.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -l name=update-demo --namespace=kubectl-1111 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 28 04:20:10.144: INFO: stderr: ""
Dec 28 04:20:10.144: INFO: stdout: "update-demo-nautilus-kvn95\nupdate-demo-nautilus-rlgjt\n"
Dec 28 04:20:10.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1111'
Dec 28 04:20:10.724: INFO: stderr: "No resources found in kubectl-1111 namespace.\n"
Dec 28 04:20:10.724: INFO: stdout: ""
Dec 28 04:20:10.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -l name=update-demo --namespace=kubectl-1111 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 28 04:20:10.801: INFO: stderr: ""
Dec 28 04:20:10.801: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:20:10.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1111" for this suite.
Dec 28 04:20:22.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:20:22.868: INFO: namespace kubectl-1111 deletion completed in 12.063331615s

• [SLOW TEST:35.904 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:20:22.868: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5635
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-5635
I1228 04:20:22.898488      22 runners.go:184] Created replication controller with name: externalname-service, namespace: services-5635, replica count: 2
Dec 28 04:20:25.948: INFO: Creating new exec pod
I1228 04:20:25.948834      22 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 28 04:20:28.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-5635 execpod7ch6m -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 28 04:20:29.178: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 28 04:20:29.178: INFO: stdout: ""
Dec 28 04:20:29.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-5635 execpod7ch6m -- /bin/sh -x -c nc -zv -t -w 2 10.108.55.145 80'
Dec 28 04:20:29.398: INFO: stderr: "+ nc -zv -t -w 2 10.108.55.145 80\nConnection to 10.108.55.145 80 port [tcp/http] succeeded!\n"
Dec 28 04:20:29.398: INFO: stdout: ""
Dec 28 04:20:29.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-5635 execpod7ch6m -- /bin/sh -x -c nc -zv -t -w 2 10.0.128.42 31962'
Dec 28 04:20:29.610: INFO: stderr: "+ nc -zv -t -w 2 10.0.128.42 31962\nConnection to 10.0.128.42 31962 port [tcp/31962] succeeded!\n"
Dec 28 04:20:29.610: INFO: stdout: ""
Dec 28 04:20:29.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-5635 execpod7ch6m -- /bin/sh -x -c nc -zv -t -w 2 10.0.128.16 31962'
Dec 28 04:20:29.829: INFO: stderr: "+ nc -zv -t -w 2 10.0.128.16 31962\nConnection to 10.0.128.16 31962 port [tcp/31962] succeeded!\n"
Dec 28 04:20:29.829: INFO: stdout: ""
Dec 28 04:20:29.829: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:20:29.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5635" for this suite.
Dec 28 04:20:35.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:20:35.920: INFO: namespace services-5635 deletion completed in 6.072181129s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.052 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:20:35.921: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-2c580273-0fbe-43a2-85a0-62904170e9fe
STEP: Creating a pod to test consume secrets
Dec 28 04:20:35.942: INFO: Waiting up to 5m0s for pod "pod-secrets-22be1656-7f95-47e2-beb3-cd6aa2da4c3b" in namespace "secrets-6690" to be "success or failure"
Dec 28 04:20:35.944: INFO: Pod "pod-secrets-22be1656-7f95-47e2-beb3-cd6aa2da4c3b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.454827ms
Dec 28 04:20:37.946: INFO: Pod "pod-secrets-22be1656-7f95-47e2-beb3-cd6aa2da4c3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003859266s
STEP: Saw pod success
Dec 28 04:20:37.946: INFO: Pod "pod-secrets-22be1656-7f95-47e2-beb3-cd6aa2da4c3b" satisfied condition "success or failure"
Dec 28 04:20:37.947: INFO: Trying to get logs from node hxx-m-2 pod pod-secrets-22be1656-7f95-47e2-beb3-cd6aa2da4c3b container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 04:20:37.958: INFO: Waiting for pod pod-secrets-22be1656-7f95-47e2-beb3-cd6aa2da4c3b to disappear
Dec 28 04:20:37.959: INFO: Pod pod-secrets-22be1656-7f95-47e2-beb3-cd6aa2da4c3b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:20:37.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6690" for this suite.
Dec 28 04:20:43.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:20:44.025: INFO: namespace secrets-6690 deletion completed in 6.063212038s

• [SLOW TEST:8.104 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:20:44.025: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 04:20:44.320: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 04:20:47.332: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:20:47.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4103" for this suite.
Dec 28 04:20:53.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:20:53.436: INFO: namespace webhook-4103 deletion completed in 6.069860566s
STEP: Destroying namespace "webhook-4103-markers" for this suite.
Dec 28 04:20:59.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:20:59.501: INFO: namespace webhook-4103-markers deletion completed in 6.06451094s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.482 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:20:59.508: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8456
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8456
STEP: creating replication controller externalsvc in namespace services-8456
I1228 04:20:59.546267      22 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8456, replica count: 2
I1228 04:21:02.596653      22 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec 28 04:21:02.608: INFO: Creating new exec pod
Dec 28 04:21:04.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-8456 execpod2ttkt -- /bin/sh -x -c nslookup nodeport-service'
Dec 28 04:21:04.833: INFO: stderr: "+ nslookup nodeport-service\n"
Dec 28 04:21:04.833: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-8456.svc.cluster.local\tcanonical name = externalsvc.services-8456.svc.cluster.local.\nName:\texternalsvc.services-8456.svc.cluster.local\nAddress: 10.97.91.167\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8456, will wait for the garbage collector to delete the pods
Dec 28 04:21:04.889: INFO: Deleting ReplicationController externalsvc took: 3.718289ms
Dec 28 04:21:04.990: INFO: Terminating ReplicationController externalsvc pods took: 101.008215ms
Dec 28 04:21:11.300: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:21:11.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8456" for this suite.
Dec 28 04:21:17.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:21:17.432: INFO: namespace services-8456 deletion completed in 6.123312723s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:17.924 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:21:17.432: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:21:17.451: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1eb433cb-3f57-461a-8465-175391e75823" in namespace "downward-api-7601" to be "success or failure"
Dec 28 04:21:17.453: INFO: Pod "downwardapi-volume-1eb433cb-3f57-461a-8465-175391e75823": Phase="Pending", Reason="", readiness=false. Elapsed: 1.49934ms
Dec 28 04:21:19.455: INFO: Pod "downwardapi-volume-1eb433cb-3f57-461a-8465-175391e75823": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003849717s
STEP: Saw pod success
Dec 28 04:21:19.455: INFO: Pod "downwardapi-volume-1eb433cb-3f57-461a-8465-175391e75823" satisfied condition "success or failure"
Dec 28 04:21:19.457: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-1eb433cb-3f57-461a-8465-175391e75823 container client-container: <nil>
STEP: delete the pod
Dec 28 04:21:19.470: INFO: Waiting for pod downwardapi-volume-1eb433cb-3f57-461a-8465-175391e75823 to disappear
Dec 28 04:21:19.471: INFO: Pod downwardapi-volume-1eb433cb-3f57-461a-8465-175391e75823 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:21:19.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7601" for this suite.
Dec 28 04:21:25.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:21:25.538: INFO: namespace downward-api-7601 deletion completed in 6.064261319s

• [SLOW TEST:8.106 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:21:25.538: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 28 04:21:25.554: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 28 04:21:25.560: INFO: Waiting for terminating namespaces to be deleted...
Dec 28 04:21:25.562: INFO: 
Logging pods the kubelet thinks is on node hxx-m-1 before test
Dec 28 04:21:25.574: INFO: coredns-66447b44c9-zphmm from kube-system started at 2019-12-27 13:58:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container coredns ready: true, restart count 0
Dec 28 04:21:25.574: INFO: cert-manager-77f5bf4f5-h86rt from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container cert-manager ready: true, restart count 0
Dec 28 04:21:25.574: INFO: cert-manager-webhook-578c59dddd-k697c from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container webhook ready: true, restart count 0
Dec 28 04:21:25.574: INFO: apollo-cfdd64bb4-4lssk from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container apollo ready: true, restart count 0
Dec 28 04:21:25.574: INFO: dex-8448b48ff8-2bd5h from cpaas-system started at 2019-12-27 14:09:25 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container dex ready: true, restart count 0
Dec 28 04:21:25.574: INFO: erebus-5597f9565d-zwjnz from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container erebus ready: true, restart count 0
Dec 28 04:21:25.574: INFO: auth-controller2-79ff55cd75-cbjbn from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container auth-controller2-manager ready: true, restart count 0
Dec 28 04:21:25.574: INFO: furion-679c948779-jz6lf from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container furion ready: true, restart count 0
Dec 28 04:21:25.574: INFO: underlord-5c45b96c5d-nmjjq from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container alauda-console ready: true, restart count 0
Dec 28 04:21:25.574: INFO: cert-manager-cainjector-67d4dd59ff-8jhs9 from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container cainjector ready: true, restart count 0
Dec 28 04:21:25.574: INFO: archon-5fdc59d78c-rhtzm from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container archon-api ready: true, restart count 0
Dec 28 04:21:25.574: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-lzsqv from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:21:25.574: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:21:25.574: INFO: kube-proxy-bnhj6 from kube-system started at 2019-12-27 13:58:01 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:21:25.574: INFO: agon-75b987dff5-7bht5 from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container agon ready: true, restart count 2
Dec 28 04:21:25.574: INFO: cluster-registry-controller-manager-76774c98d-7c7mz from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (2 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 28 04:21:25.574: INFO: 	Container manager ready: true, restart count 0
Dec 28 04:21:25.574: INFO: kube-flannel-8hgpf from kube-system started at 2019-12-27 13:58:14 +0000 UTC (2 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:21:25.574: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:21:25.574: INFO: sonobuoy-e2e-job-af99efc4f7ea449a from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:21:25.574: INFO: 	Container e2e ready: true, restart count 0
Dec 28 04:21:25.574: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:21:25.574: INFO: 
Logging pods the kubelet thinks is on node hxx-m-2 before test
Dec 28 04:21:25.578: INFO: kube-apiserver-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.578: INFO: 	Container kube-apiserver ready: true, restart count 0
Dec 28 04:21:25.578: INFO: kube-controller-manager-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.578: INFO: 	Container kube-controller-manager ready: true, restart count 0
Dec 28 04:21:25.578: INFO: kube-flannel-ffhtx from kube-system started at 2019-12-28 01:52:50 +0000 UTC (2 container statuses recorded)
Dec 28 04:21:25.578: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:21:25.578: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:21:25.578: INFO: etcd-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.578: INFO: 	Container etcd ready: true, restart count 0
Dec 28 04:21:25.578: INFO: nginx-ingress-controller-f9b5d49fd-67nvw from cpaas-system started at 2019-12-28 01:52:27 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.578: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 28 04:21:25.578: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-89sp4 from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:21:25.578: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:21:25.578: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:21:25.578: INFO: kube-proxy-44f6q from kube-system started at 2019-12-27 13:57:35 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.578: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:21:25.578: INFO: sonobuoy from sonobuoy started at 2019-12-28 04:15:38 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.578: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 28 04:21:25.578: INFO: kube-scheduler-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.578: INFO: 	Container kube-scheduler ready: true, restart count 0
Dec 28 04:21:25.578: INFO: 
Logging pods the kubelet thinks is on node hxx-m-3 before test
Dec 28 04:21:25.592: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-pjj5l from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:21:25.592: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:21:25.592: INFO: tiller-deploy-7c757c6f9c-67l6b from kube-system started at 2019-12-27 13:59:57 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container tiller ready: true, restart count 0
Dec 28 04:21:25.592: INFO: auth-controller2-79ff55cd75-4clk9 from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container auth-controller2-manager ready: true, restart count 0
Dec 28 04:21:25.592: INFO: erebus-5597f9565d-ptdps from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container erebus ready: true, restart count 0
Dec 28 04:21:25.592: INFO: kube-proxy-5kzvk from kube-system started at 2019-12-27 13:57:57 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:21:25.592: INFO: kube-flannel-f87zg from kube-system started at 2019-12-27 13:58:14 +0000 UTC (2 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:21:25.592: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:21:25.592: INFO: cert-manager-webhook-578c59dddd-flp52 from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container webhook ready: true, restart count 0
Dec 28 04:21:25.592: INFO: cert-manager-cainjector-67d4dd59ff-tngcj from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container cainjector ready: true, restart count 0
Dec 28 04:21:25.592: INFO: dex-8448b48ff8-9qn2j from cpaas-system started at 2019-12-27 14:09:25 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container dex ready: true, restart count 0
Dec 28 04:21:25.592: INFO: cert-manager-77f5bf4f5-2wz6n from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container cert-manager ready: true, restart count 0
Dec 28 04:21:25.592: INFO: underlord-5c45b96c5d-6cvvc from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container alauda-console ready: true, restart count 0
Dec 28 04:21:25.592: INFO: agon-75b987dff5-bl7sb from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container agon ready: true, restart count 2
Dec 28 04:21:25.592: INFO: apollo-cfdd64bb4-hjth5 from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container apollo ready: true, restart count 0
Dec 28 04:21:25.592: INFO: coredns-66447b44c9-5qbrm from kube-system started at 2019-12-27 13:58:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container coredns ready: true, restart count 0
Dec 28 04:21:25.592: INFO: cluster-registry-controller-manager-76774c98d-rmnh2 from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (2 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 28 04:21:25.592: INFO: 	Container manager ready: true, restart count 0
Dec 28 04:21:25.592: INFO: furion-679c948779-xjs2n from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container furion ready: true, restart count 0
Dec 28 04:21:25.592: INFO: archon-5fdc59d78c-k5jbm from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:21:25.592: INFO: 	Container archon-api ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node hxx-m-1
STEP: verifying the node has the label node hxx-m-2
STEP: verifying the node has the label node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod cert-manager-77f5bf4f5-2wz6n requesting resource cpu=10m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod cert-manager-77f5bf4f5-h86rt requesting resource cpu=10m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod cert-manager-cainjector-67d4dd59ff-8jhs9 requesting resource cpu=10m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod cert-manager-cainjector-67d4dd59ff-tngcj requesting resource cpu=10m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod cert-manager-webhook-578c59dddd-flp52 requesting resource cpu=10m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod cert-manager-webhook-578c59dddd-k697c requesting resource cpu=10m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod agon-75b987dff5-7bht5 requesting resource cpu=256m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod agon-75b987dff5-bl7sb requesting resource cpu=256m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod apollo-cfdd64bb4-4lssk requesting resource cpu=256m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod apollo-cfdd64bb4-hjth5 requesting resource cpu=256m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod archon-5fdc59d78c-k5jbm requesting resource cpu=256m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod archon-5fdc59d78c-rhtzm requesting resource cpu=256m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod auth-controller2-79ff55cd75-4clk9 requesting resource cpu=256m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod auth-controller2-79ff55cd75-cbjbn requesting resource cpu=256m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod cluster-registry-controller-manager-76774c98d-7c7mz requesting resource cpu=512m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod cluster-registry-controller-manager-76774c98d-rmnh2 requesting resource cpu=512m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod dex-8448b48ff8-2bd5h requesting resource cpu=256m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod dex-8448b48ff8-9qn2j requesting resource cpu=256m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod erebus-5597f9565d-ptdps requesting resource cpu=256m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod erebus-5597f9565d-zwjnz requesting resource cpu=256m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod furion-679c948779-jz6lf requesting resource cpu=256m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod furion-679c948779-xjs2n requesting resource cpu=256m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod nginx-ingress-controller-f9b5d49fd-67nvw requesting resource cpu=256m on Node hxx-m-2
Dec 28 04:21:25.621: INFO: Pod underlord-5c45b96c5d-6cvvc requesting resource cpu=256m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod underlord-5c45b96c5d-nmjjq requesting resource cpu=256m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod coredns-66447b44c9-5qbrm requesting resource cpu=100m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod coredns-66447b44c9-zphmm requesting resource cpu=100m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod etcd-hxx-m-2 requesting resource cpu=0m on Node hxx-m-2
Dec 28 04:21:25.621: INFO: Pod kube-apiserver-hxx-m-2 requesting resource cpu=250m on Node hxx-m-2
Dec 28 04:21:25.621: INFO: Pod kube-controller-manager-hxx-m-2 requesting resource cpu=200m on Node hxx-m-2
Dec 28 04:21:25.621: INFO: Pod kube-flannel-8hgpf requesting resource cpu=50m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod kube-flannel-f87zg requesting resource cpu=50m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod kube-flannel-ffhtx requesting resource cpu=50m on Node hxx-m-2
Dec 28 04:21:25.621: INFO: Pod kube-proxy-44f6q requesting resource cpu=0m on Node hxx-m-2
Dec 28 04:21:25.621: INFO: Pod kube-proxy-5kzvk requesting resource cpu=0m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod kube-proxy-bnhj6 requesting resource cpu=0m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod kube-scheduler-hxx-m-2 requesting resource cpu=100m on Node hxx-m-2
Dec 28 04:21:25.621: INFO: Pod tiller-deploy-7c757c6f9c-67l6b requesting resource cpu=0m on Node hxx-m-3
Dec 28 04:21:25.621: INFO: Pod sonobuoy requesting resource cpu=0m on Node hxx-m-2
Dec 28 04:21:25.621: INFO: Pod sonobuoy-e2e-job-af99efc4f7ea449a requesting resource cpu=0m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-89sp4 requesting resource cpu=0m on Node hxx-m-2
Dec 28 04:21:25.621: INFO: Pod sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-lzsqv requesting resource cpu=0m on Node hxx-m-1
Dec 28 04:21:25.621: INFO: Pod sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-pjj5l requesting resource cpu=0m on Node hxx-m-3
STEP: Starting Pods to consume most of the cluster CPU.
Dec 28 04:21:25.621: INFO: Creating a pod which consumes cpu=3682m on Node hxx-m-1
Dec 28 04:21:25.624: INFO: Creating a pod which consumes cpu=5000m on Node hxx-m-2
Dec 28 04:21:25.627: INFO: Creating a pod which consumes cpu=3682m on Node hxx-m-3
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-137f1fce-1f97-4969-b6ba-8e4e764f2d47.15e46e278c944de6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8769/filler-pod-137f1fce-1f97-4969-b6ba-8e4e764f2d47 to hxx-m-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-137f1fce-1f97-4969-b6ba-8e4e764f2d47.15e46e27b495d948], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-137f1fce-1f97-4969-b6ba-8e4e764f2d47.15e46e27b62b8f7d], Reason = [Created], Message = [Created container filler-pod-137f1fce-1f97-4969-b6ba-8e4e764f2d47]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-137f1fce-1f97-4969-b6ba-8e4e764f2d47.15e46e27bfbe62c6], Reason = [Started], Message = [Started container filler-pod-137f1fce-1f97-4969-b6ba-8e4e764f2d47]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a212a856-1113-4850-b453-7b98ba798e61.15e46e278cf0107d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8769/filler-pod-a212a856-1113-4850-b453-7b98ba798e61 to hxx-m-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a212a856-1113-4850-b453-7b98ba798e61.15e46e27b2c77d57], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a212a856-1113-4850-b453-7b98ba798e61.15e46e27b48ca0e0], Reason = [Created], Message = [Created container filler-pod-a212a856-1113-4850-b453-7b98ba798e61]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a212a856-1113-4850-b453-7b98ba798e61.15e46e27bdcfdf0d], Reason = [Started], Message = [Started container filler-pod-a212a856-1113-4850-b453-7b98ba798e61]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bae73426-e816-49ad-9b96-58acdddf11ea.15e46e278cad6145], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8769/filler-pod-bae73426-e816-49ad-9b96-58acdddf11ea to hxx-m-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bae73426-e816-49ad-9b96-58acdddf11ea.15e46e27b2519c68], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bae73426-e816-49ad-9b96-58acdddf11ea.15e46e27b3b8fd9c], Reason = [Created], Message = [Created container filler-pod-bae73426-e816-49ad-9b96-58acdddf11ea]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bae73426-e816-49ad-9b96-58acdddf11ea.15e46e27bd5eee6b], Reason = [Started], Message = [Started container filler-pod-bae73426-e816-49ad-9b96-58acdddf11ea]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15e46e2804e33dc7], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node hxx-m-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node hxx-m-3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node hxx-m-1
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:21:28.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8769" for this suite.
Dec 28 04:21:34.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:21:34.741: INFO: namespace sched-pred-8769 deletion completed in 6.065929011s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:9.203 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:21:34.741: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-rzfb
STEP: Creating a pod to test atomic-volume-subpath
Dec 28 04:21:34.764: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rzfb" in namespace "subpath-6545" to be "success or failure"
Dec 28 04:21:34.766: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.501398ms
Dec 28 04:21:36.769: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Running", Reason="", readiness=true. Elapsed: 2.004877276s
Dec 28 04:21:38.771: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Running", Reason="", readiness=true. Elapsed: 4.007116825s
Dec 28 04:21:40.773: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Running", Reason="", readiness=true. Elapsed: 6.009362032s
Dec 28 04:21:42.775: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Running", Reason="", readiness=true. Elapsed: 8.011635787s
Dec 28 04:21:44.777: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Running", Reason="", readiness=true. Elapsed: 10.013569077s
Dec 28 04:21:46.779: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Running", Reason="", readiness=true. Elapsed: 12.015642843s
Dec 28 04:21:48.782: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Running", Reason="", readiness=true. Elapsed: 14.01790437s
Dec 28 04:21:50.784: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Running", Reason="", readiness=true. Elapsed: 16.020116734s
Dec 28 04:21:52.786: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Running", Reason="", readiness=true. Elapsed: 18.022460943s
Dec 28 04:21:54.788: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Running", Reason="", readiness=true. Elapsed: 20.02445361s
Dec 28 04:21:56.791: INFO: Pod "pod-subpath-test-secret-rzfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.026797584s
STEP: Saw pod success
Dec 28 04:21:56.791: INFO: Pod "pod-subpath-test-secret-rzfb" satisfied condition "success or failure"
Dec 28 04:21:56.792: INFO: Trying to get logs from node hxx-m-2 pod pod-subpath-test-secret-rzfb container test-container-subpath-secret-rzfb: <nil>
STEP: delete the pod
Dec 28 04:21:56.802: INFO: Waiting for pod pod-subpath-test-secret-rzfb to disappear
Dec 28 04:21:56.804: INFO: Pod pod-subpath-test-secret-rzfb no longer exists
STEP: Deleting pod pod-subpath-test-secret-rzfb
Dec 28 04:21:56.804: INFO: Deleting pod "pod-subpath-test-secret-rzfb" in namespace "subpath-6545"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:21:56.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6545" for this suite.
Dec 28 04:22:02.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:22:02.875: INFO: namespace subpath-6545 deletion completed in 6.06743341s

• [SLOW TEST:28.134 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:22:02.876: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Dec 28 04:22:02.892: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 28 04:23:02.908: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:23:02.909: INFO: Starting informer...
STEP: Starting pod...
Dec 28 04:23:03.117: INFO: Pod is running on hxx-m-2. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Dec 28 04:23:03.127: INFO: Pod wasn't evicted. Proceeding
Dec 28 04:23:03.127: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Dec 28 04:24:18.147: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:24:18.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-4872" for this suite.
Dec 28 04:24:46.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:24:46.230: INFO: namespace taint-single-pod-4872 deletion completed in 28.080066701s

• [SLOW TEST:163.355 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:24:46.230: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 28 04:24:46.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-8386'
Dec 28 04:24:46.330: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 28 04:24:46.330: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Dec 28 04:24:46.334: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-mgjgb]
Dec 28 04:24:46.334: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-mgjgb" in namespace "kubectl-8386" to be "running and ready"
Dec 28 04:24:46.336: INFO: Pod "e2e-test-httpd-rc-mgjgb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.485237ms
Dec 28 04:24:48.338: INFO: Pod "e2e-test-httpd-rc-mgjgb": Phase="Running", Reason="", readiness=true. Elapsed: 2.003376896s
Dec 28 04:24:48.338: INFO: Pod "e2e-test-httpd-rc-mgjgb" satisfied condition "running and ready"
Dec 28 04:24:48.338: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-mgjgb]
Dec 28 04:24:48.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 logs rc/e2e-test-httpd-rc --namespace=kubectl-8386'
Dec 28 04:24:48.426: INFO: stderr: ""
Dec 28 04:24:48.426: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.199.0.161. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.199.0.161. Set the 'ServerName' directive globally to suppress this message\n[Sat Dec 28 04:24:47.139043 2019] [mpm_event:notice] [pid 1:tid 140711485033320] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Sat Dec 28 04:24:47.139086 2019] [core:notice] [pid 1:tid 140711485033320] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Dec 28 04:24:48.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete rc e2e-test-httpd-rc --namespace=kubectl-8386'
Dec 28 04:24:48.503: INFO: stderr: ""
Dec 28 04:24:48.503: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:24:48.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8386" for this suite.
Dec 28 04:25:16.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:25:16.577: INFO: namespace kubectl-8386 deletion completed in 28.071189519s

• [SLOW TEST:30.347 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:25:16.577: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:25:16.597: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-7af96978-069a-4a8d-b1b4-64ace685fdc9" in namespace "security-context-test-1944" to be "success or failure"
Dec 28 04:25:16.598: INFO: Pod "busybox-readonly-false-7af96978-069a-4a8d-b1b4-64ace685fdc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.285033ms
Dec 28 04:25:18.600: INFO: Pod "busybox-readonly-false-7af96978-069a-4a8d-b1b4-64ace685fdc9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003385067s
Dec 28 04:25:18.600: INFO: Pod "busybox-readonly-false-7af96978-069a-4a8d-b1b4-64ace685fdc9" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:25:18.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1944" for this suite.
Dec 28 04:25:24.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:25:24.669: INFO: namespace security-context-test-1944 deletion completed in 6.066471598s

• [SLOW TEST:8.092 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:25:24.669: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 28 04:25:28.716: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 04:25:28.718: INFO: Pod pod-with-poststart-http-hook still exists
Dec 28 04:25:30.718: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 04:25:30.720: INFO: Pod pod-with-poststart-http-hook still exists
Dec 28 04:25:32.718: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 04:25:32.720: INFO: Pod pod-with-poststart-http-hook still exists
Dec 28 04:25:34.718: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 04:25:34.720: INFO: Pod pod-with-poststart-http-hook still exists
Dec 28 04:25:36.718: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 04:25:36.720: INFO: Pod pod-with-poststart-http-hook still exists
Dec 28 04:25:38.718: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 04:25:38.720: INFO: Pod pod-with-poststart-http-hook still exists
Dec 28 04:25:40.718: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 04:25:40.720: INFO: Pod pod-with-poststart-http-hook still exists
Dec 28 04:25:42.718: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 04:25:42.720: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:25:42.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-283" for this suite.
Dec 28 04:25:54.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:25:54.788: INFO: namespace container-lifecycle-hook-283 deletion completed in 12.065239445s

• [SLOW TEST:30.119 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:25:54.788: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Dec 28 04:25:54.808: INFO: Waiting up to 5m0s for pod "var-expansion-d4b286f6-632c-4d79-b317-9cab5ef1e54a" in namespace "var-expansion-4687" to be "success or failure"
Dec 28 04:25:54.809: INFO: Pod "var-expansion-d4b286f6-632c-4d79-b317-9cab5ef1e54a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.322495ms
Dec 28 04:25:56.812: INFO: Pod "var-expansion-d4b286f6-632c-4d79-b317-9cab5ef1e54a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003671567s
STEP: Saw pod success
Dec 28 04:25:56.812: INFO: Pod "var-expansion-d4b286f6-632c-4d79-b317-9cab5ef1e54a" satisfied condition "success or failure"
Dec 28 04:25:56.813: INFO: Trying to get logs from node hxx-m-2 pod var-expansion-d4b286f6-632c-4d79-b317-9cab5ef1e54a container dapi-container: <nil>
STEP: delete the pod
Dec 28 04:25:56.823: INFO: Waiting for pod var-expansion-d4b286f6-632c-4d79-b317-9cab5ef1e54a to disappear
Dec 28 04:25:56.824: INFO: Pod var-expansion-d4b286f6-632c-4d79-b317-9cab5ef1e54a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:25:56.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4687" for this suite.
Dec 28 04:26:02.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:26:02.896: INFO: namespace var-expansion-4687 deletion completed in 6.068771862s

• [SLOW TEST:8.107 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:26:02.896: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:26:02.924: INFO: (0) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.82128ms)
Dec 28 04:26:02.927: INFO: (1) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.268242ms)
Dec 28 04:26:02.929: INFO: (2) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.185494ms)
Dec 28 04:26:02.932: INFO: (3) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.268567ms)
Dec 28 04:26:02.934: INFO: (4) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.141086ms)
Dec 28 04:26:02.936: INFO: (5) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.034925ms)
Dec 28 04:26:02.938: INFO: (6) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.203517ms)
Dec 28 04:26:02.940: INFO: (7) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.972192ms)
Dec 28 04:26:02.942: INFO: (8) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.175932ms)
Dec 28 04:26:02.945: INFO: (9) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.196824ms)
Dec 28 04:26:02.947: INFO: (10) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.172541ms)
Dec 28 04:26:02.949: INFO: (11) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.156125ms)
Dec 28 04:26:02.951: INFO: (12) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.148697ms)
Dec 28 04:26:02.953: INFO: (13) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.045631ms)
Dec 28 04:26:02.955: INFO: (14) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.088224ms)
Dec 28 04:26:02.957: INFO: (15) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.140746ms)
Dec 28 04:26:02.960: INFO: (16) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.107846ms)
Dec 28 04:26:02.962: INFO: (17) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.26825ms)
Dec 28 04:26:02.964: INFO: (18) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.059797ms)
Dec 28 04:26:02.966: INFO: (19) /api/v1/nodes/hxx-m-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.066874ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:26:02.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3660" for this suite.
Dec 28 04:26:08.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:26:09.031: INFO: namespace proxy-3660 deletion completed in 6.062868742s

• [SLOW TEST:6.135 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:26:09.031: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-8d81c43a-9dfc-43dc-a0a4-d5f4f860661f
STEP: Creating a pod to test consume configMaps
Dec 28 04:26:09.053: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1c9fdb8e-07b8-4cc9-ae59-64353b910c5d" in namespace "projected-7918" to be "success or failure"
Dec 28 04:26:09.054: INFO: Pod "pod-projected-configmaps-1c9fdb8e-07b8-4cc9-ae59-64353b910c5d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.369096ms
Dec 28 04:26:11.057: INFO: Pod "pod-projected-configmaps-1c9fdb8e-07b8-4cc9-ae59-64353b910c5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004053318s
STEP: Saw pod success
Dec 28 04:26:11.057: INFO: Pod "pod-projected-configmaps-1c9fdb8e-07b8-4cc9-ae59-64353b910c5d" satisfied condition "success or failure"
Dec 28 04:26:11.058: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-configmaps-1c9fdb8e-07b8-4cc9-ae59-64353b910c5d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 04:26:11.069: INFO: Waiting for pod pod-projected-configmaps-1c9fdb8e-07b8-4cc9-ae59-64353b910c5d to disappear
Dec 28 04:26:11.070: INFO: Pod pod-projected-configmaps-1c9fdb8e-07b8-4cc9-ae59-64353b910c5d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:26:11.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7918" for this suite.
Dec 28 04:26:17.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:26:17.139: INFO: namespace projected-7918 deletion completed in 6.06641629s

• [SLOW TEST:8.108 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:26:17.140: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:26:17.155: INFO: Creating deployment "webserver-deployment"
Dec 28 04:26:17.157: INFO: Waiting for observed generation 1
Dec 28 04:26:19.162: INFO: Waiting for all required pods to come up
Dec 28 04:26:19.164: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 28 04:26:21.169: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 28 04:26:21.172: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 28 04:26:21.176: INFO: Updating deployment webserver-deployment
Dec 28 04:26:21.176: INFO: Waiting for observed generation 2
Dec 28 04:26:23.180: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 28 04:26:23.181: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 28 04:26:23.183: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 28 04:26:23.187: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 28 04:26:23.187: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 28 04:26:23.188: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 28 04:26:23.190: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 28 04:26:23.190: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 28 04:26:23.194: INFO: Updating deployment webserver-deployment
Dec 28 04:26:23.194: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 28 04:26:23.197: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 28 04:26:23.199: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 28 04:26:23.211: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-780 /apis/apps/v1/namespaces/deployment-780/deployments/webserver-deployment 1588e727-b1c5-4055-8d0d-cada813d4588 211322 3 2019-12-28 04:26:17 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006225e98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-12-28 04:26:21 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-28 04:26:23 +0000 UTC,LastTransitionTime:2019-12-28 04:26:23 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec 28 04:26:23.214: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-780 /apis/apps/v1/namespaces/deployment-780/replicasets/webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 211316 3 2019-12-28 04:26:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 1588e727-b1c5-4055-8d0d-cada813d4588 0xc003fb03b7 0xc003fb03b8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003fb0428 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 28 04:26:23.214: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 28 04:26:23.214: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-780 /apis/apps/v1/namespaces/deployment-780/replicasets/webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 211315 3 2019-12-28 04:26:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 1588e727-b1c5-4055-8d0d-cada813d4588 0xc003fb02f7 0xc003fb02f8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003fb0358 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec 28 04:26:23.222: INFO: Pod "webserver-deployment-595b5b9587-bfdf9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bfdf9 webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-bfdf9 a5dfcde2-b005-4d57-9c63-4d14e9a624d9 211223 0 2019-12-28 04:26:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb08d7 0xc003fb08d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.42,PodIP:10.199.2.182,StartTime:2019-12-28 04:26:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 04:26:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://dfc1e90644483aee6bc95182052fccee40dcbea3db21567f9664db3ec0e0d47c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.2.182,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.222: INFO: Pod "webserver-deployment-595b5b9587-cf5dn" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-cf5dn webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-cf5dn eca8e05e-eb21-4509-8108-84e186d8ab90 211217 0 2019-12-28 04:26:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb0a57 0xc003fb0a58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.35,PodIP:10.199.1.105,StartTime:2019-12-28 04:26:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 04:26:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://8ccc86004fcb71fd55799dbd4c96984cdbdaf0372477c1da524ebae9b669b849,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.1.105,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.222: INFO: Pod "webserver-deployment-595b5b9587-fnl42" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fnl42 webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-fnl42 0961f4d8-a99c-4142-8cfd-145babb758ee 211331 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb0bd7 0xc003fb0bd8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.222: INFO: Pod "webserver-deployment-595b5b9587-gvb2c" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gvb2c webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-gvb2c 845400cc-80c8-4839-afdc-a417ed0115a3 211226 0 2019-12-28 04:26:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb0cf0 0xc003fb0cf1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.42,PodIP:10.199.2.180,StartTime:2019-12-28 04:26:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 04:26:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2d6859e0f7bd2f50dc5c1837d2d272d1ff5c1ec314d2f4343ebb2a0dc2c4df18,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.2.180,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.222: INFO: Pod "webserver-deployment-595b5b9587-h659x" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-h659x webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-h659x 307184d8-7306-4f85-a1e6-e99be405bdf1 211320 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb0e67 0xc003fb0e68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.222: INFO: Pod "webserver-deployment-595b5b9587-ljfzw" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ljfzw webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-ljfzw f54aa42d-ba15-4c58-9156-c5de817263e9 211236 0 2019-12-28 04:26:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb0f80 0xc003fb0f81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.16,PodIP:10.199.0.170,StartTime:2019-12-28 04:26:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 04:26:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://ca55af0878c1a6da4ef5b5bcfda42dabdc8927be0ba27c64b9d884e00d1f45f4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.0.170,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.222: INFO: Pod "webserver-deployment-595b5b9587-pb7gh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pb7gh webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-pb7gh 89bd7586-d9d9-4c73-86a5-8e4829b9175d 211334 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb10f7 0xc003fb10f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.222: INFO: Pod "webserver-deployment-595b5b9587-phvtk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-phvtk webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-phvtk 4f803754-c987-49ee-b3cf-e13608e28e6c 211211 0 2019-12-28 04:26:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb1210 0xc003fb1211}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.35,PodIP:10.199.1.106,StartTime:2019-12-28 04:26:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 04:26:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3fdd52da32e0e8f42dd862ebd8d6c359e8b4dc750dfe973a03094ae6125b0387,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.1.106,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.222: INFO: Pod "webserver-deployment-595b5b9587-pp45z" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pp45z webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-pp45z 43f23b5a-2795-4adc-815d-ead98b5e43dd 211233 0 2019-12-28 04:26:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb1387 0xc003fb1388}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.16,PodIP:10.199.0.167,StartTime:2019-12-28 04:26:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 04:26:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://bdebcd985810f7584f8ef1b1e278cbab8efe994d6514b1ac37fa3d48cfc6e880,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.0.167,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.223: INFO: Pod "webserver-deployment-595b5b9587-pr9b5" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pr9b5 webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-pr9b5 5a5d3797-ff89-4cad-9bdb-447060bcc69f 211219 0 2019-12-28 04:26:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb1507 0xc003fb1508}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.42,PodIP:10.199.2.181,StartTime:2019-12-28 04:26:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 04:26:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://4ddf7c2f3c8bd6895a52003b4786221cb9dae489c7cfd8d8dab56d72c5737625,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.2.181,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.223: INFO: Pod "webserver-deployment-595b5b9587-ps7r5" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ps7r5 webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-ps7r5 551dc111-d107-4f47-bba5-c1cc8ba2cecf 211333 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb1687 0xc003fb1688}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.223: INFO: Pod "webserver-deployment-595b5b9587-qlh5r" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qlh5r webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-qlh5r 889401e9-8241-4824-98c8-062eef86d1f4 211345 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb1780 0xc003fb1781}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.223: INFO: Pod "webserver-deployment-595b5b9587-rbcdv" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rbcdv webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-rbcdv 1046ff8d-f84c-4bc6-bc4d-b28d0e863d82 211214 0 2019-12-28 04:26:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb1890 0xc003fb1891}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.35,PodIP:10.199.1.107,StartTime:2019-12-28 04:26:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 04:26:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://10c62c5ff55cb61d7c1ec475d9ee1f082a09eaacde907c9e3a735322ab6e12a1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.1.107,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.223: INFO: Pod "webserver-deployment-595b5b9587-s6mb2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-s6mb2 webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-s6mb2 217a53b6-bce0-4d3c-a9ab-4bd10229e3ce 211335 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb1a07 0xc003fb1a08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.223: INFO: Pod "webserver-deployment-595b5b9587-zcjlv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zcjlv webserver-deployment-595b5b9587- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-595b5b9587-zcjlv 9221e423-8ea6-4daa-92fd-239d9e42d37c 211332 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 91fc4437-a743-4331-a8f4-dbbfa5088787 0xc003fb1b00 0xc003fb1b01}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.223: INFO: Pod "webserver-deployment-c7997dcc8-fnccj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fnccj webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-fnccj af81542f-1b9a-4413-b6b4-74b814c1485a 211280 0 2019-12-28 04:26:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc003fb1bf0 0xc003fb1bf1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.35,PodIP:,StartTime:2019-12-28 04:26:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.223: INFO: Pod "webserver-deployment-c7997dcc8-kcw9v" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kcw9v webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-kcw9v 691bf532-789b-47aa-bb7e-7a77c191faa5 211274 0 2019-12-28 04:26:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc003fb1d60 0xc003fb1d61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.16,PodIP:,StartTime:2019-12-28 04:26:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.224: INFO: Pod "webserver-deployment-c7997dcc8-ksck4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ksck4 webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-ksck4 07c0f020-314b-48ae-8bdd-699e363bc83c 211341 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc003fb1ed0 0xc003fb1ed1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.224: INFO: Pod "webserver-deployment-c7997dcc8-kvc6f" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kvc6f webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-kvc6f 539b7033-fd61-4b16-a62e-7ba8bf2dbe1b 211344 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc003fb1fd0 0xc003fb1fd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.224: INFO: Pod "webserver-deployment-c7997dcc8-mggzc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-mggzc webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-mggzc 38d4b05f-c26e-42cd-9b95-8fee8322f39e 211328 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc0032c80d0 0xc0032c80d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.224: INFO: Pod "webserver-deployment-c7997dcc8-p7hxp" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-p7hxp webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-p7hxp 6a63bfa5-5cc9-47b4-908e-cdef93bc26a6 211336 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc0032c81f0 0xc0032c81f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.224: INFO: Pod "webserver-deployment-c7997dcc8-pvw59" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-pvw59 webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-pvw59 ff9a7f9f-3843-404b-900b-7bdf5156d8ff 211300 0 2019-12-28 04:26:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc0032c8310 0xc0032c8311}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.42,PodIP:,StartTime:2019-12-28 04:26:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.224: INFO: Pod "webserver-deployment-c7997dcc8-q4g7t" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-q4g7t webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-q4g7t 7417dbda-15ff-4ca9-b1c0-0566b729d9f7 211275 0 2019-12-28 04:26:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc0032c8480 0xc0032c8481}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.42,PodIP:,StartTime:2019-12-28 04:26:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.225: INFO: Pod "webserver-deployment-c7997dcc8-qlwj6" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qlwj6 webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-qlwj6 be9fcaaa-c20a-4980-9b13-d8dc3681e640 211343 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc0032c85f0 0xc0032c85f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.225: INFO: Pod "webserver-deployment-c7997dcc8-r9z4w" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-r9z4w webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-r9z4w 34c3c099-f449-4b09-8d7a-8a9a536463c8 211298 0 2019-12-28 04:26:21 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc0032c86f0 0xc0032c86f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:21 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.16,PodIP:,StartTime:2019-12-28 04:26:21 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.225: INFO: Pod "webserver-deployment-c7997dcc8-rv5dz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rv5dz webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-rv5dz bed6642f-c45d-4c43-af20-fe6c48d3e861 211339 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc0032c8860 0xc0032c8861}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 04:26:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 04:26:23.225: INFO: Pod "webserver-deployment-c7997dcc8-wb7dj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wb7dj webserver-deployment-c7997dcc8- deployment-780 /api/v1/namespaces/deployment-780/pods/webserver-deployment-c7997dcc8-wb7dj e2d93e1e-4259-444c-aa98-a48b04b0f7e9 211342 0 2019-12-28 04:26:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d4bba230-6371-4fd4-888a-c7c63a83a75d 0xc0032c8980 0xc0032c8981}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tvvr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tvvr4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tvvr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:26:23.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-780" for this suite.
Dec 28 04:26:29.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:26:29.347: INFO: namespace deployment-780 deletion completed in 6.11590676s

• [SLOW TEST:12.207 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:26:29.347: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 28 04:26:29.375: INFO: Waiting up to 5m0s for pod "downward-api-c2393b7b-d5ce-4d9b-870c-a4552afad1fb" in namespace "downward-api-1668" to be "success or failure"
Dec 28 04:26:29.377: INFO: Pod "downward-api-c2393b7b-d5ce-4d9b-870c-a4552afad1fb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.927922ms
Dec 28 04:26:31.379: INFO: Pod "downward-api-c2393b7b-d5ce-4d9b-870c-a4552afad1fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003990488s
Dec 28 04:26:33.381: INFO: Pod "downward-api-c2393b7b-d5ce-4d9b-870c-a4552afad1fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006109573s
STEP: Saw pod success
Dec 28 04:26:33.381: INFO: Pod "downward-api-c2393b7b-d5ce-4d9b-870c-a4552afad1fb" satisfied condition "success or failure"
Dec 28 04:26:33.383: INFO: Trying to get logs from node hxx-m-2 pod downward-api-c2393b7b-d5ce-4d9b-870c-a4552afad1fb container dapi-container: <nil>
STEP: delete the pod
Dec 28 04:26:33.395: INFO: Waiting for pod downward-api-c2393b7b-d5ce-4d9b-870c-a4552afad1fb to disappear
Dec 28 04:26:33.396: INFO: Pod downward-api-c2393b7b-d5ce-4d9b-870c-a4552afad1fb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:26:33.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1668" for this suite.
Dec 28 04:26:39.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:26:39.473: INFO: namespace downward-api-1668 deletion completed in 6.07444701s

• [SLOW TEST:10.126 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:26:39.474: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:26:39.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-754" for this suite.
Dec 28 04:27:07.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:27:07.575: INFO: namespace pods-754 deletion completed in 28.073919857s

• [SLOW TEST:28.102 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:27:07.576: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:27:23.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4393" for this suite.
Dec 28 04:27:29.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:27:29.713: INFO: namespace resourcequota-4393 deletion completed in 6.065404205s

• [SLOW TEST:22.137 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:27:29.713: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 28 04:27:29.729: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 28 04:27:29.735: INFO: Waiting for terminating namespaces to be deleted...
Dec 28 04:27:29.737: INFO: 
Logging pods the kubelet thinks is on node hxx-m-1 before test
Dec 28 04:27:29.750: INFO: dex-8448b48ff8-2bd5h from cpaas-system started at 2019-12-27 14:09:25 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container dex ready: true, restart count 0
Dec 28 04:27:29.750: INFO: erebus-5597f9565d-zwjnz from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container erebus ready: true, restart count 0
Dec 28 04:27:29.750: INFO: auth-controller2-79ff55cd75-cbjbn from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container auth-controller2-manager ready: true, restart count 0
Dec 28 04:27:29.750: INFO: furion-679c948779-jz6lf from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container furion ready: true, restart count 0
Dec 28 04:27:29.750: INFO: underlord-5c45b96c5d-nmjjq from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container alauda-console ready: true, restart count 0
Dec 28 04:27:29.750: INFO: cert-manager-cainjector-67d4dd59ff-8jhs9 from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container cainjector ready: true, restart count 0
Dec 28 04:27:29.750: INFO: archon-5fdc59d78c-rhtzm from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container archon-api ready: true, restart count 0
Dec 28 04:27:29.750: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-lzsqv from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:27:29.750: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:27:29.750: INFO: kube-proxy-bnhj6 from kube-system started at 2019-12-27 13:58:01 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:27:29.750: INFO: agon-75b987dff5-7bht5 from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container agon ready: true, restart count 2
Dec 28 04:27:29.750: INFO: cluster-registry-controller-manager-76774c98d-7c7mz from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (2 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 28 04:27:29.750: INFO: 	Container manager ready: true, restart count 0
Dec 28 04:27:29.750: INFO: kube-flannel-8hgpf from kube-system started at 2019-12-27 13:58:14 +0000 UTC (2 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:27:29.750: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:27:29.750: INFO: sonobuoy-e2e-job-af99efc4f7ea449a from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container e2e ready: true, restart count 0
Dec 28 04:27:29.750: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:27:29.750: INFO: coredns-66447b44c9-zphmm from kube-system started at 2019-12-27 13:58:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container coredns ready: true, restart count 0
Dec 28 04:27:29.750: INFO: cert-manager-77f5bf4f5-h86rt from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container cert-manager ready: true, restart count 0
Dec 28 04:27:29.750: INFO: cert-manager-webhook-578c59dddd-k697c from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container webhook ready: true, restart count 0
Dec 28 04:27:29.750: INFO: apollo-cfdd64bb4-4lssk from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.750: INFO: 	Container apollo ready: true, restart count 0
Dec 28 04:27:29.750: INFO: 
Logging pods the kubelet thinks is on node hxx-m-2 before test
Dec 28 04:27:29.760: INFO: etcd-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.760: INFO: 	Container etcd ready: true, restart count 0
Dec 28 04:27:29.760: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-89sp4 from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:27:29.760: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:27:29.760: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:27:29.760: INFO: kube-proxy-44f6q from kube-system started at 2019-12-27 13:57:35 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.760: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:27:29.760: INFO: sonobuoy from sonobuoy started at 2019-12-28 04:15:38 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.760: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 28 04:27:29.760: INFO: kube-flannel-nt4gw from kube-system started at 2019-12-28 04:23:35 +0000 UTC (2 container statuses recorded)
Dec 28 04:27:29.760: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:27:29.760: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:27:29.760: INFO: kube-scheduler-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.760: INFO: 	Container kube-scheduler ready: true, restart count 0
Dec 28 04:27:29.760: INFO: nginx-ingress-controller-f9b5d49fd-gmgv6 from cpaas-system started at 2019-12-28 04:23:17 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.760: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 28 04:27:29.760: INFO: kube-apiserver-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.760: INFO: 	Container kube-apiserver ready: true, restart count 0
Dec 28 04:27:29.760: INFO: kube-controller-manager-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.760: INFO: 	Container kube-controller-manager ready: true, restart count 0
Dec 28 04:27:29.760: INFO: 
Logging pods the kubelet thinks is on node hxx-m-3 before test
Dec 28 04:27:29.777: INFO: cluster-registry-controller-manager-76774c98d-rmnh2 from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (2 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 28 04:27:29.777: INFO: 	Container manager ready: true, restart count 0
Dec 28 04:27:29.777: INFO: furion-679c948779-xjs2n from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container furion ready: true, restart count 0
Dec 28 04:27:29.777: INFO: archon-5fdc59d78c-k5jbm from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container archon-api ready: true, restart count 0
Dec 28 04:27:29.777: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-pjj5l from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:27:29.777: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:27:29.777: INFO: tiller-deploy-7c757c6f9c-67l6b from kube-system started at 2019-12-27 13:59:57 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container tiller ready: true, restart count 0
Dec 28 04:27:29.777: INFO: auth-controller2-79ff55cd75-4clk9 from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container auth-controller2-manager ready: true, restart count 0
Dec 28 04:27:29.777: INFO: erebus-5597f9565d-ptdps from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container erebus ready: true, restart count 0
Dec 28 04:27:29.777: INFO: kube-proxy-5kzvk from kube-system started at 2019-12-27 13:57:57 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:27:29.777: INFO: kube-flannel-f87zg from kube-system started at 2019-12-27 13:58:14 +0000 UTC (2 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:27:29.777: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:27:29.777: INFO: cert-manager-webhook-578c59dddd-flp52 from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container webhook ready: true, restart count 0
Dec 28 04:27:29.777: INFO: cert-manager-cainjector-67d4dd59ff-tngcj from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container cainjector ready: true, restart count 0
Dec 28 04:27:29.777: INFO: dex-8448b48ff8-9qn2j from cpaas-system started at 2019-12-27 14:09:25 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container dex ready: true, restart count 0
Dec 28 04:27:29.777: INFO: cert-manager-77f5bf4f5-2wz6n from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container cert-manager ready: true, restart count 0
Dec 28 04:27:29.777: INFO: underlord-5c45b96c5d-6cvvc from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container alauda-console ready: true, restart count 0
Dec 28 04:27:29.777: INFO: agon-75b987dff5-bl7sb from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container agon ready: true, restart count 2
Dec 28 04:27:29.777: INFO: apollo-cfdd64bb4-hjth5 from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container apollo ready: true, restart count 0
Dec 28 04:27:29.777: INFO: coredns-66447b44c9-5qbrm from kube-system started at 2019-12-27 13:58:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:27:29.777: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15e46e7c5642091a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:27:30.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-278" for this suite.
Dec 28 04:27:36.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:27:36.859: INFO: namespace sched-pred-278 deletion completed in 6.065923305s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.147 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:27:36.860: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:27:36.875: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec 28 04:27:40.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-8864 create -f -'
Dec 28 04:27:40.894: INFO: stderr: ""
Dec 28 04:27:40.894: INFO: stdout: "e2e-test-crd-publish-openapi-7315-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 28 04:27:40.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-8864 delete e2e-test-crd-publish-openapi-7315-crds test-foo'
Dec 28 04:27:40.971: INFO: stderr: ""
Dec 28 04:27:40.971: INFO: stdout: "e2e-test-crd-publish-openapi-7315-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 28 04:27:40.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-8864 apply -f -'
Dec 28 04:27:41.119: INFO: stderr: ""
Dec 28 04:27:41.119: INFO: stdout: "e2e-test-crd-publish-openapi-7315-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 28 04:27:41.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-8864 delete e2e-test-crd-publish-openapi-7315-crds test-foo'
Dec 28 04:27:41.195: INFO: stderr: ""
Dec 28 04:27:41.195: INFO: stdout: "e2e-test-crd-publish-openapi-7315-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec 28 04:27:41.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-8864 create -f -'
Dec 28 04:27:41.329: INFO: rc: 1
Dec 28 04:27:41.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-8864 apply -f -'
Dec 28 04:27:41.458: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec 28 04:27:41.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-8864 create -f -'
Dec 28 04:27:41.584: INFO: rc: 1
Dec 28 04:27:41.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-8864 apply -f -'
Dec 28 04:27:41.710: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec 28 04:27:41.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 explain e2e-test-crd-publish-openapi-7315-crds'
Dec 28 04:27:41.842: INFO: stderr: ""
Dec 28 04:27:41.842: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7315-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec 28 04:27:41.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 explain e2e-test-crd-publish-openapi-7315-crds.metadata'
Dec 28 04:27:41.985: INFO: stderr: ""
Dec 28 04:27:41.985: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7315-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 28 04:27:41.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 explain e2e-test-crd-publish-openapi-7315-crds.spec'
Dec 28 04:27:42.124: INFO: stderr: ""
Dec 28 04:27:42.124: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7315-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 28 04:27:42.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 explain e2e-test-crd-publish-openapi-7315-crds.spec.bars'
Dec 28 04:27:42.259: INFO: stderr: ""
Dec 28 04:27:42.259: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7315-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec 28 04:27:42.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 explain e2e-test-crd-publish-openapi-7315-crds.spec.bars2'
Dec 28 04:27:42.389: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:27:46.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8864" for this suite.
Dec 28 04:27:52.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:27:52.111: INFO: namespace crd-publish-openapi-8864 deletion completed in 6.070770843s

• [SLOW TEST:15.251 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:27:52.111: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-332
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-332
STEP: Creating statefulset with conflicting port in namespace statefulset-332
STEP: Waiting until pod test-pod will start running in namespace statefulset-332
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-332
Dec 28 04:27:54.145: INFO: Observed stateful pod in namespace: statefulset-332, name: ss-0, uid: 43a6736a-e5d2-4a65-88db-65bae44a08b8, status phase: Pending. Waiting for statefulset controller to delete.
Dec 28 04:27:54.541: INFO: Observed stateful pod in namespace: statefulset-332, name: ss-0, uid: 43a6736a-e5d2-4a65-88db-65bae44a08b8, status phase: Failed. Waiting for statefulset controller to delete.
Dec 28 04:27:54.544: INFO: Observed stateful pod in namespace: statefulset-332, name: ss-0, uid: 43a6736a-e5d2-4a65-88db-65bae44a08b8, status phase: Failed. Waiting for statefulset controller to delete.
Dec 28 04:27:54.545: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-332
STEP: Removing pod with conflicting port in namespace statefulset-332
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-332 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 28 04:27:56.562: INFO: Deleting all statefulset in ns statefulset-332
Dec 28 04:27:56.566: INFO: Scaling statefulset ss to 0
Dec 28 04:28:16.575: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 04:28:16.576: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:28:16.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-332" for this suite.
Dec 28 04:28:22.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:28:22.657: INFO: namespace statefulset-332 deletion completed in 6.072383407s

• [SLOW TEST:30.546 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:28:22.657: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-efd0881e-ba86-4ff0-a342-357b4b04cced
Dec 28 04:28:22.677: INFO: Pod name my-hostname-basic-efd0881e-ba86-4ff0-a342-357b4b04cced: Found 0 pods out of 1
Dec 28 04:28:27.679: INFO: Pod name my-hostname-basic-efd0881e-ba86-4ff0-a342-357b4b04cced: Found 1 pods out of 1
Dec 28 04:28:27.679: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-efd0881e-ba86-4ff0-a342-357b4b04cced" are running
Dec 28 04:28:27.680: INFO: Pod "my-hostname-basic-efd0881e-ba86-4ff0-a342-357b4b04cced-rhcdp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-28 04:28:22 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-28 04:28:23 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-28 04:28:23 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-28 04:28:22 +0000 UTC Reason: Message:}])
Dec 28 04:28:27.680: INFO: Trying to dial the pod
Dec 28 04:28:32.686: INFO: Controller my-hostname-basic-efd0881e-ba86-4ff0-a342-357b4b04cced: Got expected result from replica 1 [my-hostname-basic-efd0881e-ba86-4ff0-a342-357b4b04cced-rhcdp]: "my-hostname-basic-efd0881e-ba86-4ff0-a342-357b4b04cced-rhcdp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:28:32.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7665" for this suite.
Dec 28 04:28:38.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:28:38.755: INFO: namespace replication-controller-7665 deletion completed in 6.0663614s

• [SLOW TEST:16.098 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:28:38.755: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Dec 28 04:28:38.771: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-505712781 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:28:38.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3578" for this suite.
Dec 28 04:28:44.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:28:44.899: INFO: namespace kubectl-3578 deletion completed in 6.065126764s

• [SLOW TEST:6.144 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:28:44.899: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 28 04:28:44.916: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:28:49.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-277" for this suite.
Dec 28 04:29:17.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:29:17.146: INFO: namespace init-container-277 deletion completed in 28.068437665s

• [SLOW TEST:32.247 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:29:17.146: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Dec 28 04:29:19.171: INFO: Pod pod-hostip-2888375b-e0b8-4b8f-a9c4-84d79dbda7e0 has hostIP: 10.0.128.16
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:29:19.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5402" for this suite.
Dec 28 04:29:47.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:29:47.248: INFO: namespace pods-5402 deletion completed in 28.074905875s

• [SLOW TEST:30.102 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:29:47.249: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:29:47.269: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f2f88b0a-b13b-41bd-9b99-9ddb2a584fc2" in namespace "downward-api-5755" to be "success or failure"
Dec 28 04:29:47.270: INFO: Pod "downwardapi-volume-f2f88b0a-b13b-41bd-9b99-9ddb2a584fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.395607ms
Dec 28 04:29:49.272: INFO: Pod "downwardapi-volume-f2f88b0a-b13b-41bd-9b99-9ddb2a584fc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003421997s
STEP: Saw pod success
Dec 28 04:29:49.272: INFO: Pod "downwardapi-volume-f2f88b0a-b13b-41bd-9b99-9ddb2a584fc2" satisfied condition "success or failure"
Dec 28 04:29:49.273: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-f2f88b0a-b13b-41bd-9b99-9ddb2a584fc2 container client-container: <nil>
STEP: delete the pod
Dec 28 04:29:49.288: INFO: Waiting for pod downwardapi-volume-f2f88b0a-b13b-41bd-9b99-9ddb2a584fc2 to disappear
Dec 28 04:29:49.290: INFO: Pod downwardapi-volume-f2f88b0a-b13b-41bd-9b99-9ddb2a584fc2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:29:49.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5755" for this suite.
Dec 28 04:29:55.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:29:55.360: INFO: namespace downward-api-5755 deletion completed in 6.06784603s

• [SLOW TEST:8.111 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:29:55.360: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec 28 04:30:35.395: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1228 04:30:35.395491      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:30:35.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9992" for this suite.
Dec 28 04:30:41.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:30:41.465: INFO: namespace gc-9992 deletion completed in 6.067559493s

• [SLOW TEST:46.105 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:30:41.465: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Dec 28 04:30:41.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 cluster-info'
Dec 28 04:30:41.555: INFO: stderr: ""
Dec 28 04:30:41.555: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:30:41.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1381" for this suite.
Dec 28 04:30:47.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:30:47.628: INFO: namespace kubectl-1381 deletion completed in 6.070582992s

• [SLOW TEST:6.163 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:30:47.628: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-520b2300-c2e9-4f1b-a22d-288c472c577b
STEP: Creating a pod to test consume configMaps
Dec 28 04:30:47.650: INFO: Waiting up to 5m0s for pod "pod-configmaps-c5ee6038-bafd-4d16-b7a1-02786ca2854a" in namespace "configmap-8781" to be "success or failure"
Dec 28 04:30:47.653: INFO: Pod "pod-configmaps-c5ee6038-bafd-4d16-b7a1-02786ca2854a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.454179ms
Dec 28 04:30:49.655: INFO: Pod "pod-configmaps-c5ee6038-bafd-4d16-b7a1-02786ca2854a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004808111s
STEP: Saw pod success
Dec 28 04:30:49.655: INFO: Pod "pod-configmaps-c5ee6038-bafd-4d16-b7a1-02786ca2854a" satisfied condition "success or failure"
Dec 28 04:30:49.657: INFO: Trying to get logs from node hxx-m-2 pod pod-configmaps-c5ee6038-bafd-4d16-b7a1-02786ca2854a container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 04:30:49.666: INFO: Waiting for pod pod-configmaps-c5ee6038-bafd-4d16-b7a1-02786ca2854a to disappear
Dec 28 04:30:49.667: INFO: Pod pod-configmaps-c5ee6038-bafd-4d16-b7a1-02786ca2854a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:30:49.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8781" for this suite.
Dec 28 04:30:55.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:30:55.735: INFO: namespace configmap-8781 deletion completed in 6.065288844s

• [SLOW TEST:8.107 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:30:55.735: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:30:55.755: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c463b6da-1fb6-475b-a7ce-5592dd30b6e1" in namespace "downward-api-8875" to be "success or failure"
Dec 28 04:30:55.757: INFO: Pod "downwardapi-volume-c463b6da-1fb6-475b-a7ce-5592dd30b6e1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.388031ms
Dec 28 04:30:57.759: INFO: Pod "downwardapi-volume-c463b6da-1fb6-475b-a7ce-5592dd30b6e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00373073s
STEP: Saw pod success
Dec 28 04:30:57.759: INFO: Pod "downwardapi-volume-c463b6da-1fb6-475b-a7ce-5592dd30b6e1" satisfied condition "success or failure"
Dec 28 04:30:57.760: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-c463b6da-1fb6-475b-a7ce-5592dd30b6e1 container client-container: <nil>
STEP: delete the pod
Dec 28 04:30:57.770: INFO: Waiting for pod downwardapi-volume-c463b6da-1fb6-475b-a7ce-5592dd30b6e1 to disappear
Dec 28 04:30:57.771: INFO: Pod downwardapi-volume-c463b6da-1fb6-475b-a7ce-5592dd30b6e1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:30:57.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8875" for this suite.
Dec 28 04:31:03.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:31:03.839: INFO: namespace downward-api-8875 deletion completed in 6.065493256s

• [SLOW TEST:8.104 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:31:03.839: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 28 04:31:03.859: INFO: Waiting up to 5m0s for pod "downward-api-f842de4b-446e-4200-ba0c-7853a901b255" in namespace "downward-api-8725" to be "success or failure"
Dec 28 04:31:03.861: INFO: Pod "downward-api-f842de4b-446e-4200-ba0c-7853a901b255": Phase="Pending", Reason="", readiness=false. Elapsed: 1.444766ms
Dec 28 04:31:05.863: INFO: Pod "downward-api-f842de4b-446e-4200-ba0c-7853a901b255": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003701102s
STEP: Saw pod success
Dec 28 04:31:05.863: INFO: Pod "downward-api-f842de4b-446e-4200-ba0c-7853a901b255" satisfied condition "success or failure"
Dec 28 04:31:05.865: INFO: Trying to get logs from node hxx-m-2 pod downward-api-f842de4b-446e-4200-ba0c-7853a901b255 container dapi-container: <nil>
STEP: delete the pod
Dec 28 04:31:05.875: INFO: Waiting for pod downward-api-f842de4b-446e-4200-ba0c-7853a901b255 to disappear
Dec 28 04:31:05.876: INFO: Pod downward-api-f842de4b-446e-4200-ba0c-7853a901b255 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:31:05.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8725" for this suite.
Dec 28 04:31:11.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:31:11.945: INFO: namespace downward-api-8725 deletion completed in 6.06586131s

• [SLOW TEST:8.105 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:31:11.945: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 28 04:31:21.993: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:31:21.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1228 04:31:21.993421      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-3761" for this suite.
Dec 28 04:31:28.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:31:28.065: INFO: namespace gc-3761 deletion completed in 6.069931931s

• [SLOW TEST:16.120 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:31:28.065: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 04:31:28.599: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 28 04:31:30.605: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713104288, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713104288, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713104288, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713104288, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 04:31:33.612: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:31:33.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1813" for this suite.
Dec 28 04:31:39.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:31:39.716: INFO: namespace webhook-1813 deletion completed in 6.071948529s
STEP: Destroying namespace "webhook-1813-markers" for this suite.
Dec 28 04:31:45.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:31:45.783: INFO: namespace webhook-1813-markers deletion completed in 6.066838492s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.724 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:31:45.789: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:32:05.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7365" for this suite.
Dec 28 04:32:11.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:32:11.974: INFO: namespace container-runtime-7365 deletion completed in 6.067655578s

• [SLOW TEST:26.185 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:32:11.974: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 28 04:32:16.018: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:32:16.020: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:32:18.020: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:32:18.022: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:32:20.020: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:32:20.022: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:32:20.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9897" for this suite.
Dec 28 04:32:32.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:32:32.097: INFO: namespace container-lifecycle-hook-9897 deletion completed in 12.072181802s

• [SLOW TEST:20.123 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:32:32.098: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-fd76345d-e697-44c4-b653-4393a202bd54
STEP: Creating a pod to test consume secrets
Dec 28 04:32:32.119: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a256dca8-8e93-41ec-9d4d-ebbb189314b9" in namespace "projected-8969" to be "success or failure"
Dec 28 04:32:32.121: INFO: Pod "pod-projected-secrets-a256dca8-8e93-41ec-9d4d-ebbb189314b9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.520286ms
Dec 28 04:32:34.123: INFO: Pod "pod-projected-secrets-a256dca8-8e93-41ec-9d4d-ebbb189314b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003846232s
STEP: Saw pod success
Dec 28 04:32:34.123: INFO: Pod "pod-projected-secrets-a256dca8-8e93-41ec-9d4d-ebbb189314b9" satisfied condition "success or failure"
Dec 28 04:32:34.124: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-secrets-a256dca8-8e93-41ec-9d4d-ebbb189314b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 28 04:32:34.134: INFO: Waiting for pod pod-projected-secrets-a256dca8-8e93-41ec-9d4d-ebbb189314b9 to disappear
Dec 28 04:32:34.136: INFO: Pod pod-projected-secrets-a256dca8-8e93-41ec-9d4d-ebbb189314b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:32:34.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8969" for this suite.
Dec 28 04:32:40.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:32:40.205: INFO: namespace projected-8969 deletion completed in 6.066078866s

• [SLOW TEST:8.107 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:32:40.205: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:32:40.235: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 28 04:32:40.239: INFO: Number of nodes with available pods: 0
Dec 28 04:32:40.239: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 28 04:32:40.249: INFO: Number of nodes with available pods: 0
Dec 28 04:32:40.249: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:32:41.251: INFO: Number of nodes with available pods: 0
Dec 28 04:32:41.251: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:32:42.251: INFO: Number of nodes with available pods: 1
Dec 28 04:32:42.251: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 28 04:32:42.259: INFO: Number of nodes with available pods: 1
Dec 28 04:32:42.259: INFO: Number of running nodes: 0, number of available pods: 1
Dec 28 04:32:43.261: INFO: Number of nodes with available pods: 0
Dec 28 04:32:43.261: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 28 04:32:43.265: INFO: Number of nodes with available pods: 0
Dec 28 04:32:43.265: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:32:44.268: INFO: Number of nodes with available pods: 0
Dec 28 04:32:44.268: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:32:45.267: INFO: Number of nodes with available pods: 0
Dec 28 04:32:45.267: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:32:46.268: INFO: Number of nodes with available pods: 0
Dec 28 04:32:46.268: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:32:47.267: INFO: Number of nodes with available pods: 1
Dec 28 04:32:47.267: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7766, will wait for the garbage collector to delete the pods
Dec 28 04:32:47.325: INFO: Deleting DaemonSet.extensions daemon-set took: 3.126573ms
Dec 28 04:32:48.125: INFO: Terminating DaemonSet.extensions daemon-set pods took: 800.204839ms
Dec 28 04:33:01.227: INFO: Number of nodes with available pods: 0
Dec 28 04:33:01.227: INFO: Number of running nodes: 0, number of available pods: 0
Dec 28 04:33:01.230: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7766/daemonsets","resourceVersion":"214129"},"items":null}

Dec 28 04:33:01.231: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7766/pods","resourceVersion":"214129"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:33:01.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7766" for this suite.
Dec 28 04:33:07.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:33:07.317: INFO: namespace daemonsets-7766 deletion completed in 6.071654609s

• [SLOW TEST:27.112 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:33:07.317: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 28 04:33:07.336: INFO: Waiting up to 5m0s for pod "downward-api-09d53473-5e7d-444b-a267-ad97ac6285e3" in namespace "downward-api-3140" to be "success or failure"
Dec 28 04:33:07.337: INFO: Pod "downward-api-09d53473-5e7d-444b-a267-ad97ac6285e3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.423101ms
Dec 28 04:33:09.339: INFO: Pod "downward-api-09d53473-5e7d-444b-a267-ad97ac6285e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003422011s
STEP: Saw pod success
Dec 28 04:33:09.339: INFO: Pod "downward-api-09d53473-5e7d-444b-a267-ad97ac6285e3" satisfied condition "success or failure"
Dec 28 04:33:09.341: INFO: Trying to get logs from node hxx-m-2 pod downward-api-09d53473-5e7d-444b-a267-ad97ac6285e3 container dapi-container: <nil>
STEP: delete the pod
Dec 28 04:33:09.351: INFO: Waiting for pod downward-api-09d53473-5e7d-444b-a267-ad97ac6285e3 to disappear
Dec 28 04:33:09.353: INFO: Pod downward-api-09d53473-5e7d-444b-a267-ad97ac6285e3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:33:09.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3140" for this suite.
Dec 28 04:33:15.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:33:15.422: INFO: namespace downward-api-3140 deletion completed in 6.066984273s

• [SLOW TEST:8.105 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:33:15.422: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-02cbd2dc-f1c3-4f8a-acd5-34d9fada3752
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-02cbd2dc-f1c3-4f8a-acd5-34d9fada3752
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:34:37.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5637" for this suite.
Dec 28 04:34:51.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:34:51.772: INFO: namespace projected-5637 deletion completed in 14.063273736s

• [SLOW TEST:96.350 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:34:51.772: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 28 04:34:51.805: INFO: Number of nodes with available pods: 0
Dec 28 04:34:51.805: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:34:52.810: INFO: Number of nodes with available pods: 1
Dec 28 04:34:52.810: INFO: Node hxx-m-2 is running more than one daemon pod
Dec 28 04:34:53.810: INFO: Number of nodes with available pods: 3
Dec 28 04:34:53.810: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 28 04:34:53.824: INFO: Number of nodes with available pods: 2
Dec 28 04:34:53.824: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:34:54.829: INFO: Number of nodes with available pods: 3
Dec 28 04:34:54.829: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1216, will wait for the garbage collector to delete the pods
Dec 28 04:34:54.886: INFO: Deleting DaemonSet.extensions daemon-set took: 2.972337ms
Dec 28 04:34:55.687: INFO: Terminating DaemonSet.extensions daemon-set pods took: 800.207702ms
Dec 28 04:35:06.988: INFO: Number of nodes with available pods: 0
Dec 28 04:35:06.988: INFO: Number of running nodes: 0, number of available pods: 0
Dec 28 04:35:06.990: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1216/daemonsets","resourceVersion":"214708"},"items":null}

Dec 28 04:35:06.991: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1216/pods","resourceVersion":"214708"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:35:06.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1216" for this suite.
Dec 28 04:35:13.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:35:13.069: INFO: namespace daemonsets-1216 deletion completed in 6.068422254s

• [SLOW TEST:21.296 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:35:13.069: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 28 04:35:13.089: INFO: Waiting up to 5m0s for pod "pod-329f150c-9fd8-4d2a-8faa-2e4e2e459b1e" in namespace "emptydir-9226" to be "success or failure"
Dec 28 04:35:13.090: INFO: Pod "pod-329f150c-9fd8-4d2a-8faa-2e4e2e459b1e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.390079ms
Dec 28 04:35:15.092: INFO: Pod "pod-329f150c-9fd8-4d2a-8faa-2e4e2e459b1e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003708215s
STEP: Saw pod success
Dec 28 04:35:15.092: INFO: Pod "pod-329f150c-9fd8-4d2a-8faa-2e4e2e459b1e" satisfied condition "success or failure"
Dec 28 04:35:15.094: INFO: Trying to get logs from node hxx-m-2 pod pod-329f150c-9fd8-4d2a-8faa-2e4e2e459b1e container test-container: <nil>
STEP: delete the pod
Dec 28 04:35:15.104: INFO: Waiting for pod pod-329f150c-9fd8-4d2a-8faa-2e4e2e459b1e to disappear
Dec 28 04:35:15.105: INFO: Pod pod-329f150c-9fd8-4d2a-8faa-2e4e2e459b1e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:35:15.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9226" for this suite.
Dec 28 04:35:21.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:35:21.179: INFO: namespace emptydir-9226 deletion completed in 6.071771096s

• [SLOW TEST:8.110 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:35:21.179: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Dec 28 04:35:21.199: INFO: Waiting up to 5m0s for pod "var-expansion-b51e2b30-e6f7-4e22-a44f-770df5fe6cee" in namespace "var-expansion-4742" to be "success or failure"
Dec 28 04:35:21.201: INFO: Pod "var-expansion-b51e2b30-e6f7-4e22-a44f-770df5fe6cee": Phase="Pending", Reason="", readiness=false. Elapsed: 1.556974ms
Dec 28 04:35:23.203: INFO: Pod "var-expansion-b51e2b30-e6f7-4e22-a44f-770df5fe6cee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003697337s
STEP: Saw pod success
Dec 28 04:35:23.203: INFO: Pod "var-expansion-b51e2b30-e6f7-4e22-a44f-770df5fe6cee" satisfied condition "success or failure"
Dec 28 04:35:23.204: INFO: Trying to get logs from node hxx-m-2 pod var-expansion-b51e2b30-e6f7-4e22-a44f-770df5fe6cee container dapi-container: <nil>
STEP: delete the pod
Dec 28 04:35:23.214: INFO: Waiting for pod var-expansion-b51e2b30-e6f7-4e22-a44f-770df5fe6cee to disappear
Dec 28 04:35:23.216: INFO: Pod var-expansion-b51e2b30-e6f7-4e22-a44f-770df5fe6cee no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:35:23.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4742" for this suite.
Dec 28 04:35:29.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:35:29.290: INFO: namespace var-expansion-4742 deletion completed in 6.07183234s

• [SLOW TEST:8.111 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:35:29.291: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5995
I1228 04:35:29.308764      22 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5995, replica count: 1
I1228 04:35:30.359148      22 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 28 04:35:30.465: INFO: Created: latency-svc-mwbkf
Dec 28 04:35:30.468: INFO: Got endpoints: latency-svc-mwbkf [9.352381ms]
Dec 28 04:35:30.474: INFO: Created: latency-svc-f2f79
Dec 28 04:35:30.476: INFO: Got endpoints: latency-svc-f2f79 [7.889771ms]
Dec 28 04:35:30.480: INFO: Created: latency-svc-hd8rl
Dec 28 04:35:30.481: INFO: Got endpoints: latency-svc-hd8rl [12.702428ms]
Dec 28 04:35:30.485: INFO: Created: latency-svc-89b2v
Dec 28 04:35:30.487: INFO: Got endpoints: latency-svc-89b2v [18.512619ms]
Dec 28 04:35:30.492: INFO: Created: latency-svc-wv8lc
Dec 28 04:35:30.493: INFO: Got endpoints: latency-svc-wv8lc [24.514675ms]
Dec 28 04:35:30.497: INFO: Created: latency-svc-gjq24
Dec 28 04:35:30.499: INFO: Got endpoints: latency-svc-gjq24 [30.448246ms]
Dec 28 04:35:30.503: INFO: Created: latency-svc-9v7xq
Dec 28 04:35:30.505: INFO: Got endpoints: latency-svc-9v7xq [36.310926ms]
Dec 28 04:35:30.507: INFO: Created: latency-svc-d2xnq
Dec 28 04:35:30.508: INFO: Got endpoints: latency-svc-d2xnq [39.838758ms]
Dec 28 04:35:30.517: INFO: Created: latency-svc-bxbj7
Dec 28 04:35:30.521: INFO: Got endpoints: latency-svc-bxbj7 [51.953417ms]
Dec 28 04:35:30.521: INFO: Created: latency-svc-d6rhm
Dec 28 04:35:30.526: INFO: Got endpoints: latency-svc-d6rhm [56.889083ms]
Dec 28 04:35:30.526: INFO: Created: latency-svc-hq2ps
Dec 28 04:35:30.528: INFO: Got endpoints: latency-svc-hq2ps [59.764198ms]
Dec 28 04:35:30.530: INFO: Created: latency-svc-rm9tn
Dec 28 04:35:30.532: INFO: Got endpoints: latency-svc-rm9tn [63.458498ms]
Dec 28 04:35:30.535: INFO: Created: latency-svc-jmr8j
Dec 28 04:35:30.539: INFO: Got endpoints: latency-svc-jmr8j [70.152568ms]
Dec 28 04:35:30.540: INFO: Created: latency-svc-zzp6j
Dec 28 04:35:30.545: INFO: Got endpoints: latency-svc-zzp6j [75.986243ms]
Dec 28 04:35:30.546: INFO: Created: latency-svc-zlvbd
Dec 28 04:35:30.548: INFO: Got endpoints: latency-svc-zlvbd [79.610586ms]
Dec 28 04:35:30.552: INFO: Created: latency-svc-sgqms
Dec 28 04:35:30.554: INFO: Got endpoints: latency-svc-sgqms [85.206654ms]
Dec 28 04:35:30.557: INFO: Created: latency-svc-llvdd
Dec 28 04:35:30.559: INFO: Got endpoints: latency-svc-llvdd [82.958243ms]
Dec 28 04:35:30.562: INFO: Created: latency-svc-9cpv8
Dec 28 04:35:30.564: INFO: Got endpoints: latency-svc-9cpv8 [82.891674ms]
Dec 28 04:35:30.568: INFO: Created: latency-svc-ftnc8
Dec 28 04:35:30.572: INFO: Created: latency-svc-d57qs
Dec 28 04:35:30.572: INFO: Got endpoints: latency-svc-ftnc8 [12.594005ms]
Dec 28 04:35:30.576: INFO: Got endpoints: latency-svc-d57qs [89.169385ms]
Dec 28 04:35:30.577: INFO: Created: latency-svc-m9gwq
Dec 28 04:35:30.582: INFO: Got endpoints: latency-svc-m9gwq [88.477095ms]
Dec 28 04:35:30.583: INFO: Created: latency-svc-q9pcn
Dec 28 04:35:30.587: INFO: Got endpoints: latency-svc-q9pcn [87.939548ms]
Dec 28 04:35:30.588: INFO: Created: latency-svc-x29br
Dec 28 04:35:30.590: INFO: Got endpoints: latency-svc-x29br [84.642436ms]
Dec 28 04:35:30.597: INFO: Created: latency-svc-mzdnm
Dec 28 04:35:30.599: INFO: Got endpoints: latency-svc-mzdnm [90.641162ms]
Dec 28 04:35:30.603: INFO: Created: latency-svc-4b7lm
Dec 28 04:35:30.604: INFO: Got endpoints: latency-svc-4b7lm [83.726782ms]
Dec 28 04:35:30.607: INFO: Created: latency-svc-v8skh
Dec 28 04:35:30.610: INFO: Got endpoints: latency-svc-v8skh [84.31754ms]
Dec 28 04:35:30.614: INFO: Created: latency-svc-59vrx
Dec 28 04:35:30.618: INFO: Got endpoints: latency-svc-59vrx [89.099664ms]
Dec 28 04:35:30.618: INFO: Created: latency-svc-f9kvf
Dec 28 04:35:30.620: INFO: Got endpoints: latency-svc-f9kvf [88.245362ms]
Dec 28 04:35:30.623: INFO: Created: latency-svc-hn9l9
Dec 28 04:35:30.625: INFO: Got endpoints: latency-svc-hn9l9 [86.210751ms]
Dec 28 04:35:30.628: INFO: Created: latency-svc-w62sk
Dec 28 04:35:30.630: INFO: Got endpoints: latency-svc-w62sk [85.553195ms]
Dec 28 04:35:30.633: INFO: Created: latency-svc-zhrjx
Dec 28 04:35:30.636: INFO: Got endpoints: latency-svc-zhrjx [87.440452ms]
Dec 28 04:35:30.637: INFO: Created: latency-svc-5cdjv
Dec 28 04:35:30.641: INFO: Created: latency-svc-rtbj7
Dec 28 04:35:30.641: INFO: Got endpoints: latency-svc-5cdjv [86.950132ms]
Dec 28 04:35:30.644: INFO: Got endpoints: latency-svc-rtbj7 [80.428907ms]
Dec 28 04:35:30.645: INFO: Created: latency-svc-d8lzj
Dec 28 04:35:30.653: INFO: Created: latency-svc-j97sg
Dec 28 04:35:30.658: INFO: Created: latency-svc-snl2v
Dec 28 04:35:30.664: INFO: Created: latency-svc-7qfqk
Dec 28 04:35:30.669: INFO: Got endpoints: latency-svc-d8lzj [96.909991ms]
Dec 28 04:35:30.669: INFO: Created: latency-svc-7r8sb
Dec 28 04:35:30.673: INFO: Created: latency-svc-rrskb
Dec 28 04:35:30.677: INFO: Created: latency-svc-mgzz2
Dec 28 04:35:30.688: INFO: Created: latency-svc-fpxgv
Dec 28 04:35:30.694: INFO: Created: latency-svc-fpntw
Dec 28 04:35:30.699: INFO: Created: latency-svc-4csnh
Dec 28 04:35:30.703: INFO: Created: latency-svc-nmrfx
Dec 28 04:35:30.707: INFO: Created: latency-svc-87zrw
Dec 28 04:35:30.711: INFO: Created: latency-svc-7w4br
Dec 28 04:35:30.714: INFO: Created: latency-svc-2549q
Dec 28 04:35:30.717: INFO: Created: latency-svc-6vpt9
Dec 28 04:35:30.719: INFO: Got endpoints: latency-svc-j97sg [142.760332ms]
Dec 28 04:35:30.722: INFO: Created: latency-svc-xlx7t
Dec 28 04:35:30.725: INFO: Created: latency-svc-44hfm
Dec 28 04:35:30.769: INFO: Got endpoints: latency-svc-snl2v [187.183736ms]
Dec 28 04:35:30.776: INFO: Created: latency-svc-tvg4z
Dec 28 04:35:30.820: INFO: Got endpoints: latency-svc-7qfqk [233.093663ms]
Dec 28 04:35:30.826: INFO: Created: latency-svc-tc6r6
Dec 28 04:35:30.868: INFO: Got endpoints: latency-svc-7r8sb [278.491829ms]
Dec 28 04:35:30.875: INFO: Created: latency-svc-g2df5
Dec 28 04:35:30.918: INFO: Got endpoints: latency-svc-rrskb [318.510388ms]
Dec 28 04:35:30.925: INFO: Created: latency-svc-f9nts
Dec 28 04:35:30.968: INFO: Got endpoints: latency-svc-mgzz2 [363.385807ms]
Dec 28 04:35:30.975: INFO: Created: latency-svc-6vmvs
Dec 28 04:35:31.018: INFO: Got endpoints: latency-svc-fpxgv [408.012275ms]
Dec 28 04:35:31.025: INFO: Created: latency-svc-r5mcp
Dec 28 04:35:31.069: INFO: Got endpoints: latency-svc-fpntw [451.049398ms]
Dec 28 04:35:31.075: INFO: Created: latency-svc-cntw9
Dec 28 04:35:31.118: INFO: Got endpoints: latency-svc-4csnh [497.609599ms]
Dec 28 04:35:31.127: INFO: Created: latency-svc-776hn
Dec 28 04:35:31.168: INFO: Got endpoints: latency-svc-nmrfx [542.924054ms]
Dec 28 04:35:31.182: INFO: Created: latency-svc-8s7dj
Dec 28 04:35:31.218: INFO: Got endpoints: latency-svc-87zrw [587.640986ms]
Dec 28 04:35:31.235: INFO: Created: latency-svc-27vcq
Dec 28 04:35:31.268: INFO: Got endpoints: latency-svc-7w4br [632.664368ms]
Dec 28 04:35:31.275: INFO: Created: latency-svc-w652g
Dec 28 04:35:31.318: INFO: Got endpoints: latency-svc-2549q [677.011326ms]
Dec 28 04:35:31.325: INFO: Created: latency-svc-bff58
Dec 28 04:35:31.368: INFO: Got endpoints: latency-svc-6vpt9 [723.790916ms]
Dec 28 04:35:31.375: INFO: Created: latency-svc-tdx9d
Dec 28 04:35:31.418: INFO: Got endpoints: latency-svc-xlx7t [749.149736ms]
Dec 28 04:35:31.425: INFO: Created: latency-svc-5bls4
Dec 28 04:35:31.468: INFO: Got endpoints: latency-svc-44hfm [748.915554ms]
Dec 28 04:35:31.475: INFO: Created: latency-svc-p6pcf
Dec 28 04:35:31.518: INFO: Got endpoints: latency-svc-tvg4z [749.278111ms]
Dec 28 04:35:31.525: INFO: Created: latency-svc-5nvnf
Dec 28 04:35:31.570: INFO: Got endpoints: latency-svc-tc6r6 [749.462861ms]
Dec 28 04:35:31.576: INFO: Created: latency-svc-z54hz
Dec 28 04:35:31.617: INFO: Got endpoints: latency-svc-g2df5 [749.174364ms]
Dec 28 04:35:31.624: INFO: Created: latency-svc-ntf57
Dec 28 04:35:31.668: INFO: Got endpoints: latency-svc-f9nts [750.25046ms]
Dec 28 04:35:31.676: INFO: Created: latency-svc-mr8l6
Dec 28 04:35:31.718: INFO: Got endpoints: latency-svc-6vmvs [750.047113ms]
Dec 28 04:35:31.724: INFO: Created: latency-svc-c8sxm
Dec 28 04:35:31.769: INFO: Got endpoints: latency-svc-r5mcp [750.545014ms]
Dec 28 04:35:31.775: INFO: Created: latency-svc-kxhf5
Dec 28 04:35:31.819: INFO: Got endpoints: latency-svc-cntw9 [750.375453ms]
Dec 28 04:35:31.825: INFO: Created: latency-svc-6vdbw
Dec 28 04:35:31.868: INFO: Got endpoints: latency-svc-776hn [750.283209ms]
Dec 28 04:35:31.878: INFO: Created: latency-svc-jhpcb
Dec 28 04:35:31.919: INFO: Got endpoints: latency-svc-8s7dj [750.721098ms]
Dec 28 04:35:31.926: INFO: Created: latency-svc-mrbn4
Dec 28 04:35:31.968: INFO: Got endpoints: latency-svc-27vcq [749.742467ms]
Dec 28 04:35:31.979: INFO: Created: latency-svc-6hlhg
Dec 28 04:35:32.018: INFO: Got endpoints: latency-svc-w652g [749.655822ms]
Dec 28 04:35:32.025: INFO: Created: latency-svc-nk7s9
Dec 28 04:35:32.068: INFO: Got endpoints: latency-svc-bff58 [749.89313ms]
Dec 28 04:35:32.074: INFO: Created: latency-svc-zbd4p
Dec 28 04:35:32.118: INFO: Got endpoints: latency-svc-tdx9d [749.968731ms]
Dec 28 04:35:32.125: INFO: Created: latency-svc-h4kl2
Dec 28 04:35:32.169: INFO: Got endpoints: latency-svc-5bls4 [751.184493ms]
Dec 28 04:35:32.175: INFO: Created: latency-svc-ccspj
Dec 28 04:35:32.218: INFO: Got endpoints: latency-svc-p6pcf [750.286017ms]
Dec 28 04:35:32.225: INFO: Created: latency-svc-mqfvm
Dec 28 04:35:32.269: INFO: Got endpoints: latency-svc-5nvnf [750.788213ms]
Dec 28 04:35:32.276: INFO: Created: latency-svc-r88dc
Dec 28 04:35:32.318: INFO: Got endpoints: latency-svc-z54hz [748.202926ms]
Dec 28 04:35:32.325: INFO: Created: latency-svc-kdcwh
Dec 28 04:35:32.368: INFO: Got endpoints: latency-svc-ntf57 [750.618635ms]
Dec 28 04:35:32.376: INFO: Created: latency-svc-629gv
Dec 28 04:35:32.419: INFO: Got endpoints: latency-svc-mr8l6 [750.7689ms]
Dec 28 04:35:32.427: INFO: Created: latency-svc-r6hkj
Dec 28 04:35:32.468: INFO: Got endpoints: latency-svc-c8sxm [749.944643ms]
Dec 28 04:35:32.475: INFO: Created: latency-svc-tngr7
Dec 28 04:35:32.518: INFO: Got endpoints: latency-svc-kxhf5 [749.674674ms]
Dec 28 04:35:32.525: INFO: Created: latency-svc-xzhpn
Dec 28 04:35:32.568: INFO: Got endpoints: latency-svc-6vdbw [749.048818ms]
Dec 28 04:35:32.576: INFO: Created: latency-svc-cdrlx
Dec 28 04:35:32.618: INFO: Got endpoints: latency-svc-jhpcb [749.614279ms]
Dec 28 04:35:32.625: INFO: Created: latency-svc-zgbn4
Dec 28 04:35:32.668: INFO: Got endpoints: latency-svc-mrbn4 [749.268247ms]
Dec 28 04:35:32.675: INFO: Created: latency-svc-m6j2w
Dec 28 04:35:32.719: INFO: Got endpoints: latency-svc-6hlhg [751.14125ms]
Dec 28 04:35:32.727: INFO: Created: latency-svc-pfmtz
Dec 28 04:35:32.768: INFO: Got endpoints: latency-svc-nk7s9 [750.14742ms]
Dec 28 04:35:32.775: INFO: Created: latency-svc-4xvcq
Dec 28 04:35:32.818: INFO: Got endpoints: latency-svc-zbd4p [750.411163ms]
Dec 28 04:35:32.826: INFO: Created: latency-svc-ml757
Dec 28 04:35:32.868: INFO: Got endpoints: latency-svc-h4kl2 [749.869653ms]
Dec 28 04:35:32.875: INFO: Created: latency-svc-frfpv
Dec 28 04:35:32.918: INFO: Got endpoints: latency-svc-ccspj [749.193035ms]
Dec 28 04:35:32.927: INFO: Created: latency-svc-q9jmt
Dec 28 04:35:32.968: INFO: Got endpoints: latency-svc-mqfvm [750.21107ms]
Dec 28 04:35:32.976: INFO: Created: latency-svc-csztv
Dec 28 04:35:33.018: INFO: Got endpoints: latency-svc-r88dc [749.301736ms]
Dec 28 04:35:33.026: INFO: Created: latency-svc-9pd6w
Dec 28 04:35:33.068: INFO: Got endpoints: latency-svc-kdcwh [750.383822ms]
Dec 28 04:35:33.080: INFO: Created: latency-svc-jrpfw
Dec 28 04:35:33.119: INFO: Got endpoints: latency-svc-629gv [750.756476ms]
Dec 28 04:35:33.126: INFO: Created: latency-svc-dn67t
Dec 28 04:35:33.168: INFO: Got endpoints: latency-svc-r6hkj [749.240463ms]
Dec 28 04:35:33.175: INFO: Created: latency-svc-4c2tl
Dec 28 04:35:33.220: INFO: Got endpoints: latency-svc-tngr7 [751.964127ms]
Dec 28 04:35:33.231: INFO: Created: latency-svc-5lbzh
Dec 28 04:35:33.269: INFO: Got endpoints: latency-svc-xzhpn [750.296474ms]
Dec 28 04:35:33.276: INFO: Created: latency-svc-xfkbm
Dec 28 04:35:33.318: INFO: Got endpoints: latency-svc-cdrlx [749.850771ms]
Dec 28 04:35:33.324: INFO: Created: latency-svc-4ngt5
Dec 28 04:35:33.368: INFO: Got endpoints: latency-svc-zgbn4 [750.398166ms]
Dec 28 04:35:33.375: INFO: Created: latency-svc-47c5c
Dec 28 04:35:33.418: INFO: Got endpoints: latency-svc-m6j2w [749.696732ms]
Dec 28 04:35:33.424: INFO: Created: latency-svc-hrgp7
Dec 28 04:35:33.468: INFO: Got endpoints: latency-svc-pfmtz [748.905621ms]
Dec 28 04:35:33.477: INFO: Created: latency-svc-r2rv5
Dec 28 04:35:33.518: INFO: Got endpoints: latency-svc-4xvcq [749.587229ms]
Dec 28 04:35:33.560: INFO: Created: latency-svc-fmjzq
Dec 28 04:35:33.570: INFO: Got endpoints: latency-svc-ml757 [751.984356ms]
Dec 28 04:35:33.606: INFO: Created: latency-svc-ckt84
Dec 28 04:35:33.618: INFO: Got endpoints: latency-svc-frfpv [750.114714ms]
Dec 28 04:35:33.626: INFO: Created: latency-svc-9lxs7
Dec 28 04:35:33.668: INFO: Got endpoints: latency-svc-q9jmt [749.481123ms]
Dec 28 04:35:33.676: INFO: Created: latency-svc-pkmpr
Dec 28 04:35:33.718: INFO: Got endpoints: latency-svc-csztv [749.59801ms]
Dec 28 04:35:33.725: INFO: Created: latency-svc-qc9x5
Dec 28 04:35:33.768: INFO: Got endpoints: latency-svc-9pd6w [749.887482ms]
Dec 28 04:35:33.775: INFO: Created: latency-svc-nn6nl
Dec 28 04:35:33.818: INFO: Got endpoints: latency-svc-jrpfw [749.545381ms]
Dec 28 04:35:33.823: INFO: Created: latency-svc-x5l9c
Dec 28 04:35:33.870: INFO: Got endpoints: latency-svc-dn67t [750.873391ms]
Dec 28 04:35:33.876: INFO: Created: latency-svc-w46r8
Dec 28 04:35:33.919: INFO: Got endpoints: latency-svc-4c2tl [751.409921ms]
Dec 28 04:35:33.925: INFO: Created: latency-svc-gbw4d
Dec 28 04:35:33.968: INFO: Got endpoints: latency-svc-5lbzh [748.061965ms]
Dec 28 04:35:33.974: INFO: Created: latency-svc-j75g2
Dec 28 04:35:34.018: INFO: Got endpoints: latency-svc-xfkbm [749.33549ms]
Dec 28 04:35:34.027: INFO: Created: latency-svc-lwb7h
Dec 28 04:35:34.069: INFO: Got endpoints: latency-svc-4ngt5 [750.958013ms]
Dec 28 04:35:34.075: INFO: Created: latency-svc-59lq5
Dec 28 04:35:34.118: INFO: Got endpoints: latency-svc-47c5c [749.052667ms]
Dec 28 04:35:34.131: INFO: Created: latency-svc-mnr2w
Dec 28 04:35:34.169: INFO: Got endpoints: latency-svc-hrgp7 [750.75928ms]
Dec 28 04:35:34.175: INFO: Created: latency-svc-z82gt
Dec 28 04:35:34.218: INFO: Got endpoints: latency-svc-r2rv5 [750.234028ms]
Dec 28 04:35:34.228: INFO: Created: latency-svc-9rr5q
Dec 28 04:35:34.269: INFO: Got endpoints: latency-svc-fmjzq [750.820581ms]
Dec 28 04:35:34.278: INFO: Created: latency-svc-c252s
Dec 28 04:35:34.318: INFO: Got endpoints: latency-svc-ckt84 [747.464465ms]
Dec 28 04:35:34.324: INFO: Created: latency-svc-rzzqh
Dec 28 04:35:34.368: INFO: Got endpoints: latency-svc-9lxs7 [749.51739ms]
Dec 28 04:35:34.374: INFO: Created: latency-svc-knftq
Dec 28 04:35:34.419: INFO: Got endpoints: latency-svc-pkmpr [750.522362ms]
Dec 28 04:35:34.426: INFO: Created: latency-svc-vr4hp
Dec 28 04:35:34.468: INFO: Got endpoints: latency-svc-qc9x5 [750.374403ms]
Dec 28 04:35:34.475: INFO: Created: latency-svc-f2827
Dec 28 04:35:34.519: INFO: Got endpoints: latency-svc-nn6nl [750.784542ms]
Dec 28 04:35:34.526: INFO: Created: latency-svc-hkf2v
Dec 28 04:35:34.568: INFO: Got endpoints: latency-svc-x5l9c [750.269727ms]
Dec 28 04:35:34.574: INFO: Created: latency-svc-9bmwf
Dec 28 04:35:34.624: INFO: Got endpoints: latency-svc-w46r8 [754.262148ms]
Dec 28 04:35:34.630: INFO: Created: latency-svc-jv9nf
Dec 28 04:35:34.668: INFO: Got endpoints: latency-svc-gbw4d [748.529112ms]
Dec 28 04:35:34.674: INFO: Created: latency-svc-wqq2c
Dec 28 04:35:34.718: INFO: Got endpoints: latency-svc-j75g2 [750.010257ms]
Dec 28 04:35:34.724: INFO: Created: latency-svc-st2wq
Dec 28 04:35:34.768: INFO: Got endpoints: latency-svc-lwb7h [750.121704ms]
Dec 28 04:35:34.775: INFO: Created: latency-svc-gsqtb
Dec 28 04:35:34.818: INFO: Got endpoints: latency-svc-59lq5 [749.24903ms]
Dec 28 04:35:34.825: INFO: Created: latency-svc-v7cp9
Dec 28 04:35:34.872: INFO: Got endpoints: latency-svc-mnr2w [754.007938ms]
Dec 28 04:35:34.880: INFO: Created: latency-svc-pcfj2
Dec 28 04:35:34.918: INFO: Got endpoints: latency-svc-z82gt [749.770888ms]
Dec 28 04:35:34.926: INFO: Created: latency-svc-zsddr
Dec 28 04:35:34.968: INFO: Got endpoints: latency-svc-9rr5q [749.42338ms]
Dec 28 04:35:34.975: INFO: Created: latency-svc-8lj5q
Dec 28 04:35:35.018: INFO: Got endpoints: latency-svc-c252s [749.347341ms]
Dec 28 04:35:35.025: INFO: Created: latency-svc-89dwj
Dec 28 04:35:35.069: INFO: Got endpoints: latency-svc-rzzqh [751.309928ms]
Dec 28 04:35:35.076: INFO: Created: latency-svc-7c9qt
Dec 28 04:35:35.118: INFO: Got endpoints: latency-svc-knftq [749.757931ms]
Dec 28 04:35:35.125: INFO: Created: latency-svc-jzprz
Dec 28 04:35:35.168: INFO: Got endpoints: latency-svc-vr4hp [749.585504ms]
Dec 28 04:35:35.174: INFO: Created: latency-svc-vdc56
Dec 28 04:35:35.218: INFO: Got endpoints: latency-svc-f2827 [749.825058ms]
Dec 28 04:35:35.232: INFO: Created: latency-svc-9qjdv
Dec 28 04:35:35.269: INFO: Got endpoints: latency-svc-hkf2v [750.016816ms]
Dec 28 04:35:35.275: INFO: Created: latency-svc-kt27p
Dec 28 04:35:35.318: INFO: Got endpoints: latency-svc-9bmwf [750.2853ms]
Dec 28 04:35:35.324: INFO: Created: latency-svc-jrvq2
Dec 28 04:35:35.368: INFO: Got endpoints: latency-svc-jv9nf [744.043794ms]
Dec 28 04:35:35.375: INFO: Created: latency-svc-cgfnr
Dec 28 04:35:35.418: INFO: Got endpoints: latency-svc-wqq2c [750.04705ms]
Dec 28 04:35:35.425: INFO: Created: latency-svc-7pxkf
Dec 28 04:35:35.470: INFO: Got endpoints: latency-svc-st2wq [751.326013ms]
Dec 28 04:35:35.476: INFO: Created: latency-svc-ljw6l
Dec 28 04:35:35.519: INFO: Got endpoints: latency-svc-gsqtb [750.388444ms]
Dec 28 04:35:35.525: INFO: Created: latency-svc-q9fst
Dec 28 04:35:35.569: INFO: Got endpoints: latency-svc-v7cp9 [750.486162ms]
Dec 28 04:35:35.576: INFO: Created: latency-svc-rs7kj
Dec 28 04:35:35.619: INFO: Got endpoints: latency-svc-pcfj2 [746.92231ms]
Dec 28 04:35:35.627: INFO: Created: latency-svc-h792s
Dec 28 04:35:35.668: INFO: Got endpoints: latency-svc-zsddr [749.285213ms]
Dec 28 04:35:35.675: INFO: Created: latency-svc-4w758
Dec 28 04:35:35.718: INFO: Got endpoints: latency-svc-8lj5q [750.664451ms]
Dec 28 04:35:35.727: INFO: Created: latency-svc-vldmq
Dec 28 04:35:35.769: INFO: Got endpoints: latency-svc-89dwj [750.452224ms]
Dec 28 04:35:35.775: INFO: Created: latency-svc-hntpf
Dec 28 04:35:35.818: INFO: Got endpoints: latency-svc-7c9qt [748.43179ms]
Dec 28 04:35:35.829: INFO: Created: latency-svc-k242g
Dec 28 04:35:35.868: INFO: Got endpoints: latency-svc-jzprz [750.362026ms]
Dec 28 04:35:35.874: INFO: Created: latency-svc-pvdl4
Dec 28 04:35:35.919: INFO: Got endpoints: latency-svc-vdc56 [750.944393ms]
Dec 28 04:35:35.925: INFO: Created: latency-svc-ls5t5
Dec 28 04:35:35.968: INFO: Got endpoints: latency-svc-9qjdv [749.604175ms]
Dec 28 04:35:35.974: INFO: Created: latency-svc-tz97h
Dec 28 04:35:36.018: INFO: Got endpoints: latency-svc-kt27p [749.064765ms]
Dec 28 04:35:36.024: INFO: Created: latency-svc-bhw7d
Dec 28 04:35:36.068: INFO: Got endpoints: latency-svc-jrvq2 [749.641604ms]
Dec 28 04:35:36.075: INFO: Created: latency-svc-zxhhb
Dec 28 04:35:36.119: INFO: Got endpoints: latency-svc-cgfnr [751.133578ms]
Dec 28 04:35:36.125: INFO: Created: latency-svc-4j4pg
Dec 28 04:35:36.169: INFO: Got endpoints: latency-svc-7pxkf [750.630647ms]
Dec 28 04:35:36.175: INFO: Created: latency-svc-p4wbt
Dec 28 04:35:36.219: INFO: Got endpoints: latency-svc-ljw6l [749.331812ms]
Dec 28 04:35:36.228: INFO: Created: latency-svc-pgzhf
Dec 28 04:35:36.268: INFO: Got endpoints: latency-svc-q9fst [749.53357ms]
Dec 28 04:35:36.276: INFO: Created: latency-svc-l2vsf
Dec 28 04:35:36.318: INFO: Got endpoints: latency-svc-rs7kj [749.371123ms]
Dec 28 04:35:36.324: INFO: Created: latency-svc-wtblr
Dec 28 04:35:36.368: INFO: Got endpoints: latency-svc-h792s [749.380087ms]
Dec 28 04:35:36.375: INFO: Created: latency-svc-nm8fq
Dec 28 04:35:36.418: INFO: Got endpoints: latency-svc-4w758 [750.074987ms]
Dec 28 04:35:36.425: INFO: Created: latency-svc-4g2cg
Dec 28 04:35:36.468: INFO: Got endpoints: latency-svc-vldmq [750.037794ms]
Dec 28 04:35:36.479: INFO: Created: latency-svc-zj4jf
Dec 28 04:35:36.518: INFO: Got endpoints: latency-svc-hntpf [749.411039ms]
Dec 28 04:35:36.526: INFO: Created: latency-svc-586xx
Dec 28 04:35:36.569: INFO: Got endpoints: latency-svc-k242g [751.598235ms]
Dec 28 04:35:36.576: INFO: Created: latency-svc-gzl4l
Dec 28 04:35:36.618: INFO: Got endpoints: latency-svc-pvdl4 [749.646298ms]
Dec 28 04:35:36.624: INFO: Created: latency-svc-4njtm
Dec 28 04:35:36.668: INFO: Got endpoints: latency-svc-ls5t5 [749.096888ms]
Dec 28 04:35:36.676: INFO: Created: latency-svc-tktc4
Dec 28 04:35:36.718: INFO: Got endpoints: latency-svc-tz97h [749.908104ms]
Dec 28 04:35:36.724: INFO: Created: latency-svc-wkdck
Dec 28 04:35:36.769: INFO: Got endpoints: latency-svc-bhw7d [750.872031ms]
Dec 28 04:35:36.777: INFO: Created: latency-svc-ngzvm
Dec 28 04:35:36.819: INFO: Got endpoints: latency-svc-zxhhb [750.538618ms]
Dec 28 04:35:36.825: INFO: Created: latency-svc-fv2d9
Dec 28 04:35:36.868: INFO: Got endpoints: latency-svc-4j4pg [748.707795ms]
Dec 28 04:35:36.874: INFO: Created: latency-svc-9frvm
Dec 28 04:35:36.919: INFO: Got endpoints: latency-svc-p4wbt [750.010346ms]
Dec 28 04:35:36.927: INFO: Created: latency-svc-lxdns
Dec 28 04:35:36.968: INFO: Got endpoints: latency-svc-pgzhf [748.817168ms]
Dec 28 04:35:36.973: INFO: Created: latency-svc-ll2nw
Dec 28 04:35:37.018: INFO: Got endpoints: latency-svc-l2vsf [749.667504ms]
Dec 28 04:35:37.024: INFO: Created: latency-svc-vngrl
Dec 28 04:35:37.068: INFO: Got endpoints: latency-svc-wtblr [749.518872ms]
Dec 28 04:35:37.075: INFO: Created: latency-svc-hrwgt
Dec 28 04:35:37.118: INFO: Got endpoints: latency-svc-nm8fq [749.619349ms]
Dec 28 04:35:37.128: INFO: Created: latency-svc-sc4lm
Dec 28 04:35:37.168: INFO: Got endpoints: latency-svc-4g2cg [750.075149ms]
Dec 28 04:35:37.174: INFO: Created: latency-svc-68lxs
Dec 28 04:35:37.218: INFO: Got endpoints: latency-svc-zj4jf [749.23995ms]
Dec 28 04:35:37.224: INFO: Created: latency-svc-4s2s6
Dec 28 04:35:37.268: INFO: Got endpoints: latency-svc-586xx [749.62144ms]
Dec 28 04:35:37.276: INFO: Created: latency-svc-6dqlv
Dec 28 04:35:37.319: INFO: Got endpoints: latency-svc-gzl4l [749.758761ms]
Dec 28 04:35:37.326: INFO: Created: latency-svc-xzrdd
Dec 28 04:35:37.369: INFO: Got endpoints: latency-svc-4njtm [751.085572ms]
Dec 28 04:35:37.375: INFO: Created: latency-svc-kjswd
Dec 28 04:35:37.418: INFO: Got endpoints: latency-svc-tktc4 [749.753683ms]
Dec 28 04:35:37.426: INFO: Created: latency-svc-p2756
Dec 28 04:35:37.469: INFO: Got endpoints: latency-svc-wkdck [751.425258ms]
Dec 28 04:35:37.476: INFO: Created: latency-svc-nmr8h
Dec 28 04:35:37.518: INFO: Got endpoints: latency-svc-ngzvm [748.808486ms]
Dec 28 04:35:37.526: INFO: Created: latency-svc-zmxrb
Dec 28 04:35:37.568: INFO: Got endpoints: latency-svc-fv2d9 [749.208419ms]
Dec 28 04:35:37.573: INFO: Created: latency-svc-4plqf
Dec 28 04:35:37.618: INFO: Got endpoints: latency-svc-9frvm [750.423207ms]
Dec 28 04:35:37.625: INFO: Created: latency-svc-txvv8
Dec 28 04:35:37.668: INFO: Got endpoints: latency-svc-lxdns [748.684161ms]
Dec 28 04:35:37.674: INFO: Created: latency-svc-nptpz
Dec 28 04:35:37.718: INFO: Got endpoints: latency-svc-ll2nw [750.197272ms]
Dec 28 04:35:37.725: INFO: Created: latency-svc-bsn7p
Dec 28 04:35:37.768: INFO: Got endpoints: latency-svc-vngrl [750.485534ms]
Dec 28 04:35:37.775: INFO: Created: latency-svc-nkdr9
Dec 28 04:35:37.818: INFO: Got endpoints: latency-svc-hrwgt [750.419948ms]
Dec 28 04:35:37.831: INFO: Created: latency-svc-99w64
Dec 28 04:35:37.868: INFO: Got endpoints: latency-svc-sc4lm [750.612192ms]
Dec 28 04:35:37.874: INFO: Created: latency-svc-lkk78
Dec 28 04:35:37.918: INFO: Got endpoints: latency-svc-68lxs [750.275249ms]
Dec 28 04:35:37.927: INFO: Created: latency-svc-pz65d
Dec 28 04:35:37.968: INFO: Got endpoints: latency-svc-4s2s6 [750.268476ms]
Dec 28 04:35:37.974: INFO: Created: latency-svc-d4pbl
Dec 28 04:35:38.018: INFO: Got endpoints: latency-svc-6dqlv [749.766242ms]
Dec 28 04:35:38.024: INFO: Created: latency-svc-7k7rj
Dec 28 04:35:38.068: INFO: Got endpoints: latency-svc-xzrdd [748.695907ms]
Dec 28 04:35:38.074: INFO: Created: latency-svc-xgbvd
Dec 28 04:35:38.118: INFO: Got endpoints: latency-svc-kjswd [749.06773ms]
Dec 28 04:35:38.125: INFO: Created: latency-svc-l4nlv
Dec 28 04:35:38.168: INFO: Got endpoints: latency-svc-p2756 [749.975335ms]
Dec 28 04:35:38.174: INFO: Created: latency-svc-vpmnh
Dec 28 04:35:38.218: INFO: Got endpoints: latency-svc-nmr8h [748.674847ms]
Dec 28 04:35:38.227: INFO: Created: latency-svc-4dcjj
Dec 28 04:35:38.268: INFO: Got endpoints: latency-svc-zmxrb [750.461339ms]
Dec 28 04:35:38.275: INFO: Created: latency-svc-kn57d
Dec 28 04:35:38.318: INFO: Got endpoints: latency-svc-4plqf [750.129385ms]
Dec 28 04:35:38.368: INFO: Got endpoints: latency-svc-txvv8 [749.494481ms]
Dec 28 04:35:38.418: INFO: Got endpoints: latency-svc-nptpz [750.657562ms]
Dec 28 04:35:38.469: INFO: Got endpoints: latency-svc-bsn7p [751.414003ms]
Dec 28 04:35:38.518: INFO: Got endpoints: latency-svc-nkdr9 [749.325597ms]
Dec 28 04:35:38.568: INFO: Got endpoints: latency-svc-99w64 [749.942461ms]
Dec 28 04:35:38.618: INFO: Got endpoints: latency-svc-lkk78 [749.665325ms]
Dec 28 04:35:38.668: INFO: Got endpoints: latency-svc-pz65d [749.706401ms]
Dec 28 04:35:38.718: INFO: Got endpoints: latency-svc-d4pbl [750.06531ms]
Dec 28 04:35:38.768: INFO: Got endpoints: latency-svc-7k7rj [750.505201ms]
Dec 28 04:35:38.819: INFO: Got endpoints: latency-svc-xgbvd [751.001969ms]
Dec 28 04:35:38.868: INFO: Got endpoints: latency-svc-l4nlv [750.043764ms]
Dec 28 04:35:38.918: INFO: Got endpoints: latency-svc-vpmnh [749.703225ms]
Dec 28 04:35:38.968: INFO: Got endpoints: latency-svc-4dcjj [750.313764ms]
Dec 28 04:35:39.018: INFO: Got endpoints: latency-svc-kn57d [749.748448ms]
Dec 28 04:35:39.018: INFO: Latencies: [7.889771ms 12.594005ms 12.702428ms 18.512619ms 24.514675ms 30.448246ms 36.310926ms 39.838758ms 51.953417ms 56.889083ms 59.764198ms 63.458498ms 70.152568ms 75.986243ms 79.610586ms 80.428907ms 82.891674ms 82.958243ms 83.726782ms 84.31754ms 84.642436ms 85.206654ms 85.553195ms 86.210751ms 86.950132ms 87.440452ms 87.939548ms 88.245362ms 88.477095ms 89.099664ms 89.169385ms 90.641162ms 96.909991ms 142.760332ms 187.183736ms 233.093663ms 278.491829ms 318.510388ms 363.385807ms 408.012275ms 451.049398ms 497.609599ms 542.924054ms 587.640986ms 632.664368ms 677.011326ms 723.790916ms 744.043794ms 746.92231ms 747.464465ms 748.061965ms 748.202926ms 748.43179ms 748.529112ms 748.674847ms 748.684161ms 748.695907ms 748.707795ms 748.808486ms 748.817168ms 748.905621ms 748.915554ms 749.048818ms 749.052667ms 749.064765ms 749.06773ms 749.096888ms 749.149736ms 749.174364ms 749.193035ms 749.208419ms 749.23995ms 749.240463ms 749.24903ms 749.268247ms 749.278111ms 749.285213ms 749.301736ms 749.325597ms 749.331812ms 749.33549ms 749.347341ms 749.371123ms 749.380087ms 749.411039ms 749.42338ms 749.462861ms 749.481123ms 749.494481ms 749.51739ms 749.518872ms 749.53357ms 749.545381ms 749.585504ms 749.587229ms 749.59801ms 749.604175ms 749.614279ms 749.619349ms 749.62144ms 749.641604ms 749.646298ms 749.655822ms 749.665325ms 749.667504ms 749.674674ms 749.696732ms 749.703225ms 749.706401ms 749.742467ms 749.748448ms 749.753683ms 749.757931ms 749.758761ms 749.766242ms 749.770888ms 749.825058ms 749.850771ms 749.869653ms 749.887482ms 749.89313ms 749.908104ms 749.942461ms 749.944643ms 749.968731ms 749.975335ms 750.010257ms 750.010346ms 750.016816ms 750.037794ms 750.043764ms 750.04705ms 750.047113ms 750.06531ms 750.074987ms 750.075149ms 750.114714ms 750.121704ms 750.129385ms 750.14742ms 750.197272ms 750.21107ms 750.234028ms 750.25046ms 750.268476ms 750.269727ms 750.275249ms 750.283209ms 750.2853ms 750.286017ms 750.296474ms 750.313764ms 750.362026ms 750.374403ms 750.375453ms 750.383822ms 750.388444ms 750.398166ms 750.411163ms 750.419948ms 750.423207ms 750.452224ms 750.461339ms 750.485534ms 750.486162ms 750.505201ms 750.522362ms 750.538618ms 750.545014ms 750.612192ms 750.618635ms 750.630647ms 750.657562ms 750.664451ms 750.721098ms 750.756476ms 750.75928ms 750.7689ms 750.784542ms 750.788213ms 750.820581ms 750.872031ms 750.873391ms 750.944393ms 750.958013ms 751.001969ms 751.085572ms 751.133578ms 751.14125ms 751.184493ms 751.309928ms 751.326013ms 751.409921ms 751.414003ms 751.425258ms 751.598235ms 751.964127ms 751.984356ms 754.007938ms 754.262148ms]
Dec 28 04:35:39.018: INFO: 50 %ile: 749.641604ms
Dec 28 04:35:39.018: INFO: 90 %ile: 750.820581ms
Dec 28 04:35:39.018: INFO: 99 %ile: 754.007938ms
Dec 28 04:35:39.018: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:35:39.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5995" for this suite.
Dec 28 04:35:53.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:35:53.089: INFO: namespace svc-latency-5995 deletion completed in 14.068156108s

• [SLOW TEST:23.799 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:35:53.089: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec 28 04:35:55.617: INFO: Successfully updated pod "adopt-release-nmz67"
STEP: Checking that the Job readopts the Pod
Dec 28 04:35:55.617: INFO: Waiting up to 15m0s for pod "adopt-release-nmz67" in namespace "job-7275" to be "adopted"
Dec 28 04:35:55.618: INFO: Pod "adopt-release-nmz67": Phase="Running", Reason="", readiness=true. Elapsed: 1.381742ms
Dec 28 04:35:57.620: INFO: Pod "adopt-release-nmz67": Phase="Running", Reason="", readiness=true. Elapsed: 2.003296091s
Dec 28 04:35:57.620: INFO: Pod "adopt-release-nmz67" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec 28 04:35:58.126: INFO: Successfully updated pod "adopt-release-nmz67"
STEP: Checking that the Job releases the Pod
Dec 28 04:35:58.126: INFO: Waiting up to 15m0s for pod "adopt-release-nmz67" in namespace "job-7275" to be "released"
Dec 28 04:35:58.127: INFO: Pod "adopt-release-nmz67": Phase="Running", Reason="", readiness=true. Elapsed: 1.441178ms
Dec 28 04:36:00.129: INFO: Pod "adopt-release-nmz67": Phase="Running", Reason="", readiness=true. Elapsed: 2.003642554s
Dec 28 04:36:00.129: INFO: Pod "adopt-release-nmz67" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:36:00.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7275" for this suite.
Dec 28 04:36:44.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:36:44.264: INFO: namespace job-7275 deletion completed in 44.131893173s

• [SLOW TEST:51.174 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:36:44.264: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Dec 28 04:36:44.793: INFO: created pod pod-service-account-defaultsa
Dec 28 04:36:44.793: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 28 04:36:44.796: INFO: created pod pod-service-account-mountsa
Dec 28 04:36:44.796: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 28 04:36:44.799: INFO: created pod pod-service-account-nomountsa
Dec 28 04:36:44.799: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 28 04:36:44.802: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 28 04:36:44.802: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 28 04:36:44.804: INFO: created pod pod-service-account-mountsa-mountspec
Dec 28 04:36:44.804: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 28 04:36:44.807: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 28 04:36:44.807: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 28 04:36:44.809: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 28 04:36:44.809: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 28 04:36:44.813: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 28 04:36:44.813: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 28 04:36:44.815: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 28 04:36:44.815: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:36:44.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2966" for this suite.
Dec 28 04:36:56.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:36:56.897: INFO: namespace svcaccounts-2966 deletion completed in 12.073635876s

• [SLOW TEST:12.633 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:36:56.897: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Dec 28 04:36:56.917: INFO: Waiting up to 5m0s for pod "var-expansion-5d413e00-cd8f-4ed2-842b-6257227344a2" in namespace "var-expansion-4414" to be "success or failure"
Dec 28 04:36:56.919: INFO: Pod "var-expansion-5d413e00-cd8f-4ed2-842b-6257227344a2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.989055ms
Dec 28 04:36:58.921: INFO: Pod "var-expansion-5d413e00-cd8f-4ed2-842b-6257227344a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003733737s
STEP: Saw pod success
Dec 28 04:36:58.921: INFO: Pod "var-expansion-5d413e00-cd8f-4ed2-842b-6257227344a2" satisfied condition "success or failure"
Dec 28 04:36:58.922: INFO: Trying to get logs from node hxx-m-2 pod var-expansion-5d413e00-cd8f-4ed2-842b-6257227344a2 container dapi-container: <nil>
STEP: delete the pod
Dec 28 04:36:58.938: INFO: Waiting for pod var-expansion-5d413e00-cd8f-4ed2-842b-6257227344a2 to disappear
Dec 28 04:36:58.939: INFO: Pod var-expansion-5d413e00-cd8f-4ed2-842b-6257227344a2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:36:58.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4414" for this suite.
Dec 28 04:37:04.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:37:05.016: INFO: namespace var-expansion-4414 deletion completed in 6.074014125s

• [SLOW TEST:8.119 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:37:05.017: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:37:05.036: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-7289e2c4-e2f6-42f3-8380-65bbc4f6bb88" in namespace "security-context-test-5680" to be "success or failure"
Dec 28 04:37:05.038: INFO: Pod "alpine-nnp-false-7289e2c4-e2f6-42f3-8380-65bbc4f6bb88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083237ms
Dec 28 04:37:07.040: INFO: Pod "alpine-nnp-false-7289e2c4-e2f6-42f3-8380-65bbc4f6bb88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004606894s
Dec 28 04:37:07.040: INFO: Pod "alpine-nnp-false-7289e2c4-e2f6-42f3-8380-65bbc4f6bb88" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:37:07.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5680" for this suite.
Dec 28 04:37:13.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:37:13.120: INFO: namespace security-context-test-5680 deletion completed in 6.07259901s

• [SLOW TEST:8.104 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:37:13.121: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:37:13.140: INFO: Creating ReplicaSet my-hostname-basic-7a123765-3375-49b6-86d8-509b5427a6cf
Dec 28 04:37:13.145: INFO: Pod name my-hostname-basic-7a123765-3375-49b6-86d8-509b5427a6cf: Found 0 pods out of 1
Dec 28 04:37:18.147: INFO: Pod name my-hostname-basic-7a123765-3375-49b6-86d8-509b5427a6cf: Found 1 pods out of 1
Dec 28 04:37:18.147: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-7a123765-3375-49b6-86d8-509b5427a6cf" is running
Dec 28 04:37:18.149: INFO: Pod "my-hostname-basic-7a123765-3375-49b6-86d8-509b5427a6cf-c5qqk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-28 04:37:13 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-28 04:37:14 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-28 04:37:14 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-28 04:37:13 +0000 UTC Reason: Message:}])
Dec 28 04:37:18.149: INFO: Trying to dial the pod
Dec 28 04:37:23.155: INFO: Controller my-hostname-basic-7a123765-3375-49b6-86d8-509b5427a6cf: Got expected result from replica 1 [my-hostname-basic-7a123765-3375-49b6-86d8-509b5427a6cf-c5qqk]: "my-hostname-basic-7a123765-3375-49b6-86d8-509b5427a6cf-c5qqk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:37:23.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1713" for this suite.
Dec 28 04:37:29.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:37:29.232: INFO: namespace replicaset-1713 deletion completed in 6.074046871s

• [SLOW TEST:16.111 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:37:29.232: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 28 04:37:31.768: INFO: Successfully updated pod "annotationupdatef41d1669-7f36-465d-9fa8-9bc7bf2f49d2"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:37:33.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4035" for this suite.
Dec 28 04:37:55.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:37:55.853: INFO: namespace projected-4035 deletion completed in 22.071494202s

• [SLOW TEST:26.621 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:37:55.853: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:37:55.874: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94cba478-cdc5-4f9a-9374-ef2cc4461328" in namespace "projected-1251" to be "success or failure"
Dec 28 04:37:55.876: INFO: Pod "downwardapi-volume-94cba478-cdc5-4f9a-9374-ef2cc4461328": Phase="Pending", Reason="", readiness=false. Elapsed: 1.532243ms
Dec 28 04:37:57.878: INFO: Pod "downwardapi-volume-94cba478-cdc5-4f9a-9374-ef2cc4461328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003876791s
STEP: Saw pod success
Dec 28 04:37:57.878: INFO: Pod "downwardapi-volume-94cba478-cdc5-4f9a-9374-ef2cc4461328" satisfied condition "success or failure"
Dec 28 04:37:57.880: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-94cba478-cdc5-4f9a-9374-ef2cc4461328 container client-container: <nil>
STEP: delete the pod
Dec 28 04:37:57.889: INFO: Waiting for pod downwardapi-volume-94cba478-cdc5-4f9a-9374-ef2cc4461328 to disappear
Dec 28 04:37:57.890: INFO: Pod downwardapi-volume-94cba478-cdc5-4f9a-9374-ef2cc4461328 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:37:57.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1251" for this suite.
Dec 28 04:38:03.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:38:03.967: INFO: namespace projected-1251 deletion completed in 6.074701736s

• [SLOW TEST:8.114 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:38:03.967: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:38:03.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4909" for this suite.
Dec 28 04:38:09.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:38:10.053: INFO: namespace tables-4909 deletion completed in 6.066526292s

• [SLOW TEST:6.086 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:38:10.053: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4775
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4775
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4775
Dec 28 04:38:10.079: INFO: Found 0 stateful pods, waiting for 1
Dec 28 04:38:20.081: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 28 04:38:20.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-4775 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 28 04:38:20.390: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 28 04:38:20.390: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 28 04:38:20.390: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 28 04:38:20.392: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 28 04:38:30.395: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 04:38:30.395: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 04:38:30.402: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998887s
Dec 28 04:38:31.404: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.998230039s
Dec 28 04:38:32.407: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.995697714s
Dec 28 04:38:33.409: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.993133092s
Dec 28 04:38:34.412: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.990996406s
Dec 28 04:38:35.414: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.988384862s
Dec 28 04:38:36.417: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.986162278s
Dec 28 04:38:37.419: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.983478327s
Dec 28 04:38:38.421: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.981353102s
Dec 28 04:38:39.423: INFO: Verifying statefulset ss doesn't scale past 1 for another 978.812441ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4775
Dec 28 04:38:40.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-4775 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 28 04:38:40.637: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 28 04:38:40.637: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 28 04:38:40.637: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 28 04:38:40.639: INFO: Found 1 stateful pods, waiting for 3
Dec 28 04:38:50.642: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 04:38:50.642: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 04:38:50.642: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 28 04:38:50.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-4775 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 28 04:38:50.874: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 28 04:38:50.874: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 28 04:38:50.874: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 28 04:38:50.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-4775 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 28 04:38:51.106: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 28 04:38:51.106: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 28 04:38:51.106: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 28 04:38:51.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-4775 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 28 04:38:51.327: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 28 04:38:51.327: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 28 04:38:51.327: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 28 04:38:51.327: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 04:38:51.329: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 28 04:39:01.333: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 04:39:01.333: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 04:39:01.333: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 04:39:01.339: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998792s
Dec 28 04:39:02.342: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997601302s
Dec 28 04:39:03.344: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.995023279s
Dec 28 04:39:04.347: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992459066s
Dec 28 04:39:05.350: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.989728896s
Dec 28 04:39:06.353: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.987048639s
Dec 28 04:39:07.355: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.984369799s
Dec 28 04:39:08.358: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.981598446s
Dec 28 04:39:09.361: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.97883285s
Dec 28 04:39:10.364: INFO: Verifying statefulset ss doesn't scale past 3 for another 976.242025ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4775
Dec 28 04:39:11.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-4775 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 28 04:39:11.582: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 28 04:39:11.582: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 28 04:39:11.582: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 28 04:39:11.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-4775 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 28 04:39:11.809: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 28 04:39:11.809: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 28 04:39:11.809: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 28 04:39:11.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-4775 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 28 04:39:12.027: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 28 04:39:12.027: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 28 04:39:12.027: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 28 04:39:12.027: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 28 04:39:32.036: INFO: Deleting all statefulset in ns statefulset-4775
Dec 28 04:39:32.038: INFO: Scaling statefulset ss to 0
Dec 28 04:39:32.043: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 04:39:32.044: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:39:32.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4775" for this suite.
Dec 28 04:39:38.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:39:38.122: INFO: namespace statefulset-4775 deletion completed in 6.068188557s

• [SLOW TEST:88.068 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:39:38.122: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7432
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-7432
Dec 28 04:39:38.146: INFO: Found 0 stateful pods, waiting for 1
Dec 28 04:39:48.149: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 28 04:39:48.159: INFO: Deleting all statefulset in ns statefulset-7432
Dec 28 04:39:48.161: INFO: Scaling statefulset ss to 0
Dec 28 04:40:08.171: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 04:40:08.173: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:40:08.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7432" for this suite.
Dec 28 04:40:14.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:40:14.254: INFO: namespace statefulset-7432 deletion completed in 6.072102254s

• [SLOW TEST:36.132 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:40:14.254: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:40:14.283: INFO: Create a RollingUpdate DaemonSet
Dec 28 04:40:14.285: INFO: Check that daemon pods launch on every node of the cluster
Dec 28 04:40:14.289: INFO: Number of nodes with available pods: 0
Dec 28 04:40:14.289: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:40:15.294: INFO: Number of nodes with available pods: 0
Dec 28 04:40:15.294: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:40:16.293: INFO: Number of nodes with available pods: 3
Dec 28 04:40:16.293: INFO: Number of running nodes: 3, number of available pods: 3
Dec 28 04:40:16.293: INFO: Update the DaemonSet to trigger a rollout
Dec 28 04:40:16.297: INFO: Updating DaemonSet daemon-set
Dec 28 04:40:20.305: INFO: Roll back the DaemonSet before rollout is complete
Dec 28 04:40:20.309: INFO: Updating DaemonSet daemon-set
Dec 28 04:40:20.309: INFO: Make sure DaemonSet rollback is complete
Dec 28 04:40:20.311: INFO: Wrong image for pod: daemon-set-qrqxw. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 28 04:40:20.311: INFO: Pod daemon-set-qrqxw is not available
Dec 28 04:40:21.316: INFO: Wrong image for pod: daemon-set-qrqxw. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 28 04:40:21.316: INFO: Pod daemon-set-qrqxw is not available
Dec 28 04:40:22.316: INFO: Pod daemon-set-vhnvt is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1571, will wait for the garbage collector to delete the pods
Dec 28 04:40:22.377: INFO: Deleting DaemonSet.extensions daemon-set took: 3.204468ms
Dec 28 04:40:23.177: INFO: Terminating DaemonSet.extensions daemon-set pods took: 800.189763ms
Dec 28 04:40:31.279: INFO: Number of nodes with available pods: 0
Dec 28 04:40:31.279: INFO: Number of running nodes: 0, number of available pods: 0
Dec 28 04:40:31.280: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1571/daemonsets","resourceVersion":"217857"},"items":null}

Dec 28 04:40:31.282: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1571/pods","resourceVersion":"217857"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:40:31.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1571" for this suite.
Dec 28 04:40:37.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:40:37.359: INFO: namespace daemonsets-1571 deletion completed in 6.067934969s

• [SLOW TEST:23.105 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:40:37.359: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 28 04:40:37.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-6602'
Dec 28 04:40:37.450: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 28 04:40:37.450: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Dec 28 04:40:37.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete deployment e2e-test-httpd-deployment --namespace=kubectl-6602'
Dec 28 04:40:37.527: INFO: stderr: ""
Dec 28 04:40:37.527: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:40:37.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6602" for this suite.
Dec 28 04:40:43.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:40:43.596: INFO: namespace kubectl-6602 deletion completed in 6.06590868s

• [SLOW TEST:6.237 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:40:43.596: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 28 04:40:43.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-810'
Dec 28 04:40:43.830: INFO: stderr: ""
Dec 28 04:40:43.830: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 04:40:43.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-810'
Dec 28 04:40:43.902: INFO: stderr: ""
Dec 28 04:40:43.902: INFO: stdout: "update-demo-nautilus-82trt update-demo-nautilus-mngrb "
Dec 28 04:40:43.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-82trt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-810'
Dec 28 04:40:43.975: INFO: stderr: ""
Dec 28 04:40:43.975: INFO: stdout: ""
Dec 28 04:40:43.975: INFO: update-demo-nautilus-82trt is created but not running
Dec 28 04:40:48.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-810'
Dec 28 04:40:49.052: INFO: stderr: ""
Dec 28 04:40:49.053: INFO: stdout: "update-demo-nautilus-82trt update-demo-nautilus-mngrb "
Dec 28 04:40:49.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-82trt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-810'
Dec 28 04:40:49.123: INFO: stderr: ""
Dec 28 04:40:49.123: INFO: stdout: "true"
Dec 28 04:40:49.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-82trt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-810'
Dec 28 04:40:49.195: INFO: stderr: ""
Dec 28 04:40:49.195: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 04:40:49.195: INFO: validating pod update-demo-nautilus-82trt
Dec 28 04:40:49.198: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 04:40:49.198: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 04:40:49.198: INFO: update-demo-nautilus-82trt is verified up and running
Dec 28 04:40:49.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-mngrb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-810'
Dec 28 04:40:49.272: INFO: stderr: ""
Dec 28 04:40:49.272: INFO: stdout: "true"
Dec 28 04:40:49.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-mngrb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-810'
Dec 28 04:40:49.338: INFO: stderr: ""
Dec 28 04:40:49.338: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 04:40:49.338: INFO: validating pod update-demo-nautilus-mngrb
Dec 28 04:40:49.341: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 04:40:49.341: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 04:40:49.341: INFO: update-demo-nautilus-mngrb is verified up and running
STEP: using delete to clean up resources
Dec 28 04:40:49.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete --grace-period=0 --force -f - --namespace=kubectl-810'
Dec 28 04:40:49.414: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 04:40:49.414: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 28 04:40:49.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-810'
Dec 28 04:40:49.489: INFO: stderr: "No resources found in kubectl-810 namespace.\n"
Dec 28 04:40:49.489: INFO: stdout: ""
Dec 28 04:40:49.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -l name=update-demo --namespace=kubectl-810 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 28 04:40:49.566: INFO: stderr: ""
Dec 28 04:40:49.566: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:40:49.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-810" for this suite.
Dec 28 04:41:01.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:41:01.635: INFO: namespace kubectl-810 deletion completed in 12.066202869s

• [SLOW TEST:18.039 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:41:01.636: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 28 04:41:01.656: INFO: Waiting up to 5m0s for pod "pod-f74b7d54-ace0-4895-afae-88abc08870e0" in namespace "emptydir-6615" to be "success or failure"
Dec 28 04:41:01.657: INFO: Pod "pod-f74b7d54-ace0-4895-afae-88abc08870e0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.489247ms
Dec 28 04:41:03.660: INFO: Pod "pod-f74b7d54-ace0-4895-afae-88abc08870e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003677457s
STEP: Saw pod success
Dec 28 04:41:03.660: INFO: Pod "pod-f74b7d54-ace0-4895-afae-88abc08870e0" satisfied condition "success or failure"
Dec 28 04:41:03.661: INFO: Trying to get logs from node hxx-m-2 pod pod-f74b7d54-ace0-4895-afae-88abc08870e0 container test-container: <nil>
STEP: delete the pod
Dec 28 04:41:03.675: INFO: Waiting for pod pod-f74b7d54-ace0-4895-afae-88abc08870e0 to disappear
Dec 28 04:41:03.677: INFO: Pod pod-f74b7d54-ace0-4895-afae-88abc08870e0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:41:03.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6615" for this suite.
Dec 28 04:41:09.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:41:09.747: INFO: namespace emptydir-6615 deletion completed in 6.068103354s

• [SLOW TEST:8.112 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:41:09.748: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-2081
STEP: creating replication controller nodeport-test in namespace services-2081
I1228 04:41:09.776633      22 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-2081, replica count: 2
I1228 04:41:12.826960      22 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 28 04:41:12.826: INFO: Creating new exec pod
Dec 28 04:41:15.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-2081 execpodgctzv -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec 28 04:41:16.056: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 28 04:41:16.056: INFO: stdout: ""
Dec 28 04:41:16.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-2081 execpodgctzv -- /bin/sh -x -c nc -zv -t -w 2 10.97.118.251 80'
Dec 28 04:41:16.271: INFO: stderr: "+ nc -zv -t -w 2 10.97.118.251 80\nConnection to 10.97.118.251 80 port [tcp/http] succeeded!\n"
Dec 28 04:41:16.271: INFO: stdout: ""
Dec 28 04:41:16.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-2081 execpodgctzv -- /bin/sh -x -c nc -zv -t -w 2 10.0.128.42 31461'
Dec 28 04:41:16.483: INFO: stderr: "+ nc -zv -t -w 2 10.0.128.42 31461\nConnection to 10.0.128.42 31461 port [tcp/31461] succeeded!\n"
Dec 28 04:41:16.483: INFO: stdout: ""
Dec 28 04:41:16.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-2081 execpodgctzv -- /bin/sh -x -c nc -zv -t -w 2 10.0.128.16 31461'
Dec 28 04:41:16.697: INFO: stderr: "+ nc -zv -t -w 2 10.0.128.16 31461\nConnection to 10.0.128.16 31461 port [tcp/31461] succeeded!\n"
Dec 28 04:41:16.697: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:41:16.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2081" for this suite.
Dec 28 04:41:22.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:41:22.768: INFO: namespace services-2081 deletion completed in 6.067983557s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.021 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:41:22.769: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:41:38.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3705" for this suite.
Dec 28 04:41:44.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:41:44.887: INFO: namespace resourcequota-3705 deletion completed in 6.076322335s

• [SLOW TEST:22.118 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:41:44.887: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 28 04:41:44.907: INFO: Waiting up to 5m0s for pod "pod-96db1757-ae71-4ea9-b452-f939ca2c3fa0" in namespace "emptydir-8684" to be "success or failure"
Dec 28 04:41:44.908: INFO: Pod "pod-96db1757-ae71-4ea9-b452-f939ca2c3fa0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.460761ms
Dec 28 04:41:46.910: INFO: Pod "pod-96db1757-ae71-4ea9-b452-f939ca2c3fa0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003781131s
STEP: Saw pod success
Dec 28 04:41:46.910: INFO: Pod "pod-96db1757-ae71-4ea9-b452-f939ca2c3fa0" satisfied condition "success or failure"
Dec 28 04:41:46.912: INFO: Trying to get logs from node hxx-m-2 pod pod-96db1757-ae71-4ea9-b452-f939ca2c3fa0 container test-container: <nil>
STEP: delete the pod
Dec 28 04:41:46.923: INFO: Waiting for pod pod-96db1757-ae71-4ea9-b452-f939ca2c3fa0 to disappear
Dec 28 04:41:46.924: INFO: Pod pod-96db1757-ae71-4ea9-b452-f939ca2c3fa0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:41:46.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8684" for this suite.
Dec 28 04:41:52.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:41:52.996: INFO: namespace emptydir-8684 deletion completed in 6.068603219s

• [SLOW TEST:8.109 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:41:52.996: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 28 04:41:53.015: INFO: Waiting up to 5m0s for pod "pod-8f657a02-16ed-4295-a1f2-f8778d2013e7" in namespace "emptydir-5051" to be "success or failure"
Dec 28 04:41:53.016: INFO: Pod "pod-8f657a02-16ed-4295-a1f2-f8778d2013e7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.451686ms
Dec 28 04:41:55.019: INFO: Pod "pod-8f657a02-16ed-4295-a1f2-f8778d2013e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003784874s
STEP: Saw pod success
Dec 28 04:41:55.019: INFO: Pod "pod-8f657a02-16ed-4295-a1f2-f8778d2013e7" satisfied condition "success or failure"
Dec 28 04:41:55.020: INFO: Trying to get logs from node hxx-m-2 pod pod-8f657a02-16ed-4295-a1f2-f8778d2013e7 container test-container: <nil>
STEP: delete the pod
Dec 28 04:41:55.029: INFO: Waiting for pod pod-8f657a02-16ed-4295-a1f2-f8778d2013e7 to disappear
Dec 28 04:41:55.031: INFO: Pod pod-8f657a02-16ed-4295-a1f2-f8778d2013e7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:41:55.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5051" for this suite.
Dec 28 04:42:01.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:42:01.101: INFO: namespace emptydir-5051 deletion completed in 6.067251174s

• [SLOW TEST:8.105 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:42:01.101: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 28 04:42:01.118: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 28 04:42:01.125: INFO: Waiting for terminating namespaces to be deleted...
Dec 28 04:42:01.126: INFO: 
Logging pods the kubelet thinks is on node hxx-m-1 before test
Dec 28 04:42:01.140: INFO: sonobuoy-e2e-job-af99efc4f7ea449a from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container e2e ready: true, restart count 0
Dec 28 04:42:01.140: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:42:01.140: INFO: cert-manager-77f5bf4f5-h86rt from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container cert-manager ready: true, restart count 0
Dec 28 04:42:01.140: INFO: cert-manager-webhook-578c59dddd-k697c from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container webhook ready: true, restart count 0
Dec 28 04:42:01.140: INFO: apollo-cfdd64bb4-4lssk from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container apollo ready: true, restart count 0
Dec 28 04:42:01.140: INFO: coredns-66447b44c9-zphmm from kube-system started at 2019-12-27 13:58:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container coredns ready: true, restart count 0
Dec 28 04:42:01.140: INFO: erebus-5597f9565d-zwjnz from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container erebus ready: true, restart count 0
Dec 28 04:42:01.140: INFO: auth-controller2-79ff55cd75-cbjbn from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container auth-controller2-manager ready: true, restart count 0
Dec 28 04:42:01.140: INFO: furion-679c948779-jz6lf from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container furion ready: true, restart count 0
Dec 28 04:42:01.140: INFO: underlord-5c45b96c5d-nmjjq from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container alauda-console ready: true, restart count 0
Dec 28 04:42:01.140: INFO: dex-8448b48ff8-2bd5h from cpaas-system started at 2019-12-27 14:09:25 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container dex ready: true, restart count 0
Dec 28 04:42:01.140: INFO: archon-5fdc59d78c-rhtzm from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container archon-api ready: true, restart count 0
Dec 28 04:42:01.140: INFO: cert-manager-cainjector-67d4dd59ff-8jhs9 from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container cainjector ready: true, restart count 0
Dec 28 04:42:01.140: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-lzsqv from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:42:01.140: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:42:01.140: INFO: agon-75b987dff5-7bht5 from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container agon ready: true, restart count 2
Dec 28 04:42:01.140: INFO: cluster-registry-controller-manager-76774c98d-7c7mz from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (2 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 28 04:42:01.140: INFO: 	Container manager ready: true, restart count 0
Dec 28 04:42:01.140: INFO: kube-proxy-bnhj6 from kube-system started at 2019-12-27 13:58:01 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:42:01.140: INFO: kube-flannel-8hgpf from kube-system started at 2019-12-27 13:58:14 +0000 UTC (2 container statuses recorded)
Dec 28 04:42:01.140: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:42:01.140: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:42:01.140: INFO: 
Logging pods the kubelet thinks is on node hxx-m-2 before test
Dec 28 04:42:01.148: INFO: kube-scheduler-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.148: INFO: 	Container kube-scheduler ready: true, restart count 0
Dec 28 04:42:01.148: INFO: nginx-ingress-controller-f9b5d49fd-gmgv6 from cpaas-system started at 2019-12-28 04:23:17 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.148: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 28 04:42:01.148: INFO: kube-flannel-nt4gw from kube-system started at 2019-12-28 04:23:35 +0000 UTC (2 container statuses recorded)
Dec 28 04:42:01.148: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:42:01.148: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:42:01.148: INFO: kube-apiserver-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.148: INFO: 	Container kube-apiserver ready: true, restart count 0
Dec 28 04:42:01.148: INFO: kube-controller-manager-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.148: INFO: 	Container kube-controller-manager ready: true, restart count 0
Dec 28 04:42:01.148: INFO: etcd-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.148: INFO: 	Container etcd ready: true, restart count 0
Dec 28 04:42:01.148: INFO: kube-proxy-44f6q from kube-system started at 2019-12-27 13:57:35 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.148: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:42:01.148: INFO: sonobuoy from sonobuoy started at 2019-12-28 04:15:38 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.148: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 28 04:42:01.148: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-89sp4 from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:42:01.148: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:42:01.148: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:42:01.148: INFO: 
Logging pods the kubelet thinks is on node hxx-m-3 before test
Dec 28 04:42:01.162: INFO: furion-679c948779-xjs2n from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container furion ready: true, restart count 0
Dec 28 04:42:01.162: INFO: archon-5fdc59d78c-k5jbm from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container archon-api ready: true, restart count 0
Dec 28 04:42:01.162: INFO: cluster-registry-controller-manager-76774c98d-rmnh2 from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (2 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 28 04:42:01.162: INFO: 	Container manager ready: true, restart count 0
Dec 28 04:42:01.162: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-pjj5l from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:42:01.162: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:42:01.162: INFO: auth-controller2-79ff55cd75-4clk9 from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container auth-controller2-manager ready: true, restart count 0
Dec 28 04:42:01.162: INFO: tiller-deploy-7c757c6f9c-67l6b from kube-system started at 2019-12-27 13:59:57 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container tiller ready: true, restart count 0
Dec 28 04:42:01.162: INFO: kube-flannel-f87zg from kube-system started at 2019-12-27 13:58:14 +0000 UTC (2 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:42:01.162: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:42:01.162: INFO: cert-manager-webhook-578c59dddd-flp52 from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container webhook ready: true, restart count 0
Dec 28 04:42:01.162: INFO: cert-manager-cainjector-67d4dd59ff-tngcj from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container cainjector ready: true, restart count 0
Dec 28 04:42:01.162: INFO: erebus-5597f9565d-ptdps from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container erebus ready: true, restart count 0
Dec 28 04:42:01.162: INFO: kube-proxy-5kzvk from kube-system started at 2019-12-27 13:57:57 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:42:01.162: INFO: cert-manager-77f5bf4f5-2wz6n from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container cert-manager ready: true, restart count 0
Dec 28 04:42:01.162: INFO: underlord-5c45b96c5d-6cvvc from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container alauda-console ready: true, restart count 0
Dec 28 04:42:01.162: INFO: dex-8448b48ff8-9qn2j from cpaas-system started at 2019-12-27 14:09:25 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container dex ready: true, restart count 0
Dec 28 04:42:01.162: INFO: apollo-cfdd64bb4-hjth5 from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container apollo ready: true, restart count 0
Dec 28 04:42:01.162: INFO: agon-75b987dff5-bl7sb from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container agon ready: true, restart count 2
Dec 28 04:42:01.162: INFO: coredns-66447b44c9-5qbrm from kube-system started at 2019-12-27 13:58:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:42:01.162: INFO: 	Container coredns ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-32129950-565a-47d7-a4e9-669f7dbd3fb8 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-32129950-565a-47d7-a4e9-669f7dbd3fb8 off the node hxx-m-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-32129950-565a-47d7-a4e9-669f7dbd3fb8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:42:09.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4345" for this suite.
Dec 28 04:42:27.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:42:27.282: INFO: namespace sched-pred-4345 deletion completed in 18.068884747s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:26.181 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:42:27.282: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:42:27.302: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8ae158a-50b4-4d1e-ace4-087d69695580" in namespace "downward-api-2612" to be "success or failure"
Dec 28 04:42:27.304: INFO: Pod "downwardapi-volume-e8ae158a-50b4-4d1e-ace4-087d69695580": Phase="Pending", Reason="", readiness=false. Elapsed: 1.449945ms
Dec 28 04:42:29.306: INFO: Pod "downwardapi-volume-e8ae158a-50b4-4d1e-ace4-087d69695580": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003732426s
STEP: Saw pod success
Dec 28 04:42:29.306: INFO: Pod "downwardapi-volume-e8ae158a-50b4-4d1e-ace4-087d69695580" satisfied condition "success or failure"
Dec 28 04:42:29.307: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-e8ae158a-50b4-4d1e-ace4-087d69695580 container client-container: <nil>
STEP: delete the pod
Dec 28 04:42:29.318: INFO: Waiting for pod downwardapi-volume-e8ae158a-50b4-4d1e-ace4-087d69695580 to disappear
Dec 28 04:42:29.319: INFO: Pod downwardapi-volume-e8ae158a-50b4-4d1e-ace4-087d69695580 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:42:29.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2612" for this suite.
Dec 28 04:42:35.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:42:35.388: INFO: namespace downward-api-2612 deletion completed in 6.066574528s

• [SLOW TEST:8.106 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:42:35.389: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:42:35.411: INFO: (0) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.632634ms)
Dec 28 04:42:35.413: INFO: (1) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.134385ms)
Dec 28 04:42:35.415: INFO: (2) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.268552ms)
Dec 28 04:42:35.418: INFO: (3) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.219152ms)
Dec 28 04:42:35.420: INFO: (4) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.146758ms)
Dec 28 04:42:35.422: INFO: (5) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.110961ms)
Dec 28 04:42:35.424: INFO: (6) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.202091ms)
Dec 28 04:42:35.426: INFO: (7) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.179919ms)
Dec 28 04:42:35.428: INFO: (8) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.001071ms)
Dec 28 04:42:35.430: INFO: (9) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.011565ms)
Dec 28 04:42:35.433: INFO: (10) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.166267ms)
Dec 28 04:42:35.435: INFO: (11) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.132102ms)
Dec 28 04:42:35.437: INFO: (12) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.105365ms)
Dec 28 04:42:35.439: INFO: (13) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.238089ms)
Dec 28 04:42:35.441: INFO: (14) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.275853ms)
Dec 28 04:42:35.443: INFO: (15) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.10452ms)
Dec 28 04:42:35.446: INFO: (16) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.130603ms)
Dec 28 04:42:35.448: INFO: (17) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 1.980411ms)
Dec 28 04:42:35.450: INFO: (18) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.064051ms)
Dec 28 04:42:35.452: INFO: (19) /api/v1/nodes/hxx-m-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.131586ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:42:35.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4608" for this suite.
Dec 28 04:42:41.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:42:41.524: INFO: namespace proxy-4608 deletion completed in 6.070047952s

• [SLOW TEST:6.136 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:42:41.525: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:42:43.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2730" for this suite.
Dec 28 04:43:11.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:43:11.624: INFO: namespace containers-2730 deletion completed in 28.066348424s

• [SLOW TEST:30.099 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:43:11.624: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a11b7987-b12b-4423-9718-49650ad23de6
STEP: Creating a pod to test consume secrets
Dec 28 04:43:11.645: INFO: Waiting up to 5m0s for pod "pod-secrets-8b0b1b42-df62-4a0c-b85b-d2d588ae2ab3" in namespace "secrets-1570" to be "success or failure"
Dec 28 04:43:11.647: INFO: Pod "pod-secrets-8b0b1b42-df62-4a0c-b85b-d2d588ae2ab3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.514399ms
Dec 28 04:43:13.649: INFO: Pod "pod-secrets-8b0b1b42-df62-4a0c-b85b-d2d588ae2ab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003798489s
STEP: Saw pod success
Dec 28 04:43:13.649: INFO: Pod "pod-secrets-8b0b1b42-df62-4a0c-b85b-d2d588ae2ab3" satisfied condition "success or failure"
Dec 28 04:43:13.651: INFO: Trying to get logs from node hxx-m-2 pod pod-secrets-8b0b1b42-df62-4a0c-b85b-d2d588ae2ab3 container secret-env-test: <nil>
STEP: delete the pod
Dec 28 04:43:13.661: INFO: Waiting for pod pod-secrets-8b0b1b42-df62-4a0c-b85b-d2d588ae2ab3 to disappear
Dec 28 04:43:13.663: INFO: Pod pod-secrets-8b0b1b42-df62-4a0c-b85b-d2d588ae2ab3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:43:13.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1570" for this suite.
Dec 28 04:43:19.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:43:19.733: INFO: namespace secrets-1570 deletion completed in 6.068036235s

• [SLOW TEST:8.109 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:43:19.733: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:43:21.764: INFO: Waiting up to 5m0s for pod "client-envvars-1f325aef-265f-409b-ad90-37bc54ce6f71" in namespace "pods-2570" to be "success or failure"
Dec 28 04:43:21.767: INFO: Pod "client-envvars-1f325aef-265f-409b-ad90-37bc54ce6f71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.256673ms
Dec 28 04:43:23.769: INFO: Pod "client-envvars-1f325aef-265f-409b-ad90-37bc54ce6f71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004446398s
STEP: Saw pod success
Dec 28 04:43:23.769: INFO: Pod "client-envvars-1f325aef-265f-409b-ad90-37bc54ce6f71" satisfied condition "success or failure"
Dec 28 04:43:23.771: INFO: Trying to get logs from node hxx-m-2 pod client-envvars-1f325aef-265f-409b-ad90-37bc54ce6f71 container env3cont: <nil>
STEP: delete the pod
Dec 28 04:43:23.780: INFO: Waiting for pod client-envvars-1f325aef-265f-409b-ad90-37bc54ce6f71 to disappear
Dec 28 04:43:23.782: INFO: Pod client-envvars-1f325aef-265f-409b-ad90-37bc54ce6f71 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:43:23.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2570" for this suite.
Dec 28 04:43:35.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:43:35.860: INFO: namespace pods-2570 deletion completed in 12.075714364s

• [SLOW TEST:16.127 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:43:35.861: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-49dn
STEP: Creating a pod to test atomic-volume-subpath
Dec 28 04:43:35.884: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-49dn" in namespace "subpath-9785" to be "success or failure"
Dec 28 04:43:35.885: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Pending", Reason="", readiness=false. Elapsed: 1.680705ms
Dec 28 04:43:37.888: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Running", Reason="", readiness=true. Elapsed: 2.00431825s
Dec 28 04:43:39.890: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Running", Reason="", readiness=true. Elapsed: 4.006768055s
Dec 28 04:43:41.893: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Running", Reason="", readiness=true. Elapsed: 6.009275764s
Dec 28 04:43:43.895: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Running", Reason="", readiness=true. Elapsed: 8.011791638s
Dec 28 04:43:45.899: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Running", Reason="", readiness=true. Elapsed: 10.015646331s
Dec 28 04:43:47.902: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Running", Reason="", readiness=true. Elapsed: 12.018054666s
Dec 28 04:43:49.904: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Running", Reason="", readiness=true. Elapsed: 14.020355326s
Dec 28 04:43:51.906: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Running", Reason="", readiness=true. Elapsed: 16.022578475s
Dec 28 04:43:53.909: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Running", Reason="", readiness=true. Elapsed: 18.025000807s
Dec 28 04:43:55.911: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Running", Reason="", readiness=true. Elapsed: 20.027350704s
Dec 28 04:43:57.913: INFO: Pod "pod-subpath-test-projected-49dn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.029572805s
STEP: Saw pod success
Dec 28 04:43:57.913: INFO: Pod "pod-subpath-test-projected-49dn" satisfied condition "success or failure"
Dec 28 04:43:57.915: INFO: Trying to get logs from node hxx-m-2 pod pod-subpath-test-projected-49dn container test-container-subpath-projected-49dn: <nil>
STEP: delete the pod
Dec 28 04:43:57.924: INFO: Waiting for pod pod-subpath-test-projected-49dn to disappear
Dec 28 04:43:57.927: INFO: Pod pod-subpath-test-projected-49dn no longer exists
STEP: Deleting pod pod-subpath-test-projected-49dn
Dec 28 04:43:57.927: INFO: Deleting pod "pod-subpath-test-projected-49dn" in namespace "subpath-9785"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:43:57.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9785" for this suite.
Dec 28 04:44:03.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:44:03.998: INFO: namespace subpath-9785 deletion completed in 6.066655206s

• [SLOW TEST:28.137 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:44:03.998: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-1137/configmap-test-bd5c6318-8ecf-4ca6-9f58-0017beadbcf0
STEP: Creating a pod to test consume configMaps
Dec 28 04:44:04.021: INFO: Waiting up to 5m0s for pod "pod-configmaps-6e3137ab-8c64-4341-bfb9-268e1e3ef178" in namespace "configmap-1137" to be "success or failure"
Dec 28 04:44:04.025: INFO: Pod "pod-configmaps-6e3137ab-8c64-4341-bfb9-268e1e3ef178": Phase="Pending", Reason="", readiness=false. Elapsed: 3.255783ms
Dec 28 04:44:06.027: INFO: Pod "pod-configmaps-6e3137ab-8c64-4341-bfb9-268e1e3ef178": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005683382s
STEP: Saw pod success
Dec 28 04:44:06.027: INFO: Pod "pod-configmaps-6e3137ab-8c64-4341-bfb9-268e1e3ef178" satisfied condition "success or failure"
Dec 28 04:44:06.028: INFO: Trying to get logs from node hxx-m-2 pod pod-configmaps-6e3137ab-8c64-4341-bfb9-268e1e3ef178 container env-test: <nil>
STEP: delete the pod
Dec 28 04:44:06.039: INFO: Waiting for pod pod-configmaps-6e3137ab-8c64-4341-bfb9-268e1e3ef178 to disappear
Dec 28 04:44:06.040: INFO: Pod pod-configmaps-6e3137ab-8c64-4341-bfb9-268e1e3ef178 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:44:06.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1137" for this suite.
Dec 28 04:44:12.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:44:12.112: INFO: namespace configmap-1137 deletion completed in 6.068324598s

• [SLOW TEST:8.114 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:44:12.112: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-1998
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1998 to expose endpoints map[]
Dec 28 04:44:12.137: INFO: Get endpoints failed (2.742591ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 28 04:44:13.139: INFO: successfully validated that service multi-endpoint-test in namespace services-1998 exposes endpoints map[] (1.004834186s elapsed)
STEP: Creating pod pod1 in namespace services-1998
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1998 to expose endpoints map[pod1:[100]]
Dec 28 04:44:15.155: INFO: successfully validated that service multi-endpoint-test in namespace services-1998 exposes endpoints map[pod1:[100]] (2.011912823s elapsed)
STEP: Creating pod pod2 in namespace services-1998
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1998 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 28 04:44:17.173: INFO: successfully validated that service multi-endpoint-test in namespace services-1998 exposes endpoints map[pod1:[100] pod2:[101]] (2.015223634s elapsed)
STEP: Deleting pod pod1 in namespace services-1998
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1998 to expose endpoints map[pod2:[101]]
Dec 28 04:44:18.184: INFO: successfully validated that service multi-endpoint-test in namespace services-1998 exposes endpoints map[pod2:[101]] (1.008166078s elapsed)
STEP: Deleting pod pod2 in namespace services-1998
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1998 to expose endpoints map[]
Dec 28 04:44:18.189: INFO: successfully validated that service multi-endpoint-test in namespace services-1998 exposes endpoints map[] (2.405419ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:44:18.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1998" for this suite.
Dec 28 04:44:24.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:44:24.268: INFO: namespace services-1998 deletion completed in 6.064779833s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.156 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:44:24.268: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-dc9ea2c8-89d9-44e3-aeb8-c862391d3acc
STEP: Creating configMap with name cm-test-opt-upd-6bf174fb-a348-4a1b-b3d7-65a9bd40a486
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-dc9ea2c8-89d9-44e3-aeb8-c862391d3acc
STEP: Updating configmap cm-test-opt-upd-6bf174fb-a348-4a1b-b3d7-65a9bd40a486
STEP: Creating configMap with name cm-test-opt-create-ef498afb-5325-499c-9bcc-0620b920d0ab
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:45:42.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7960" for this suite.
Dec 28 04:46:10.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:46:10.624: INFO: namespace configmap-7960 deletion completed in 28.069237014s

• [SLOW TEST:106.357 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:46:10.625: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-6f23f825-c60c-4092-98ad-e9751c4c7e95
STEP: Creating secret with name secret-projected-all-test-volume-28edd500-8c94-449e-892e-322d2bb76900
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 28 04:46:10.650: INFO: Waiting up to 5m0s for pod "projected-volume-260b97d6-8905-40bc-aee4-046a19f5f7d2" in namespace "projected-6437" to be "success or failure"
Dec 28 04:46:10.651: INFO: Pod "projected-volume-260b97d6-8905-40bc-aee4-046a19f5f7d2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.569281ms
Dec 28 04:46:12.654: INFO: Pod "projected-volume-260b97d6-8905-40bc-aee4-046a19f5f7d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004041424s
STEP: Saw pod success
Dec 28 04:46:12.654: INFO: Pod "projected-volume-260b97d6-8905-40bc-aee4-046a19f5f7d2" satisfied condition "success or failure"
Dec 28 04:46:12.655: INFO: Trying to get logs from node hxx-m-2 pod projected-volume-260b97d6-8905-40bc-aee4-046a19f5f7d2 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 28 04:46:12.665: INFO: Waiting for pod projected-volume-260b97d6-8905-40bc-aee4-046a19f5f7d2 to disappear
Dec 28 04:46:12.666: INFO: Pod projected-volume-260b97d6-8905-40bc-aee4-046a19f5f7d2 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:46:12.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6437" for this suite.
Dec 28 04:46:18.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:46:18.734: INFO: namespace projected-6437 deletion completed in 6.065145525s

• [SLOW TEST:8.109 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:46:18.734: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4290.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4290.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 28 04:46:20.765: INFO: DNS probes using dns-test-0c549f8b-2e39-4149-8f81-97178f233cab succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4290.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4290.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 28 04:46:22.785: INFO: File wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:22.787: INFO: File jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:22.787: INFO: Lookups using dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 failed for: [wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local]

Dec 28 04:46:27.790: INFO: File wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:27.792: INFO: File jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:27.792: INFO: Lookups using dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 failed for: [wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local]

Dec 28 04:46:32.790: INFO: File wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:32.792: INFO: File jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:32.792: INFO: Lookups using dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 failed for: [wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local]

Dec 28 04:46:37.790: INFO: File wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:37.792: INFO: File jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:37.792: INFO: Lookups using dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 failed for: [wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local]

Dec 28 04:46:42.790: INFO: File wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:42.792: INFO: File jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:42.792: INFO: Lookups using dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 failed for: [wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local]

Dec 28 04:46:47.790: INFO: File wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:47.792: INFO: File jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 28 04:46:47.792: INFO: Lookups using dns-4290/dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 failed for: [wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local]

Dec 28 04:46:52.792: INFO: DNS probes using dns-test-c5e9ab67-fe93-413a-91b4-8c17f0d122d2 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4290.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4290.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4290.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 28 04:46:56.823: INFO: File wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local from pod  dns-4290/dns-test-ae747a8e-73d6-4acc-9010-77f94cfc1238 contains '' instead of '10.100.222.210'
Dec 28 04:46:56.826: INFO: Lookups using dns-4290/dns-test-ae747a8e-73d6-4acc-9010-77f94cfc1238 failed for: [wheezy_udp@dns-test-service-3.dns-4290.svc.cluster.local]

Dec 28 04:47:01.831: INFO: DNS probes using dns-test-ae747a8e-73d6-4acc-9010-77f94cfc1238 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:47:01.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4290" for this suite.
Dec 28 04:47:07.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:47:07.936: INFO: namespace dns-4290 deletion completed in 6.070940278s

• [SLOW TEST:49.202 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:47:07.936: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 28 04:47:38.471: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1228 04:47:38.471143      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:47:38.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7866" for this suite.
Dec 28 04:47:44.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:47:44.543: INFO: namespace gc-7866 deletion completed in 6.069568365s

• [SLOW TEST:36.607 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:47:44.543: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-78b0391f-0459-4216-91be-9d9ea3421203
STEP: Creating a pod to test consume secrets
Dec 28 04:47:44.565: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8f1c8be4-7ba4-4e3a-b3ea-1a097dea2d6d" in namespace "projected-2997" to be "success or failure"
Dec 28 04:47:44.573: INFO: Pod "pod-projected-secrets-8f1c8be4-7ba4-4e3a-b3ea-1a097dea2d6d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.088272ms
Dec 28 04:47:46.581: INFO: Pod "pod-projected-secrets-8f1c8be4-7ba4-4e3a-b3ea-1a097dea2d6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016287869s
STEP: Saw pod success
Dec 28 04:47:46.581: INFO: Pod "pod-projected-secrets-8f1c8be4-7ba4-4e3a-b3ea-1a097dea2d6d" satisfied condition "success or failure"
Dec 28 04:47:46.582: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-secrets-8f1c8be4-7ba4-4e3a-b3ea-1a097dea2d6d container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 04:47:46.599: INFO: Waiting for pod pod-projected-secrets-8f1c8be4-7ba4-4e3a-b3ea-1a097dea2d6d to disappear
Dec 28 04:47:46.601: INFO: Pod pod-projected-secrets-8f1c8be4-7ba4-4e3a-b3ea-1a097dea2d6d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:47:46.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2997" for this suite.
Dec 28 04:47:52.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:47:52.667: INFO: namespace projected-2997 deletion completed in 6.063219375s

• [SLOW TEST:8.124 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:47:52.667: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 28 04:47:52.685: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 28 04:47:52.692: INFO: Waiting for terminating namespaces to be deleted...
Dec 28 04:47:52.693: INFO: 
Logging pods the kubelet thinks is on node hxx-m-1 before test
Dec 28 04:47:52.707: INFO: coredns-66447b44c9-zphmm from kube-system started at 2019-12-27 13:58:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container coredns ready: true, restart count 0
Dec 28 04:47:52.707: INFO: cert-manager-77f5bf4f5-h86rt from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container cert-manager ready: true, restart count 0
Dec 28 04:47:52.707: INFO: cert-manager-webhook-578c59dddd-k697c from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container webhook ready: true, restart count 0
Dec 28 04:47:52.707: INFO: apollo-cfdd64bb4-4lssk from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container apollo ready: true, restart count 0
Dec 28 04:47:52.707: INFO: dex-8448b48ff8-2bd5h from cpaas-system started at 2019-12-27 14:09:25 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container dex ready: true, restart count 0
Dec 28 04:47:52.707: INFO: erebus-5597f9565d-zwjnz from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container erebus ready: true, restart count 0
Dec 28 04:47:52.707: INFO: auth-controller2-79ff55cd75-cbjbn from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container auth-controller2-manager ready: true, restart count 0
Dec 28 04:47:52.707: INFO: furion-679c948779-jz6lf from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container furion ready: true, restart count 0
Dec 28 04:47:52.707: INFO: underlord-5c45b96c5d-nmjjq from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container alauda-console ready: true, restart count 0
Dec 28 04:47:52.707: INFO: cert-manager-cainjector-67d4dd59ff-8jhs9 from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container cainjector ready: true, restart count 0
Dec 28 04:47:52.707: INFO: archon-5fdc59d78c-rhtzm from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container archon-api ready: true, restart count 0
Dec 28 04:47:52.707: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-lzsqv from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:47:52.707: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:47:52.707: INFO: kube-proxy-bnhj6 from kube-system started at 2019-12-27 13:58:01 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:47:52.707: INFO: agon-75b987dff5-7bht5 from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container agon ready: true, restart count 2
Dec 28 04:47:52.707: INFO: cluster-registry-controller-manager-76774c98d-7c7mz from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (2 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 28 04:47:52.707: INFO: 	Container manager ready: true, restart count 0
Dec 28 04:47:52.707: INFO: kube-flannel-8hgpf from kube-system started at 2019-12-27 13:58:14 +0000 UTC (2 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:47:52.707: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:47:52.707: INFO: sonobuoy-e2e-job-af99efc4f7ea449a from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:47:52.707: INFO: 	Container e2e ready: true, restart count 0
Dec 28 04:47:52.707: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:47:52.707: INFO: 
Logging pods the kubelet thinks is on node hxx-m-2 before test
Dec 28 04:47:52.712: INFO: etcd-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.712: INFO: 	Container etcd ready: true, restart count 0
Dec 28 04:47:52.712: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-89sp4 from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:47:52.712: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:47:52.712: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:47:52.712: INFO: kube-proxy-44f6q from kube-system started at 2019-12-27 13:57:35 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.712: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:47:52.712: INFO: sonobuoy from sonobuoy started at 2019-12-28 04:15:38 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.712: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 28 04:47:52.712: INFO: kube-flannel-nt4gw from kube-system started at 2019-12-28 04:23:35 +0000 UTC (2 container statuses recorded)
Dec 28 04:47:52.712: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:47:52.712: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:47:52.712: INFO: kube-scheduler-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.712: INFO: 	Container kube-scheduler ready: true, restart count 0
Dec 28 04:47:52.712: INFO: nginx-ingress-controller-f9b5d49fd-gmgv6 from cpaas-system started at 2019-12-28 04:23:17 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.712: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 28 04:47:52.712: INFO: kube-apiserver-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.712: INFO: 	Container kube-apiserver ready: true, restart count 0
Dec 28 04:47:52.712: INFO: kube-controller-manager-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.712: INFO: 	Container kube-controller-manager ready: true, restart count 0
Dec 28 04:47:52.712: INFO: 
Logging pods the kubelet thinks is on node hxx-m-3 before test
Dec 28 04:47:52.729: INFO: coredns-66447b44c9-5qbrm from kube-system started at 2019-12-27 13:58:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container coredns ready: true, restart count 0
Dec 28 04:47:52.729: INFO: cluster-registry-controller-manager-76774c98d-rmnh2 from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (2 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 28 04:47:52.729: INFO: 	Container manager ready: true, restart count 0
Dec 28 04:47:52.729: INFO: furion-679c948779-xjs2n from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container furion ready: true, restart count 0
Dec 28 04:47:52.729: INFO: archon-5fdc59d78c-k5jbm from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container archon-api ready: true, restart count 0
Dec 28 04:47:52.729: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-pjj5l from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 04:47:52.729: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 04:47:52.729: INFO: tiller-deploy-7c757c6f9c-67l6b from kube-system started at 2019-12-27 13:59:57 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container tiller ready: true, restart count 0
Dec 28 04:47:52.729: INFO: auth-controller2-79ff55cd75-4clk9 from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container auth-controller2-manager ready: true, restart count 0
Dec 28 04:47:52.729: INFO: cert-manager-cainjector-67d4dd59ff-tngcj from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container cainjector ready: true, restart count 0
Dec 28 04:47:52.729: INFO: erebus-5597f9565d-ptdps from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container erebus ready: true, restart count 0
Dec 28 04:47:52.729: INFO: kube-proxy-5kzvk from kube-system started at 2019-12-27 13:57:57 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 04:47:52.729: INFO: kube-flannel-f87zg from kube-system started at 2019-12-27 13:58:14 +0000 UTC (2 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 04:47:52.729: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 04:47:52.729: INFO: cert-manager-webhook-578c59dddd-flp52 from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container webhook ready: true, restart count 0
Dec 28 04:47:52.729: INFO: dex-8448b48ff8-9qn2j from cpaas-system started at 2019-12-27 14:09:25 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container dex ready: true, restart count 0
Dec 28 04:47:52.729: INFO: cert-manager-77f5bf4f5-2wz6n from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container cert-manager ready: true, restart count 0
Dec 28 04:47:52.729: INFO: underlord-5c45b96c5d-6cvvc from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container alauda-console ready: true, restart count 0
Dec 28 04:47:52.729: INFO: agon-75b987dff5-bl7sb from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container agon ready: true, restart count 2
Dec 28 04:47:52.729: INFO: apollo-cfdd64bb4-hjth5 from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 04:47:52.729: INFO: 	Container apollo ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6cf890b2-15ef-4cd0-a5e8-9d30c7aabefb 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-6cf890b2-15ef-4cd0-a5e8-9d30c7aabefb off the node hxx-m-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6cf890b2-15ef-4cd0-a5e8-9d30c7aabefb
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:52:56.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5835" for this suite.
Dec 28 04:53:04.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:53:04.842: INFO: namespace sched-pred-5835 deletion completed in 8.070677005s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:312.175 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:53:04.842: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-0058693b-e95a-4cc0-82d9-b6b3aa307af7
STEP: Creating a pod to test consume secrets
Dec 28 04:53:04.864: INFO: Waiting up to 5m0s for pod "pod-secrets-d426025e-6b07-40ba-82e6-be03a72c84f6" in namespace "secrets-2459" to be "success or failure"
Dec 28 04:53:04.865: INFO: Pod "pod-secrets-d426025e-6b07-40ba-82e6-be03a72c84f6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.273578ms
Dec 28 04:53:06.867: INFO: Pod "pod-secrets-d426025e-6b07-40ba-82e6-be03a72c84f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003622298s
STEP: Saw pod success
Dec 28 04:53:06.868: INFO: Pod "pod-secrets-d426025e-6b07-40ba-82e6-be03a72c84f6" satisfied condition "success or failure"
Dec 28 04:53:06.869: INFO: Trying to get logs from node hxx-m-2 pod pod-secrets-d426025e-6b07-40ba-82e6-be03a72c84f6 container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 04:53:06.885: INFO: Waiting for pod pod-secrets-d426025e-6b07-40ba-82e6-be03a72c84f6 to disappear
Dec 28 04:53:06.887: INFO: Pod pod-secrets-d426025e-6b07-40ba-82e6-be03a72c84f6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:53:06.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2459" for this suite.
Dec 28 04:53:12.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:53:12.958: INFO: namespace secrets-2459 deletion completed in 6.069161071s

• [SLOW TEST:8.117 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:53:12.959: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 28 04:53:13.215: INFO: Pod name wrapped-volume-race-9d7b8e14-bae5-4f09-858e-59772dcee93a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9d7b8e14-bae5-4f09-858e-59772dcee93a in namespace emptydir-wrapper-8717, will wait for the garbage collector to delete the pods
Dec 28 04:53:27.328: INFO: Deleting ReplicationController wrapped-volume-race-9d7b8e14-bae5-4f09-858e-59772dcee93a took: 3.698275ms
Dec 28 04:53:28.128: INFO: Terminating ReplicationController wrapped-volume-race-9d7b8e14-bae5-4f09-858e-59772dcee93a pods took: 800.179545ms
STEP: Creating RC which spawns configmap-volume pods
Dec 28 04:54:12.237: INFO: Pod name wrapped-volume-race-74ade4a4-4117-4851-9b55-c73bad77b46d: Found 0 pods out of 5
Dec 28 04:54:17.241: INFO: Pod name wrapped-volume-race-74ade4a4-4117-4851-9b55-c73bad77b46d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-74ade4a4-4117-4851-9b55-c73bad77b46d in namespace emptydir-wrapper-8717, will wait for the garbage collector to delete the pods
Dec 28 04:54:27.308: INFO: Deleting ReplicationController wrapped-volume-race-74ade4a4-4117-4851-9b55-c73bad77b46d took: 4.012336ms
Dec 28 04:54:28.108: INFO: Terminating ReplicationController wrapped-volume-race-74ade4a4-4117-4851-9b55-c73bad77b46d pods took: 800.178347ms
STEP: Creating RC which spawns configmap-volume pods
Dec 28 04:55:02.417: INFO: Pod name wrapped-volume-race-0b4fdab4-c412-4b77-a897-0d6f58f3d9cd: Found 0 pods out of 5
Dec 28 04:55:07.422: INFO: Pod name wrapped-volume-race-0b4fdab4-c412-4b77-a897-0d6f58f3d9cd: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0b4fdab4-c412-4b77-a897-0d6f58f3d9cd in namespace emptydir-wrapper-8717, will wait for the garbage collector to delete the pods
Dec 28 04:55:17.490: INFO: Deleting ReplicationController wrapped-volume-race-0b4fdab4-c412-4b77-a897-0d6f58f3d9cd took: 3.635303ms
Dec 28 04:55:18.290: INFO: Terminating ReplicationController wrapped-volume-race-0b4fdab4-c412-4b77-a897-0d6f58f3d9cd pods took: 800.21737ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:55:52.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8717" for this suite.
Dec 28 04:55:58.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:55:58.405: INFO: namespace emptydir-wrapper-8717 deletion completed in 6.072916467s

• [SLOW TEST:165.447 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:55:58.405: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Dec 28 04:55:58.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-8696'
Dec 28 04:55:58.640: INFO: stderr: ""
Dec 28 04:55:58.640: INFO: stdout: "pod/pause created\n"
Dec 28 04:55:58.640: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 28 04:55:58.640: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8696" to be "running and ready"
Dec 28 04:55:58.643: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.446122ms
Dec 28 04:56:00.645: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.004903024s
Dec 28 04:56:00.645: INFO: Pod "pause" satisfied condition "running and ready"
Dec 28 04:56:00.645: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 28 04:56:00.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 label pods pause testing-label=testing-label-value --namespace=kubectl-8696'
Dec 28 04:56:00.721: INFO: stderr: ""
Dec 28 04:56:00.721: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 28 04:56:00.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pod pause -L testing-label --namespace=kubectl-8696'
Dec 28 04:56:00.797: INFO: stderr: ""
Dec 28 04:56:00.797: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 28 04:56:00.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 label pods pause testing-label- --namespace=kubectl-8696'
Dec 28 04:56:00.884: INFO: stderr: ""
Dec 28 04:56:00.885: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 28 04:56:00.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pod pause -L testing-label --namespace=kubectl-8696'
Dec 28 04:56:00.956: INFO: stderr: ""
Dec 28 04:56:00.956: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Dec 28 04:56:00.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete --grace-period=0 --force -f - --namespace=kubectl-8696'
Dec 28 04:56:01.037: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 04:56:01.037: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 28 04:56:01.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get rc,svc -l name=pause --no-headers --namespace=kubectl-8696'
Dec 28 04:56:01.120: INFO: stderr: "No resources found in kubectl-8696 namespace.\n"
Dec 28 04:56:01.120: INFO: stdout: ""
Dec 28 04:56:01.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -l name=pause --namespace=kubectl-8696 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 28 04:56:01.210: INFO: stderr: ""
Dec 28 04:56:01.210: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:56:01.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8696" for this suite.
Dec 28 04:56:07.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:56:07.282: INFO: namespace kubectl-8696 deletion completed in 6.068865729s

• [SLOW TEST:8.877 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:56:07.282: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:56:09.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7209" for this suite.
Dec 28 04:56:53.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:56:53.387: INFO: namespace kubelet-test-7209 deletion completed in 44.067097795s

• [SLOW TEST:46.105 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:56:53.388: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-2f135f59-f8b6-435d-bcfd-745fcffc4b0d
STEP: Creating secret with name s-test-opt-upd-ffe1a480-90b5-42e3-b9da-d392fde8ba9f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2f135f59-f8b6-435d-bcfd-745fcffc4b0d
STEP: Updating secret s-test-opt-upd-ffe1a480-90b5-42e3-b9da-d392fde8ba9f
STEP: Creating secret with name s-test-opt-create-11615904-a451-4b8c-9107-e05c7a7c4349
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:56:57.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4797" for this suite.
Dec 28 04:57:11.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:57:11.542: INFO: namespace projected-4797 deletion completed in 14.076030459s

• [SLOW TEST:18.154 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:57:11.542: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 04:57:11.802: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 28 04:57:13.808: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713105831, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713105831, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713105831, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713105831, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 04:57:16.817: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:57:16.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9477" for this suite.
Dec 28 04:57:22.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:57:22.986: INFO: namespace webhook-9477 deletion completed in 6.073273111s
STEP: Destroying namespace "webhook-9477-markers" for this suite.
Dec 28 04:57:28.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:57:29.057: INFO: namespace webhook-9477-markers deletion completed in 6.07124055s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.522 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:57:29.064: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 28 04:57:29.081: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:57:47.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5128" for this suite.
Dec 28 04:57:53.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:57:54.028: INFO: namespace crd-publish-openapi-5128 deletion completed in 6.068523822s

• [SLOW TEST:24.964 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:57:54.028: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-f6cb3166-3d9c-435d-9119-2690495f1e85
STEP: Creating a pod to test consume configMaps
Dec 28 04:57:54.049: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a8ea5dc6-76bb-41cf-aa3c-eff84091e952" in namespace "projected-1383" to be "success or failure"
Dec 28 04:57:54.051: INFO: Pod "pod-projected-configmaps-a8ea5dc6-76bb-41cf-aa3c-eff84091e952": Phase="Pending", Reason="", readiness=false. Elapsed: 1.542804ms
Dec 28 04:57:56.053: INFO: Pod "pod-projected-configmaps-a8ea5dc6-76bb-41cf-aa3c-eff84091e952": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003430958s
STEP: Saw pod success
Dec 28 04:57:56.053: INFO: Pod "pod-projected-configmaps-a8ea5dc6-76bb-41cf-aa3c-eff84091e952" satisfied condition "success or failure"
Dec 28 04:57:56.054: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-configmaps-a8ea5dc6-76bb-41cf-aa3c-eff84091e952 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 04:57:56.064: INFO: Waiting for pod pod-projected-configmaps-a8ea5dc6-76bb-41cf-aa3c-eff84091e952 to disappear
Dec 28 04:57:56.065: INFO: Pod pod-projected-configmaps-a8ea5dc6-76bb-41cf-aa3c-eff84091e952 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:57:56.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1383" for this suite.
Dec 28 04:58:02.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:58:02.136: INFO: namespace projected-1383 deletion completed in 6.068252944s

• [SLOW TEST:8.108 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:58:02.136: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 04:58:02.163: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 28 04:58:02.169: INFO: Number of nodes with available pods: 0
Dec 28 04:58:02.169: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:03.174: INFO: Number of nodes with available pods: 0
Dec 28 04:58:03.174: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:04.174: INFO: Number of nodes with available pods: 3
Dec 28 04:58:04.174: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 28 04:58:04.186: INFO: Wrong image for pod: daemon-set-98xv2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:04.186: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:04.186: INFO: Wrong image for pod: daemon-set-btl8r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:05.191: INFO: Wrong image for pod: daemon-set-98xv2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:05.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:05.191: INFO: Wrong image for pod: daemon-set-btl8r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:06.191: INFO: Wrong image for pod: daemon-set-98xv2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:06.192: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:06.192: INFO: Wrong image for pod: daemon-set-btl8r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:07.191: INFO: Wrong image for pod: daemon-set-98xv2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:07.191: INFO: Pod daemon-set-98xv2 is not available
Dec 28 04:58:07.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:07.191: INFO: Wrong image for pod: daemon-set-btl8r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:08.192: INFO: Wrong image for pod: daemon-set-98xv2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:08.192: INFO: Pod daemon-set-98xv2 is not available
Dec 28 04:58:08.192: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:08.192: INFO: Wrong image for pod: daemon-set-btl8r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:09.191: INFO: Wrong image for pod: daemon-set-98xv2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:09.191: INFO: Pod daemon-set-98xv2 is not available
Dec 28 04:58:09.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:09.191: INFO: Wrong image for pod: daemon-set-btl8r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:10.191: INFO: Wrong image for pod: daemon-set-98xv2. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:10.191: INFO: Pod daemon-set-98xv2 is not available
Dec 28 04:58:10.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:10.191: INFO: Wrong image for pod: daemon-set-btl8r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:11.191: INFO: Pod daemon-set-4w7xr is not available
Dec 28 04:58:11.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:11.191: INFO: Wrong image for pod: daemon-set-btl8r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:12.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:12.191: INFO: Wrong image for pod: daemon-set-btl8r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:13.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:13.191: INFO: Wrong image for pod: daemon-set-btl8r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:13.191: INFO: Pod daemon-set-btl8r is not available
Dec 28 04:58:14.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:14.191: INFO: Pod daemon-set-tsxpc is not available
Dec 28 04:58:15.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:16.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:16.191: INFO: Pod daemon-set-9wf7r is not available
Dec 28 04:58:17.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:17.191: INFO: Pod daemon-set-9wf7r is not available
Dec 28 04:58:18.192: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:18.192: INFO: Pod daemon-set-9wf7r is not available
Dec 28 04:58:19.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:19.191: INFO: Pod daemon-set-9wf7r is not available
Dec 28 04:58:20.192: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:20.192: INFO: Pod daemon-set-9wf7r is not available
Dec 28 04:58:21.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:21.191: INFO: Pod daemon-set-9wf7r is not available
Dec 28 04:58:22.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:22.191: INFO: Pod daemon-set-9wf7r is not available
Dec 28 04:58:23.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:23.191: INFO: Pod daemon-set-9wf7r is not available
Dec 28 04:58:24.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:24.192: INFO: Pod daemon-set-9wf7r is not available
Dec 28 04:58:25.192: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:25.192: INFO: Pod daemon-set-9wf7r is not available
Dec 28 04:58:26.191: INFO: Wrong image for pod: daemon-set-9wf7r. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 28 04:58:26.191: INFO: Pod daemon-set-9wf7r is not available
Dec 28 04:58:27.191: INFO: Pod daemon-set-fk7zx is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 28 04:58:27.197: INFO: Number of nodes with available pods: 2
Dec 28 04:58:27.197: INFO: Node hxx-m-3 is running more than one daemon pod
Dec 28 04:58:28.201: INFO: Number of nodes with available pods: 2
Dec 28 04:58:28.201: INFO: Node hxx-m-3 is running more than one daemon pod
Dec 28 04:58:29.202: INFO: Number of nodes with available pods: 3
Dec 28 04:58:29.202: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3165, will wait for the garbage collector to delete the pods
Dec 28 04:58:29.265: INFO: Deleting DaemonSet.extensions daemon-set took: 3.238954ms
Dec 28 04:58:30.065: INFO: Terminating DaemonSet.extensions daemon-set pods took: 800.210693ms
Dec 28 04:58:40.967: INFO: Number of nodes with available pods: 0
Dec 28 04:58:40.967: INFO: Number of running nodes: 0, number of available pods: 0
Dec 28 04:58:40.968: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3165/daemonsets","resourceVersion":"223743"},"items":null}

Dec 28 04:58:40.970: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3165/pods","resourceVersion":"223743"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:58:40.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3165" for this suite.
Dec 28 04:58:46.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:58:47.045: INFO: namespace daemonsets-3165 deletion completed in 6.066214247s

• [SLOW TEST:44.909 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:58:47.045: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 28 04:58:47.079: INFO: Number of nodes with available pods: 0
Dec 28 04:58:47.079: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:48.083: INFO: Number of nodes with available pods: 2
Dec 28 04:58:48.083: INFO: Node hxx-m-2 is running more than one daemon pod
Dec 28 04:58:49.084: INFO: Number of nodes with available pods: 3
Dec 28 04:58:49.084: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 28 04:58:49.093: INFO: Number of nodes with available pods: 2
Dec 28 04:58:49.093: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:50.097: INFO: Number of nodes with available pods: 2
Dec 28 04:58:50.097: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:51.098: INFO: Number of nodes with available pods: 2
Dec 28 04:58:51.098: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:52.098: INFO: Number of nodes with available pods: 2
Dec 28 04:58:52.098: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:53.098: INFO: Number of nodes with available pods: 2
Dec 28 04:58:53.098: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:54.098: INFO: Number of nodes with available pods: 2
Dec 28 04:58:54.098: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:55.098: INFO: Number of nodes with available pods: 2
Dec 28 04:58:55.098: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:56.098: INFO: Number of nodes with available pods: 2
Dec 28 04:58:56.098: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:57.098: INFO: Number of nodes with available pods: 2
Dec 28 04:58:57.098: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:58.098: INFO: Number of nodes with available pods: 2
Dec 28 04:58:58.098: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:58:59.098: INFO: Number of nodes with available pods: 2
Dec 28 04:58:59.098: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:59:00.098: INFO: Number of nodes with available pods: 2
Dec 28 04:59:00.098: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:59:01.102: INFO: Number of nodes with available pods: 2
Dec 28 04:59:01.102: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:59:02.098: INFO: Number of nodes with available pods: 2
Dec 28 04:59:02.098: INFO: Node hxx-m-1 is running more than one daemon pod
Dec 28 04:59:03.098: INFO: Number of nodes with available pods: 3
Dec 28 04:59:03.098: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7387, will wait for the garbage collector to delete the pods
Dec 28 04:59:03.154: INFO: Deleting DaemonSet.extensions daemon-set took: 3.272634ms
Dec 28 04:59:03.954: INFO: Terminating DaemonSet.extensions daemon-set pods took: 800.191009ms
Dec 28 04:59:16.956: INFO: Number of nodes with available pods: 0
Dec 28 04:59:16.956: INFO: Number of running nodes: 0, number of available pods: 0
Dec 28 04:59:16.957: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7387/daemonsets","resourceVersion":"223982"},"items":null}

Dec 28 04:59:16.959: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7387/pods","resourceVersion":"223982"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:59:16.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7387" for this suite.
Dec 28 04:59:22.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:59:23.035: INFO: namespace daemonsets-7387 deletion completed in 6.067187798s

• [SLOW TEST:35.990 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:59:23.036: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 28 04:59:23.052: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:59:26.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8482" for this suite.
Dec 28 04:59:32.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:59:32.511: INFO: namespace init-container-8482 deletion completed in 6.065226878s

• [SLOW TEST:9.475 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:59:32.511: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 28 04:59:35.040: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4865 pod-service-account-787fe4b0-f39a-4119-9b25-fe2114d6cc4b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 28 04:59:35.251: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4865 pod-service-account-787fe4b0-f39a-4119-9b25-fe2114d6cc4b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 28 04:59:35.459: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4865 pod-service-account-787fe4b0-f39a-4119-9b25-fe2114d6cc4b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 04:59:35.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4865" for this suite.
Dec 28 04:59:41.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:59:41.753: INFO: namespace svcaccounts-4865 deletion completed in 6.068984705s

• [SLOW TEST:9.242 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 04:59:41.753: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7903.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7903.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7903.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7903.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7903.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7903.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 28 04:59:45.783: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:45.785: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:45.787: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:45.788: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:45.794: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:45.795: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:45.797: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:45.799: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:45.803: INFO: Lookups using dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local]

Dec 28 04:59:50.805: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:50.807: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:50.809: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:50.811: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:50.815: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:50.817: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:50.818: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:50.820: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:50.823: INFO: Lookups using dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local]

Dec 28 04:59:55.805: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:55.807: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:55.809: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:55.810: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:55.815: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:55.817: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:55.819: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:55.820: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 04:59:55.824: INFO: Lookups using dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local]

Dec 28 05:00:00.806: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:00.808: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:00.809: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:00.811: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:00.816: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:00.818: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:00.820: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:00.822: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:00.825: INFO: Lookups using dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local]

Dec 28 05:00:05.806: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:05.807: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:05.809: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:05.811: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:05.817: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:05.818: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:05.820: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:05.822: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:05.825: INFO: Lookups using dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local]

Dec 28 05:00:10.805: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:10.807: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:10.809: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:10.811: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:10.816: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:10.818: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:10.820: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:10.821: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local from pod dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874: the server could not find the requested resource (get pods dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874)
Dec 28 05:00:10.825: INFO: Lookups using dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7903.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7903.svc.cluster.local jessie_udp@dns-test-service-2.dns-7903.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7903.svc.cluster.local]

Dec 28 05:00:15.825: INFO: DNS probes using dns-7903/dns-test-23a96b28-3b08-41a9-aa5b-74cb7baa3874 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:00:15.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7903" for this suite.
Dec 28 05:00:21.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:00:21.922: INFO: namespace dns-7903 deletion completed in 6.072137745s

• [SLOW TEST:40.169 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:00:21.923: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-05f9b890-c2b6-4698-8157-56a4162d7d70
STEP: Creating a pod to test consume configMaps
Dec 28 05:00:21.944: INFO: Waiting up to 5m0s for pod "pod-configmaps-cd8185ee-6773-4fde-bf5a-fed0f4953eaa" in namespace "configmap-4766" to be "success or failure"
Dec 28 05:00:21.945: INFO: Pod "pod-configmaps-cd8185ee-6773-4fde-bf5a-fed0f4953eaa": Phase="Pending", Reason="", readiness=false. Elapsed: 1.333936ms
Dec 28 05:00:23.947: INFO: Pod "pod-configmaps-cd8185ee-6773-4fde-bf5a-fed0f4953eaa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003399531s
STEP: Saw pod success
Dec 28 05:00:23.947: INFO: Pod "pod-configmaps-cd8185ee-6773-4fde-bf5a-fed0f4953eaa" satisfied condition "success or failure"
Dec 28 05:00:23.949: INFO: Trying to get logs from node hxx-m-2 pod pod-configmaps-cd8185ee-6773-4fde-bf5a-fed0f4953eaa container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:00:23.965: INFO: Waiting for pod pod-configmaps-cd8185ee-6773-4fde-bf5a-fed0f4953eaa to disappear
Dec 28 05:00:23.966: INFO: Pod pod-configmaps-cd8185ee-6773-4fde-bf5a-fed0f4953eaa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:00:23.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4766" for this suite.
Dec 28 05:00:29.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:00:30.036: INFO: namespace configmap-4766 deletion completed in 6.066942987s

• [SLOW TEST:8.113 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:00:30.036: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 28 05:00:36.067: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1228 05:00:36.067745      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:00:36.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6276" for this suite.
Dec 28 05:00:42.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:00:42.135: INFO: namespace gc-6276 deletion completed in 6.065111999s

• [SLOW TEST:12.099 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:00:42.135: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:00:53.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1079" for this suite.
Dec 28 05:00:59.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:00:59.242: INFO: namespace resourcequota-1079 deletion completed in 6.071853238s

• [SLOW TEST:17.107 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:00:59.242: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:00:59.262: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:01:00.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6710" for this suite.
Dec 28 05:01:06.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:01:06.345: INFO: namespace custom-resource-definition-6710 deletion completed in 6.068115164s

• [SLOW TEST:7.103 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:01:06.346: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-1c6d23e4-2429-47c3-adef-8afc871e53cf in namespace container-probe-9002
Dec 28 05:01:08.369: INFO: Started pod busybox-1c6d23e4-2429-47c3-adef-8afc871e53cf in namespace container-probe-9002
STEP: checking the pod's current state and verifying that restartCount is present
Dec 28 05:01:08.371: INFO: Initial restart count of pod busybox-1c6d23e4-2429-47c3-adef-8afc871e53cf is 0
Dec 28 05:02:02.434: INFO: Restart count of pod container-probe-9002/busybox-1c6d23e4-2429-47c3-adef-8afc871e53cf is now 1 (54.063042575s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:02:02.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9002" for this suite.
Dec 28 05:02:08.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:02:08.511: INFO: namespace container-probe-9002 deletion completed in 6.068728583s

• [SLOW TEST:62.166 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:02:08.511: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-cfd3d908-92ae-490d-9e1e-982bba6dd091
STEP: Creating configMap with name cm-test-opt-upd-89871d5e-ab14-464c-b85f-d5193ca963b8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-cfd3d908-92ae-490d-9e1e-982bba6dd091
STEP: Updating configmap cm-test-opt-upd-89871d5e-ab14-464c-b85f-d5193ca963b8
STEP: Creating configMap with name cm-test-opt-create-ad380ee9-e61e-4247-979f-73aacd498b6c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:02:12.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8146" for this suite.
Dec 28 05:02:24.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:02:24.652: INFO: namespace projected-8146 deletion completed in 12.064246954s

• [SLOW TEST:16.141 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:02:24.652: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:03:24.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8502" for this suite.
Dec 28 05:03:52.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:03:52.746: INFO: namespace container-probe-8502 deletion completed in 28.069869005s

• [SLOW TEST:88.094 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:03:52.747: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:03:52.764: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 28 05:03:56.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-984 create -f -'
Dec 28 05:03:56.771: INFO: stderr: ""
Dec 28 05:03:56.771: INFO: stdout: "e2e-test-crd-publish-openapi-5821-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 28 05:03:56.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-984 delete e2e-test-crd-publish-openapi-5821-crds test-cr'
Dec 28 05:03:56.849: INFO: stderr: ""
Dec 28 05:03:56.849: INFO: stdout: "e2e-test-crd-publish-openapi-5821-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 28 05:03:56.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-984 apply -f -'
Dec 28 05:03:56.983: INFO: stderr: ""
Dec 28 05:03:56.983: INFO: stdout: "e2e-test-crd-publish-openapi-5821-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 28 05:03:56.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-984 delete e2e-test-crd-publish-openapi-5821-crds test-cr'
Dec 28 05:03:57.055: INFO: stderr: ""
Dec 28 05:03:57.055: INFO: stdout: "e2e-test-crd-publish-openapi-5821-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec 28 05:03:57.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 explain e2e-test-crd-publish-openapi-5821-crds'
Dec 28 05:03:57.189: INFO: stderr: ""
Dec 28 05:03:57.189: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5821-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:04:00.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-984" for this suite.
Dec 28 05:04:06.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:04:06.929: INFO: namespace crd-publish-openapi-984 deletion completed in 6.071376122s

• [SLOW TEST:14.183 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:04:06.930: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 28 05:04:08.960: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:04:08.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5678" for this suite.
Dec 28 05:04:14.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:04:15.034: INFO: namespace container-runtime-5678 deletion completed in 6.065480389s

• [SLOW TEST:8.103 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:04:15.034: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec 28 05:04:15.058: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Dec 28 05:04:15.350: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 28 05:04:17.379: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106255, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106255, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106255, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106255, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:04:20.099: INFO: Waited 715.473739ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:04:21.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-7893" for this suite.
Dec 28 05:04:27.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:04:27.255: INFO: namespace aggregator-7893 deletion completed in 6.163383565s

• [SLOW TEST:12.221 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:04:27.255: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:04:27.290: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"fa756cc4-9994-469d-96c6-1d64a76b1caa", Controller:(*bool)(0xc004af9fa2), BlockOwnerDeletion:(*bool)(0xc004af9fa3)}}
Dec 28 05:04:27.293: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"32021fd5-8554-4b41-9a7f-113e7cb7d892", Controller:(*bool)(0xc003dcaaa2), BlockOwnerDeletion:(*bool)(0xc003dcaaa3)}}
Dec 28 05:04:27.303: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"50cce0af-037f-4fb7-b2ae-08b5bee43474", Controller:(*bool)(0xc003dcae0a), BlockOwnerDeletion:(*bool)(0xc003dcae0b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:04:32.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2353" for this suite.
Dec 28 05:04:38.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:04:38.381: INFO: namespace gc-2353 deletion completed in 6.0702942s

• [SLOW TEST:11.125 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:04:38.381: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:04:38.401: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66f97e2f-6713-46a9-8f46-5ad27959b117" in namespace "downward-api-8052" to be "success or failure"
Dec 28 05:04:38.403: INFO: Pod "downwardapi-volume-66f97e2f-6713-46a9-8f46-5ad27959b117": Phase="Pending", Reason="", readiness=false. Elapsed: 1.482737ms
Dec 28 05:04:40.405: INFO: Pod "downwardapi-volume-66f97e2f-6713-46a9-8f46-5ad27959b117": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003452553s
STEP: Saw pod success
Dec 28 05:04:40.405: INFO: Pod "downwardapi-volume-66f97e2f-6713-46a9-8f46-5ad27959b117" satisfied condition "success or failure"
Dec 28 05:04:40.406: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-66f97e2f-6713-46a9-8f46-5ad27959b117 container client-container: <nil>
STEP: delete the pod
Dec 28 05:04:40.424: INFO: Waiting for pod downwardapi-volume-66f97e2f-6713-46a9-8f46-5ad27959b117 to disappear
Dec 28 05:04:40.426: INFO: Pod downwardapi-volume-66f97e2f-6713-46a9-8f46-5ad27959b117 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:04:40.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8052" for this suite.
Dec 28 05:04:46.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:04:46.501: INFO: namespace downward-api-8052 deletion completed in 6.0734267s

• [SLOW TEST:8.120 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:04:46.502: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 28 05:04:46.522: INFO: Waiting up to 5m0s for pod "pod-1d2b2ff2-f4ba-40f0-8bc0-299418ed8e44" in namespace "emptydir-6725" to be "success or failure"
Dec 28 05:04:46.523: INFO: Pod "pod-1d2b2ff2-f4ba-40f0-8bc0-299418ed8e44": Phase="Pending", Reason="", readiness=false. Elapsed: 1.37891ms
Dec 28 05:04:48.526: INFO: Pod "pod-1d2b2ff2-f4ba-40f0-8bc0-299418ed8e44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003570861s
STEP: Saw pod success
Dec 28 05:04:48.526: INFO: Pod "pod-1d2b2ff2-f4ba-40f0-8bc0-299418ed8e44" satisfied condition "success or failure"
Dec 28 05:04:48.527: INFO: Trying to get logs from node hxx-m-2 pod pod-1d2b2ff2-f4ba-40f0-8bc0-299418ed8e44 container test-container: <nil>
STEP: delete the pod
Dec 28 05:04:48.536: INFO: Waiting for pod pod-1d2b2ff2-f4ba-40f0-8bc0-299418ed8e44 to disappear
Dec 28 05:04:48.537: INFO: Pod pod-1d2b2ff2-f4ba-40f0-8bc0-299418ed8e44 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:04:48.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6725" for this suite.
Dec 28 05:04:54.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:04:54.608: INFO: namespace emptydir-6725 deletion completed in 6.068049117s

• [SLOW TEST:8.106 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:04:54.608: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec 28 05:05:04.639: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:05:04.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1228 05:05:04.639313      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2087" for this suite.
Dec 28 05:05:10.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:05:10.708: INFO: namespace gc-2087 deletion completed in 6.067304622s

• [SLOW TEST:16.100 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:05:10.708: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:05:10.728: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b15e864d-45b8-4183-ae11-b3318f9c0567" in namespace "projected-2884" to be "success or failure"
Dec 28 05:05:10.729: INFO: Pod "downwardapi-volume-b15e864d-45b8-4183-ae11-b3318f9c0567": Phase="Pending", Reason="", readiness=false. Elapsed: 1.57887ms
Dec 28 05:05:12.732: INFO: Pod "downwardapi-volume-b15e864d-45b8-4183-ae11-b3318f9c0567": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003849323s
STEP: Saw pod success
Dec 28 05:05:12.732: INFO: Pod "downwardapi-volume-b15e864d-45b8-4183-ae11-b3318f9c0567" satisfied condition "success or failure"
Dec 28 05:05:12.733: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-b15e864d-45b8-4183-ae11-b3318f9c0567 container client-container: <nil>
STEP: delete the pod
Dec 28 05:05:12.743: INFO: Waiting for pod downwardapi-volume-b15e864d-45b8-4183-ae11-b3318f9c0567 to disappear
Dec 28 05:05:12.744: INFO: Pod downwardapi-volume-b15e864d-45b8-4183-ae11-b3318f9c0567 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:05:12.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2884" for this suite.
Dec 28 05:05:18.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:05:18.811: INFO: namespace projected-2884 deletion completed in 6.064504991s

• [SLOW TEST:8.102 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:05:18.811: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-kclw
STEP: Creating a pod to test atomic-volume-subpath
Dec 28 05:05:18.834: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-kclw" in namespace "subpath-482" to be "success or failure"
Dec 28 05:05:18.835: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Pending", Reason="", readiness=false. Elapsed: 1.370944ms
Dec 28 05:05:20.838: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Running", Reason="", readiness=true. Elapsed: 2.00362161s
Dec 28 05:05:22.840: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Running", Reason="", readiness=true. Elapsed: 4.005738722s
Dec 28 05:05:24.842: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Running", Reason="", readiness=true. Elapsed: 6.008178096s
Dec 28 05:05:26.845: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Running", Reason="", readiness=true. Elapsed: 8.010700303s
Dec 28 05:05:28.847: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Running", Reason="", readiness=true. Elapsed: 10.013147522s
Dec 28 05:05:30.850: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Running", Reason="", readiness=true. Elapsed: 12.01562089s
Dec 28 05:05:32.852: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Running", Reason="", readiness=true. Elapsed: 14.017794105s
Dec 28 05:05:34.854: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Running", Reason="", readiness=true. Elapsed: 16.020077251s
Dec 28 05:05:36.856: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Running", Reason="", readiness=true. Elapsed: 18.022284693s
Dec 28 05:05:38.859: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Running", Reason="", readiness=true. Elapsed: 20.024680723s
Dec 28 05:05:40.861: INFO: Pod "pod-subpath-test-configmap-kclw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.026987167s
STEP: Saw pod success
Dec 28 05:05:40.861: INFO: Pod "pod-subpath-test-configmap-kclw" satisfied condition "success or failure"
Dec 28 05:05:40.862: INFO: Trying to get logs from node hxx-m-2 pod pod-subpath-test-configmap-kclw container test-container-subpath-configmap-kclw: <nil>
STEP: delete the pod
Dec 28 05:05:40.873: INFO: Waiting for pod pod-subpath-test-configmap-kclw to disappear
Dec 28 05:05:40.874: INFO: Pod pod-subpath-test-configmap-kclw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-kclw
Dec 28 05:05:40.874: INFO: Deleting pod "pod-subpath-test-configmap-kclw" in namespace "subpath-482"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:05:40.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-482" for this suite.
Dec 28 05:05:46.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:05:46.947: INFO: namespace subpath-482 deletion completed in 6.067949394s

• [SLOW TEST:28.135 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:05:46.947: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-xbjl
STEP: Creating a pod to test atomic-volume-subpath
Dec 28 05:05:46.970: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xbjl" in namespace "subpath-6213" to be "success or failure"
Dec 28 05:05:46.972: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Pending", Reason="", readiness=false. Elapsed: 1.877832ms
Dec 28 05:05:48.974: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Running", Reason="", readiness=true. Elapsed: 2.003934546s
Dec 28 05:05:50.977: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Running", Reason="", readiness=true. Elapsed: 4.006151517s
Dec 28 05:05:52.979: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Running", Reason="", readiness=true. Elapsed: 6.008589546s
Dec 28 05:05:54.981: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Running", Reason="", readiness=true. Elapsed: 8.010866642s
Dec 28 05:05:56.984: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Running", Reason="", readiness=true. Elapsed: 10.013181412s
Dec 28 05:05:58.986: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Running", Reason="", readiness=true. Elapsed: 12.015496823s
Dec 28 05:06:00.994: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Running", Reason="", readiness=true. Elapsed: 14.024040425s
Dec 28 05:06:02.997: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Running", Reason="", readiness=true. Elapsed: 16.026601647s
Dec 28 05:06:04.999: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Running", Reason="", readiness=true. Elapsed: 18.028959937s
Dec 28 05:06:07.002: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Running", Reason="", readiness=true. Elapsed: 20.031202392s
Dec 28 05:06:09.004: INFO: Pod "pod-subpath-test-configmap-xbjl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.033615579s
STEP: Saw pod success
Dec 28 05:06:09.004: INFO: Pod "pod-subpath-test-configmap-xbjl" satisfied condition "success or failure"
Dec 28 05:06:09.006: INFO: Trying to get logs from node hxx-m-2 pod pod-subpath-test-configmap-xbjl container test-container-subpath-configmap-xbjl: <nil>
STEP: delete the pod
Dec 28 05:06:09.015: INFO: Waiting for pod pod-subpath-test-configmap-xbjl to disappear
Dec 28 05:06:09.017: INFO: Pod pod-subpath-test-configmap-xbjl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xbjl
Dec 28 05:06:09.017: INFO: Deleting pod "pod-subpath-test-configmap-xbjl" in namespace "subpath-6213"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:06:09.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6213" for this suite.
Dec 28 05:06:15.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:06:15.087: INFO: namespace subpath-6213 deletion completed in 6.066421281s

• [SLOW TEST:28.141 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:06:15.088: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:06:32.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6870" for this suite.
Dec 28 05:06:38.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:06:38.199: INFO: namespace resourcequota-6870 deletion completed in 6.070194003s

• [SLOW TEST:23.112 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:06:38.200: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8090
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 28 05:06:38.224: INFO: Found 0 stateful pods, waiting for 3
Dec 28 05:06:48.226: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:06:48.226: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:06:48.226: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 28 05:06:48.246: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 28 05:06:58.267: INFO: Updating stateful set ss2
Dec 28 05:06:58.270: INFO: Waiting for Pod statefulset-8090/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec 28 05:07:08.296: INFO: Found 2 stateful pods, waiting for 3
Dec 28 05:07:18.299: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:07:18.299: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:07:18.299: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 28 05:07:18.317: INFO: Updating stateful set ss2
Dec 28 05:07:18.320: INFO: Waiting for Pod statefulset-8090/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 28 05:07:28.339: INFO: Updating stateful set ss2
Dec 28 05:07:28.342: INFO: Waiting for StatefulSet statefulset-8090/ss2 to complete update
Dec 28 05:07:28.342: INFO: Waiting for Pod statefulset-8090/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 28 05:07:38.346: INFO: Waiting for StatefulSet statefulset-8090/ss2 to complete update
Dec 28 05:07:38.346: INFO: Waiting for Pod statefulset-8090/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 28 05:07:48.347: INFO: Deleting all statefulset in ns statefulset-8090
Dec 28 05:07:48.349: INFO: Scaling statefulset ss2 to 0
Dec 28 05:08:08.357: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 05:08:08.358: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:08:08.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8090" for this suite.
Dec 28 05:08:14.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:08:14.438: INFO: namespace statefulset-8090 deletion completed in 6.071581897s

• [SLOW TEST:96.239 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:08:14.438: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 28 05:08:14.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-6005'
Dec 28 05:08:14.652: INFO: stderr: ""
Dec 28 05:08:14.652: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 28 05:08:15.654: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:08:15.654: INFO: Found 0 / 1
Dec 28 05:08:16.654: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:08:16.654: INFO: Found 1 / 1
Dec 28 05:08:16.654: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 28 05:08:16.656: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:08:16.656: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 28 05:08:16.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 patch pod redis-master-7vjqq --namespace=kubectl-6005 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 28 05:08:16.736: INFO: stderr: ""
Dec 28 05:08:16.736: INFO: stdout: "pod/redis-master-7vjqq patched\n"
STEP: checking annotations
Dec 28 05:08:16.738: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:08:16.738: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:08:16.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6005" for this suite.
Dec 28 05:08:28.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:08:28.807: INFO: namespace kubectl-6005 deletion completed in 12.06663443s

• [SLOW TEST:14.369 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:08:28.808: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Dec 28 05:08:28.824: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 28 05:09:28.842: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:09:28.844: INFO: Starting informer...
STEP: Starting pods...
Dec 28 05:09:29.052: INFO: Pod1 is running on hxx-m-2. Tainting Node
Dec 28 05:09:31.263: INFO: Pod2 is running on hxx-m-2. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Dec 28 05:09:37.799: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec 28 05:10:00.931: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:10:00.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-4225" for this suite.
Dec 28 05:10:06.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:10:07.016: INFO: namespace taint-multiple-pods-4225 deletion completed in 6.075701483s

• [SLOW TEST:98.209 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:10:07.017: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 28 05:10:11.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec pod-sharedvolume-e5a2ce31-0e1c-450f-a550-55934fd2da2c -c busybox-main-container --namespace=emptydir-1505 -- cat /usr/share/volumeshare/shareddata.txt'
Dec 28 05:10:11.265: INFO: stderr: ""
Dec 28 05:10:11.265: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:10:11.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1505" for this suite.
Dec 28 05:10:17.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:10:17.338: INFO: namespace emptydir-1505 deletion completed in 6.07011301s

• [SLOW TEST:10.322 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:10:17.338: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 28 05:10:17.358: INFO: Waiting up to 5m0s for pod "pod-7d94f347-d21f-4b79-8af5-18a5d1ff9a9e" in namespace "emptydir-726" to be "success or failure"
Dec 28 05:10:17.359: INFO: Pod "pod-7d94f347-d21f-4b79-8af5-18a5d1ff9a9e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.465939ms
Dec 28 05:10:19.362: INFO: Pod "pod-7d94f347-d21f-4b79-8af5-18a5d1ff9a9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004116016s
STEP: Saw pod success
Dec 28 05:10:19.362: INFO: Pod "pod-7d94f347-d21f-4b79-8af5-18a5d1ff9a9e" satisfied condition "success or failure"
Dec 28 05:10:19.364: INFO: Trying to get logs from node hxx-m-2 pod pod-7d94f347-d21f-4b79-8af5-18a5d1ff9a9e container test-container: <nil>
STEP: delete the pod
Dec 28 05:10:19.380: INFO: Waiting for pod pod-7d94f347-d21f-4b79-8af5-18a5d1ff9a9e to disappear
Dec 28 05:10:19.381: INFO: Pod pod-7d94f347-d21f-4b79-8af5-18a5d1ff9a9e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:10:19.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-726" for this suite.
Dec 28 05:10:25.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:10:25.453: INFO: namespace emptydir-726 deletion completed in 6.069415438s

• [SLOW TEST:8.115 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:10:25.453: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:10:36.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5854" for this suite.
Dec 28 05:10:42.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:10:42.554: INFO: namespace resourcequota-5854 deletion completed in 6.064073794s

• [SLOW TEST:17.101 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:10:42.555: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:10:42.571: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:10:44.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6605" for this suite.
Dec 28 05:11:28.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:11:28.665: INFO: namespace pods-6605 deletion completed in 44.073918621s

• [SLOW TEST:46.111 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:11:28.666: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:11:29.160: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 28 05:11:31.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106689, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106689, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106689, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106689, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:11:34.173: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec 28 05:11:34.185: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:11:34.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4235" for this suite.
Dec 28 05:11:40.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:11:40.265: INFO: namespace webhook-4235 deletion completed in 6.068434448s
STEP: Destroying namespace "webhook-4235-markers" for this suite.
Dec 28 05:11:46.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:11:46.329: INFO: namespace webhook-4235-markers deletion completed in 6.06381368s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.670 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:11:46.336: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:11:46.351: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Creating first CR 
Dec 28 05:11:46.898: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-28T05:11:46Z generation:1 name:name1 resourceVersion:228025 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4e653e37-8b67-4dcc-952b-d69c450d0567] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec 28 05:11:56.901: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-28T05:11:56Z generation:1 name:name2 resourceVersion:228063 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:6e554fdc-e538-43e0-bdec-35001efb7423] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec 28 05:12:06.904: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-28T05:11:46Z generation:2 name:name1 resourceVersion:228098 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4e653e37-8b67-4dcc-952b-d69c450d0567] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec 28 05:12:16.907: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-28T05:11:56Z generation:2 name:name2 resourceVersion:228130 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:6e554fdc-e538-43e0-bdec-35001efb7423] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec 28 05:12:26.911: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-28T05:11:46Z generation:2 name:name1 resourceVersion:228168 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4e653e37-8b67-4dcc-952b-d69c450d0567] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec 28 05:12:36.915: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-28T05:11:56Z generation:2 name:name2 resourceVersion:228205 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:6e554fdc-e538-43e0-bdec-35001efb7423] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:12:47.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4242" for this suite.
Dec 28 05:12:53.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:12:53.492: INFO: namespace crd-watch-4242 deletion completed in 6.067794813s

• [SLOW TEST:67.156 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:12:53.492: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:12:55.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1172" for this suite.
Dec 28 05:13:01.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:13:01.609: INFO: namespace emptydir-wrapper-1172 deletion completed in 6.073190784s

• [SLOW TEST:8.117 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:13:01.609: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:13:02.160: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:13:05.171: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:13:05.174: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:13:06.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2458" for this suite.
Dec 28 05:13:12.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:13:12.429: INFO: namespace crd-webhook-2458 deletion completed in 6.068505697s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:10.827 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:13:12.436: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec 28 05:13:12.452: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:13:16.137: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:13:30.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8524" for this suite.
Dec 28 05:13:36.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:13:36.591: INFO: namespace crd-publish-openapi-8524 deletion completed in 6.066515458s

• [SLOW TEST:24.155 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:13:36.591: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:13:36.841: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 28 05:13:38.846: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106816, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106816, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106816, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713106816, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:13:41.854: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:13:41.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2407" for this suite.
Dec 28 05:13:47.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:13:47.999: INFO: namespace webhook-2407 deletion completed in 6.069454627s
STEP: Destroying namespace "webhook-2407-markers" for this suite.
Dec 28 05:13:54.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:13:54.065: INFO: namespace webhook-2407-markers deletion completed in 6.065815063s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.480 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:13:54.072: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-55a68723-4c01-4b6c-84ee-092e9e494b5f
STEP: Creating a pod to test consume secrets
Dec 28 05:13:54.093: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2494ddf7-da7e-467c-97b3-4cb0180cfd21" in namespace "projected-6038" to be "success or failure"
Dec 28 05:13:54.094: INFO: Pod "pod-projected-secrets-2494ddf7-da7e-467c-97b3-4cb0180cfd21": Phase="Pending", Reason="", readiness=false. Elapsed: 1.828768ms
Dec 28 05:13:56.097: INFO: Pod "pod-projected-secrets-2494ddf7-da7e-467c-97b3-4cb0180cfd21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00416657s
STEP: Saw pod success
Dec 28 05:13:56.097: INFO: Pod "pod-projected-secrets-2494ddf7-da7e-467c-97b3-4cb0180cfd21" satisfied condition "success or failure"
Dec 28 05:13:56.098: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-secrets-2494ddf7-da7e-467c-97b3-4cb0180cfd21 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:13:56.113: INFO: Waiting for pod pod-projected-secrets-2494ddf7-da7e-467c-97b3-4cb0180cfd21 to disappear
Dec 28 05:13:56.115: INFO: Pod pod-projected-secrets-2494ddf7-da7e-467c-97b3-4cb0180cfd21 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:13:56.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6038" for this suite.
Dec 28 05:14:02.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:14:02.184: INFO: namespace projected-6038 deletion completed in 6.066581078s

• [SLOW TEST:8.112 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:14:02.184: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-14222e71-3805-4d12-af54-35b42e1e73ad in namespace container-probe-5126
Dec 28 05:14:04.207: INFO: Started pod liveness-14222e71-3805-4d12-af54-35b42e1e73ad in namespace container-probe-5126
STEP: checking the pod's current state and verifying that restartCount is present
Dec 28 05:14:04.208: INFO: Initial restart count of pod liveness-14222e71-3805-4d12-af54-35b42e1e73ad is 0
Dec 28 05:14:20.228: INFO: Restart count of pod container-probe-5126/liveness-14222e71-3805-4d12-af54-35b42e1e73ad is now 1 (16.019453254s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:14:20.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5126" for this suite.
Dec 28 05:14:26.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:14:26.308: INFO: namespace container-probe-5126 deletion completed in 6.072687809s

• [SLOW TEST:24.124 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:14:26.310: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:14:39.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5843" for this suite.
Dec 28 05:14:45.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:14:45.452: INFO: namespace namespaces-5843 deletion completed in 6.080884748s
STEP: Destroying namespace "nsdeletetest-9511" for this suite.
Dec 28 05:14:45.454: INFO: Namespace nsdeletetest-9511 was already deleted
STEP: Destroying namespace "nsdeletetest-903" for this suite.
Dec 28 05:14:51.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:14:51.524: INFO: namespace nsdeletetest-903 deletion completed in 6.070179939s

• [SLOW TEST:25.214 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:14:51.524: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4547
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 28 05:14:51.541: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 28 05:15:15.583: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.199.2.229:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4547 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:15:15.583: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:15:15.724: INFO: Found all expected endpoints: [netserver-0]
Dec 28 05:15:15.726: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.199.0.58:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4547 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:15:15.726: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:15:15.902: INFO: Found all expected endpoints: [netserver-1]
Dec 28 05:15:15.905: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.199.1.137:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4547 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:15:15.905: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:15:16.056: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:15:16.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4547" for this suite.
Dec 28 05:15:28.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:15:28.125: INFO: namespace pod-network-test-4547 deletion completed in 12.065613423s

• [SLOW TEST:36.601 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:15:28.125: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:15:28.456: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:15:31.468: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:15:31.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6940" for this suite.
Dec 28 05:15:43.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:15:43.571: INFO: namespace webhook-6940 deletion completed in 12.073471471s
STEP: Destroying namespace "webhook-6940-markers" for this suite.
Dec 28 05:15:49.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:15:49.638: INFO: namespace webhook-6940-markers deletion completed in 6.06690484s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.520 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:15:49.645: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1355
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 28 05:15:49.661: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 28 05:16:09.703: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.199.2.230 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1355 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:16:09.703: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:16:10.839: INFO: Found all expected endpoints: [netserver-0]
Dec 28 05:16:10.841: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.199.1.138 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1355 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:16:10.841: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:16:12.059: INFO: Found all expected endpoints: [netserver-1]
Dec 28 05:16:12.061: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.199.0.62 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1355 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:16:12.061: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:16:13.236: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:16:13.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1355" for this suite.
Dec 28 05:16:25.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:16:25.307: INFO: namespace pod-network-test-1355 deletion completed in 12.068747764s

• [SLOW TEST:35.663 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:16:25.308: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-4de73761-ca35-476e-b0e5-5db648a6e7a6
STEP: Creating a pod to test consume configMaps
Dec 28 05:16:25.329: INFO: Waiting up to 5m0s for pod "pod-configmaps-fe43a088-ef83-46b3-96e2-1243a705d2fa" in namespace "configmap-68" to be "success or failure"
Dec 28 05:16:25.330: INFO: Pod "pod-configmaps-fe43a088-ef83-46b3-96e2-1243a705d2fa": Phase="Pending", Reason="", readiness=false. Elapsed: 1.338001ms
Dec 28 05:16:27.332: INFO: Pod "pod-configmaps-fe43a088-ef83-46b3-96e2-1243a705d2fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003535255s
STEP: Saw pod success
Dec 28 05:16:27.332: INFO: Pod "pod-configmaps-fe43a088-ef83-46b3-96e2-1243a705d2fa" satisfied condition "success or failure"
Dec 28 05:16:27.334: INFO: Trying to get logs from node hxx-m-2 pod pod-configmaps-fe43a088-ef83-46b3-96e2-1243a705d2fa container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:16:27.350: INFO: Waiting for pod pod-configmaps-fe43a088-ef83-46b3-96e2-1243a705d2fa to disappear
Dec 28 05:16:27.351: INFO: Pod pod-configmaps-fe43a088-ef83-46b3-96e2-1243a705d2fa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:16:27.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-68" for this suite.
Dec 28 05:16:33.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:16:33.419: INFO: namespace configmap-68 deletion completed in 6.065856144s

• [SLOW TEST:8.112 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:16:33.420: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 28 05:16:33.438: INFO: Waiting up to 5m0s for pod "pod-33234993-6f0d-4d28-a1ab-9e138731f734" in namespace "emptydir-7784" to be "success or failure"
Dec 28 05:16:33.441: INFO: Pod "pod-33234993-6f0d-4d28-a1ab-9e138731f734": Phase="Pending", Reason="", readiness=false. Elapsed: 2.689801ms
Dec 28 05:16:35.443: INFO: Pod "pod-33234993-6f0d-4d28-a1ab-9e138731f734": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005025047s
STEP: Saw pod success
Dec 28 05:16:35.443: INFO: Pod "pod-33234993-6f0d-4d28-a1ab-9e138731f734" satisfied condition "success or failure"
Dec 28 05:16:35.445: INFO: Trying to get logs from node hxx-m-2 pod pod-33234993-6f0d-4d28-a1ab-9e138731f734 container test-container: <nil>
STEP: delete the pod
Dec 28 05:16:35.454: INFO: Waiting for pod pod-33234993-6f0d-4d28-a1ab-9e138731f734 to disappear
Dec 28 05:16:35.455: INFO: Pod pod-33234993-6f0d-4d28-a1ab-9e138731f734 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:16:35.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7784" for this suite.
Dec 28 05:16:41.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:16:41.525: INFO: namespace emptydir-7784 deletion completed in 6.067184566s

• [SLOW TEST:8.106 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:16:41.525: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-d8c136a1-a1c3-43ff-8f9c-037f2989b56c
STEP: Creating a pod to test consume secrets
Dec 28 05:16:41.547: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-de45dc34-0ab8-4588-8705-f00b2fb790f0" in namespace "projected-6259" to be "success or failure"
Dec 28 05:16:41.548: INFO: Pod "pod-projected-secrets-de45dc34-0ab8-4588-8705-f00b2fb790f0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.437564ms
Dec 28 05:16:43.550: INFO: Pod "pod-projected-secrets-de45dc34-0ab8-4588-8705-f00b2fb790f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003501519s
STEP: Saw pod success
Dec 28 05:16:43.550: INFO: Pod "pod-projected-secrets-de45dc34-0ab8-4588-8705-f00b2fb790f0" satisfied condition "success or failure"
Dec 28 05:16:43.552: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-secrets-de45dc34-0ab8-4588-8705-f00b2fb790f0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:16:43.561: INFO: Waiting for pod pod-projected-secrets-de45dc34-0ab8-4588-8705-f00b2fb790f0 to disappear
Dec 28 05:16:43.563: INFO: Pod pod-projected-secrets-de45dc34-0ab8-4588-8705-f00b2fb790f0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:16:43.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6259" for this suite.
Dec 28 05:16:49.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:16:49.639: INFO: namespace projected-6259 deletion completed in 6.073073022s

• [SLOW TEST:8.114 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:16:49.639: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:16:49.656: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 28 05:16:53.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-3045 create -f -'
Dec 28 05:16:53.655: INFO: stderr: ""
Dec 28 05:16:53.655: INFO: stdout: "e2e-test-crd-publish-openapi-8862-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 28 05:16:53.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-3045 delete e2e-test-crd-publish-openapi-8862-crds test-cr'
Dec 28 05:16:53.731: INFO: stderr: ""
Dec 28 05:16:53.731: INFO: stdout: "e2e-test-crd-publish-openapi-8862-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 28 05:16:53.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-3045 apply -f -'
Dec 28 05:16:53.872: INFO: stderr: ""
Dec 28 05:16:53.872: INFO: stdout: "e2e-test-crd-publish-openapi-8862-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 28 05:16:53.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-3045 delete e2e-test-crd-publish-openapi-8862-crds test-cr'
Dec 28 05:16:53.947: INFO: stderr: ""
Dec 28 05:16:53.947: INFO: stdout: "e2e-test-crd-publish-openapi-8862-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 28 05:16:53.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 explain e2e-test-crd-publish-openapi-8862-crds'
Dec 28 05:16:54.080: INFO: stderr: ""
Dec 28 05:16:54.080: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8862-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:16:57.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3045" for this suite.
Dec 28 05:17:03.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:17:03.815: INFO: namespace crd-publish-openapi-3045 deletion completed in 6.069342476s

• [SLOW TEST:14.176 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:17:03.815: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7271, will wait for the garbage collector to delete the pods
Dec 28 05:17:05.891: INFO: Deleting Job.batch foo took: 3.560524ms
Dec 28 05:17:06.691: INFO: Terminating Job.batch foo pods took: 800.19698ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:17:50.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7271" for this suite.
Dec 28 05:17:57.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:17:57.066: INFO: namespace job-7271 deletion completed in 6.07012051s

• [SLOW TEST:53.250 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:17:57.066: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:17:57.602: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:18:00.612: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec 28 05:18:02.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 attach --namespace=webhook-7693 to-be-attached-pod -i -c=container1'
Dec 28 05:18:02.713: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:18:02.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7693" for this suite.
Dec 28 05:18:14.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:18:14.788: INFO: namespace webhook-7693 deletion completed in 12.068142461s
STEP: Destroying namespace "webhook-7693-markers" for this suite.
Dec 28 05:18:20.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:18:20.858: INFO: namespace webhook-7693-markers deletion completed in 6.070026156s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.799 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:18:20.865: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Dec 28 05:18:20.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-3828'
Dec 28 05:18:21.078: INFO: stderr: ""
Dec 28 05:18:21.078: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 05:18:21.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3828'
Dec 28 05:18:21.157: INFO: stderr: ""
Dec 28 05:18:21.157: INFO: stdout: "update-demo-nautilus-hxpxg update-demo-nautilus-m67q7 "
Dec 28 05:18:21.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-hxpxg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3828'
Dec 28 05:18:21.232: INFO: stderr: ""
Dec 28 05:18:21.232: INFO: stdout: ""
Dec 28 05:18:21.232: INFO: update-demo-nautilus-hxpxg is created but not running
Dec 28 05:18:26.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3828'
Dec 28 05:18:26.313: INFO: stderr: ""
Dec 28 05:18:26.313: INFO: stdout: "update-demo-nautilus-hxpxg update-demo-nautilus-m67q7 "
Dec 28 05:18:26.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-hxpxg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3828'
Dec 28 05:18:26.379: INFO: stderr: ""
Dec 28 05:18:26.379: INFO: stdout: "true"
Dec 28 05:18:26.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-hxpxg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3828'
Dec 28 05:18:26.450: INFO: stderr: ""
Dec 28 05:18:26.450: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 05:18:26.450: INFO: validating pod update-demo-nautilus-hxpxg
Dec 28 05:18:26.452: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 05:18:26.452: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 05:18:26.452: INFO: update-demo-nautilus-hxpxg is verified up and running
Dec 28 05:18:26.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-m67q7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3828'
Dec 28 05:18:26.523: INFO: stderr: ""
Dec 28 05:18:26.523: INFO: stdout: "true"
Dec 28 05:18:26.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-nautilus-m67q7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3828'
Dec 28 05:18:26.595: INFO: stderr: ""
Dec 28 05:18:26.595: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 05:18:26.595: INFO: validating pod update-demo-nautilus-m67q7
Dec 28 05:18:26.599: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 05:18:26.599: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 05:18:26.599: INFO: update-demo-nautilus-m67q7 is verified up and running
STEP: rolling-update to new replication controller
Dec 28 05:18:26.600: INFO: scanned /root for discovery docs: <nil>
Dec 28 05:18:26.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3828'
Dec 28 05:18:48.870: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 28 05:18:48.870: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 05:18:48.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3828'
Dec 28 05:18:48.938: INFO: stderr: ""
Dec 28 05:18:48.938: INFO: stdout: "update-demo-kitten-7z4sk update-demo-kitten-9tvdh "
Dec 28 05:18:48.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-kitten-7z4sk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3828'
Dec 28 05:18:49.011: INFO: stderr: ""
Dec 28 05:18:49.011: INFO: stdout: "true"
Dec 28 05:18:49.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-kitten-7z4sk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3828'
Dec 28 05:18:49.080: INFO: stderr: ""
Dec 28 05:18:49.080: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 28 05:18:49.080: INFO: validating pod update-demo-kitten-7z4sk
Dec 28 05:18:49.082: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 28 05:18:49.082: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 28 05:18:49.082: INFO: update-demo-kitten-7z4sk is verified up and running
Dec 28 05:18:49.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-kitten-9tvdh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3828'
Dec 28 05:18:49.153: INFO: stderr: ""
Dec 28 05:18:49.153: INFO: stdout: "true"
Dec 28 05:18:49.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods update-demo-kitten-9tvdh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3828'
Dec 28 05:18:49.225: INFO: stderr: ""
Dec 28 05:18:49.225: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 28 05:18:49.225: INFO: validating pod update-demo-kitten-9tvdh
Dec 28 05:18:49.228: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 28 05:18:49.228: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 28 05:18:49.228: INFO: update-demo-kitten-9tvdh is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:18:49.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3828" for this suite.
Dec 28 05:19:01.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:19:01.302: INFO: namespace kubectl-3828 deletion completed in 12.071510993s

• [SLOW TEST:40.437 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:19:01.302: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 28 05:19:01.323: INFO: Waiting up to 5m0s for pod "downward-api-b361c8ff-81cc-4fc7-bd80-181523c9a39e" in namespace "downward-api-3208" to be "success or failure"
Dec 28 05:19:01.329: INFO: Pod "downward-api-b361c8ff-81cc-4fc7-bd80-181523c9a39e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.592614ms
Dec 28 05:19:03.331: INFO: Pod "downward-api-b361c8ff-81cc-4fc7-bd80-181523c9a39e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007621695s
STEP: Saw pod success
Dec 28 05:19:03.331: INFO: Pod "downward-api-b361c8ff-81cc-4fc7-bd80-181523c9a39e" satisfied condition "success or failure"
Dec 28 05:19:03.332: INFO: Trying to get logs from node hxx-m-2 pod downward-api-b361c8ff-81cc-4fc7-bd80-181523c9a39e container dapi-container: <nil>
STEP: delete the pod
Dec 28 05:19:03.353: INFO: Waiting for pod downward-api-b361c8ff-81cc-4fc7-bd80-181523c9a39e to disappear
Dec 28 05:19:03.355: INFO: Pod downward-api-b361c8ff-81cc-4fc7-bd80-181523c9a39e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:19:03.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3208" for this suite.
Dec 28 05:19:09.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:19:09.429: INFO: namespace downward-api-3208 deletion completed in 6.071283563s

• [SLOW TEST:8.127 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:19:09.429: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7133.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7133.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 28 05:19:11.469: INFO: DNS probes using dns-7133/dns-test-0ecedee6-a991-44a8-a70e-40c4ba185067 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:19:11.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7133" for this suite.
Dec 28 05:19:17.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:19:17.549: INFO: namespace dns-7133 deletion completed in 6.071955665s

• [SLOW TEST:8.120 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:19:17.549: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:19:17.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2015" for this suite.
Dec 28 05:19:23.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:19:23.639: INFO: namespace custom-resource-definition-2015 deletion completed in 6.065053583s

• [SLOW TEST:6.090 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:19:23.639: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-0a9cc4be-62be-4960-b581-bf842a1652b7
STEP: Creating a pod to test consume configMaps
Dec 28 05:19:23.660: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9de7a0df-7d0d-46e1-b7ea-0fb73a07566b" in namespace "projected-1822" to be "success or failure"
Dec 28 05:19:23.662: INFO: Pod "pod-projected-configmaps-9de7a0df-7d0d-46e1-b7ea-0fb73a07566b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.45104ms
Dec 28 05:19:25.664: INFO: Pod "pod-projected-configmaps-9de7a0df-7d0d-46e1-b7ea-0fb73a07566b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003995775s
STEP: Saw pod success
Dec 28 05:19:25.664: INFO: Pod "pod-projected-configmaps-9de7a0df-7d0d-46e1-b7ea-0fb73a07566b" satisfied condition "success or failure"
Dec 28 05:19:25.665: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-configmaps-9de7a0df-7d0d-46e1-b7ea-0fb73a07566b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:19:25.675: INFO: Waiting for pod pod-projected-configmaps-9de7a0df-7d0d-46e1-b7ea-0fb73a07566b to disappear
Dec 28 05:19:25.677: INFO: Pod pod-projected-configmaps-9de7a0df-7d0d-46e1-b7ea-0fb73a07566b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:19:25.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1822" for this suite.
Dec 28 05:19:31.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:19:31.746: INFO: namespace projected-1822 deletion completed in 6.066588876s

• [SLOW TEST:8.107 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:19:31.746: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 28 05:19:31.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3092'
Dec 28 05:19:31.844: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 28 05:19:31.844: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Dec 28 05:19:31.849: INFO: scanned /root for discovery docs: <nil>
Dec 28 05:19:31.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-3092'
Dec 28 05:19:47.593: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 28 05:19:47.593: INFO: stdout: "Created e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da\nScaling up e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Dec 28 05:19:47.593: INFO: stdout: "Created e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da\nScaling up e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Dec 28 05:19:47.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-3092'
Dec 28 05:19:47.668: INFO: stderr: ""
Dec 28 05:19:47.668: INFO: stdout: "e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da-dv2cg "
Dec 28 05:19:47.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da-dv2cg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3092'
Dec 28 05:19:47.749: INFO: stderr: ""
Dec 28 05:19:47.749: INFO: stdout: "true"
Dec 28 05:19:47.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pods e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da-dv2cg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3092'
Dec 28 05:19:47.831: INFO: stderr: ""
Dec 28 05:19:47.831: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Dec 28 05:19:47.831: INFO: e2e-test-httpd-rc-a5c2fa72453217bba7a068e366b066da-dv2cg is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Dec 28 05:19:47.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete rc e2e-test-httpd-rc --namespace=kubectl-3092'
Dec 28 05:19:47.905: INFO: stderr: ""
Dec 28 05:19:47.905: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:19:47.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3092" for this suite.
Dec 28 05:19:53.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:19:53.977: INFO: namespace kubectl-3092 deletion completed in 6.067688268s

• [SLOW TEST:22.231 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:19:53.977: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4454.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4454.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4454.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4454.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4454.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4454.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 28 05:19:56.017: INFO: DNS probes using dns-4454/dns-test-ffae648e-af93-4472-9d95-4c72ecb51dab succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:19:56.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4454" for this suite.
Dec 28 05:20:02.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:20:02.095: INFO: namespace dns-4454 deletion completed in 6.070432336s

• [SLOW TEST:8.118 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:20:02.096: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec 28 05:20:04.124: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-505712781 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 28 05:20:14.197: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:20:14.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6174" for this suite.
Dec 28 05:20:20.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:20:20.268: INFO: namespace pods-6174 deletion completed in 6.067204828s

• [SLOW TEST:18.173 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:20:20.268: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:20:27.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3202" for this suite.
Dec 28 05:20:33.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:20:33.361: INFO: namespace resourcequota-3202 deletion completed in 6.066611791s

• [SLOW TEST:13.093 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:20:33.361: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-57e95f0b-43de-477a-8d1a-eb00f36637ab
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:20:35.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-569" for this suite.
Dec 28 05:20:53.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:20:53.468: INFO: namespace configmap-569 deletion completed in 18.066683168s

• [SLOW TEST:20.107 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:20:53.468: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:20:53.488: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 28 05:20:58.491: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 28 05:20:58.491: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 28 05:20:58.500: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-1007 /apis/apps/v1/namespaces/deployment-1007/deployments/test-cleanup-deployment 6a2f38ab-f882-4fcf-95fe-fcc49f73335e 231169 1 2019-12-28 05:20:58 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0026d0098 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Dec 28 05:20:58.504: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-1007 /apis/apps/v1/namespaces/deployment-1007/replicasets/test-cleanup-deployment-65db99849b c5f57485-c982-40b8-a8d9-b006d827220a 231171 1 2019-12-28 05:20:58 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 6a2f38ab-f882-4fcf-95fe-fcc49f73335e 0xc0026d04e7 0xc0026d04e8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0026d0548 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 28 05:20:58.504: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 28 05:20:58.504: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-1007 /apis/apps/v1/namespaces/deployment-1007/replicasets/test-cleanup-controller 319de884-2c62-4b54-a14a-df91c01e17b3 231170 1 2019-12-28 05:20:53 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 6a2f38ab-f882-4fcf-95fe-fcc49f73335e 0xc0026d0417 0xc0026d0418}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0026d0478 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 28 05:20:58.506: INFO: Pod "test-cleanup-controller-wqcg5" is available:
&Pod{ObjectMeta:{test-cleanup-controller-wqcg5 test-cleanup-controller- deployment-1007 /api/v1/namespaces/deployment-1007/pods/test-cleanup-controller-wqcg5 f5e88b9f-5436-4731-8e19-b420cbd02e76 231152 0 2019-12-28 05:20:53 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 319de884-2c62-4b54-a14a-df91c01e17b3 0xc0026d09b7 0xc0026d09b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qvrqp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qvrqp,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qvrqp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:20:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:20:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:20:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:20:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.16,PodIP:10.199.0.81,StartTime:2019-12-28 05:20:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 05:20:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://11dc4d0cc41b86f6418703566c2f069dc13d77bf5c14eeca448b2d4c6a1f02aa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.0.81,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 28 05:20:58.506: INFO: Pod "test-cleanup-deployment-65db99849b-472pd" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-472pd test-cleanup-deployment-65db99849b- deployment-1007 /api/v1/namespaces/deployment-1007/pods/test-cleanup-deployment-65db99849b-472pd 330f6b0b-5fc2-44f1-ac7b-ee1e23e9f2fd 231172 0 2019-12-28 05:20:58 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b c5f57485-c982-40b8-a8d9-b006d827220a 0xc0026d0b47 0xc0026d0b48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qvrqp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qvrqp,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qvrqp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:20:58.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1007" for this suite.
Dec 28 05:21:04.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:21:04.579: INFO: namespace deployment-1007 deletion completed in 6.068919046s

• [SLOW TEST:11.111 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:21:04.579: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:21:04.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5264" for this suite.
Dec 28 05:21:10.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:21:10.677: INFO: namespace resourcequota-5264 deletion completed in 6.068193573s

• [SLOW TEST:6.098 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:21:10.677: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7332.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7332.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7332.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7332.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7332.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7332.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 28 05:21:12.719: INFO: DNS probes using dns-7332/dns-test-6848ccb1-349f-4017-abc9-dccea7199d6e succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:21:12.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7332" for this suite.
Dec 28 05:21:18.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:21:18.814: INFO: namespace dns-7332 deletion completed in 6.079595074s

• [SLOW TEST:8.137 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:21:18.814: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-5acdad42-ba0f-4f34-bc4b-2b1764cd739a
STEP: Creating a pod to test consume configMaps
Dec 28 05:21:18.836: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-49df95b4-40e2-4f3a-904a-c0e9530ab6b7" in namespace "projected-5507" to be "success or failure"
Dec 28 05:21:18.838: INFO: Pod "pod-projected-configmaps-49df95b4-40e2-4f3a-904a-c0e9530ab6b7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.491357ms
Dec 28 05:21:20.840: INFO: Pod "pod-projected-configmaps-49df95b4-40e2-4f3a-904a-c0e9530ab6b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003670248s
STEP: Saw pod success
Dec 28 05:21:20.840: INFO: Pod "pod-projected-configmaps-49df95b4-40e2-4f3a-904a-c0e9530ab6b7" satisfied condition "success or failure"
Dec 28 05:21:20.841: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-configmaps-49df95b4-40e2-4f3a-904a-c0e9530ab6b7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:21:20.851: INFO: Waiting for pod pod-projected-configmaps-49df95b4-40e2-4f3a-904a-c0e9530ab6b7 to disappear
Dec 28 05:21:20.852: INFO: Pod pod-projected-configmaps-49df95b4-40e2-4f3a-904a-c0e9530ab6b7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:21:20.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5507" for this suite.
Dec 28 05:21:26.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:21:26.922: INFO: namespace projected-5507 deletion completed in 6.066838665s

• [SLOW TEST:8.108 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:21:26.922: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 28 05:21:29.453: INFO: Successfully updated pod "pod-update-15c2536f-92c8-4675-ae53-4727b2d62d90"
STEP: verifying the updated pod is in kubernetes
Dec 28 05:21:29.456: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:21:29.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9138" for this suite.
Dec 28 05:21:57.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:21:57.528: INFO: namespace pods-9138 deletion completed in 28.06943269s

• [SLOW TEST:30.606 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:21:57.528: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:22:00.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6124" for this suite.
Dec 28 05:22:12.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:22:12.630: INFO: namespace replication-controller-6124 deletion completed in 12.070119017s

• [SLOW TEST:15.102 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:22:12.630: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 28 05:22:12.651: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-a 1ab59de5-37a4-4ab3-95c7-f94c75a33043 231609 0 2019-12-28 05:22:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 28 05:22:12.651: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-a 1ab59de5-37a4-4ab3-95c7-f94c75a33043 231609 0 2019-12-28 05:22:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 28 05:22:22.656: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-a 1ab59de5-37a4-4ab3-95c7-f94c75a33043 231645 0 2019-12-28 05:22:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 28 05:22:22.656: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-a 1ab59de5-37a4-4ab3-95c7-f94c75a33043 231645 0 2019-12-28 05:22:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 28 05:22:32.660: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-a 1ab59de5-37a4-4ab3-95c7-f94c75a33043 231680 0 2019-12-28 05:22:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 28 05:22:32.660: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-a 1ab59de5-37a4-4ab3-95c7-f94c75a33043 231680 0 2019-12-28 05:22:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 28 05:22:42.664: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-a 1ab59de5-37a4-4ab3-95c7-f94c75a33043 231715 0 2019-12-28 05:22:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 28 05:22:42.664: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-a 1ab59de5-37a4-4ab3-95c7-f94c75a33043 231715 0 2019-12-28 05:22:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 28 05:22:52.668: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-b 67633df0-69c8-4a08-bc33-bdee30c7b03d 231751 0 2019-12-28 05:22:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 28 05:22:52.668: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-b 67633df0-69c8-4a08-bc33-bdee30c7b03d 231751 0 2019-12-28 05:22:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 28 05:23:02.672: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-b 67633df0-69c8-4a08-bc33-bdee30c7b03d 231786 0 2019-12-28 05:22:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 28 05:23:02.672: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8478 /api/v1/namespaces/watch-8478/configmaps/e2e-watch-test-configmap-b 67633df0-69c8-4a08-bc33-bdee30c7b03d 231786 0 2019-12-28 05:22:52 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:23:12.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8478" for this suite.
Dec 28 05:23:18.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:23:18.746: INFO: namespace watch-8478 deletion completed in 6.070829149s

• [SLOW TEST:66.117 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:23:18.747: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Dec 28 05:23:18.766: INFO: Waiting up to 5m0s for pod "client-containers-5c68e10f-e6da-434b-b443-5a77f2f6393b" in namespace "containers-3410" to be "success or failure"
Dec 28 05:23:18.768: INFO: Pod "client-containers-5c68e10f-e6da-434b-b443-5a77f2f6393b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.435676ms
Dec 28 05:23:20.770: INFO: Pod "client-containers-5c68e10f-e6da-434b-b443-5a77f2f6393b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003531615s
STEP: Saw pod success
Dec 28 05:23:20.770: INFO: Pod "client-containers-5c68e10f-e6da-434b-b443-5a77f2f6393b" satisfied condition "success or failure"
Dec 28 05:23:20.772: INFO: Trying to get logs from node hxx-m-2 pod client-containers-5c68e10f-e6da-434b-b443-5a77f2f6393b container test-container: <nil>
STEP: delete the pod
Dec 28 05:23:20.788: INFO: Waiting for pod client-containers-5c68e10f-e6da-434b-b443-5a77f2f6393b to disappear
Dec 28 05:23:20.789: INFO: Pod client-containers-5c68e10f-e6da-434b-b443-5a77f2f6393b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:23:20.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3410" for this suite.
Dec 28 05:23:26.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:23:26.859: INFO: namespace containers-3410 deletion completed in 6.067355077s

• [SLOW TEST:8.113 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:23:26.860: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:23:42.883: INFO: Container started at 2019-12-28 05:23:27 +0000 UTC, pod became ready at 2019-12-28 05:23:42 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:23:42.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5966" for this suite.
Dec 28 05:24:10.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:24:10.958: INFO: namespace container-probe-5966 deletion completed in 28.072103928s

• [SLOW TEST:44.098 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:24:10.958: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 28 05:24:12.989: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:24:12.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5740" for this suite.
Dec 28 05:24:19.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:24:19.070: INFO: namespace container-runtime-5740 deletion completed in 6.072234419s

• [SLOW TEST:8.111 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:24:19.070: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:24:19.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-167'
Dec 28 05:24:19.231: INFO: stderr: ""
Dec 28 05:24:19.231: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 28 05:24:19.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-167'
Dec 28 05:24:19.372: INFO: stderr: ""
Dec 28 05:24:19.372: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 28 05:24:20.374: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:24:20.374: INFO: Found 1 / 1
Dec 28 05:24:20.374: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 28 05:24:20.376: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:24:20.376: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 28 05:24:20.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 describe pod redis-master-6cr9f --namespace=kubectl-167'
Dec 28 05:24:20.457: INFO: stderr: ""
Dec 28 05:24:20.457: INFO: stdout: "Name:         redis-master-6cr9f\nNamespace:    kubectl-167\nPriority:     0\nNode:         hxx-m-2/10.0.128.16\nStart Time:   Sat, 28 Dec 2019 05:24:19 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.199.0.90\nIPs:\n  IP:           10.199.0.90\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://08cb4d6b454acce281d8c82aa7327dbe01451fee58358b722f4d182d04ed73c5\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 28 Dec 2019 05:24:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-55tdw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-55tdw:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-55tdw\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-167/redis-master-6cr9f to hxx-m-2\n  Normal  Pulled     1s    kubelet, hxx-m-2   Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s    kubelet, hxx-m-2   Created container redis-master\n  Normal  Started    0s    kubelet, hxx-m-2   Started container redis-master\n"
Dec 28 05:24:20.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 describe rc redis-master --namespace=kubectl-167'
Dec 28 05:24:20.544: INFO: stderr: ""
Dec 28 05:24:20.544: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-167\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: redis-master-6cr9f\n"
Dec 28 05:24:20.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 describe service redis-master --namespace=kubectl-167'
Dec 28 05:24:20.622: INFO: stderr: ""
Dec 28 05:24:20.622: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-167\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.97.42.153\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.199.0.90:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 28 05:24:20.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 describe node hxx-m-1'
Dec 28 05:24:20.718: INFO: stderr: ""
Dec 28 05:24:20.718: INFO: stdout: "Name:               hxx-m-1\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    global=true\n                    ingress=false\n                    ip=10.0.128.42\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=hxx-m-1\n                    kubernetes.io/os=linux\n                    log=true\n                    node-role.kubernetes.io/node=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"de:eb:10:d3:14:86\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.128.42\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 27 Dec 2019 13:58:01 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 28 Dec 2019 05:23:32 +0000   Fri, 27 Dec 2019 13:58:01 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 28 Dec 2019 05:23:32 +0000   Fri, 27 Dec 2019 13:58:01 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 28 Dec 2019 05:23:32 +0000   Fri, 27 Dec 2019 13:58:01 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 28 Dec 2019 05:23:32 +0000   Fri, 27 Dec 2019 13:58:21 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.128.42\n  Hostname:    hxx-m-1\nCapacity:\n cpu:                8\n ephemeral-storage:  51473868Ki\n hugepages-2Mi:      0\n memory:             16265872Ki\n pods:               110\nAllocatable:\n cpu:                8\n ephemeral-storage:  47438316671\n hugepages-2Mi:      0\n memory:             16163472Ki\n pods:               110\nSystem Info:\n Machine ID:                 0ea734564f9a4e2881b866b82d679dfc\n System UUID:                76729676-2E42-4F05-9CDD-C6D412C7234C\n Boot ID:                    c2d146bd-96ba-47db-a038-25cbe99666d4\n Kernel Version:             3.10.0-957.21.3.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.9\n Kubelet Version:            v1.16.3\n Kube-Proxy Version:         v1.16.3\nPodCIDR:                     10.199.2.0/24\nPodCIDRs:                    10.199.2.0/24\nNon-terminated Pods:         (17 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  cert-manager               cert-manager-77f5bf4f5-h86rt                               10m (0%)      100m (1%)   32Mi (0%)        128Mi (0%)     15h\n  cert-manager               cert-manager-cainjector-67d4dd59ff-8jhs9                   10m (0%)      100m (1%)   32Mi (0%)        128Mi (0%)     15h\n  cert-manager               cert-manager-webhook-578c59dddd-k697c                      10m (0%)      100m (1%)   32Mi (0%)        128Mi (0%)     15h\n  cpaas-system               agon-75b987dff5-7bht5                                      256m (3%)     2 (25%)     512Mi (3%)       4Gi (25%)      15h\n  cpaas-system               apollo-cfdd64bb4-4lssk                                     256m (3%)     2 (25%)     512Mi (3%)       4Gi (25%)      15h\n  cpaas-system               archon-5fdc59d78c-rhtzm                                    256m (3%)     2 (25%)     512Mi (3%)       4Gi (25%)      15h\n  cpaas-system               auth-controller2-79ff55cd75-cbjbn                          256m (3%)     2 (25%)     512Mi (3%)       4Gi (25%)      15h\n  cpaas-system               cluster-registry-controller-manager-76774c98d-7c7mz        512m (6%)     4 (50%)     1Gi (6%)         8Gi (51%)      15h\n  cpaas-system               dex-8448b48ff8-2bd5h                                       256m (3%)     2 (25%)     512Mi (3%)       4Gi (25%)      15h\n  cpaas-system               erebus-5597f9565d-zwjnz                                    256m (3%)     2 (25%)     512Mi (3%)       4Gi (25%)      15h\n  cpaas-system               furion-679c948779-jz6lf                                    256m (3%)     2 (25%)     512Mi (3%)       4Gi (25%)      15h\n  cpaas-system               underlord-5c45b96c5d-nmjjq                                 256m (3%)     2 (25%)     512Mi (3%)       4Gi (25%)      14h\n  kube-system                coredns-66447b44c9-zphmm                                   100m (1%)     0 (0%)      70Mi (0%)        170Mi (1%)     15h\n  kube-system                kube-flannel-8hgpf                                         50m (0%)      300m (3%)   64M (0%)         500M (3%)      15h\n  kube-system                kube-proxy-bnhj6                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         15h\n  sonobuoy                   sonobuoy-e2e-job-af99efc4f7ea449a                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         68m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-lzsqv    0 (0%)        0 (0%)      0 (0%)           0 (0%)         68m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests         Limits\n  --------           --------         ------\n  cpu                2740m (34%)      20600m (257%)\n  memory             5475364Ki (33%)  44030584064 (266%)\n  ephemeral-storage  0 (0%)           0 (0%)\nEvents:              <none>\n"
Dec 28 05:24:20.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 describe namespace kubectl-167'
Dec 28 05:24:20.797: INFO: stderr: ""
Dec 28 05:24:20.798: INFO: stdout: "Name:         kubectl-167\nLabels:       e2e-framework=kubectl\n              e2e-run=535d0e95-1b92-4b2b-bc7e-376d8e5e7513\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:24:20.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-167" for this suite.
Dec 28 05:24:32.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:24:32.868: INFO: namespace kubectl-167 deletion completed in 12.067817191s

• [SLOW TEST:13.798 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:24:32.868: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 28 05:24:34.895: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:24:34.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6809" for this suite.
Dec 28 05:24:40.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:24:40.973: INFO: namespace container-runtime-6809 deletion completed in 6.069998218s

• [SLOW TEST:8.105 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:24:40.974: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:24:41.469: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 28 05:24:43.475: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713107481, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713107481, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713107481, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713107481, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:24:46.483: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:24:46.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8303" for this suite.
Dec 28 05:24:52.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:24:52.573: INFO: namespace webhook-8303 deletion completed in 6.069326602s
STEP: Destroying namespace "webhook-8303-markers" for this suite.
Dec 28 05:24:58.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:24:58.638: INFO: namespace webhook-8303-markers deletion completed in 6.065690784s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.671 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:24:58.645: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Dec 28 05:24:58.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 api-versions'
Dec 28 05:24:58.730: INFO: stderr: ""
Dec 28 05:24:58.730: INFO: stdout: "ace3.alauda.io/v1\nadmission.certmanager.k8s.io/v1beta1\nadmissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\naiops.alauda.io/v1beta1\nalauda.io/v1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauth.alauda.io/v1\nauth.alauda.io/v1beta1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncertmanager.k8s.io/v1alpha1\nclusterregistry.k8s.io/v1alpha1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.alauda.io/v2\ndex.coreos.com/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nportal.alauda.io/v1alpha1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:24:58.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2508" for this suite.
Dec 28 05:25:04.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:25:04.802: INFO: namespace kubectl-2508 deletion completed in 6.069837997s

• [SLOW TEST:6.157 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:25:04.802: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7107
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 28 05:25:04.818: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 28 05:25:24.865: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.199.0.94:8080/dial?request=hostName&protocol=udp&host=10.199.2.232&port=8081&tries=1'] Namespace:pod-network-test-7107 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:25:24.865: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:25:25.011: INFO: Waiting for endpoints: map[]
Dec 28 05:25:25.014: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.199.0.94:8080/dial?request=hostName&protocol=udp&host=10.199.0.93&port=8081&tries=1'] Namespace:pod-network-test-7107 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:25:25.014: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:25:25.161: INFO: Waiting for endpoints: map[]
Dec 28 05:25:25.163: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.199.0.94:8080/dial?request=hostName&protocol=udp&host=10.199.1.140&port=8081&tries=1'] Namespace:pod-network-test-7107 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:25:25.164: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:25:25.336: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:25:25.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7107" for this suite.
Dec 28 05:25:37.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:25:37.409: INFO: namespace pod-network-test-7107 deletion completed in 12.069985214s

• [SLOW TEST:32.606 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:25:37.409: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Dec 28 05:25:37.429: INFO: Waiting up to 5m0s for pod "client-containers-8451ebdf-b612-4513-b78e-8f63e8c49726" in namespace "containers-489" to be "success or failure"
Dec 28 05:25:37.431: INFO: Pod "client-containers-8451ebdf-b612-4513-b78e-8f63e8c49726": Phase="Pending", Reason="", readiness=false. Elapsed: 1.927669ms
Dec 28 05:25:39.433: INFO: Pod "client-containers-8451ebdf-b612-4513-b78e-8f63e8c49726": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004052135s
STEP: Saw pod success
Dec 28 05:25:39.433: INFO: Pod "client-containers-8451ebdf-b612-4513-b78e-8f63e8c49726" satisfied condition "success or failure"
Dec 28 05:25:39.434: INFO: Trying to get logs from node hxx-m-2 pod client-containers-8451ebdf-b612-4513-b78e-8f63e8c49726 container test-container: <nil>
STEP: delete the pod
Dec 28 05:25:39.452: INFO: Waiting for pod client-containers-8451ebdf-b612-4513-b78e-8f63e8c49726 to disappear
Dec 28 05:25:39.454: INFO: Pod client-containers-8451ebdf-b612-4513-b78e-8f63e8c49726 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:25:39.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-489" for this suite.
Dec 28 05:25:45.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:25:45.524: INFO: namespace containers-489 deletion completed in 6.067895867s

• [SLOW TEST:8.115 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:25:45.525: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2464
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-2464
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2464
Dec 28 05:25:45.548: INFO: Found 0 stateful pods, waiting for 1
Dec 28 05:25:55.550: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 28 05:25:55.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-2464 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 28 05:25:55.769: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 28 05:25:55.769: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 28 05:25:55.769: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 28 05:25:55.774: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 28 05:26:05.776: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 05:26:05.776: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 05:26:05.783: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Dec 28 05:26:05.783: INFO: ss-0  hxx-m-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:25:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:25:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:25:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:25:45 +0000 UTC  }]
Dec 28 05:26:05.783: INFO: 
Dec 28 05:26:05.783: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 28 05:26:06.786: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.998224626s
Dec 28 05:26:07.788: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.995543437s
Dec 28 05:26:08.791: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992811536s
Dec 28 05:26:09.794: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98970783s
Dec 28 05:26:10.797: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.987135081s
Dec 28 05:26:11.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.984044291s
Dec 28 05:26:12.802: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.98142858s
Dec 28 05:26:13.805: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.978929293s
Dec 28 05:26:14.807: INFO: Verifying statefulset ss doesn't scale past 3 for another 976.454217ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2464
Dec 28 05:26:15.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-2464 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 28 05:26:16.027: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 28 05:26:16.027: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 28 05:26:16.027: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 28 05:26:16.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-2464 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 28 05:26:16.251: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 28 05:26:16.251: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 28 05:26:16.251: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 28 05:26:16.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-2464 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 28 05:26:16.485: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 28 05:26:16.485: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 28 05:26:16.485: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 28 05:26:16.487: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec 28 05:26:26.489: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:26:26.490: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:26:26.490: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 28 05:26:26.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-2464 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 28 05:26:26.703: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 28 05:26:26.703: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 28 05:26:26.703: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 28 05:26:26.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-2464 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 28 05:26:26.949: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 28 05:26:26.949: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 28 05:26:26.949: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 28 05:26:26.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-2464 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 28 05:26:27.172: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 28 05:26:27.172: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 28 05:26:27.173: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 28 05:26:27.173: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 05:26:27.175: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 28 05:26:37.179: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 05:26:37.179: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 05:26:37.179: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 05:26:37.184: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Dec 28 05:26:37.184: INFO: ss-0  hxx-m-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:25:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:25:45 +0000 UTC  }]
Dec 28 05:26:37.184: INFO: ss-1  hxx-m-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  }]
Dec 28 05:26:37.184: INFO: ss-2  hxx-m-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  }]
Dec 28 05:26:37.184: INFO: 
Dec 28 05:26:37.184: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 28 05:26:38.187: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Dec 28 05:26:38.187: INFO: ss-0  hxx-m-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:25:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:25:45 +0000 UTC  }]
Dec 28 05:26:38.187: INFO: ss-1  hxx-m-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  }]
Dec 28 05:26:38.187: INFO: ss-2  hxx-m-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  }]
Dec 28 05:26:38.187: INFO: 
Dec 28 05:26:38.187: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 28 05:26:39.190: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Dec 28 05:26:39.190: INFO: ss-0  hxx-m-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:25:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:25:45 +0000 UTC  }]
Dec 28 05:26:39.190: INFO: ss-1  hxx-m-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  }]
Dec 28 05:26:39.190: INFO: 
Dec 28 05:26:39.190: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 28 05:26:40.192: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Dec 28 05:26:40.192: INFO: ss-1  hxx-m-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  }]
Dec 28 05:26:40.192: INFO: 
Dec 28 05:26:40.192: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 28 05:26:41.195: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Dec 28 05:26:41.195: INFO: ss-1  hxx-m-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-28 05:26:05 +0000 UTC  }]
Dec 28 05:26:41.195: INFO: 
Dec 28 05:26:41.195: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 28 05:26:42.197: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.987219564s
Dec 28 05:26:43.199: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.985245174s
Dec 28 05:26:44.202: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.98290625s
Dec 28 05:26:45.204: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.980508419s
Dec 28 05:26:46.206: INFO: Verifying statefulset ss doesn't scale past 0 for another 978.440466ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2464
Dec 28 05:26:47.208: INFO: Scaling statefulset ss to 0
Dec 28 05:26:47.213: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 28 05:26:47.215: INFO: Deleting all statefulset in ns statefulset-2464
Dec 28 05:26:47.216: INFO: Scaling statefulset ss to 0
Dec 28 05:26:47.221: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 05:26:47.222: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:26:47.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2464" for this suite.
Dec 28 05:26:53.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:26:53.301: INFO: namespace statefulset-2464 deletion completed in 6.069731022s

• [SLOW TEST:67.777 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:26:53.302: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:26:53.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8352" for this suite.
Dec 28 05:26:59.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:26:59.396: INFO: namespace kubelet-test-8352 deletion completed in 6.06511443s

• [SLOW TEST:6.095 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:26:59.396: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-ab107f7f-d6a2-4c4e-b288-813cfd403760
STEP: Creating a pod to test consume secrets
Dec 28 05:26:59.418: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8795b3a1-84ea-4dc6-adba-ed761f226e8e" in namespace "projected-7397" to be "success or failure"
Dec 28 05:26:59.419: INFO: Pod "pod-projected-secrets-8795b3a1-84ea-4dc6-adba-ed761f226e8e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.323796ms
Dec 28 05:27:01.421: INFO: Pod "pod-projected-secrets-8795b3a1-84ea-4dc6-adba-ed761f226e8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003628536s
STEP: Saw pod success
Dec 28 05:27:01.421: INFO: Pod "pod-projected-secrets-8795b3a1-84ea-4dc6-adba-ed761f226e8e" satisfied condition "success or failure"
Dec 28 05:27:01.423: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-secrets-8795b3a1-84ea-4dc6-adba-ed761f226e8e container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:27:01.432: INFO: Waiting for pod pod-projected-secrets-8795b3a1-84ea-4dc6-adba-ed761f226e8e to disappear
Dec 28 05:27:01.434: INFO: Pod pod-projected-secrets-8795b3a1-84ea-4dc6-adba-ed761f226e8e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:27:01.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7397" for this suite.
Dec 28 05:27:07.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:27:07.505: INFO: namespace projected-7397 deletion completed in 6.068730706s

• [SLOW TEST:8.108 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:27:07.505: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-b6abd9db-0a2c-4f50-acd7-7f46401d5f99
STEP: Creating a pod to test consume configMaps
Dec 28 05:27:07.526: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-85009c0a-406c-49d0-9e1f-ad1b2657be2f" in namespace "projected-2087" to be "success or failure"
Dec 28 05:27:07.528: INFO: Pod "pod-projected-configmaps-85009c0a-406c-49d0-9e1f-ad1b2657be2f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.554817ms
Dec 28 05:27:09.530: INFO: Pod "pod-projected-configmaps-85009c0a-406c-49d0-9e1f-ad1b2657be2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003748161s
STEP: Saw pod success
Dec 28 05:27:09.530: INFO: Pod "pod-projected-configmaps-85009c0a-406c-49d0-9e1f-ad1b2657be2f" satisfied condition "success or failure"
Dec 28 05:27:09.531: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-configmaps-85009c0a-406c-49d0-9e1f-ad1b2657be2f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:27:09.541: INFO: Waiting for pod pod-projected-configmaps-85009c0a-406c-49d0-9e1f-ad1b2657be2f to disappear
Dec 28 05:27:09.543: INFO: Pod pod-projected-configmaps-85009c0a-406c-49d0-9e1f-ad1b2657be2f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:27:09.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2087" for this suite.
Dec 28 05:27:15.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:27:15.615: INFO: namespace projected-2087 deletion completed in 6.069672327s

• [SLOW TEST:8.110 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:27:15.615: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:27:15.635: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c875f60f-2de5-4131-8530-88922f4a06e4" in namespace "projected-6828" to be "success or failure"
Dec 28 05:27:15.637: INFO: Pod "downwardapi-volume-c875f60f-2de5-4131-8530-88922f4a06e4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.781697ms
Dec 28 05:27:17.639: INFO: Pod "downwardapi-volume-c875f60f-2de5-4131-8530-88922f4a06e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004148961s
STEP: Saw pod success
Dec 28 05:27:17.639: INFO: Pod "downwardapi-volume-c875f60f-2de5-4131-8530-88922f4a06e4" satisfied condition "success or failure"
Dec 28 05:27:17.640: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-c875f60f-2de5-4131-8530-88922f4a06e4 container client-container: <nil>
STEP: delete the pod
Dec 28 05:27:17.653: INFO: Waiting for pod downwardapi-volume-c875f60f-2de5-4131-8530-88922f4a06e4 to disappear
Dec 28 05:27:17.654: INFO: Pod downwardapi-volume-c875f60f-2de5-4131-8530-88922f4a06e4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:27:17.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6828" for this suite.
Dec 28 05:27:23.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:27:23.723: INFO: namespace projected-6828 deletion completed in 6.066433589s

• [SLOW TEST:8.108 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:27:23.723: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-230fe8aa-5efd-4a9e-9ecd-b7684c5f0902
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-230fe8aa-5efd-4a9e-9ecd-b7684c5f0902
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:27:27.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6313" for this suite.
Dec 28 05:27:39.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:27:39.839: INFO: namespace configmap-6313 deletion completed in 12.069162891s

• [SLOW TEST:16.116 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:27:39.840: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-2433
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2433
STEP: Deleting pre-stop pod
Dec 28 05:27:48.880: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:27:48.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2433" for this suite.
Dec 28 05:28:32.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:28:32.958: INFO: namespace prestop-2433 deletion completed in 44.071989284s

• [SLOW TEST:53.118 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:28:32.958: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 28 05:28:32.985: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7664 /api/v1/namespaces/watch-7664/configmaps/e2e-watch-test-label-changed ed211fa6-a47a-4082-affe-26c4046b6265 233582 0 2019-12-28 05:28:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 28 05:28:32.985: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7664 /api/v1/namespaces/watch-7664/configmaps/e2e-watch-test-label-changed ed211fa6-a47a-4082-affe-26c4046b6265 233583 0 2019-12-28 05:28:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 28 05:28:32.985: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7664 /api/v1/namespaces/watch-7664/configmaps/e2e-watch-test-label-changed ed211fa6-a47a-4082-affe-26c4046b6265 233584 0 2019-12-28 05:28:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 28 05:28:42.999: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7664 /api/v1/namespaces/watch-7664/configmaps/e2e-watch-test-label-changed ed211fa6-a47a-4082-affe-26c4046b6265 233618 0 2019-12-28 05:28:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 28 05:28:42.999: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7664 /api/v1/namespaces/watch-7664/configmaps/e2e-watch-test-label-changed ed211fa6-a47a-4082-affe-26c4046b6265 233619 0 2019-12-28 05:28:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 28 05:28:42.999: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7664 /api/v1/namespaces/watch-7664/configmaps/e2e-watch-test-label-changed ed211fa6-a47a-4082-affe-26c4046b6265 233620 0 2019-12-28 05:28:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:28:42.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7664" for this suite.
Dec 28 05:28:49.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:28:49.069: INFO: namespace watch-7664 deletion completed in 6.067329073s

• [SLOW TEST:16.110 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:28:49.069: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 28 05:28:51.600: INFO: Successfully updated pod "pod-update-activedeadlineseconds-16a93a30-0865-42ef-9ca1-cbc8578f7d2f"
Dec 28 05:28:51.600: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-16a93a30-0865-42ef-9ca1-cbc8578f7d2f" in namespace "pods-1632" to be "terminated due to deadline exceeded"
Dec 28 05:28:51.602: INFO: Pod "pod-update-activedeadlineseconds-16a93a30-0865-42ef-9ca1-cbc8578f7d2f": Phase="Running", Reason="", readiness=true. Elapsed: 1.55051ms
Dec 28 05:28:53.604: INFO: Pod "pod-update-activedeadlineseconds-16a93a30-0865-42ef-9ca1-cbc8578f7d2f": Phase="Running", Reason="", readiness=true. Elapsed: 2.003832211s
Dec 28 05:28:55.606: INFO: Pod "pod-update-activedeadlineseconds-16a93a30-0865-42ef-9ca1-cbc8578f7d2f": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.006387487s
Dec 28 05:28:55.606: INFO: Pod "pod-update-activedeadlineseconds-16a93a30-0865-42ef-9ca1-cbc8578f7d2f" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:28:55.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1632" for this suite.
Dec 28 05:29:01.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:29:01.685: INFO: namespace pods-1632 deletion completed in 6.075656445s

• [SLOW TEST:12.616 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:29:01.685: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-a156bfea-0d35-48d7-b9e5-07ffc6d5f955
STEP: Creating a pod to test consume secrets
Dec 28 05:29:01.706: INFO: Waiting up to 5m0s for pod "pod-secrets-f118525b-fb33-4159-ab86-fb90b2454def" in namespace "secrets-5722" to be "success or failure"
Dec 28 05:29:01.708: INFO: Pod "pod-secrets-f118525b-fb33-4159-ab86-fb90b2454def": Phase="Pending", Reason="", readiness=false. Elapsed: 1.561694ms
Dec 28 05:29:03.718: INFO: Pod "pod-secrets-f118525b-fb33-4159-ab86-fb90b2454def": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011440064s
STEP: Saw pod success
Dec 28 05:29:03.718: INFO: Pod "pod-secrets-f118525b-fb33-4159-ab86-fb90b2454def" satisfied condition "success or failure"
Dec 28 05:29:03.719: INFO: Trying to get logs from node hxx-m-2 pod pod-secrets-f118525b-fb33-4159-ab86-fb90b2454def container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:29:03.737: INFO: Waiting for pod pod-secrets-f118525b-fb33-4159-ab86-fb90b2454def to disappear
Dec 28 05:29:03.743: INFO: Pod pod-secrets-f118525b-fb33-4159-ab86-fb90b2454def no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:29:03.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5722" for this suite.
Dec 28 05:29:09.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:29:09.812: INFO: namespace secrets-5722 deletion completed in 6.066176182s

• [SLOW TEST:8.127 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:29:09.813: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:29:09.833: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fc5a02e3-5eb7-4568-95ec-aeee3465df32" in namespace "projected-4106" to be "success or failure"
Dec 28 05:29:09.834: INFO: Pod "downwardapi-volume-fc5a02e3-5eb7-4568-95ec-aeee3465df32": Phase="Pending", Reason="", readiness=false. Elapsed: 1.762107ms
Dec 28 05:29:11.837: INFO: Pod "downwardapi-volume-fc5a02e3-5eb7-4568-95ec-aeee3465df32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004109135s
STEP: Saw pod success
Dec 28 05:29:11.837: INFO: Pod "downwardapi-volume-fc5a02e3-5eb7-4568-95ec-aeee3465df32" satisfied condition "success or failure"
Dec 28 05:29:11.838: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-fc5a02e3-5eb7-4568-95ec-aeee3465df32 container client-container: <nil>
STEP: delete the pod
Dec 28 05:29:11.849: INFO: Waiting for pod downwardapi-volume-fc5a02e3-5eb7-4568-95ec-aeee3465df32 to disappear
Dec 28 05:29:11.851: INFO: Pod downwardapi-volume-fc5a02e3-5eb7-4568-95ec-aeee3465df32 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:29:11.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4106" for this suite.
Dec 28 05:29:17.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:29:17.922: INFO: namespace projected-4106 deletion completed in 6.068719984s

• [SLOW TEST:8.110 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:29:17.923: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Dec 28 05:29:17.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=kubectl-3799 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 28 05:29:20.098: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 28 05:29:20.098: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:29:22.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3799" for this suite.
Dec 28 05:29:34.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:29:34.173: INFO: namespace kubectl-3799 deletion completed in 12.06900493s

• [SLOW TEST:16.250 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:29:34.173: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 28 05:29:34.194: INFO: Waiting up to 5m0s for pod "pod-1d823818-17b6-4980-9b52-a7947eae753f" in namespace "emptydir-2590" to be "success or failure"
Dec 28 05:29:34.195: INFO: Pod "pod-1d823818-17b6-4980-9b52-a7947eae753f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.383808ms
Dec 28 05:29:36.198: INFO: Pod "pod-1d823818-17b6-4980-9b52-a7947eae753f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003657111s
STEP: Saw pod success
Dec 28 05:29:36.198: INFO: Pod "pod-1d823818-17b6-4980-9b52-a7947eae753f" satisfied condition "success or failure"
Dec 28 05:29:36.199: INFO: Trying to get logs from node hxx-m-2 pod pod-1d823818-17b6-4980-9b52-a7947eae753f container test-container: <nil>
STEP: delete the pod
Dec 28 05:29:36.208: INFO: Waiting for pod pod-1d823818-17b6-4980-9b52-a7947eae753f to disappear
Dec 28 05:29:36.210: INFO: Pod pod-1d823818-17b6-4980-9b52-a7947eae753f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:29:36.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2590" for this suite.
Dec 28 05:29:42.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:29:42.282: INFO: namespace emptydir-2590 deletion completed in 6.069475756s

• [SLOW TEST:8.108 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:29:42.282: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 28 05:29:42.298: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:29:45.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3011" for this suite.
Dec 28 05:29:51.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:29:51.537: INFO: namespace init-container-3011 deletion completed in 6.074460411s

• [SLOW TEST:9.255 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:29:51.537: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-dv5j
STEP: Creating a pod to test atomic-volume-subpath
Dec 28 05:29:51.567: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-dv5j" in namespace "subpath-5323" to be "success or failure"
Dec 28 05:29:51.569: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Pending", Reason="", readiness=false. Elapsed: 1.423766ms
Dec 28 05:29:53.571: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Running", Reason="", readiness=true. Elapsed: 2.003551564s
Dec 28 05:29:55.573: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Running", Reason="", readiness=true. Elapsed: 4.005519484s
Dec 28 05:29:57.575: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Running", Reason="", readiness=true. Elapsed: 6.007932743s
Dec 28 05:29:59.578: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Running", Reason="", readiness=true. Elapsed: 8.010041349s
Dec 28 05:30:01.580: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Running", Reason="", readiness=true. Elapsed: 10.01253206s
Dec 28 05:30:03.585: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Running", Reason="", readiness=true. Elapsed: 12.017002187s
Dec 28 05:30:05.587: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Running", Reason="", readiness=true. Elapsed: 14.019080611s
Dec 28 05:30:07.589: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Running", Reason="", readiness=true. Elapsed: 16.021381723s
Dec 28 05:30:09.591: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Running", Reason="", readiness=true. Elapsed: 18.023541893s
Dec 28 05:30:11.593: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Running", Reason="", readiness=true. Elapsed: 20.02596321s
Dec 28 05:30:13.595: INFO: Pod "pod-subpath-test-downwardapi-dv5j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.027956255s
STEP: Saw pod success
Dec 28 05:30:13.596: INFO: Pod "pod-subpath-test-downwardapi-dv5j" satisfied condition "success or failure"
Dec 28 05:30:13.597: INFO: Trying to get logs from node hxx-m-2 pod pod-subpath-test-downwardapi-dv5j container test-container-subpath-downwardapi-dv5j: <nil>
STEP: delete the pod
Dec 28 05:30:13.606: INFO: Waiting for pod pod-subpath-test-downwardapi-dv5j to disappear
Dec 28 05:30:13.608: INFO: Pod pod-subpath-test-downwardapi-dv5j no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-dv5j
Dec 28 05:30:13.608: INFO: Deleting pod "pod-subpath-test-downwardapi-dv5j" in namespace "subpath-5323"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:30:13.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5323" for this suite.
Dec 28 05:30:19.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:30:19.676: INFO: namespace subpath-5323 deletion completed in 6.0649997s

• [SLOW TEST:28.139 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:30:19.676: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-361fde45-7844-450d-a083-0dcac5492c3d
STEP: Creating a pod to test consume configMaps
Dec 28 05:30:19.697: INFO: Waiting up to 5m0s for pod "pod-configmaps-50c53311-1690-46df-b27e-0cd51c13927f" in namespace "configmap-5768" to be "success or failure"
Dec 28 05:30:19.699: INFO: Pod "pod-configmaps-50c53311-1690-46df-b27e-0cd51c13927f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.358013ms
Dec 28 05:30:21.701: INFO: Pod "pod-configmaps-50c53311-1690-46df-b27e-0cd51c13927f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003905791s
STEP: Saw pod success
Dec 28 05:30:21.701: INFO: Pod "pod-configmaps-50c53311-1690-46df-b27e-0cd51c13927f" satisfied condition "success or failure"
Dec 28 05:30:21.703: INFO: Trying to get logs from node hxx-m-2 pod pod-configmaps-50c53311-1690-46df-b27e-0cd51c13927f container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:30:21.713: INFO: Waiting for pod pod-configmaps-50c53311-1690-46df-b27e-0cd51c13927f to disappear
Dec 28 05:30:21.715: INFO: Pod pod-configmaps-50c53311-1690-46df-b27e-0cd51c13927f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:30:21.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5768" for this suite.
Dec 28 05:30:27.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:30:27.785: INFO: namespace configmap-5768 deletion completed in 6.068041669s

• [SLOW TEST:8.109 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:30:27.785: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-4470442f-f26f-4cc6-b5e1-05e741f3e61d
STEP: Creating secret with name s-test-opt-upd-2f7ee3b7-bba1-4cc7-895b-c8df4a2c3c51
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-4470442f-f26f-4cc6-b5e1-05e741f3e61d
STEP: Updating secret s-test-opt-upd-2f7ee3b7-bba1-4cc7-895b-c8df4a2c3c51
STEP: Creating secret with name s-test-opt-create-f6d7ea15-230a-4959-a8f5-558e148468d1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:31:54.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8719" for this suite.
Dec 28 05:32:06.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:32:06.175: INFO: namespace secrets-8719 deletion completed in 12.078535025s

• [SLOW TEST:98.390 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:32:06.175: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:32:06.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9354" for this suite.
Dec 28 05:32:12.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:32:12.262: INFO: namespace services-9354 deletion completed in 6.066179359s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.087 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:32:12.262: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:32:17.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7700" for this suite.
Dec 28 05:32:23.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:32:23.478: INFO: namespace watch-7700 deletion completed in 6.16126419s

• [SLOW TEST:11.216 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:32:23.478: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:32:24.024: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 28 05:32:26.029: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713107944, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713107944, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713107944, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713107944, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:32:29.037: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:32:29.039: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:32:30.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8706" for this suite.
Dec 28 05:32:36.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:32:36.195: INFO: namespace webhook-8706 deletion completed in 6.071370495s
STEP: Destroying namespace "webhook-8706-markers" for this suite.
Dec 28 05:32:42.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:32:42.267: INFO: namespace webhook-8706-markers deletion completed in 6.071817998s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.796 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:32:42.274: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 28 05:32:42.294: INFO: Waiting up to 5m0s for pod "pod-f000a395-e5b0-468a-99da-be5c56622354" in namespace "emptydir-6146" to be "success or failure"
Dec 28 05:32:42.296: INFO: Pod "pod-f000a395-e5b0-468a-99da-be5c56622354": Phase="Pending", Reason="", readiness=false. Elapsed: 1.568349ms
Dec 28 05:32:44.298: INFO: Pod "pod-f000a395-e5b0-468a-99da-be5c56622354": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004002968s
STEP: Saw pod success
Dec 28 05:32:44.298: INFO: Pod "pod-f000a395-e5b0-468a-99da-be5c56622354" satisfied condition "success or failure"
Dec 28 05:32:44.300: INFO: Trying to get logs from node hxx-m-2 pod pod-f000a395-e5b0-468a-99da-be5c56622354 container test-container: <nil>
STEP: delete the pod
Dec 28 05:32:44.309: INFO: Waiting for pod pod-f000a395-e5b0-468a-99da-be5c56622354 to disappear
Dec 28 05:32:44.310: INFO: Pod pod-f000a395-e5b0-468a-99da-be5c56622354 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:32:44.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6146" for this suite.
Dec 28 05:32:50.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:32:50.387: INFO: namespace emptydir-6146 deletion completed in 6.074249825s

• [SLOW TEST:8.113 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:32:50.387: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 28 05:32:50.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-3004'
Dec 28 05:32:50.477: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 28 05:32:50.477: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Dec 28 05:32:50.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete jobs e2e-test-httpd-job --namespace=kubectl-3004'
Dec 28 05:32:50.558: INFO: stderr: ""
Dec 28 05:32:50.558: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:32:50.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3004" for this suite.
Dec 28 05:33:18.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:33:18.636: INFO: namespace kubectl-3004 deletion completed in 28.075264973s

• [SLOW TEST:28.249 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:33:18.636: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:33:18.653: INFO: Creating deployment "test-recreate-deployment"
Dec 28 05:33:18.655: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 28 05:33:18.659: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 28 05:33:20.662: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 28 05:33:20.663: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 28 05:33:20.667: INFO: Updating deployment test-recreate-deployment
Dec 28 05:33:20.667: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 28 05:33:20.696: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-553 /apis/apps/v1/namespaces/deployment-553/deployments/test-recreate-deployment 3ab61ef7-8408-4c65-a278-968a63cfb1a4 235126 2 2019-12-28 05:33:18 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0047bba88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-28 05:33:20 +0000 UTC,LastTransitionTime:2019-12-28 05:33:20 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-12-28 05:33:20 +0000 UTC,LastTransitionTime:2019-12-28 05:33:18 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 28 05:33:20.700: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-553 /apis/apps/v1/namespaces/deployment-553/replicasets/test-recreate-deployment-5f94c574ff b8db924d-c3b1-445d-8422-85f18cc4f890 235124 1 2019-12-28 05:33:20 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 3ab61ef7-8408-4c65-a278-968a63cfb1a4 0xc0047bbe67 0xc0047bbe68}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0047bbec8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 28 05:33:20.700: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 28 05:33:20.700: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-553 /apis/apps/v1/namespaces/deployment-553/replicasets/test-recreate-deployment-68fc85c7bb bbda7283-4ad7-46c0-a58f-00e93a9f86e0 235115 2 2019-12-28 05:33:18 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 3ab61ef7-8408-4c65-a278-968a63cfb1a4 0xc0047bbf37 0xc0047bbf38}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0047bbf98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 28 05:33:20.702: INFO: Pod "test-recreate-deployment-5f94c574ff-qhbbn" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-qhbbn test-recreate-deployment-5f94c574ff- deployment-553 /api/v1/namespaces/deployment-553/pods/test-recreate-deployment-5f94c574ff-qhbbn e2e0930e-286b-44df-a27e-c3316f7b5a74 235127 0 2019-12-28 05:33:20 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff b8db924d-c3b1-445d-8422-85f18cc4f890 0xc003e90407 0xc003e90408}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8lglk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8lglk,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8lglk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:33:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:33:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:33:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:33:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.16,PodIP:,StartTime:2019-12-28 05:33:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:33:20.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-553" for this suite.
Dec 28 05:33:26.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:33:26.774: INFO: namespace deployment-553 deletion completed in 6.070435496s

• [SLOW TEST:8.138 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:33:26.775: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 28 05:33:29.308: INFO: Successfully updated pod "labelsupdate404ffdaa-2e77-4018-ab16-638e6a12f132"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:33:31.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1615" for this suite.
Dec 28 05:33:43.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:33:43.393: INFO: namespace projected-1615 deletion completed in 12.070804266s

• [SLOW TEST:16.618 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:33:43.393: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 28 05:33:43.409: INFO: PodSpec: initContainers in spec.initContainers
Dec 28 05:34:31.908: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ce3bc8d2-0e25-4e78-aadc-84e05aea3898", GenerateName:"", Namespace:"init-container-7313", SelfLink:"/api/v1/namespaces/init-container-7313/pods/pod-init-ce3bc8d2-0e25-4e78-aadc-84e05aea3898", UID:"17d74997-12b1-400b-910a-cb5d0c8fd044", ResourceVersion:"235458", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63713108023, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"409073972"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-jnrhm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc005480640), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jnrhm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jnrhm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jnrhm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004c93268), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"hxx-m-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002a116e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004c93310)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004c93330)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004c93338), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004c9333c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108023, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108023, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108023, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108023, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.128.16", PodIP:"10.199.0.119", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.199.0.119"}}, StartTime:(*v1.Time)(0xc004043520), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002f33c00)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002f33c70)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://0400afbb9258cc29c144d01eefcf907e0181f77436ab8279399613c0406bd125", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004043560), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004043540), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc004c933bf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:34:31.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7313" for this suite.
Dec 28 05:34:59.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:34:59.986: INFO: namespace init-container-7313 deletion completed in 28.074474563s

• [SLOW TEST:76.593 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:34:59.986: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-982h9 in namespace proxy-8550
I1228 05:35:00.012457      22 runners.go:184] Created replication controller with name: proxy-service-982h9, namespace: proxy-8550, replica count: 1
I1228 05:35:01.062799      22 runners.go:184] proxy-service-982h9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 05:35:02.063001      22 runners.go:184] proxy-service-982h9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1228 05:35:03.063170      22 runners.go:184] proxy-service-982h9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1228 05:35:04.063370      22 runners.go:184] proxy-service-982h9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1228 05:35:05.064662      22 runners.go:184] proxy-service-982h9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1228 05:35:06.064855      22 runners.go:184] proxy-service-982h9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1228 05:35:07.065040      22 runners.go:184] proxy-service-982h9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 28 05:35:07.067: INFO: setup took 7.063370737s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 28 05:35:07.069: INFO: (0) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 2.724357ms)
Dec 28 05:35:07.070: INFO: (0) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 3.575451ms)
Dec 28 05:35:07.071: INFO: (0) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.045688ms)
Dec 28 05:35:07.073: INFO: (0) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 5.727496ms)
Dec 28 05:35:07.073: INFO: (0) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 5.97503ms)
Dec 28 05:35:07.075: INFO: (0) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 8.111093ms)
Dec 28 05:35:07.075: INFO: (0) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 8.16139ms)
Dec 28 05:35:07.075: INFO: (0) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 8.537347ms)
Dec 28 05:35:07.075: INFO: (0) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 8.575532ms)
Dec 28 05:35:07.076: INFO: (0) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 8.832562ms)
Dec 28 05:35:07.076: INFO: (0) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 8.995453ms)
Dec 28 05:35:07.077: INFO: (0) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 10.691005ms)
Dec 28 05:35:07.080: INFO: (0) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 13.170346ms)
Dec 28 05:35:07.080: INFO: (0) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 13.387901ms)
Dec 28 05:35:07.081: INFO: (0) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 14.063558ms)
Dec 28 05:35:07.081: INFO: (0) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 14.203212ms)
Dec 28 05:35:07.085: INFO: (1) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 3.936225ms)
Dec 28 05:35:07.085: INFO: (1) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 3.915885ms)
Dec 28 05:35:07.085: INFO: (1) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.060387ms)
Dec 28 05:35:07.086: INFO: (1) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 4.263786ms)
Dec 28 05:35:07.086: INFO: (1) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 4.255172ms)
Dec 28 05:35:07.086: INFO: (1) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 4.602099ms)
Dec 28 05:35:07.086: INFO: (1) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.423299ms)
Dec 28 05:35:07.086: INFO: (1) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.686808ms)
Dec 28 05:35:07.086: INFO: (1) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 4.579106ms)
Dec 28 05:35:07.086: INFO: (1) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 4.807003ms)
Dec 28 05:35:07.086: INFO: (1) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 4.633021ms)
Dec 28 05:35:07.086: INFO: (1) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 4.71128ms)
Dec 28 05:35:07.086: INFO: (1) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 4.85595ms)
Dec 28 05:35:07.086: INFO: (1) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 4.906878ms)
Dec 28 05:35:07.087: INFO: (1) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.533146ms)
Dec 28 05:35:07.087: INFO: (1) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 5.585546ms)
Dec 28 05:35:07.092: INFO: (2) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 3.953491ms)
Dec 28 05:35:07.092: INFO: (2) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.052235ms)
Dec 28 05:35:07.092: INFO: (2) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 3.856943ms)
Dec 28 05:35:07.092: INFO: (2) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 4.325085ms)
Dec 28 05:35:07.092: INFO: (2) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 4.589715ms)
Dec 28 05:35:07.092: INFO: (2) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 3.616587ms)
Dec 28 05:35:07.092: INFO: (2) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.80423ms)
Dec 28 05:35:07.092: INFO: (2) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.015909ms)
Dec 28 05:35:07.092: INFO: (2) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 4.567754ms)
Dec 28 05:35:07.093: INFO: (2) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 5.281323ms)
Dec 28 05:35:07.093: INFO: (2) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 5.289311ms)
Dec 28 05:35:07.093: INFO: (2) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 5.274901ms)
Dec 28 05:35:07.093: INFO: (2) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.820226ms)
Dec 28 05:35:07.093: INFO: (2) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 5.760208ms)
Dec 28 05:35:07.094: INFO: (2) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 5.25399ms)
Dec 28 05:35:07.094: INFO: (2) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 6.271448ms)
Dec 28 05:35:07.098: INFO: (3) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 4.142169ms)
Dec 28 05:35:07.098: INFO: (3) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 3.909809ms)
Dec 28 05:35:07.098: INFO: (3) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 4.021737ms)
Dec 28 05:35:07.098: INFO: (3) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.060292ms)
Dec 28 05:35:07.098: INFO: (3) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.109544ms)
Dec 28 05:35:07.098: INFO: (3) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.481051ms)
Dec 28 05:35:07.098: INFO: (3) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 4.319844ms)
Dec 28 05:35:07.098: INFO: (3) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.553116ms)
Dec 28 05:35:07.098: INFO: (3) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 4.471057ms)
Dec 28 05:35:07.098: INFO: (3) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 4.515734ms)
Dec 28 05:35:07.099: INFO: (3) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 4.789865ms)
Dec 28 05:35:07.099: INFO: (3) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 4.853137ms)
Dec 28 05:35:07.099: INFO: (3) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 5.516283ms)
Dec 28 05:35:07.099: INFO: (3) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 5.728543ms)
Dec 28 05:35:07.099: INFO: (3) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 5.436742ms)
Dec 28 05:35:07.099: INFO: (3) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.598772ms)
Dec 28 05:35:07.104: INFO: (4) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 4.602497ms)
Dec 28 05:35:07.104: INFO: (4) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 4.671453ms)
Dec 28 05:35:07.104: INFO: (4) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.738702ms)
Dec 28 05:35:07.104: INFO: (4) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 4.647242ms)
Dec 28 05:35:07.104: INFO: (4) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.607081ms)
Dec 28 05:35:07.104: INFO: (4) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.59116ms)
Dec 28 05:35:07.104: INFO: (4) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 4.684097ms)
Dec 28 05:35:07.104: INFO: (4) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 4.747426ms)
Dec 28 05:35:07.104: INFO: (4) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 4.653767ms)
Dec 28 05:35:07.104: INFO: (4) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.818ms)
Dec 28 05:35:07.106: INFO: (4) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 5.863681ms)
Dec 28 05:35:07.106: INFO: (4) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.947191ms)
Dec 28 05:35:07.106: INFO: (4) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 5.84523ms)
Dec 28 05:35:07.106: INFO: (4) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 6.132903ms)
Dec 28 05:35:07.106: INFO: (4) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 5.869931ms)
Dec 28 05:35:07.106: INFO: (4) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 5.893613ms)
Dec 28 05:35:07.108: INFO: (5) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 2.478694ms)
Dec 28 05:35:07.110: INFO: (5) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 4.402221ms)
Dec 28 05:35:07.110: INFO: (5) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 4.586205ms)
Dec 28 05:35:07.110: INFO: (5) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 4.585721ms)
Dec 28 05:35:07.110: INFO: (5) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 4.538579ms)
Dec 28 05:35:07.111: INFO: (5) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 5.077693ms)
Dec 28 05:35:07.111: INFO: (5) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 5.007634ms)
Dec 28 05:35:07.111: INFO: (5) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 5.072058ms)
Dec 28 05:35:07.111: INFO: (5) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 5.143218ms)
Dec 28 05:35:07.111: INFO: (5) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 5.09443ms)
Dec 28 05:35:07.111: INFO: (5) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 5.122052ms)
Dec 28 05:35:07.111: INFO: (5) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 5.281225ms)
Dec 28 05:35:07.111: INFO: (5) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 5.438338ms)
Dec 28 05:35:07.111: INFO: (5) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 5.389261ms)
Dec 28 05:35:07.111: INFO: (5) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 5.329806ms)
Dec 28 05:35:07.111: INFO: (5) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 5.586424ms)
Dec 28 05:35:07.116: INFO: (6) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 4.12341ms)
Dec 28 05:35:07.116: INFO: (6) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.160124ms)
Dec 28 05:35:07.116: INFO: (6) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 5.072508ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.37123ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 4.867516ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 4.945101ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.487046ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 5.476636ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 5.134955ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 5.224776ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 5.024479ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 5.519165ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 5.464467ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 5.216987ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.175823ms)
Dec 28 05:35:07.117: INFO: (6) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 5.129851ms)
Dec 28 05:35:07.122: INFO: (7) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 4.780291ms)
Dec 28 05:35:07.122: INFO: (7) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 4.358993ms)
Dec 28 05:35:07.122: INFO: (7) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 4.437181ms)
Dec 28 05:35:07.122: INFO: (7) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 4.25078ms)
Dec 28 05:35:07.122: INFO: (7) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 5.021721ms)
Dec 28 05:35:07.122: INFO: (7) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.149982ms)
Dec 28 05:35:07.122: INFO: (7) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 4.798507ms)
Dec 28 05:35:07.122: INFO: (7) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.965653ms)
Dec 28 05:35:07.122: INFO: (7) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.747492ms)
Dec 28 05:35:07.122: INFO: (7) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 4.249466ms)
Dec 28 05:35:07.123: INFO: (7) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 4.866382ms)
Dec 28 05:35:07.123: INFO: (7) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 4.634823ms)
Dec 28 05:35:07.123: INFO: (7) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 5.474798ms)
Dec 28 05:35:07.123: INFO: (7) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 5.441234ms)
Dec 28 05:35:07.123: INFO: (7) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.020603ms)
Dec 28 05:35:07.123: INFO: (7) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 5.60916ms)
Dec 28 05:35:07.130: INFO: (8) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 5.153443ms)
Dec 28 05:35:07.130: INFO: (8) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 5.794695ms)
Dec 28 05:35:07.130: INFO: (8) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 5.3012ms)
Dec 28 05:35:07.130: INFO: (8) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 5.448088ms)
Dec 28 05:35:07.130: INFO: (8) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 6.397654ms)
Dec 28 05:35:07.130: INFO: (8) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 6.125476ms)
Dec 28 05:35:07.130: INFO: (8) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 6.870031ms)
Dec 28 05:35:07.130: INFO: (8) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 6.313093ms)
Dec 28 05:35:07.130: INFO: (8) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 6.750751ms)
Dec 28 05:35:07.130: INFO: (8) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 6.837902ms)
Dec 28 05:35:07.131: INFO: (8) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 6.943611ms)
Dec 28 05:35:07.131: INFO: (8) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 6.439616ms)
Dec 28 05:35:07.131: INFO: (8) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 6.58781ms)
Dec 28 05:35:07.131: INFO: (8) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 6.679245ms)
Dec 28 05:35:07.131: INFO: (8) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 6.872729ms)
Dec 28 05:35:07.132: INFO: (8) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 8.624837ms)
Dec 28 05:35:07.138: INFO: (9) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 5.279406ms)
Dec 28 05:35:07.138: INFO: (9) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 5.558069ms)
Dec 28 05:35:07.138: INFO: (9) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 5.638986ms)
Dec 28 05:35:07.138: INFO: (9) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 5.807515ms)
Dec 28 05:35:07.138: INFO: (9) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 5.761684ms)
Dec 28 05:35:07.138: INFO: (9) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 5.836125ms)
Dec 28 05:35:07.138: INFO: (9) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 5.777036ms)
Dec 28 05:35:07.139: INFO: (9) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 5.742691ms)
Dec 28 05:35:07.139: INFO: (9) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 6.020183ms)
Dec 28 05:35:07.139: INFO: (9) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 6.136821ms)
Dec 28 05:35:07.139: INFO: (9) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 6.112228ms)
Dec 28 05:35:07.139: INFO: (9) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 6.31605ms)
Dec 28 05:35:07.140: INFO: (9) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 6.88503ms)
Dec 28 05:35:07.140: INFO: (9) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 6.964124ms)
Dec 28 05:35:07.140: INFO: (9) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 7.126994ms)
Dec 28 05:35:07.140: INFO: (9) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 7.221087ms)
Dec 28 05:35:07.142: INFO: (10) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 1.821195ms)
Dec 28 05:35:07.143: INFO: (10) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 2.927281ms)
Dec 28 05:35:07.143: INFO: (10) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 2.813114ms)
Dec 28 05:35:07.143: INFO: (10) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 2.915472ms)
Dec 28 05:35:07.143: INFO: (10) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 2.780198ms)
Dec 28 05:35:07.143: INFO: (10) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 2.907799ms)
Dec 28 05:35:07.144: INFO: (10) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 2.631684ms)
Dec 28 05:35:07.144: INFO: (10) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 3.168946ms)
Dec 28 05:35:07.144: INFO: (10) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 3.952508ms)
Dec 28 05:35:07.146: INFO: (10) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 4.78628ms)
Dec 28 05:35:07.146: INFO: (10) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 5.008533ms)
Dec 28 05:35:07.147: INFO: (10) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 5.623985ms)
Dec 28 05:35:07.147: INFO: (10) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 6.226235ms)
Dec 28 05:35:07.147: INFO: (10) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 6.169439ms)
Dec 28 05:35:07.147: INFO: (10) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 5.756005ms)
Dec 28 05:35:07.147: INFO: (10) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 6.056284ms)
Dec 28 05:35:07.149: INFO: (11) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 2.10514ms)
Dec 28 05:35:07.152: INFO: (11) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 4.436847ms)
Dec 28 05:35:07.152: INFO: (11) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 5.42346ms)
Dec 28 05:35:07.153: INFO: (11) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 4.645015ms)
Dec 28 05:35:07.153: INFO: (11) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 4.883739ms)
Dec 28 05:35:07.153: INFO: (11) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 5.866247ms)
Dec 28 05:35:07.153: INFO: (11) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.440314ms)
Dec 28 05:35:07.153: INFO: (11) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 4.918232ms)
Dec 28 05:35:07.153: INFO: (11) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 5.919101ms)
Dec 28 05:35:07.154: INFO: (11) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 6.078739ms)
Dec 28 05:35:07.154: INFO: (11) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 5.947858ms)
Dec 28 05:35:07.154: INFO: (11) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 6.667001ms)
Dec 28 05:35:07.154: INFO: (11) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 6.784107ms)
Dec 28 05:35:07.154: INFO: (11) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 6.938201ms)
Dec 28 05:35:07.154: INFO: (11) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 6.598776ms)
Dec 28 05:35:07.154: INFO: (11) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 6.303596ms)
Dec 28 05:35:07.158: INFO: (12) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 3.032271ms)
Dec 28 05:35:07.158: INFO: (12) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 3.019352ms)
Dec 28 05:35:07.158: INFO: (12) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 3.195036ms)
Dec 28 05:35:07.158: INFO: (12) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 3.141576ms)
Dec 28 05:35:07.159: INFO: (12) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 4.470495ms)
Dec 28 05:35:07.159: INFO: (12) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.674191ms)
Dec 28 05:35:07.159: INFO: (12) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 4.26603ms)
Dec 28 05:35:07.159: INFO: (12) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 4.493807ms)
Dec 28 05:35:07.159: INFO: (12) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 4.801283ms)
Dec 28 05:35:07.159: INFO: (12) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.993367ms)
Dec 28 05:35:07.159: INFO: (12) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 4.929984ms)
Dec 28 05:35:07.159: INFO: (12) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 5.101042ms)
Dec 28 05:35:07.159: INFO: (12) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 4.718078ms)
Dec 28 05:35:07.161: INFO: (12) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 5.845967ms)
Dec 28 05:35:07.161: INFO: (12) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 5.802754ms)
Dec 28 05:35:07.161: INFO: (12) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 6.624275ms)
Dec 28 05:35:07.163: INFO: (13) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 1.898397ms)
Dec 28 05:35:07.164: INFO: (13) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 2.671932ms)
Dec 28 05:35:07.164: INFO: (13) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 2.627838ms)
Dec 28 05:35:07.164: INFO: (13) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 2.880509ms)
Dec 28 05:35:07.164: INFO: (13) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 2.400434ms)
Dec 28 05:35:07.165: INFO: (13) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 2.811124ms)
Dec 28 05:35:07.165: INFO: (13) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 2.985168ms)
Dec 28 05:35:07.165: INFO: (13) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 3.013951ms)
Dec 28 05:35:07.165: INFO: (13) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 2.924937ms)
Dec 28 05:35:07.166: INFO: (13) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 3.954106ms)
Dec 28 05:35:07.166: INFO: (13) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 4.553376ms)
Dec 28 05:35:07.166: INFO: (13) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 4.813617ms)
Dec 28 05:35:07.166: INFO: (13) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 5.523364ms)
Dec 28 05:35:07.166: INFO: (13) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 5.653274ms)
Dec 28 05:35:07.167: INFO: (13) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 5.191856ms)
Dec 28 05:35:07.167: INFO: (13) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.446092ms)
Dec 28 05:35:07.170: INFO: (14) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 2.45757ms)
Dec 28 05:35:07.170: INFO: (14) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 3.169683ms)
Dec 28 05:35:07.170: INFO: (14) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 3.34165ms)
Dec 28 05:35:07.170: INFO: (14) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 2.638885ms)
Dec 28 05:35:07.170: INFO: (14) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 3.503007ms)
Dec 28 05:35:07.171: INFO: (14) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 4.203962ms)
Dec 28 05:35:07.171: INFO: (14) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.125373ms)
Dec 28 05:35:07.171: INFO: (14) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 3.251936ms)
Dec 28 05:35:07.171: INFO: (14) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 3.784636ms)
Dec 28 05:35:07.171: INFO: (14) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 3.669582ms)
Dec 28 05:35:07.172: INFO: (14) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 4.331655ms)
Dec 28 05:35:07.172: INFO: (14) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 4.714003ms)
Dec 28 05:35:07.172: INFO: (14) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.264293ms)
Dec 28 05:35:07.172: INFO: (14) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 5.194192ms)
Dec 28 05:35:07.172: INFO: (14) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 4.413994ms)
Dec 28 05:35:07.172: INFO: (14) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 4.710741ms)
Dec 28 05:35:07.175: INFO: (15) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 2.841765ms)
Dec 28 05:35:07.175: INFO: (15) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 2.851692ms)
Dec 28 05:35:07.175: INFO: (15) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 3.035237ms)
Dec 28 05:35:07.175: INFO: (15) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 2.964549ms)
Dec 28 05:35:07.175: INFO: (15) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 3.382063ms)
Dec 28 05:35:07.177: INFO: (15) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.357473ms)
Dec 28 05:35:07.177: INFO: (15) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 4.418194ms)
Dec 28 05:35:07.177: INFO: (15) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 4.763554ms)
Dec 28 05:35:07.178: INFO: (15) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.434541ms)
Dec 28 05:35:07.178: INFO: (15) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 4.954236ms)
Dec 28 05:35:07.178: INFO: (15) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 5.190084ms)
Dec 28 05:35:07.178: INFO: (15) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 5.786265ms)
Dec 28 05:35:07.178: INFO: (15) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 5.513903ms)
Dec 28 05:35:07.178: INFO: (15) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 5.594789ms)
Dec 28 05:35:07.178: INFO: (15) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 5.69033ms)
Dec 28 05:35:07.178: INFO: (15) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 6.082044ms)
Dec 28 05:35:07.180: INFO: (16) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 1.689257ms)
Dec 28 05:35:07.182: INFO: (16) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 2.935432ms)
Dec 28 05:35:07.182: INFO: (16) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 3.252575ms)
Dec 28 05:35:07.182: INFO: (16) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 3.52423ms)
Dec 28 05:35:07.182: INFO: (16) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 3.518507ms)
Dec 28 05:35:07.183: INFO: (16) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 3.621178ms)
Dec 28 05:35:07.183: INFO: (16) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 3.969032ms)
Dec 28 05:35:07.183: INFO: (16) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 4.669261ms)
Dec 28 05:35:07.183: INFO: (16) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 3.985757ms)
Dec 28 05:35:07.183: INFO: (16) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 3.70421ms)
Dec 28 05:35:07.183: INFO: (16) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 4.105999ms)
Dec 28 05:35:07.184: INFO: (16) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 3.91636ms)
Dec 28 05:35:07.184: INFO: (16) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 4.513435ms)
Dec 28 05:35:07.184: INFO: (16) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 4.185052ms)
Dec 28 05:35:07.184: INFO: (16) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 4.298905ms)
Dec 28 05:35:07.184: INFO: (16) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 4.734717ms)
Dec 28 05:35:07.187: INFO: (17) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 2.657908ms)
Dec 28 05:35:07.189: INFO: (17) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 4.316724ms)
Dec 28 05:35:07.189: INFO: (17) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 4.303538ms)
Dec 28 05:35:07.190: INFO: (17) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 4.95354ms)
Dec 28 05:35:07.190: INFO: (17) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 5.333059ms)
Dec 28 05:35:07.190: INFO: (17) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 5.544784ms)
Dec 28 05:35:07.190: INFO: (17) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 4.850693ms)
Dec 28 05:35:07.191: INFO: (17) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 6.505755ms)
Dec 28 05:35:07.191: INFO: (17) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 6.601866ms)
Dec 28 05:35:07.191: INFO: (17) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 5.848302ms)
Dec 28 05:35:07.191: INFO: (17) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.724836ms)
Dec 28 05:35:07.191: INFO: (17) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 6.278536ms)
Dec 28 05:35:07.191: INFO: (17) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 5.629533ms)
Dec 28 05:35:07.191: INFO: (17) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 6.502519ms)
Dec 28 05:35:07.191: INFO: (17) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 6.107359ms)
Dec 28 05:35:07.191: INFO: (17) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 6.010813ms)
Dec 28 05:35:07.195: INFO: (18) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 3.299219ms)
Dec 28 05:35:07.195: INFO: (18) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 3.574727ms)
Dec 28 05:35:07.195: INFO: (18) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 2.65898ms)
Dec 28 05:35:07.195: INFO: (18) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 2.792365ms)
Dec 28 05:35:07.195: INFO: (18) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 4.054435ms)
Dec 28 05:35:07.195: INFO: (18) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 3.762213ms)
Dec 28 05:35:07.195: INFO: (18) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 3.177588ms)
Dec 28 05:35:07.195: INFO: (18) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 3.915744ms)
Dec 28 05:35:07.195: INFO: (18) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 3.011033ms)
Dec 28 05:35:07.195: INFO: (18) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 3.324599ms)
Dec 28 05:35:07.196: INFO: (18) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 4.387728ms)
Dec 28 05:35:07.196: INFO: (18) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 4.076108ms)
Dec 28 05:35:07.196: INFO: (18) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 4.518892ms)
Dec 28 05:35:07.196: INFO: (18) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 4.984711ms)
Dec 28 05:35:07.196: INFO: (18) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 4.444346ms)
Dec 28 05:35:07.196: INFO: (18) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 5.167281ms)
Dec 28 05:35:07.198: INFO: (19) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:462/proxy/: tls qux (200; 1.749657ms)
Dec 28 05:35:07.198: INFO: (19) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:160/proxy/: foo (200; 2.02225ms)
Dec 28 05:35:07.199: INFO: (19) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:162/proxy/: bar (200; 2.115865ms)
Dec 28 05:35:07.199: INFO: (19) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx/proxy/rewriteme">test</a> (200; 2.101906ms)
Dec 28 05:35:07.200: INFO: (19) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:162/proxy/: bar (200; 2.589596ms)
Dec 28 05:35:07.200: INFO: (19) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:160/proxy/: foo (200; 2.626166ms)
Dec 28 05:35:07.201: INFO: (19) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:443/proxy/tlsrewritem... (200; 3.092081ms)
Dec 28 05:35:07.201: INFO: (19) /api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/proxy-service-982h9-m9zkx:1080/proxy/rewriteme">test<... (200; 3.303085ms)
Dec 28 05:35:07.201: INFO: (19) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname2/proxy/: bar (200; 3.678788ms)
Dec 28 05:35:07.201: INFO: (19) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname1/proxy/: foo (200; 3.931529ms)
Dec 28 05:35:07.201: INFO: (19) /api/v1/namespaces/proxy-8550/services/http:proxy-service-982h9:portname1/proxy/: foo (200; 4.528893ms)
Dec 28 05:35:07.201: INFO: (19) /api/v1/namespaces/proxy-8550/pods/https:proxy-service-982h9-m9zkx:460/proxy/: tls baz (200; 3.819479ms)
Dec 28 05:35:07.201: INFO: (19) /api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/: <a href="/api/v1/namespaces/proxy-8550/pods/http:proxy-service-982h9-m9zkx:1080/proxy/rewriteme">... (200; 4.021497ms)
Dec 28 05:35:07.202: INFO: (19) /api/v1/namespaces/proxy-8550/services/proxy-service-982h9:portname2/proxy/: bar (200; 4.152377ms)
Dec 28 05:35:07.202: INFO: (19) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname1/proxy/: tls baz (200; 4.098029ms)
Dec 28 05:35:07.202: INFO: (19) /api/v1/namespaces/proxy-8550/services/https:proxy-service-982h9:tlsportname2/proxy/: tls qux (200; 4.654899ms)
STEP: deleting ReplicationController proxy-service-982h9 in namespace proxy-8550, will wait for the garbage collector to delete the pods
Dec 28 05:35:07.257: INFO: Deleting ReplicationController proxy-service-982h9 took: 3.295749ms
Dec 28 05:35:08.057: INFO: Terminating ReplicationController proxy-service-982h9 pods took: 800.199207ms
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:35:20.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8550" for this suite.
Dec 28 05:35:26.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:35:27.027: INFO: namespace proxy-8550 deletion completed in 6.066790001s

• [SLOW TEST:27.041 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:35:27.027: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 28 05:35:27.046: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 28 05:35:32.048: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:35:33.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-721" for this suite.
Dec 28 05:35:39.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:35:39.128: INFO: namespace replication-controller-721 deletion completed in 6.068664161s

• [SLOW TEST:12.101 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:35:39.128: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec 28 05:35:39.145: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:35:42.850: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:35:57.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3910" for this suite.
Dec 28 05:36:03.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:36:03.402: INFO: namespace crd-publish-openapi-3910 deletion completed in 6.071196726s

• [SLOW TEST:24.274 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:36:03.402: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 28 05:36:03.419: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 28 05:36:03.427: INFO: Waiting for terminating namespaces to be deleted...
Dec 28 05:36:03.428: INFO: 
Logging pods the kubelet thinks is on node hxx-m-1 before test
Dec 28 05:36:03.443: INFO: kube-flannel-8hgpf from kube-system started at 2019-12-27 13:58:14 +0000 UTC (2 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 05:36:03.443: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 05:36:03.443: INFO: sonobuoy-e2e-job-af99efc4f7ea449a from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container e2e ready: true, restart count 0
Dec 28 05:36:03.443: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 05:36:03.443: INFO: coredns-66447b44c9-zphmm from kube-system started at 2019-12-27 13:58:22 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container coredns ready: true, restart count 0
Dec 28 05:36:03.443: INFO: cert-manager-77f5bf4f5-h86rt from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container cert-manager ready: true, restart count 0
Dec 28 05:36:03.443: INFO: cert-manager-webhook-578c59dddd-k697c from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container webhook ready: true, restart count 0
Dec 28 05:36:03.443: INFO: apollo-cfdd64bb4-4lssk from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container apollo ready: true, restart count 0
Dec 28 05:36:03.443: INFO: dex-8448b48ff8-2bd5h from cpaas-system started at 2019-12-27 14:09:25 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container dex ready: true, restart count 0
Dec 28 05:36:03.443: INFO: erebus-5597f9565d-zwjnz from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container erebus ready: true, restart count 0
Dec 28 05:36:03.443: INFO: auth-controller2-79ff55cd75-cbjbn from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container auth-controller2-manager ready: true, restart count 0
Dec 28 05:36:03.443: INFO: furion-679c948779-jz6lf from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container furion ready: true, restart count 0
Dec 28 05:36:03.443: INFO: underlord-5c45b96c5d-nmjjq from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container alauda-console ready: true, restart count 0
Dec 28 05:36:03.443: INFO: cert-manager-cainjector-67d4dd59ff-8jhs9 from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container cainjector ready: true, restart count 0
Dec 28 05:36:03.443: INFO: archon-5fdc59d78c-rhtzm from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container archon-api ready: true, restart count 0
Dec 28 05:36:03.443: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-lzsqv from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 28 05:36:03.443: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 05:36:03.443: INFO: kube-proxy-bnhj6 from kube-system started at 2019-12-27 13:58:01 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 05:36:03.443: INFO: agon-75b987dff5-7bht5 from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container agon ready: true, restart count 2
Dec 28 05:36:03.443: INFO: cluster-registry-controller-manager-76774c98d-7c7mz from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (2 container statuses recorded)
Dec 28 05:36:03.443: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 28 05:36:03.443: INFO: 	Container manager ready: true, restart count 0
Dec 28 05:36:03.443: INFO: 
Logging pods the kubelet thinks is on node hxx-m-2 before test
Dec 28 05:36:03.454: INFO: kube-apiserver-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.454: INFO: 	Container kube-apiserver ready: true, restart count 0
Dec 28 05:36:03.454: INFO: kube-controller-manager-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.454: INFO: 	Container kube-controller-manager ready: true, restart count 0
Dec 28 05:36:03.454: INFO: etcd-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.454: INFO: 	Container etcd ready: true, restart count 0
Dec 28 05:36:03.454: INFO: nginx-ingress-controller-f9b5d49fd-x4774 from cpaas-system started at 2019-12-28 05:10:02 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.454: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec 28 05:36:03.454: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-89sp4 from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 05:36:03.454: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 28 05:36:03.454: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 05:36:03.454: INFO: kube-flannel-fxzw7 from kube-system started at 2019-12-28 05:10:03 +0000 UTC (2 container statuses recorded)
Dec 28 05:36:03.454: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 05:36:03.454: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 05:36:03.454: INFO: kube-proxy-44f6q from kube-system started at 2019-12-27 13:57:35 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.454: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 05:36:03.454: INFO: sonobuoy from sonobuoy started at 2019-12-28 04:15:38 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.454: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 28 05:36:03.454: INFO: kube-scheduler-hxx-m-2 from kube-system started at 2019-12-27 13:57:11 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.454: INFO: 	Container kube-scheduler ready: true, restart count 0
Dec 28 05:36:03.454: INFO: 
Logging pods the kubelet thinks is on node hxx-m-3 before test
Dec 28 05:36:03.467: INFO: dex-8448b48ff8-9qn2j from cpaas-system started at 2019-12-27 14:09:25 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container dex ready: true, restart count 0
Dec 28 05:36:03.467: INFO: cert-manager-77f5bf4f5-2wz6n from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container cert-manager ready: true, restart count 0
Dec 28 05:36:03.467: INFO: underlord-5c45b96c5d-6cvvc from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container alauda-console ready: true, restart count 0
Dec 28 05:36:03.467: INFO: agon-75b987dff5-bl7sb from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container agon ready: true, restart count 2
Dec 28 05:36:03.467: INFO: apollo-cfdd64bb4-hjth5 from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container apollo ready: true, restart count 0
Dec 28 05:36:03.467: INFO: coredns-66447b44c9-5qbrm from kube-system started at 2019-12-27 13:58:22 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container coredns ready: true, restart count 0
Dec 28 05:36:03.467: INFO: cluster-registry-controller-manager-76774c98d-rmnh2 from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (2 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Dec 28 05:36:03.467: INFO: 	Container manager ready: true, restart count 0
Dec 28 05:36:03.467: INFO: furion-679c948779-xjs2n from cpaas-system started at 2019-12-27 14:15:15 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container furion ready: true, restart count 0
Dec 28 05:36:03.467: INFO: archon-5fdc59d78c-k5jbm from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container archon-api ready: true, restart count 0
Dec 28 05:36:03.467: INFO: sonobuoy-systemd-logs-daemon-set-8919cf1320354ba5-pjj5l from sonobuoy started at 2019-12-28 04:15:39 +0000 UTC (2 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 28 05:36:03.467: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 28 05:36:03.467: INFO: tiller-deploy-7c757c6f9c-67l6b from kube-system started at 2019-12-27 13:59:57 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container tiller ready: true, restart count 0
Dec 28 05:36:03.467: INFO: auth-controller2-79ff55cd75-4clk9 from cpaas-system started at 2019-12-27 14:46:59 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container auth-controller2-manager ready: true, restart count 0
Dec 28 05:36:03.467: INFO: kube-proxy-5kzvk from kube-system started at 2019-12-27 13:57:57 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 28 05:36:03.467: INFO: kube-flannel-f87zg from kube-system started at 2019-12-27 13:58:14 +0000 UTC (2 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container install-cni ready: true, restart count 0
Dec 28 05:36:03.467: INFO: 	Container kube-flannel ready: true, restart count 0
Dec 28 05:36:03.467: INFO: cert-manager-webhook-578c59dddd-flp52 from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container webhook ready: true, restart count 0
Dec 28 05:36:03.467: INFO: cert-manager-cainjector-67d4dd59ff-tngcj from cert-manager started at 2019-12-27 14:11:22 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container cainjector ready: true, restart count 0
Dec 28 05:36:03.467: INFO: erebus-5597f9565d-ptdps from cpaas-system started at 2019-12-27 14:15:14 +0000 UTC (1 container statuses recorded)
Dec 28 05:36:03.467: INFO: 	Container erebus ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6ccafe39-90dc-48d1-b4f1-a70cce2bfeca 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-6ccafe39-90dc-48d1-b4f1-a70cce2bfeca off the node hxx-m-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6ccafe39-90dc-48d1-b4f1-a70cce2bfeca
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:36:07.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5407" for this suite.
Dec 28 05:36:25.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:36:25.575: INFO: namespace sched-pred-5407 deletion completed in 18.070156059s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:22.173 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:36:25.575: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 28 05:36:25.602: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:36:40.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9481" for this suite.
Dec 28 05:36:46.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:36:47.004: INFO: namespace pods-9481 deletion completed in 6.068453942s

• [SLOW TEST:21.429 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:36:47.005: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:36:47.021: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 28 05:36:50.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-2665 create -f -'
Dec 28 05:36:50.933: INFO: stderr: ""
Dec 28 05:36:50.933: INFO: stdout: "e2e-test-crd-publish-openapi-2066-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 28 05:36:50.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-2665 delete e2e-test-crd-publish-openapi-2066-crds test-cr'
Dec 28 05:36:51.013: INFO: stderr: ""
Dec 28 05:36:51.013: INFO: stdout: "e2e-test-crd-publish-openapi-2066-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 28 05:36:51.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-2665 apply -f -'
Dec 28 05:36:51.149: INFO: stderr: ""
Dec 28 05:36:51.149: INFO: stdout: "e2e-test-crd-publish-openapi-2066-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 28 05:36:51.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 --namespace=crd-publish-openapi-2665 delete e2e-test-crd-publish-openapi-2066-crds test-cr'
Dec 28 05:36:51.224: INFO: stderr: ""
Dec 28 05:36:51.224: INFO: stdout: "e2e-test-crd-publish-openapi-2066-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 28 05:36:51.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 explain e2e-test-crd-publish-openapi-2066-crds'
Dec 28 05:36:51.363: INFO: stderr: ""
Dec 28 05:36:51.363: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2066-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:36:55.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2665" for this suite.
Dec 28 05:37:01.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:37:01.096: INFO: namespace crd-publish-openapi-2665 deletion completed in 6.068223849s

• [SLOW TEST:14.091 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:37:01.096: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:37:07.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4092" for this suite.
Dec 28 05:37:13.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:37:13.199: INFO: namespace job-4092 deletion completed in 6.080536888s

• [SLOW TEST:12.103 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:37:13.199: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-3befb2bb-23d8-47c7-ab00-6fd8916cd413 in namespace container-probe-4554
Dec 28 05:37:15.222: INFO: Started pod liveness-3befb2bb-23d8-47c7-ab00-6fd8916cd413 in namespace container-probe-4554
STEP: checking the pod's current state and verifying that restartCount is present
Dec 28 05:37:15.224: INFO: Initial restart count of pod liveness-3befb2bb-23d8-47c7-ab00-6fd8916cd413 is 0
Dec 28 05:37:35.247: INFO: Restart count of pod container-probe-4554/liveness-3befb2bb-23d8-47c7-ab00-6fd8916cd413 is now 1 (20.02288076s elapsed)
Dec 28 05:37:55.269: INFO: Restart count of pod container-probe-4554/liveness-3befb2bb-23d8-47c7-ab00-6fd8916cd413 is now 2 (40.045102961s elapsed)
Dec 28 05:38:15.293: INFO: Restart count of pod container-probe-4554/liveness-3befb2bb-23d8-47c7-ab00-6fd8916cd413 is now 3 (1m0.069599604s elapsed)
Dec 28 05:38:35.315: INFO: Restart count of pod container-probe-4554/liveness-3befb2bb-23d8-47c7-ab00-6fd8916cd413 is now 4 (1m20.091199757s elapsed)
Dec 28 05:39:43.398: INFO: Restart count of pod container-probe-4554/liveness-3befb2bb-23d8-47c7-ab00-6fd8916cd413 is now 5 (2m28.173872894s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:39:43.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4554" for this suite.
Dec 28 05:39:49.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:39:49.480: INFO: namespace container-probe-4554 deletion completed in 6.074744616s

• [SLOW TEST:156.281 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:39:49.480: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 28 05:39:52.020: INFO: Successfully updated pod "labelsupdate3d339d29-f6e1-471e-8ac0-217dd8f4af8a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:39:56.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4824" for this suite.
Dec 28 05:40:14.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:40:14.107: INFO: namespace downward-api-4824 deletion completed in 18.068536469s

• [SLOW TEST:24.627 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:40:14.108: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 28 05:40:18.150: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 05:40:18.151: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 05:40:20.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 05:40:20.154: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 05:40:22.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 05:40:22.154: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 05:40:24.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 05:40:24.153: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 05:40:26.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 05:40:26.154: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 05:40:28.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 05:40:28.153: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 05:40:30.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 05:40:30.154: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 05:40:32.151: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 05:40:32.153: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:40:32.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9025" for this suite.
Dec 28 05:40:44.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:40:44.231: INFO: namespace container-lifecycle-hook-9025 deletion completed in 12.069373555s

• [SLOW TEST:30.123 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:40:44.231: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:40:44.251: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-a4cadcb2-c96e-4958-920f-e2e31c5d33e2" in namespace "security-context-test-3789" to be "success or failure"
Dec 28 05:40:44.253: INFO: Pod "busybox-privileged-false-a4cadcb2-c96e-4958-920f-e2e31c5d33e2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.540166ms
Dec 28 05:40:46.256: INFO: Pod "busybox-privileged-false-a4cadcb2-c96e-4958-920f-e2e31c5d33e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004294378s
Dec 28 05:40:46.256: INFO: Pod "busybox-privileged-false-a4cadcb2-c96e-4958-920f-e2e31c5d33e2" satisfied condition "success or failure"
Dec 28 05:40:46.261: INFO: Got logs for pod "busybox-privileged-false-a4cadcb2-c96e-4958-920f-e2e31c5d33e2": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:40:46.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3789" for this suite.
Dec 28 05:40:52.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:40:52.336: INFO: namespace security-context-test-3789 deletion completed in 6.073038528s

• [SLOW TEST:8.105 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:40:52.336: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:40:52.357: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99e92fdf-aeaf-48aa-83cf-4020f6451975" in namespace "downward-api-1120" to be "success or failure"
Dec 28 05:40:52.358: INFO: Pod "downwardapi-volume-99e92fdf-aeaf-48aa-83cf-4020f6451975": Phase="Pending", Reason="", readiness=false. Elapsed: 1.482542ms
Dec 28 05:40:54.361: INFO: Pod "downwardapi-volume-99e92fdf-aeaf-48aa-83cf-4020f6451975": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003921355s
STEP: Saw pod success
Dec 28 05:40:54.361: INFO: Pod "downwardapi-volume-99e92fdf-aeaf-48aa-83cf-4020f6451975" satisfied condition "success or failure"
Dec 28 05:40:54.362: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-99e92fdf-aeaf-48aa-83cf-4020f6451975 container client-container: <nil>
STEP: delete the pod
Dec 28 05:40:54.373: INFO: Waiting for pod downwardapi-volume-99e92fdf-aeaf-48aa-83cf-4020f6451975 to disappear
Dec 28 05:40:54.374: INFO: Pod downwardapi-volume-99e92fdf-aeaf-48aa-83cf-4020f6451975 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:40:54.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1120" for this suite.
Dec 28 05:41:00.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:41:00.443: INFO: namespace downward-api-1120 deletion completed in 6.066275271s

• [SLOW TEST:8.106 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:41:00.443: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-5ab02276-dc15-4975-944c-27e2e6599089 in namespace container-probe-3187
Dec 28 05:41:02.468: INFO: Started pod test-webserver-5ab02276-dc15-4975-944c-27e2e6599089 in namespace container-probe-3187
STEP: checking the pod's current state and verifying that restartCount is present
Dec 28 05:41:02.469: INFO: Initial restart count of pod test-webserver-5ab02276-dc15-4975-944c-27e2e6599089 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:45:02.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3187" for this suite.
Dec 28 05:45:08.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:45:08.851: INFO: namespace container-probe-3187 deletion completed in 6.077515819s

• [SLOW TEST:248.408 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:45:08.851: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:45:24.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6267" for this suite.
Dec 28 05:45:30.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:45:30.980: INFO: namespace resourcequota-6267 deletion completed in 6.06807486s

• [SLOW TEST:22.129 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:45:30.980: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:45:42.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6608" for this suite.
Dec 28 05:45:48.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:45:48.098: INFO: namespace resourcequota-6608 deletion completed in 6.069210287s

• [SLOW TEST:17.118 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:45:48.098: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-563fb1bc-3406-43a4-a8bd-a9a5eba51db9
STEP: Creating a pod to test consume configMaps
Dec 28 05:45:48.120: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-085593de-2099-4c71-af3c-40f4fcd24d19" in namespace "projected-45" to be "success or failure"
Dec 28 05:45:48.122: INFO: Pod "pod-projected-configmaps-085593de-2099-4c71-af3c-40f4fcd24d19": Phase="Pending", Reason="", readiness=false. Elapsed: 1.764927ms
Dec 28 05:45:50.125: INFO: Pod "pod-projected-configmaps-085593de-2099-4c71-af3c-40f4fcd24d19": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004094278s
STEP: Saw pod success
Dec 28 05:45:50.125: INFO: Pod "pod-projected-configmaps-085593de-2099-4c71-af3c-40f4fcd24d19" satisfied condition "success or failure"
Dec 28 05:45:50.126: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-configmaps-085593de-2099-4c71-af3c-40f4fcd24d19 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:45:50.142: INFO: Waiting for pod pod-projected-configmaps-085593de-2099-4c71-af3c-40f4fcd24d19 to disappear
Dec 28 05:45:50.143: INFO: Pod pod-projected-configmaps-085593de-2099-4c71-af3c-40f4fcd24d19 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:45:50.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-45" for this suite.
Dec 28 05:45:56.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:45:56.217: INFO: namespace projected-45 deletion completed in 6.069996922s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:45:56.217: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:45:56.523: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:45:59.537: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:46:11.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1887" for this suite.
Dec 28 05:46:17.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:46:17.671: INFO: namespace webhook-1887 deletion completed in 6.066785162s
STEP: Destroying namespace "webhook-1887-markers" for this suite.
Dec 28 05:46:23.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:46:23.741: INFO: namespace webhook-1887-markers deletion completed in 6.069167265s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:27.530 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:46:23.748: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 28 05:46:23.776: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-556 /api/v1/namespaces/watch-556/configmaps/e2e-watch-test-resource-version b68107f9-9d70-431f-ab84-9b1173239119 238612 0 2019-12-28 05:46:23 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 28 05:46:23.776: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-556 /api/v1/namespaces/watch-556/configmaps/e2e-watch-test-resource-version b68107f9-9d70-431f-ab84-9b1173239119 238613 0 2019-12-28 05:46:23 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:46:23.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-556" for this suite.
Dec 28 05:46:29.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:46:29.847: INFO: namespace watch-556 deletion completed in 6.067764449s

• [SLOW TEST:6.099 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:46:29.847: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-cd064d6d-e1e9-446d-a7a5-fc8fb017dbbd
STEP: Creating a pod to test consume secrets
Dec 28 05:46:29.868: INFO: Waiting up to 5m0s for pod "pod-secrets-fa2a60b9-7159-4b32-bb21-55e3796f530e" in namespace "secrets-9346" to be "success or failure"
Dec 28 05:46:29.869: INFO: Pod "pod-secrets-fa2a60b9-7159-4b32-bb21-55e3796f530e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.365038ms
Dec 28 05:46:31.872: INFO: Pod "pod-secrets-fa2a60b9-7159-4b32-bb21-55e3796f530e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003813165s
STEP: Saw pod success
Dec 28 05:46:31.872: INFO: Pod "pod-secrets-fa2a60b9-7159-4b32-bb21-55e3796f530e" satisfied condition "success or failure"
Dec 28 05:46:31.873: INFO: Trying to get logs from node hxx-m-2 pod pod-secrets-fa2a60b9-7159-4b32-bb21-55e3796f530e container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:46:31.883: INFO: Waiting for pod pod-secrets-fa2a60b9-7159-4b32-bb21-55e3796f530e to disappear
Dec 28 05:46:31.885: INFO: Pod pod-secrets-fa2a60b9-7159-4b32-bb21-55e3796f530e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:46:31.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9346" for this suite.
Dec 28 05:46:37.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:46:37.961: INFO: namespace secrets-9346 deletion completed in 6.073709728s

• [SLOW TEST:8.117 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:46:37.964: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9447
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 28 05:46:37.987: INFO: Found 0 stateful pods, waiting for 3
Dec 28 05:46:47.990: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:46:47.990: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:46:47.990: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:46:47.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-9447 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 28 05:46:48.395: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 28 05:46:48.395: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 28 05:46:48.395: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 28 05:46:58.417: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 28 05:47:08.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-9447 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 28 05:47:08.671: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 28 05:47:08.671: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 28 05:47:08.671: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 28 05:47:18.682: INFO: Waiting for StatefulSet statefulset-9447/ss2 to complete update
Dec 28 05:47:18.682: INFO: Waiting for Pod statefulset-9447/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 28 05:47:18.682: INFO: Waiting for Pod statefulset-9447/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 28 05:47:18.682: INFO: Waiting for Pod statefulset-9447/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 28 05:47:28.687: INFO: Waiting for StatefulSet statefulset-9447/ss2 to complete update
Dec 28 05:47:28.687: INFO: Waiting for Pod statefulset-9447/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Dec 28 05:47:38.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-9447 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 28 05:47:38.910: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 28 05:47:38.910: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 28 05:47:38.910: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 28 05:47:48.933: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 28 05:47:58.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=statefulset-9447 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 28 05:47:59.158: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 28 05:47:59.158: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 28 05:47:59.158: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 28 05:48:19.169: INFO: Deleting all statefulset in ns statefulset-9447
Dec 28 05:48:19.171: INFO: Scaling statefulset ss2 to 0
Dec 28 05:48:49.179: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 05:48:49.181: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:48:49.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9447" for this suite.
Dec 28 05:48:55.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:48:55.266: INFO: namespace statefulset-9447 deletion completed in 6.07562393s

• [SLOW TEST:137.303 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:48:55.266: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:48:55.283: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 28 05:48:55.286: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 28 05:49:00.288: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 28 05:49:00.288: INFO: Creating deployment "test-rolling-update-deployment"
Dec 28 05:49:00.291: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 28 05:49:00.294: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 28 05:49:02.298: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 28 05:49:02.299: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 28 05:49:02.303: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-89 /apis/apps/v1/namespaces/deployment-89/deployments/test-rolling-update-deployment 542a4060-fe9f-44a6-8064-410ebeec5b17 239589 1 2019-12-28 05:49:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0053db858 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-28 05:49:00 +0000 UTC,LastTransitionTime:2019-12-28 05:49:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-12-28 05:49:01 +0000 UTC,LastTransitionTime:2019-12-28 05:49:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 28 05:49:02.305: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-89 /apis/apps/v1/namespaces/deployment-89/replicasets/test-rolling-update-deployment-55d946486 c6e95bd9-ce1a-4edd-8ceb-c43f7fb06d33 239578 1 2019-12-28 05:49:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 542a4060-fe9f-44a6-8064-410ebeec5b17 0xc008e66c60 0xc008e66c61}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc008e66ce8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 28 05:49:02.305: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 28 05:49:02.305: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-89 /apis/apps/v1/namespaces/deployment-89/replicasets/test-rolling-update-controller 799f0db2-61cb-4805-a3d9-4f119318567a 239588 2 2019-12-28 05:48:55 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 542a4060-fe9f-44a6-8064-410ebeec5b17 0xc008e66b97 0xc008e66b98}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc008e66bf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 28 05:49:02.307: INFO: Pod "test-rolling-update-deployment-55d946486-bzvlf" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-bzvlf test-rolling-update-deployment-55d946486- deployment-89 /api/v1/namespaces/deployment-89/pods/test-rolling-update-deployment-55d946486-bzvlf cd07353f-28f1-4805-a7fa-108b96a57e7c 239577 0 2019-12-28 05:49:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 c6e95bd9-ce1a-4edd-8ceb-c43f7fb06d33 0xc0053dbc90 0xc0053dbc91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zmtfh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zmtfh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zmtfh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:49:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:49:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:49:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:49:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.16,PodIP:10.199.0.150,StartTime:2019-12-28 05:49:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 05:49:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://030aeaa395e71e0f60ed289a48e8932cfd303112a4079e821744bbb5cf7b3be7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.0.150,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:49:02.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-89" for this suite.
Dec 28 05:49:08.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:49:08.376: INFO: namespace deployment-89 deletion completed in 6.066640915s

• [SLOW TEST:13.109 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:49:08.376: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:49:08.392: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:49:14.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9850" for this suite.
Dec 28 05:49:20.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:49:20.645: INFO: namespace custom-resource-definition-9850 deletion completed in 6.063951582s

• [SLOW TEST:12.269 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:49:20.645: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-1506/configmap-test-9c59428b-66de-4952-8921-748b0a388055
STEP: Creating a pod to test consume configMaps
Dec 28 05:49:20.667: INFO: Waiting up to 5m0s for pod "pod-configmaps-378a7bc6-9988-4d5a-91b7-53abc61fb8b2" in namespace "configmap-1506" to be "success or failure"
Dec 28 05:49:20.669: INFO: Pod "pod-configmaps-378a7bc6-9988-4d5a-91b7-53abc61fb8b2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.421839ms
Dec 28 05:49:22.671: INFO: Pod "pod-configmaps-378a7bc6-9988-4d5a-91b7-53abc61fb8b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003791508s
STEP: Saw pod success
Dec 28 05:49:22.671: INFO: Pod "pod-configmaps-378a7bc6-9988-4d5a-91b7-53abc61fb8b2" satisfied condition "success or failure"
Dec 28 05:49:22.672: INFO: Trying to get logs from node hxx-m-2 pod pod-configmaps-378a7bc6-9988-4d5a-91b7-53abc61fb8b2 container env-test: <nil>
STEP: delete the pod
Dec 28 05:49:22.688: INFO: Waiting for pod pod-configmaps-378a7bc6-9988-4d5a-91b7-53abc61fb8b2 to disappear
Dec 28 05:49:22.689: INFO: Pod pod-configmaps-378a7bc6-9988-4d5a-91b7-53abc61fb8b2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:49:22.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1506" for this suite.
Dec 28 05:49:28.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:49:28.770: INFO: namespace configmap-1506 deletion completed in 6.078207792s

• [SLOW TEST:8.125 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:49:28.771: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 28 05:49:28.789: INFO: Waiting up to 5m0s for pod "pod-27a44b78-de23-4a0b-97ff-5b4115903e69" in namespace "emptydir-7372" to be "success or failure"
Dec 28 05:49:28.790: INFO: Pod "pod-27a44b78-de23-4a0b-97ff-5b4115903e69": Phase="Pending", Reason="", readiness=false. Elapsed: 1.2293ms
Dec 28 05:49:30.793: INFO: Pod "pod-27a44b78-de23-4a0b-97ff-5b4115903e69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003479984s
STEP: Saw pod success
Dec 28 05:49:30.793: INFO: Pod "pod-27a44b78-de23-4a0b-97ff-5b4115903e69" satisfied condition "success or failure"
Dec 28 05:49:30.795: INFO: Trying to get logs from node hxx-m-2 pod pod-27a44b78-de23-4a0b-97ff-5b4115903e69 container test-container: <nil>
STEP: delete the pod
Dec 28 05:49:30.804: INFO: Waiting for pod pod-27a44b78-de23-4a0b-97ff-5b4115903e69 to disappear
Dec 28 05:49:30.806: INFO: Pod pod-27a44b78-de23-4a0b-97ff-5b4115903e69 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:49:30.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7372" for this suite.
Dec 28 05:49:36.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:49:36.878: INFO: namespace emptydir-7372 deletion completed in 6.070168917s

• [SLOW TEST:8.108 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:49:36.879: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:49:36.899: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 28 05:49:41.902: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 28 05:49:41.902: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 28 05:49:43.904: INFO: Creating deployment "test-rollover-deployment"
Dec 28 05:49:43.907: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 28 05:49:45.911: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 28 05:49:45.914: INFO: Ensure that both replica sets have 1 created replica
Dec 28 05:49:45.917: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 28 05:49:45.921: INFO: Updating deployment test-rollover-deployment
Dec 28 05:49:45.921: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 28 05:49:47.925: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 28 05:49:47.928: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 28 05:49:47.931: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:47.931: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108986, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:49.935: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:49.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108986, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:51.935: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:51.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108986, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:53.935: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:53.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108986, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:55.936: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:55.936: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108986, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713108983, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:57.935: INFO: 
Dec 28 05:49:57.935: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 28 05:49:57.940: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-2095 /apis/apps/v1/namespaces/deployment-2095/deployments/test-rollover-deployment c230a5c3-6b1f-40a9-a52c-3ad6b54b24fa 239986 2 2019-12-28 05:49:43 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004899818 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-28 05:49:43 +0000 UTC,LastTransitionTime:2019-12-28 05:49:43 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-12-28 05:49:56 +0000 UTC,LastTransitionTime:2019-12-28 05:49:43 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 28 05:49:57.942: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-2095 /apis/apps/v1/namespaces/deployment-2095/replicasets/test-rollover-deployment-7d7dc6548c 4ceda9e0-4b44-4729-8057-72a2558ac59d 239975 2 2019-12-28 05:49:45 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment c230a5c3-6b1f-40a9-a52c-3ad6b54b24fa 0xc00353cfe7 0xc00353cfe8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00353d048 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 28 05:49:57.942: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 28 05:49:57.942: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-2095 /apis/apps/v1/namespaces/deployment-2095/replicasets/test-rollover-controller 9c50da1a-418b-4488-821b-a245dcc03ffa 239985 2 2019-12-28 05:49:36 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment c230a5c3-6b1f-40a9-a52c-3ad6b54b24fa 0xc00353cf17 0xc00353cf18}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00353cf78 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 28 05:49:57.942: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-2095 /apis/apps/v1/namespaces/deployment-2095/replicasets/test-rollover-deployment-f6c94f66c 2ff0b176-bee8-443c-be09-795621c79639 239928 2 2019-12-28 05:49:43 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment c230a5c3-6b1f-40a9-a52c-3ad6b54b24fa 0xc00353d0b0 0xc00353d0b1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00353d128 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 28 05:49:57.944: INFO: Pod "test-rollover-deployment-7d7dc6548c-xxdv7" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-xxdv7 test-rollover-deployment-7d7dc6548c- deployment-2095 /api/v1/namespaces/deployment-2095/pods/test-rollover-deployment-7d7dc6548c-xxdv7 cbb3d867-21f8-4ecd-bde6-3ffa0ae57c8d 239935 0 2019-12-28 05:49:45 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 4ceda9e0-4b44-4729-8057-72a2558ac59d 0xc00353d687 0xc00353d688}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-5sjw5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-5sjw5,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-5sjw5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:49:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:49:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:49:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 05:49:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.16,PodIP:10.199.0.155,StartTime:2019-12-28 05:49:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 05:49:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://0735711127cffd157a77a1421bb14bb713cade4c0e7c50e4833e53b12434aa55,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.0.155,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:49:57.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2095" for this suite.
Dec 28 05:50:03.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:50:04.015: INFO: namespace deployment-2095 deletion completed in 6.068398394s

• [SLOW TEST:27.136 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:50:04.015: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:50:04.738: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:50:07.749: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:50:17.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9538" for this suite.
Dec 28 05:50:23.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:50:23.880: INFO: namespace webhook-9538 deletion completed in 6.070987372s
STEP: Destroying namespace "webhook-9538-markers" for this suite.
Dec 28 05:50:29.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:50:29.946: INFO: namespace webhook-9538-markers deletion completed in 6.065825175s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.937 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:50:29.953: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Dec 28 05:50:31.493: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1228 05:50:31.493042      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 28 05:50:31.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3923" for this suite.
Dec 28 05:50:37.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:50:37.564: INFO: namespace gc-3923 deletion completed in 6.068693579s

• [SLOW TEST:7.611 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:50:37.564: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 28 05:50:43.597: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3704 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:50:43.597: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:50:43.733: INFO: Exec stderr: ""
Dec 28 05:50:43.733: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3704 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:50:43.733: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:50:43.905: INFO: Exec stderr: ""
Dec 28 05:50:43.905: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3704 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:50:43.905: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:50:44.051: INFO: Exec stderr: ""
Dec 28 05:50:44.051: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3704 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:50:44.052: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:50:44.221: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 28 05:50:44.221: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3704 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:50:44.221: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:50:44.362: INFO: Exec stderr: ""
Dec 28 05:50:44.362: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3704 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:50:44.362: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:50:44.511: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 28 05:50:44.511: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3704 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:50:44.511: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:50:44.647: INFO: Exec stderr: ""
Dec 28 05:50:44.647: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3704 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:50:44.647: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:50:44.811: INFO: Exec stderr: ""
Dec 28 05:50:44.811: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3704 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:50:44.811: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:50:44.948: INFO: Exec stderr: ""
Dec 28 05:50:44.948: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3704 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:50:44.948: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 05:50:45.095: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:50:45.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3704" for this suite.
Dec 28 05:51:33.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:51:33.167: INFO: namespace e2e-kubelet-etc-hosts-3704 deletion completed in 48.068546482s

• [SLOW TEST:55.603 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:51:33.167: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 28 05:51:33.185: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:51:53.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6438" for this suite.
Dec 28 05:51:59.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:52:00.028: INFO: namespace crd-publish-openapi-6438 deletion completed in 6.068445434s

• [SLOW TEST:26.861 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:52:00.028: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 28 05:52:03.062: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:52:04.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2288" for this suite.
Dec 28 05:52:16.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:52:16.140: INFO: namespace replicaset-2288 deletion completed in 12.06701918s

• [SLOW TEST:16.111 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:52:16.141: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-b872291b-438c-4be9-82fe-b72c6e9c9a36 in namespace container-probe-3287
Dec 28 05:52:18.163: INFO: Started pod busybox-b872291b-438c-4be9-82fe-b72c6e9c9a36 in namespace container-probe-3287
STEP: checking the pod's current state and verifying that restartCount is present
Dec 28 05:52:18.164: INFO: Initial restart count of pod busybox-b872291b-438c-4be9-82fe-b72c6e9c9a36 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:56:18.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3287" for this suite.
Dec 28 05:56:24.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:56:24.527: INFO: namespace container-probe-3287 deletion completed in 6.071169559s

• [SLOW TEST:248.386 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:56:24.527: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:56:24.546: INFO: Waiting up to 5m0s for pod "downwardapi-volume-71850f56-bf34-4db7-ac49-c41189705564" in namespace "downward-api-3638" to be "success or failure"
Dec 28 05:56:24.548: INFO: Pod "downwardapi-volume-71850f56-bf34-4db7-ac49-c41189705564": Phase="Pending", Reason="", readiness=false. Elapsed: 1.357697ms
Dec 28 05:56:26.550: INFO: Pod "downwardapi-volume-71850f56-bf34-4db7-ac49-c41189705564": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00349047s
STEP: Saw pod success
Dec 28 05:56:26.550: INFO: Pod "downwardapi-volume-71850f56-bf34-4db7-ac49-c41189705564" satisfied condition "success or failure"
Dec 28 05:56:26.551: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-71850f56-bf34-4db7-ac49-c41189705564 container client-container: <nil>
STEP: delete the pod
Dec 28 05:56:26.568: INFO: Waiting for pod downwardapi-volume-71850f56-bf34-4db7-ac49-c41189705564 to disappear
Dec 28 05:56:26.569: INFO: Pod downwardapi-volume-71850f56-bf34-4db7-ac49-c41189705564 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:56:26.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3638" for this suite.
Dec 28 05:56:32.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:56:32.636: INFO: namespace downward-api-3638 deletion completed in 6.064413622s

• [SLOW TEST:8.109 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:56:32.636: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 28 05:56:36.676: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 05:56:36.678: INFO: Pod pod-with-prestop-http-hook still exists
Dec 28 05:56:38.678: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 05:56:38.680: INFO: Pod pod-with-prestop-http-hook still exists
Dec 28 05:56:40.678: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 05:56:40.680: INFO: Pod pod-with-prestop-http-hook still exists
Dec 28 05:56:42.678: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 05:56:42.680: INFO: Pod pod-with-prestop-http-hook still exists
Dec 28 05:56:44.678: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 05:56:44.680: INFO: Pod pod-with-prestop-http-hook still exists
Dec 28 05:56:46.678: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 05:56:46.680: INFO: Pod pod-with-prestop-http-hook still exists
Dec 28 05:56:48.678: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 05:56:48.680: INFO: Pod pod-with-prestop-http-hook still exists
Dec 28 05:56:50.678: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 05:56:50.681: INFO: Pod pod-with-prestop-http-hook still exists
Dec 28 05:56:52.678: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 05:56:52.681: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:56:52.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9742" for this suite.
Dec 28 05:57:04.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:57:04.759: INFO: namespace container-lifecycle-hook-9742 deletion completed in 12.069755962s

• [SLOW TEST:32.122 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:57:04.759: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:57:06.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8686" for this suite.
Dec 28 05:57:50.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:57:50.867: INFO: namespace kubelet-test-8686 deletion completed in 44.074784591s

• [SLOW TEST:46.108 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:57:50.867: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:57:51.561: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 28 05:57:53.567: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713109471, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713109471, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713109471, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713109471, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:57:56.578: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:57:56.580: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-535-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:57:57.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9911" for this suite.
Dec 28 05:58:03.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:58:03.821: INFO: namespace webhook-9911 deletion completed in 6.079318316s
STEP: Destroying namespace "webhook-9911-markers" for this suite.
Dec 28 05:58:09.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:58:09.891: INFO: namespace webhook-9911-markers deletion completed in 6.069924324s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.030 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:58:09.898: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:58:09.913: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 28 05:58:11.929: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:58:11.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3565" for this suite.
Dec 28 05:58:17.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:58:18.002: INFO: namespace replication-controller-3565 deletion completed in 6.068421794s

• [SLOW TEST:8.104 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:58:18.002: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:58:18.314: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 28 05:58:20.319: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713109498, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713109498, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63713109498, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63713109498, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:58:23.327: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:58:23.329: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:58:24.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-54" for this suite.
Dec 28 05:58:30.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:58:30.483: INFO: namespace crd-webhook-54 deletion completed in 6.071220063s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:12.487 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:58:30.490: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 28 05:58:30.509: INFO: Waiting up to 5m0s for pod "pod-1fd228b7-9f12-455e-ad89-09ceba2ebb95" in namespace "emptydir-534" to be "success or failure"
Dec 28 05:58:30.511: INFO: Pod "pod-1fd228b7-9f12-455e-ad89-09ceba2ebb95": Phase="Pending", Reason="", readiness=false. Elapsed: 1.494125ms
Dec 28 05:58:32.512: INFO: Pod "pod-1fd228b7-9f12-455e-ad89-09ceba2ebb95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003322758s
STEP: Saw pod success
Dec 28 05:58:32.512: INFO: Pod "pod-1fd228b7-9f12-455e-ad89-09ceba2ebb95" satisfied condition "success or failure"
Dec 28 05:58:32.514: INFO: Trying to get logs from node hxx-m-2 pod pod-1fd228b7-9f12-455e-ad89-09ceba2ebb95 container test-container: <nil>
STEP: delete the pod
Dec 28 05:58:32.524: INFO: Waiting for pod pod-1fd228b7-9f12-455e-ad89-09ceba2ebb95 to disappear
Dec 28 05:58:32.525: INFO: Pod pod-1fd228b7-9f12-455e-ad89-09ceba2ebb95 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:58:32.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-534" for this suite.
Dec 28 05:58:38.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:58:38.593: INFO: namespace emptydir-534 deletion completed in 6.065646137s

• [SLOW TEST:8.104 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:58:38.594: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 28 05:58:38.613: INFO: Waiting up to 5m0s for pod "pod-d73cb4bf-9546-4d18-947b-899bc3b9c4d8" in namespace "emptydir-2711" to be "success or failure"
Dec 28 05:58:38.614: INFO: Pod "pod-d73cb4bf-9546-4d18-947b-899bc3b9c4d8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.5725ms
Dec 28 05:58:40.616: INFO: Pod "pod-d73cb4bf-9546-4d18-947b-899bc3b9c4d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003859263s
STEP: Saw pod success
Dec 28 05:58:40.616: INFO: Pod "pod-d73cb4bf-9546-4d18-947b-899bc3b9c4d8" satisfied condition "success or failure"
Dec 28 05:58:40.618: INFO: Trying to get logs from node hxx-m-2 pod pod-d73cb4bf-9546-4d18-947b-899bc3b9c4d8 container test-container: <nil>
STEP: delete the pod
Dec 28 05:58:40.629: INFO: Waiting for pod pod-d73cb4bf-9546-4d18-947b-899bc3b9c4d8 to disappear
Dec 28 05:58:40.631: INFO: Pod pod-d73cb4bf-9546-4d18-947b-899bc3b9c4d8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:58:40.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2711" for this suite.
Dec 28 05:58:46.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:58:46.710: INFO: namespace emptydir-2711 deletion completed in 6.076083044s

• [SLOW TEST:8.117 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:58:46.710: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Dec 28 05:58:46.730: INFO: Waiting up to 5m0s for pod "client-containers-c74b9e82-ac1c-4c79-806b-46eec4f47bd0" in namespace "containers-4823" to be "success or failure"
Dec 28 05:58:46.732: INFO: Pod "client-containers-c74b9e82-ac1c-4c79-806b-46eec4f47bd0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104432ms
Dec 28 05:58:48.735: INFO: Pod "client-containers-c74b9e82-ac1c-4c79-806b-46eec4f47bd0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004752033s
STEP: Saw pod success
Dec 28 05:58:48.735: INFO: Pod "client-containers-c74b9e82-ac1c-4c79-806b-46eec4f47bd0" satisfied condition "success or failure"
Dec 28 05:58:48.736: INFO: Trying to get logs from node hxx-m-2 pod client-containers-c74b9e82-ac1c-4c79-806b-46eec4f47bd0 container test-container: <nil>
STEP: delete the pod
Dec 28 05:58:48.746: INFO: Waiting for pod client-containers-c74b9e82-ac1c-4c79-806b-46eec4f47bd0 to disappear
Dec 28 05:58:48.748: INFO: Pod client-containers-c74b9e82-ac1c-4c79-806b-46eec4f47bd0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:58:48.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4823" for this suite.
Dec 28 05:58:54.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:58:54.819: INFO: namespace containers-4823 deletion completed in 6.067838427s

• [SLOW TEST:8.108 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:58:54.819: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 05:58:55.211: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 05:58:58.225: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:58:58.228: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3792-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:58:58.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1790" for this suite.
Dec 28 05:59:04.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:59:04.878: INFO: namespace webhook-1790 deletion completed in 6.069080231s
STEP: Destroying namespace "webhook-1790-markers" for this suite.
Dec 28 05:59:10.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:59:10.949: INFO: namespace webhook-1790-markers deletion completed in 6.070102654s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.137 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:59:10.956: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-97606c40-c6c2-4c67-8128-bf2691bbb82d
STEP: Creating a pod to test consume configMaps
Dec 28 05:59:10.977: INFO: Waiting up to 5m0s for pod "pod-configmaps-5d604092-4376-4a25-ae21-2e2a134b3a8f" in namespace "configmap-1247" to be "success or failure"
Dec 28 05:59:10.978: INFO: Pod "pod-configmaps-5d604092-4376-4a25-ae21-2e2a134b3a8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.376219ms
Dec 28 05:59:12.980: INFO: Pod "pod-configmaps-5d604092-4376-4a25-ae21-2e2a134b3a8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003880009s
STEP: Saw pod success
Dec 28 05:59:12.981: INFO: Pod "pod-configmaps-5d604092-4376-4a25-ae21-2e2a134b3a8f" satisfied condition "success or failure"
Dec 28 05:59:12.982: INFO: Trying to get logs from node hxx-m-2 pod pod-configmaps-5d604092-4376-4a25-ae21-2e2a134b3a8f container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:59:12.992: INFO: Waiting for pod pod-configmaps-5d604092-4376-4a25-ae21-2e2a134b3a8f to disappear
Dec 28 05:59:12.993: INFO: Pod pod-configmaps-5d604092-4376-4a25-ae21-2e2a134b3a8f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:59:12.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1247" for this suite.
Dec 28 05:59:19.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:59:19.063: INFO: namespace configmap-1247 deletion completed in 6.068124471s

• [SLOW TEST:8.108 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 05:59:19.064: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 05:59:19.080: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 05:59:21.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5584" for this suite.
Dec 28 06:00:05.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:00:05.302: INFO: namespace pods-5584 deletion completed in 44.070406701s

• [SLOW TEST:46.238 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:00:05.302: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-533a6e6f-59b4-4b50-90cc-b85af89793ab
STEP: Creating a pod to test consume configMaps
Dec 28 06:00:05.323: INFO: Waiting up to 5m0s for pod "pod-configmaps-d4683a3b-022b-40c7-ab26-10451527d33e" in namespace "configmap-3216" to be "success or failure"
Dec 28 06:00:05.324: INFO: Pod "pod-configmaps-d4683a3b-022b-40c7-ab26-10451527d33e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.309264ms
Dec 28 06:00:07.326: INFO: Pod "pod-configmaps-d4683a3b-022b-40c7-ab26-10451527d33e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003529527s
STEP: Saw pod success
Dec 28 06:00:07.326: INFO: Pod "pod-configmaps-d4683a3b-022b-40c7-ab26-10451527d33e" satisfied condition "success or failure"
Dec 28 06:00:07.328: INFO: Trying to get logs from node hxx-m-2 pod pod-configmaps-d4683a3b-022b-40c7-ab26-10451527d33e container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 06:00:07.337: INFO: Waiting for pod pod-configmaps-d4683a3b-022b-40c7-ab26-10451527d33e to disappear
Dec 28 06:00:07.340: INFO: Pod pod-configmaps-d4683a3b-022b-40c7-ab26-10451527d33e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:00:07.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3216" for this suite.
Dec 28 06:00:13.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:00:13.416: INFO: namespace configmap-3216 deletion completed in 6.073180869s

• [SLOW TEST:8.114 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:00:13.416: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 28 06:00:13.439: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3506 /api/v1/namespaces/watch-3506/configmaps/e2e-watch-test-watch-closed 9d27fc7b-50b7-442a-bdad-ebafa0c9a662 242977 0 2019-12-28 06:00:13 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 28 06:00:13.439: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3506 /api/v1/namespaces/watch-3506/configmaps/e2e-watch-test-watch-closed 9d27fc7b-50b7-442a-bdad-ebafa0c9a662 242978 0 2019-12-28 06:00:13 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 28 06:00:13.446: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3506 /api/v1/namespaces/watch-3506/configmaps/e2e-watch-test-watch-closed 9d27fc7b-50b7-442a-bdad-ebafa0c9a662 242979 0 2019-12-28 06:00:13 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 28 06:00:13.447: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3506 /api/v1/namespaces/watch-3506/configmaps/e2e-watch-test-watch-closed 9d27fc7b-50b7-442a-bdad-ebafa0c9a662 242980 0 2019-12-28 06:00:13 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:00:13.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3506" for this suite.
Dec 28 06:00:19.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:00:19.517: INFO: namespace watch-3506 deletion completed in 6.068141704s

• [SLOW TEST:6.102 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:00:19.518: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:00:32.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8674" for this suite.
Dec 28 06:00:38.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:00:38.634: INFO: namespace resourcequota-8674 deletion completed in 6.067607233s

• [SLOW TEST:19.116 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:00:38.635: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Dec 28 06:00:38.652: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-505712781 proxy --unix-socket=/tmp/kubectl-proxy-unix473898660/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:00:38.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1050" for this suite.
Dec 28 06:00:44.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:00:44.785: INFO: namespace kubectl-1050 deletion completed in 6.067190927s

• [SLOW TEST:6.150 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:00:44.785: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 28 06:00:44.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-8618'
Dec 28 06:00:44.972: INFO: stderr: ""
Dec 28 06:00:44.972: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec 28 06:00:50.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 get pod e2e-test-httpd-pod --namespace=kubectl-8618 -o json'
Dec 28 06:00:50.096: INFO: stderr: ""
Dec 28 06:00:50.096: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-12-28T06:00:44Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8618\",\n        \"resourceVersion\": \"243142\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8618/pods/e2e-test-httpd-pod\",\n        \"uid\": \"ae4d66b2-0968-4703-857a-963d9c902f59\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-snpk7\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"hxx-m-2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-snpk7\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-snpk7\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-28T06:00:44Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-28T06:00:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-28T06:00:46Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-28T06:00:44Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://ab07eb1ed367e3df744c41891f8e36d057136b93a6ebe064840fd9cb58b02f5e\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-28T06:00:45Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.128.16\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.199.0.177\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.199.0.177\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-28T06:00:44Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 28 06:00:50.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 replace -f - --namespace=kubectl-8618'
Dec 28 06:00:50.299: INFO: stderr: ""
Dec 28 06:00:50.299: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Dec 28 06:00:50.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete pods e2e-test-httpd-pod --namespace=kubectl-8618'
Dec 28 06:01:00.933: INFO: stderr: ""
Dec 28 06:01:00.933: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:01:00.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8618" for this suite.
Dec 28 06:01:06.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:01:07.012: INFO: namespace kubectl-8618 deletion completed in 6.076647633s

• [SLOW TEST:22.227 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:01:07.013: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 28 06:01:09.039: INFO: &Pod{ObjectMeta:{send-events-8d60448e-0a22-499e-a815-49636285f4ed  events-6041 /api/v1/namespaces/events-6041/pods/send-events-8d60448e-0a22-499e-a815-49636285f4ed f88a5be1-c8b6-4f27-93c3-62bfbcb27fc4 243252 0 2019-12-28 06:01:07 +0000 UTC <nil> <nil> map[name:foo time:29075757] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w82n9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w82n9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w82n9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hxx-m-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 06:01:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 06:01:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 06:01:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-28 06:01:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.128.16,PodIP:10.199.0.178,StartTime:2019-12-28 06:01:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-28 06:01:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://0872aa5e3247bea5a8480b385452bbeef61da5ae7429f2f114bbd721d8278735,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.199.0.178,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec 28 06:01:11.041: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 28 06:01:13.044: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:01:13.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6041" for this suite.
Dec 28 06:01:57.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:01:57.121: INFO: namespace events-6041 deletion completed in 44.071335926s

• [SLOW TEST:50.109 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:01:57.121: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-b988d89a-dc89-4b42-a1e7-a8072ff935ba
STEP: Creating a pod to test consume configMaps
Dec 28 06:01:57.143: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec9a9405-9794-4e81-b188-a1e7cf275676" in namespace "configmap-8650" to be "success or failure"
Dec 28 06:01:57.145: INFO: Pod "pod-configmaps-ec9a9405-9794-4e81-b188-a1e7cf275676": Phase="Pending", Reason="", readiness=false. Elapsed: 1.36734ms
Dec 28 06:01:59.146: INFO: Pod "pod-configmaps-ec9a9405-9794-4e81-b188-a1e7cf275676": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00326007s
STEP: Saw pod success
Dec 28 06:01:59.146: INFO: Pod "pod-configmaps-ec9a9405-9794-4e81-b188-a1e7cf275676" satisfied condition "success or failure"
Dec 28 06:01:59.148: INFO: Trying to get logs from node hxx-m-2 pod pod-configmaps-ec9a9405-9794-4e81-b188-a1e7cf275676 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 06:01:59.163: INFO: Waiting for pod pod-configmaps-ec9a9405-9794-4e81-b188-a1e7cf275676 to disappear
Dec 28 06:01:59.165: INFO: Pod pod-configmaps-ec9a9405-9794-4e81-b188-a1e7cf275676 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:01:59.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8650" for this suite.
Dec 28 06:02:05.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:02:05.240: INFO: namespace configmap-8650 deletion completed in 6.072192311s

• [SLOW TEST:8.119 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:02:05.240: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 28 06:02:05.259: INFO: Waiting up to 5m0s for pod "downward-api-51ea6ccb-e027-4ddc-822a-84cb74d0a822" in namespace "downward-api-6946" to be "success or failure"
Dec 28 06:02:05.261: INFO: Pod "downward-api-51ea6ccb-e027-4ddc-822a-84cb74d0a822": Phase="Pending", Reason="", readiness=false. Elapsed: 1.490812ms
Dec 28 06:02:07.263: INFO: Pod "downward-api-51ea6ccb-e027-4ddc-822a-84cb74d0a822": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003782505s
STEP: Saw pod success
Dec 28 06:02:07.263: INFO: Pod "downward-api-51ea6ccb-e027-4ddc-822a-84cb74d0a822" satisfied condition "success or failure"
Dec 28 06:02:07.265: INFO: Trying to get logs from node hxx-m-2 pod downward-api-51ea6ccb-e027-4ddc-822a-84cb74d0a822 container dapi-container: <nil>
STEP: delete the pod
Dec 28 06:02:07.274: INFO: Waiting for pod downward-api-51ea6ccb-e027-4ddc-822a-84cb74d0a822 to disappear
Dec 28 06:02:07.276: INFO: Pod downward-api-51ea6ccb-e027-4ddc-822a-84cb74d0a822 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:02:07.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6946" for this suite.
Dec 28 06:02:13.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:02:13.356: INFO: namespace downward-api-6946 deletion completed in 6.077613746s

• [SLOW TEST:8.116 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:02:13.356: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-26e3bb76-2d2c-40d6-890d-9e5a850c621d
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:02:13.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2108" for this suite.
Dec 28 06:02:19.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:02:19.448: INFO: namespace configmap-2108 deletion completed in 6.067007948s

• [SLOW TEST:6.092 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:02:19.448: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 28 06:02:20.474: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:02:20.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5921" for this suite.
Dec 28 06:02:26.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:02:26.554: INFO: namespace container-runtime-5921 deletion completed in 6.071891563s

• [SLOW TEST:7.106 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:02:26.554: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6558
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6558
STEP: creating replication controller externalsvc in namespace services-6558
I1228 06:02:26.584969      22 runners.go:184] Created replication controller with name: externalsvc, namespace: services-6558, replica count: 2
I1228 06:02:29.635314      22 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec 28 06:02:29.645: INFO: Creating new exec pod
Dec 28 06:02:31.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-6558 execpodrtgpv -- /bin/sh -x -c nslookup clusterip-service'
Dec 28 06:02:31.878: INFO: stderr: "+ nslookup clusterip-service\n"
Dec 28 06:02:31.878: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-6558.svc.cluster.local\tcanonical name = externalsvc.services-6558.svc.cluster.local.\nName:\texternalsvc.services-6558.svc.cluster.local\nAddress: 10.102.65.202\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6558, will wait for the garbage collector to delete the pods
Dec 28 06:02:31.935: INFO: Deleting ReplicationController externalsvc took: 4.146673ms
Dec 28 06:02:32.735: INFO: Terminating ReplicationController externalsvc pods took: 800.26563ms
Dec 28 06:02:41.244: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:02:41.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6558" for this suite.
Dec 28 06:02:47.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:02:47.320: INFO: namespace services-6558 deletion completed in 6.06808725s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:20.765 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:02:47.320: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-9c4fa175-c5fc-4545-b4db-f6d992e0c2f3
STEP: Creating a pod to test consume secrets
Dec 28 06:02:47.345: INFO: Waiting up to 5m0s for pod "pod-secrets-c149f138-c673-4683-8f3e-1a4b90410c2b" in namespace "secrets-4928" to be "success or failure"
Dec 28 06:02:47.346: INFO: Pod "pod-secrets-c149f138-c673-4683-8f3e-1a4b90410c2b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.364798ms
Dec 28 06:02:49.348: INFO: Pod "pod-secrets-c149f138-c673-4683-8f3e-1a4b90410c2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003400199s
STEP: Saw pod success
Dec 28 06:02:49.348: INFO: Pod "pod-secrets-c149f138-c673-4683-8f3e-1a4b90410c2b" satisfied condition "success or failure"
Dec 28 06:02:49.350: INFO: Trying to get logs from node hxx-m-2 pod pod-secrets-c149f138-c673-4683-8f3e-1a4b90410c2b container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 06:02:49.359: INFO: Waiting for pod pod-secrets-c149f138-c673-4683-8f3e-1a4b90410c2b to disappear
Dec 28 06:02:49.361: INFO: Pod pod-secrets-c149f138-c673-4683-8f3e-1a4b90410c2b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:02:49.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4928" for this suite.
Dec 28 06:02:55.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:02:55.427: INFO: namespace secrets-4928 deletion completed in 6.063657745s

• [SLOW TEST:8.106 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:02:55.427: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:02:59.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4272" for this suite.
Dec 28 06:03:05.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:03:05.554: INFO: namespace kubelet-test-4272 deletion completed in 6.068737856s

• [SLOW TEST:10.127 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:03:05.554: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 06:03:05.574: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cb96e432-f6fe-4d3d-9843-5ab22958b7f4" in namespace "projected-5507" to be "success or failure"
Dec 28 06:03:05.575: INFO: Pod "downwardapi-volume-cb96e432-f6fe-4d3d-9843-5ab22958b7f4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.303606ms
Dec 28 06:03:07.577: INFO: Pod "downwardapi-volume-cb96e432-f6fe-4d3d-9843-5ab22958b7f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00353159s
STEP: Saw pod success
Dec 28 06:03:07.577: INFO: Pod "downwardapi-volume-cb96e432-f6fe-4d3d-9843-5ab22958b7f4" satisfied condition "success or failure"
Dec 28 06:03:07.579: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-cb96e432-f6fe-4d3d-9843-5ab22958b7f4 container client-container: <nil>
STEP: delete the pod
Dec 28 06:03:07.588: INFO: Waiting for pod downwardapi-volume-cb96e432-f6fe-4d3d-9843-5ab22958b7f4 to disappear
Dec 28 06:03:07.590: INFO: Pod downwardapi-volume-cb96e432-f6fe-4d3d-9843-5ab22958b7f4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:03:07.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5507" for this suite.
Dec 28 06:03:13.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:03:13.665: INFO: namespace projected-5507 deletion completed in 6.072884149s

• [SLOW TEST:8.111 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:03:13.665: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 28 06:03:13.685: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e9b54887-4121-48e0-807a-3c2d211e9f8e" in namespace "downward-api-8470" to be "success or failure"
Dec 28 06:03:13.686: INFO: Pod "downwardapi-volume-e9b54887-4121-48e0-807a-3c2d211e9f8e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.470363ms
Dec 28 06:03:15.689: INFO: Pod "downwardapi-volume-e9b54887-4121-48e0-807a-3c2d211e9f8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00390396s
STEP: Saw pod success
Dec 28 06:03:15.689: INFO: Pod "downwardapi-volume-e9b54887-4121-48e0-807a-3c2d211e9f8e" satisfied condition "success or failure"
Dec 28 06:03:15.690: INFO: Trying to get logs from node hxx-m-2 pod downwardapi-volume-e9b54887-4121-48e0-807a-3c2d211e9f8e container client-container: <nil>
STEP: delete the pod
Dec 28 06:03:15.701: INFO: Waiting for pod downwardapi-volume-e9b54887-4121-48e0-807a-3c2d211e9f8e to disappear
Dec 28 06:03:15.702: INFO: Pod downwardapi-volume-e9b54887-4121-48e0-807a-3c2d211e9f8e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:03:15.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8470" for this suite.
Dec 28 06:03:21.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:03:21.774: INFO: namespace downward-api-8470 deletion completed in 6.06825073s

• [SLOW TEST:8.109 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:03:21.775: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-f3456832-df88-494f-aed6-072617c6b3e2
STEP: Creating a pod to test consume configMaps
Dec 28 06:03:21.797: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-63b831e0-8f20-48d0-bd58-077d5a79559e" in namespace "projected-664" to be "success or failure"
Dec 28 06:03:21.799: INFO: Pod "pod-projected-configmaps-63b831e0-8f20-48d0-bd58-077d5a79559e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.525659ms
Dec 28 06:03:23.801: INFO: Pod "pod-projected-configmaps-63b831e0-8f20-48d0-bd58-077d5a79559e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003688571s
STEP: Saw pod success
Dec 28 06:03:23.801: INFO: Pod "pod-projected-configmaps-63b831e0-8f20-48d0-bd58-077d5a79559e" satisfied condition "success or failure"
Dec 28 06:03:23.802: INFO: Trying to get logs from node hxx-m-2 pod pod-projected-configmaps-63b831e0-8f20-48d0-bd58-077d5a79559e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 06:03:23.812: INFO: Waiting for pod pod-projected-configmaps-63b831e0-8f20-48d0-bd58-077d5a79559e to disappear
Dec 28 06:03:23.814: INFO: Pod pod-projected-configmaps-63b831e0-8f20-48d0-bd58-077d5a79559e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:03:23.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-664" for this suite.
Dec 28 06:03:29.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:03:29.885: INFO: namespace projected-664 deletion completed in 6.069047814s

• [SLOW TEST:8.111 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:03:29.886: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 06:03:29.904: INFO: Waiting up to 5m0s for pod "busybox-user-65534-e4da0813-3ffe-415d-bb6c-f12f4221f27d" in namespace "security-context-test-9634" to be "success or failure"
Dec 28 06:03:29.905: INFO: Pod "busybox-user-65534-e4da0813-3ffe-415d-bb6c-f12f4221f27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.278835ms
Dec 28 06:03:31.908: INFO: Pod "busybox-user-65534-e4da0813-3ffe-415d-bb6c-f12f4221f27d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003584138s
Dec 28 06:03:31.908: INFO: Pod "busybox-user-65534-e4da0813-3ffe-415d-bb6c-f12f4221f27d" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:03:31.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9634" for this suite.
Dec 28 06:03:37.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:03:37.980: INFO: namespace security-context-test-9634 deletion completed in 6.06967216s

• [SLOW TEST:8.094 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:03:37.981: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:03:40.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4868" for this suite.
Dec 28 06:04:24.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:04:24.077: INFO: namespace kubelet-test-4868 deletion completed in 44.064531283s

• [SLOW TEST:46.097 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:04:24.078: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1126.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1126.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1126.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1126.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1126.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1126.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1126.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1126.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1126.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1126.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 108.122.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.122.108_udp@PTR;check="$$(dig +tcp +noall +answer +search 108.122.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.122.108_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1126.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1126.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1126.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1126.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1126.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1126.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1126.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1126.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1126.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1126.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1126.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 108.122.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.122.108_udp@PTR;check="$$(dig +tcp +noall +answer +search 108.122.101.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.101.122.108_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 28 06:04:26.116: INFO: Unable to read wheezy_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:26.118: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:26.119: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:26.121: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:26.134: INFO: Unable to read jessie_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:26.136: INFO: Unable to read jessie_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:26.138: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:26.140: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:26.149: INFO: Lookups using dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed failed for: [wheezy_udp@dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_udp@dns-test-service.dns-1126.svc.cluster.local jessie_tcp@dns-test-service.dns-1126.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local]

Dec 28 06:04:31.152: INFO: Unable to read wheezy_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:31.154: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:31.156: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:31.158: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:31.170: INFO: Unable to read jessie_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:31.171: INFO: Unable to read jessie_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:31.173: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:31.178: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:31.189: INFO: Lookups using dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed failed for: [wheezy_udp@dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_udp@dns-test-service.dns-1126.svc.cluster.local jessie_tcp@dns-test-service.dns-1126.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local]

Dec 28 06:04:36.152: INFO: Unable to read wheezy_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:36.154: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:36.156: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:36.158: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:36.170: INFO: Unable to read jessie_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:36.172: INFO: Unable to read jessie_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:36.174: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:36.175: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:36.187: INFO: Lookups using dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed failed for: [wheezy_udp@dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_udp@dns-test-service.dns-1126.svc.cluster.local jessie_tcp@dns-test-service.dns-1126.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local]

Dec 28 06:04:41.152: INFO: Unable to read wheezy_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:41.154: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:41.156: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:41.157: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:41.170: INFO: Unable to read jessie_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:41.171: INFO: Unable to read jessie_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:41.173: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:41.174: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:41.185: INFO: Lookups using dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed failed for: [wheezy_udp@dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_udp@dns-test-service.dns-1126.svc.cluster.local jessie_tcp@dns-test-service.dns-1126.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local]

Dec 28 06:04:46.152: INFO: Unable to read wheezy_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:46.154: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:46.156: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:46.158: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:46.170: INFO: Unable to read jessie_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:46.171: INFO: Unable to read jessie_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:46.173: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:46.175: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:46.185: INFO: Lookups using dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed failed for: [wheezy_udp@dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_udp@dns-test-service.dns-1126.svc.cluster.local jessie_tcp@dns-test-service.dns-1126.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local]

Dec 28 06:04:51.152: INFO: Unable to read wheezy_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:51.154: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:51.155: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:51.157: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:51.170: INFO: Unable to read jessie_udp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:51.171: INFO: Unable to read jessie_tcp@dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:51.173: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:51.175: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local from pod dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed: the server could not find the requested resource (get pods dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed)
Dec 28 06:04:51.185: INFO: Lookups using dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed failed for: [wheezy_udp@dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@dns-test-service.dns-1126.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_udp@dns-test-service.dns-1126.svc.cluster.local jessie_tcp@dns-test-service.dns-1126.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1126.svc.cluster.local]

Dec 28 06:04:56.186: INFO: DNS probes using dns-1126/dns-test-b435fee8-ba89-4e0d-9aa4-6c87802ec3ed succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:04:56.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1126" for this suite.
Dec 28 06:05:02.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:05:02.309: INFO: namespace dns-1126 deletion completed in 6.073179039s

• [SLOW TEST:38.232 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:05:02.310: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Dec 28 06:05:02.326: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 28 06:05:02.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-1690'
Dec 28 06:05:02.484: INFO: stderr: ""
Dec 28 06:05:02.484: INFO: stdout: "service/redis-slave created\n"
Dec 28 06:05:02.484: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 28 06:05:02.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-1690'
Dec 28 06:05:02.639: INFO: stderr: ""
Dec 28 06:05:02.639: INFO: stdout: "service/redis-master created\n"
Dec 28 06:05:02.639: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 28 06:05:02.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-1690'
Dec 28 06:05:02.789: INFO: stderr: ""
Dec 28 06:05:02.789: INFO: stdout: "service/frontend created\n"
Dec 28 06:05:02.789: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 28 06:05:02.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-1690'
Dec 28 06:05:02.934: INFO: stderr: ""
Dec 28 06:05:02.934: INFO: stdout: "deployment.apps/frontend created\n"
Dec 28 06:05:02.935: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 28 06:05:02.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-1690'
Dec 28 06:05:03.077: INFO: stderr: ""
Dec 28 06:05:03.077: INFO: stdout: "deployment.apps/redis-master created\n"
Dec 28 06:05:03.077: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 28 06:05:03.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 create -f - --namespace=kubectl-1690'
Dec 28 06:05:03.224: INFO: stderr: ""
Dec 28 06:05:03.224: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec 28 06:05:03.224: INFO: Waiting for all frontend pods to be Running.
Dec 28 06:05:08.274: INFO: Waiting for frontend to serve content.
Dec 28 06:05:08.287: INFO: Trying to add a new entry to the guestbook.
Dec 28 06:05:08.295: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 28 06:05:08.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete --grace-period=0 --force -f - --namespace=kubectl-1690'
Dec 28 06:05:08.388: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 06:05:08.388: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 28 06:05:08.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete --grace-period=0 --force -f - --namespace=kubectl-1690'
Dec 28 06:05:08.480: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 06:05:08.481: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 28 06:05:08.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete --grace-period=0 --force -f - --namespace=kubectl-1690'
Dec 28 06:05:08.573: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 06:05:08.573: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 28 06:05:08.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete --grace-period=0 --force -f - --namespace=kubectl-1690'
Dec 28 06:05:08.657: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 06:05:08.657: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 28 06:05:08.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete --grace-period=0 --force -f - --namespace=kubectl-1690'
Dec 28 06:05:08.732: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 06:05:08.732: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 28 06:05:08.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete --grace-period=0 --force -f - --namespace=kubectl-1690'
Dec 28 06:05:08.804: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 06:05:08.804: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:05:08.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1690" for this suite.
Dec 28 06:05:14.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:05:14.878: INFO: namespace kubectl-1690 deletion completed in 6.071738603s

• [SLOW TEST:12.568 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:05:14.878: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 28 06:05:14.898: INFO: Waiting up to 5m0s for pod "pod-ef5c6384-0f7b-4801-9378-f02caf7df0b4" in namespace "emptydir-191" to be "success or failure"
Dec 28 06:05:14.899: INFO: Pod "pod-ef5c6384-0f7b-4801-9378-f02caf7df0b4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.421571ms
Dec 28 06:05:16.901: INFO: Pod "pod-ef5c6384-0f7b-4801-9378-f02caf7df0b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003699527s
STEP: Saw pod success
Dec 28 06:05:16.902: INFO: Pod "pod-ef5c6384-0f7b-4801-9378-f02caf7df0b4" satisfied condition "success or failure"
Dec 28 06:05:16.903: INFO: Trying to get logs from node hxx-m-2 pod pod-ef5c6384-0f7b-4801-9378-f02caf7df0b4 container test-container: <nil>
STEP: delete the pod
Dec 28 06:05:16.919: INFO: Waiting for pod pod-ef5c6384-0f7b-4801-9378-f02caf7df0b4 to disappear
Dec 28 06:05:16.920: INFO: Pod pod-ef5c6384-0f7b-4801-9378-f02caf7df0b4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:05:16.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-191" for this suite.
Dec 28 06:05:22.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:05:22.997: INFO: namespace emptydir-191 deletion completed in 6.074181253s

• [SLOW TEST:8.119 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:05:22.997: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 28 06:05:25.532: INFO: Successfully updated pod "annotationupdate9dc06e2a-c9d6-4727-ac1d-a1db097cc2d0"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:05:29.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7088" for this suite.
Dec 28 06:05:41.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:05:41.614: INFO: namespace downward-api-7088 deletion completed in 12.064095994s

• [SLOW TEST:18.617 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:05:41.614: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-e2af1c9e-a425-42cf-9805-55f4ef844186
STEP: Creating a pod to test consume secrets
Dec 28 06:05:41.650: INFO: Waiting up to 5m0s for pod "pod-secrets-d8689fad-dae0-41a6-9cb9-6086108673eb" in namespace "secrets-2501" to be "success or failure"
Dec 28 06:05:41.652: INFO: Pod "pod-secrets-d8689fad-dae0-41a6-9cb9-6086108673eb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.472432ms
Dec 28 06:05:43.654: INFO: Pod "pod-secrets-d8689fad-dae0-41a6-9cb9-6086108673eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003702419s
STEP: Saw pod success
Dec 28 06:05:43.654: INFO: Pod "pod-secrets-d8689fad-dae0-41a6-9cb9-6086108673eb" satisfied condition "success or failure"
Dec 28 06:05:43.655: INFO: Trying to get logs from node hxx-m-2 pod pod-secrets-d8689fad-dae0-41a6-9cb9-6086108673eb container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 06:05:43.665: INFO: Waiting for pod pod-secrets-d8689fad-dae0-41a6-9cb9-6086108673eb to disappear
Dec 28 06:05:43.666: INFO: Pod pod-secrets-d8689fad-dae0-41a6-9cb9-6086108673eb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:05:43.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2501" for this suite.
Dec 28 06:05:49.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:05:49.738: INFO: namespace secrets-2501 deletion completed in 6.069081505s
STEP: Destroying namespace "secret-namespace-3292" for this suite.
Dec 28 06:05:55.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:05:55.807: INFO: namespace secret-namespace-3292 deletion completed in 6.068750403s

• [SLOW TEST:14.192 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:05:55.807: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 28 06:05:56.446: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 28 06:05:59.465: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:05:59.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3300" for this suite.
Dec 28 06:06:05.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:06:05.572: INFO: namespace webhook-3300 deletion completed in 6.072436626s
STEP: Destroying namespace "webhook-3300-markers" for this suite.
Dec 28 06:06:11.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:06:11.641: INFO: namespace webhook-3300-markers deletion completed in 6.069394126s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.841 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:06:11.648: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-3955/secret-test-65f1bd6e-642c-4c53-88a5-7812fa2af08c
STEP: Creating a pod to test consume secrets
Dec 28 06:06:11.669: INFO: Waiting up to 5m0s for pod "pod-configmaps-e714d30a-b8bb-43de-aadc-8c5b76b713e1" in namespace "secrets-3955" to be "success or failure"
Dec 28 06:06:11.670: INFO: Pod "pod-configmaps-e714d30a-b8bb-43de-aadc-8c5b76b713e1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.553176ms
Dec 28 06:06:13.672: INFO: Pod "pod-configmaps-e714d30a-b8bb-43de-aadc-8c5b76b713e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003685554s
STEP: Saw pod success
Dec 28 06:06:13.673: INFO: Pod "pod-configmaps-e714d30a-b8bb-43de-aadc-8c5b76b713e1" satisfied condition "success or failure"
Dec 28 06:06:13.674: INFO: Trying to get logs from node hxx-m-2 pod pod-configmaps-e714d30a-b8bb-43de-aadc-8c5b76b713e1 container env-test: <nil>
STEP: delete the pod
Dec 28 06:06:13.684: INFO: Waiting for pod pod-configmaps-e714d30a-b8bb-43de-aadc-8c5b76b713e1 to disappear
Dec 28 06:06:13.686: INFO: Pod pod-configmaps-e714d30a-b8bb-43de-aadc-8c5b76b713e1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:06:13.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3955" for this suite.
Dec 28 06:06:19.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:06:19.755: INFO: namespace secrets-3955 deletion completed in 6.065162005s

• [SLOW TEST:8.107 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:06:19.755: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7187
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 28 06:06:19.771: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 28 06:06:39.816: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.199.0.201:8080/dial?request=hostName&protocol=http&host=10.199.0.200&port=8080&tries=1'] Namespace:pod-network-test-7187 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:06:39.816: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 06:06:39.957: INFO: Waiting for endpoints: map[]
Dec 28 06:06:39.960: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.199.0.201:8080/dial?request=hostName&protocol=http&host=10.199.2.240&port=8080&tries=1'] Namespace:pod-network-test-7187 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:06:39.960: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 06:06:40.136: INFO: Waiting for endpoints: map[]
Dec 28 06:06:40.138: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.199.0.201:8080/dial?request=hostName&protocol=http&host=10.199.1.148&port=8080&tries=1'] Namespace:pod-network-test-7187 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:06:40.138: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
Dec 28 06:06:40.314: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:06:40.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7187" for this suite.
Dec 28 06:06:52.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:06:52.386: INFO: namespace pod-network-test-7187 deletion completed in 12.068801832s

• [SLOW TEST:32.631 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:06:52.386: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Dec 28 06:06:52.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-1673 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 28 06:06:52.485: INFO: stderr: ""
Dec 28 06:06:52.485: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Dec 28 06:06:52.485: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 28 06:06:52.486: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1673" to be "running and ready, or succeeded"
Dec 28 06:06:52.487: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 1.498213ms
Dec 28 06:06:54.489: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.003466614s
Dec 28 06:06:54.489: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 28 06:06:54.489: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec 28 06:06:54.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 logs logs-generator logs-generator --namespace=kubectl-1673'
Dec 28 06:06:54.572: INFO: stderr: ""
Dec 28 06:06:54.572: INFO: stdout: "I1228 06:06:53.277173       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/n59b 469\nI1228 06:06:53.477392       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/rf8d 377\nI1228 06:06:53.677299       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/v6z 394\nI1228 06:06:53.877287       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/fjch 368\nI1228 06:06:54.077309       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/mpsp 279\nI1228 06:06:54.277301       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/4f9 533\nI1228 06:06:54.477311       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/svr 203\n"
STEP: limiting log lines
Dec 28 06:06:54.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 logs logs-generator logs-generator --namespace=kubectl-1673 --tail=1'
Dec 28 06:06:54.656: INFO: stderr: ""
Dec 28 06:06:54.656: INFO: stdout: "I1228 06:06:54.477311       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/svr 203\n"
STEP: limiting log bytes
Dec 28 06:06:54.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 logs logs-generator logs-generator --namespace=kubectl-1673 --limit-bytes=1'
Dec 28 06:06:54.734: INFO: stderr: ""
Dec 28 06:06:54.734: INFO: stdout: "I"
STEP: exposing timestamps
Dec 28 06:06:54.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 logs logs-generator logs-generator --namespace=kubectl-1673 --tail=1 --timestamps'
Dec 28 06:06:54.814: INFO: stderr: ""
Dec 28 06:06:54.814: INFO: stdout: "2019-12-28T06:06:54.677420929Z I1228 06:06:54.677328       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/4544 522\n"
STEP: restricting to a time range
Dec 28 06:06:57.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 logs logs-generator logs-generator --namespace=kubectl-1673 --since=1s'
Dec 28 06:06:57.395: INFO: stderr: ""
Dec 28 06:06:57.395: INFO: stdout: "I1228 06:06:56.477298       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/45v 486\nI1228 06:06:56.677292       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/vv2 279\nI1228 06:06:56.877293       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/mdqp 301\nI1228 06:06:57.077296       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/n7q5 409\nI1228 06:06:57.277320       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/qsjg 469\n"
Dec 28 06:06:57.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 logs logs-generator logs-generator --namespace=kubectl-1673 --since=24h'
Dec 28 06:06:57.476: INFO: stderr: ""
Dec 28 06:06:57.476: INFO: stdout: "I1228 06:06:53.277173       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/n59b 469\nI1228 06:06:53.477392       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/rf8d 377\nI1228 06:06:53.677299       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/v6z 394\nI1228 06:06:53.877287       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/fjch 368\nI1228 06:06:54.077309       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/mpsp 279\nI1228 06:06:54.277301       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/4f9 533\nI1228 06:06:54.477311       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/svr 203\nI1228 06:06:54.677328       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/4544 522\nI1228 06:06:54.877294       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/mlm 206\nI1228 06:06:55.077302       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/4kn 466\nI1228 06:06:55.277306       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/v674 496\nI1228 06:06:55.477301       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/d4n 346\nI1228 06:06:55.677299       1 logs_generator.go:76] 12 GET /api/v1/namespaces/ns/pods/r2ns 296\nI1228 06:06:55.877297       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/d22 498\nI1228 06:06:56.077297       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/flms 288\nI1228 06:06:56.277306       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/6b9p 501\nI1228 06:06:56.477298       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/45v 486\nI1228 06:06:56.677292       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/vv2 279\nI1228 06:06:56.877293       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/mdqp 301\nI1228 06:06:57.077296       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/n7q5 409\nI1228 06:06:57.277320       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/qsjg 469\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Dec 28 06:06:57.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 delete pod logs-generator --namespace=kubectl-1673'
Dec 28 06:06:59.155: INFO: stderr: ""
Dec 28 06:06:59.155: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:06:59.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1673" for this suite.
Dec 28 06:07:05.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:07:05.228: INFO: namespace kubectl-1673 deletion completed in 6.070896139s

• [SLOW TEST:12.842 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:07:05.228: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-7069
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7069 to expose endpoints map[]
Dec 28 06:07:05.253: INFO: successfully validated that service endpoint-test2 in namespace services-7069 exposes endpoints map[] (2.156948ms elapsed)
STEP: Creating pod pod1 in namespace services-7069
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7069 to expose endpoints map[pod1:[80]]
Dec 28 06:07:06.264: INFO: successfully validated that service endpoint-test2 in namespace services-7069 exposes endpoints map[pod1:[80]] (1.007499317s elapsed)
STEP: Creating pod pod2 in namespace services-7069
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7069 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 28 06:07:08.281: INFO: successfully validated that service endpoint-test2 in namespace services-7069 exposes endpoints map[pod1:[80] pod2:[80]] (2.014727672s elapsed)
STEP: Deleting pod pod1 in namespace services-7069
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7069 to expose endpoints map[pod2:[80]]
Dec 28 06:07:09.292: INFO: successfully validated that service endpoint-test2 in namespace services-7069 exposes endpoints map[pod2:[80]] (1.008158451s elapsed)
STEP: Deleting pod pod2 in namespace services-7069
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7069 to expose endpoints map[]
Dec 28 06:07:10.299: INFO: successfully validated that service endpoint-test2 in namespace services-7069 exposes endpoints map[] (1.004030286s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:07:10.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7069" for this suite.
Dec 28 06:07:38.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:07:38.381: INFO: namespace services-7069 deletion completed in 28.068694038s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:33.153 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:07:38.381: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2464
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-2464
I1228 06:07:38.409595      22 runners.go:184] Created replication controller with name: externalname-service, namespace: services-2464, replica count: 2
I1228 06:07:41.459967      22 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 28 06:07:41.460: INFO: Creating new exec pod
Dec 28 06:07:44.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-2464 execpod8bblz -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 28 06:07:44.684: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 28 06:07:44.684: INFO: stdout: ""
Dec 28 06:07:44.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 exec --namespace=services-2464 execpod8bblz -- /bin/sh -x -c nc -zv -t -w 2 10.102.94.210 80'
Dec 28 06:07:44.901: INFO: stderr: "+ nc -zv -t -w 2 10.102.94.210 80\nConnection to 10.102.94.210 80 port [tcp/http] succeeded!\n"
Dec 28 06:07:44.901: INFO: stdout: ""
Dec 28 06:07:44.901: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:07:44.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2464" for this suite.
Dec 28 06:07:50.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:07:50.992: INFO: namespace services-2464 deletion completed in 6.077052756s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.610 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 28 06:07:50.992: INFO: >>> kubeConfig: /tmp/kubeconfig-505712781
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 28 06:07:51.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-505712781 version'
Dec 28 06:07:51.072: INFO: stderr: ""
Dec 28 06:07:51.073: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:23:11Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:13:49Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 28 06:07:51.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1721" for this suite.
Dec 28 06:07:57.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:07:57.147: INFO: namespace kubectl-1721 deletion completed in 6.071259933s

• [SLOW TEST:6.155 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSDec 28 06:07:57.147: INFO: Running AfterSuite actions on all nodes
Dec 28 06:07:57.147: INFO: Running AfterSuite actions on node 1
Dec 28 06:07:57.147: INFO: Skipping dumping logs from cluster

Ran 276 of 4732 Specs in 6733.403 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4456 Skipped
PASS

Ginkgo ran 1 suite in 1h52m14.796223843s
Test Suite Passed
