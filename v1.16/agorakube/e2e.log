I1104 17:00:29.362589      19 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-430892974
I1104 17:00:29.363011      19 e2e.go:92] Starting e2e run "a5f2f8f2-2f36-4d74-b0f3-69aef67339f0" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1572886827 - Will randomize all specs
Will run 276 of 4897 specs

Nov  4 17:00:29.378: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:00:29.380: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov  4 17:00:29.391: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov  4 17:00:29.415: INFO: 8 / 8 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov  4 17:00:29.415: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Nov  4 17:00:29.415: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov  4 17:00:29.423: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Nov  4 17:00:29.423: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm' (0 seconds elapsed)
Nov  4 17:00:29.423: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm64' (0 seconds elapsed)
Nov  4 17:00:29.423: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-ppc64le' (0 seconds elapsed)
Nov  4 17:00:29.423: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-s390x' (0 seconds elapsed)
Nov  4 17:00:29.424: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'traefik-ingress-controller' (0 seconds elapsed)
Nov  4 17:00:29.424: INFO: e2e test version: v1.16.2
Nov  4 17:00:29.424: INFO: kube-apiserver version: v1.16.2
Nov  4 17:00:29.424: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:00:29.428: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:00:29.436: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
Nov  4 17:00:29.467: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Nov  4 17:00:29.478: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1357
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:00:30.439: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 17:00:32.451: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483630, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483630, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483630, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483630, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:00:34.454: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483630, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483630, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483630, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483630, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:00:37.464: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:00:47.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1357" for this suite.
Nov  4 17:00:53.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:00:53.749: INFO: namespace webhook-1357 deletion completed in 6.094011215s
STEP: Destroying namespace "webhook-1357-markers" for this suite.
Nov  4 17:00:59.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:00:59.850: INFO: namespace webhook-1357-markers deletion completed in 6.101371619s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:30.428 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:00:59.865: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1980
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1104 17:01:06.026332      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 17:01:06.026: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:01:06.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1980" for this suite.
Nov  4 17:01:12.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:01:12.115: INFO: namespace gc-1980 deletion completed in 6.085622909s

â€¢ [SLOW TEST:12.250 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:01:12.115: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3381
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  4 17:01:12.257: INFO: Waiting up to 5m0s for pod "pod-f86c0388-3bb3-4157-a594-ec470900a622" in namespace "emptydir-3381" to be "success or failure"
Nov  4 17:01:12.268: INFO: Pod "pod-f86c0388-3bb3-4157-a594-ec470900a622": Phase="Pending", Reason="", readiness=false. Elapsed: 11.017309ms
Nov  4 17:01:14.270: INFO: Pod "pod-f86c0388-3bb3-4157-a594-ec470900a622": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013739011s
Nov  4 17:01:16.273: INFO: Pod "pod-f86c0388-3bb3-4157-a594-ec470900a622": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016234164s
STEP: Saw pod success
Nov  4 17:01:16.273: INFO: Pod "pod-f86c0388-3bb3-4157-a594-ec470900a622" satisfied condition "success or failure"
Nov  4 17:01:16.275: INFO: Trying to get logs from node k8s-1 pod pod-f86c0388-3bb3-4157-a594-ec470900a622 container test-container: <nil>
STEP: delete the pod
Nov  4 17:01:16.302: INFO: Waiting for pod pod-f86c0388-3bb3-4157-a594-ec470900a622 to disappear
Nov  4 17:01:16.306: INFO: Pod pod-f86c0388-3bb3-4157-a594-ec470900a622 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:01:16.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3381" for this suite.
Nov  4 17:01:22.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:01:22.395: INFO: namespace emptydir-3381 deletion completed in 6.086682943s

â€¢ [SLOW TEST:10.280 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:01:22.396: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Nov  4 17:01:22.538: INFO: Waiting up to 5m0s for pod "client-containers-42da19f8-f30a-43f0-8986-e074b273dfdd" in namespace "containers-4706" to be "success or failure"
Nov  4 17:01:22.541: INFO: Pod "client-containers-42da19f8-f30a-43f0-8986-e074b273dfdd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.555563ms
Nov  4 17:01:24.544: INFO: Pod "client-containers-42da19f8-f30a-43f0-8986-e074b273dfdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005592871s
STEP: Saw pod success
Nov  4 17:01:24.544: INFO: Pod "client-containers-42da19f8-f30a-43f0-8986-e074b273dfdd" satisfied condition "success or failure"
Nov  4 17:01:24.547: INFO: Trying to get logs from node k8s-1 pod client-containers-42da19f8-f30a-43f0-8986-e074b273dfdd container test-container: <nil>
STEP: delete the pod
Nov  4 17:01:24.567: INFO: Waiting for pod client-containers-42da19f8-f30a-43f0-8986-e074b273dfdd to disappear
Nov  4 17:01:24.571: INFO: Pod client-containers-42da19f8-f30a-43f0-8986-e074b273dfdd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:01:24.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4706" for this suite.
Nov  4 17:01:30.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:01:30.665: INFO: namespace containers-4706 deletion completed in 6.090945331s

â€¢ [SLOW TEST:8.269 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:01:30.666: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-3622
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-3622
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3622
STEP: Deleting pre-stop pod
Nov  4 17:01:39.844: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:01:39.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3622" for this suite.
Nov  4 17:02:23.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:02:23.953: INFO: namespace prestop-3622 deletion completed in 44.095090261s

â€¢ [SLOW TEST:53.288 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:02:23.954: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9474
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-5d32293e-294a-4cc0-9097-3750c15b9d78
STEP: Creating a pod to test consume configMaps
Nov  4 17:02:24.103: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-614ebec9-0e72-4020-b56a-e7f4326ae9f8" in namespace "projected-9474" to be "success or failure"
Nov  4 17:02:24.108: INFO: Pod "pod-projected-configmaps-614ebec9-0e72-4020-b56a-e7f4326ae9f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.583877ms
Nov  4 17:02:26.111: INFO: Pod "pod-projected-configmaps-614ebec9-0e72-4020-b56a-e7f4326ae9f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007186001s
Nov  4 17:02:28.114: INFO: Pod "pod-projected-configmaps-614ebec9-0e72-4020-b56a-e7f4326ae9f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010195809s
STEP: Saw pod success
Nov  4 17:02:28.114: INFO: Pod "pod-projected-configmaps-614ebec9-0e72-4020-b56a-e7f4326ae9f8" satisfied condition "success or failure"
Nov  4 17:02:28.117: INFO: Trying to get logs from node k8s-3 pod pod-projected-configmaps-614ebec9-0e72-4020-b56a-e7f4326ae9f8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 17:02:28.143: INFO: Waiting for pod pod-projected-configmaps-614ebec9-0e72-4020-b56a-e7f4326ae9f8 to disappear
Nov  4 17:02:28.146: INFO: Pod pod-projected-configmaps-614ebec9-0e72-4020-b56a-e7f4326ae9f8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:02:28.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9474" for this suite.
Nov  4 17:02:34.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:02:34.240: INFO: namespace projected-9474 deletion completed in 6.091640769s

â€¢ [SLOW TEST:10.286 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:02:34.241: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2697
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ab357834-546b-46d6-bbb6-6fe77f9e76a0
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-ab357834-546b-46d6-bbb6-6fe77f9e76a0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:02:38.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2697" for this suite.
Nov  4 17:02:50.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:02:50.517: INFO: namespace projected-2697 deletion completed in 12.095292303s

â€¢ [SLOW TEST:16.276 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:02:50.518: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:02:51.042: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 17:02:53.052: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483771, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483771, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483771, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483771, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:02:55.055: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483771, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483771, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483771, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708483771, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:02:58.063: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
Nov  4 17:02:58.083: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:02:58.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1186" for this suite.
Nov  4 17:03:10.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:03:10.415: INFO: namespace webhook-1186 deletion completed in 12.121395379s
STEP: Destroying namespace "webhook-1186-markers" for this suite.
Nov  4 17:03:16.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:03:16.500: INFO: namespace webhook-1186-markers deletion completed in 6.084136901s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:25.995 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:03:16.513: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1198
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1198
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 17:03:16.645: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 17:03:36.734: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.33.2.12:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1198 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:03:36.735: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:03:36.877: INFO: Found all expected endpoints: [netserver-0]
Nov  4 17:03:36.880: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.33.1.7:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1198 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:03:36.880: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:03:37.026: INFO: Found all expected endpoints: [netserver-1]
Nov  4 17:03:37.028: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.33.0.14:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1198 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:03:37.028: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:03:37.198: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:03:37.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1198" for this suite.
Nov  4 17:03:49.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:03:49.291: INFO: namespace pod-network-test-1198 deletion completed in 12.089087919s

â€¢ [SLOW TEST:32.778 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:03:49.292: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3472
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Nov  4 17:03:49.432: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:03:57.496: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:04:13.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3472" for this suite.
Nov  4 17:04:19.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:04:19.479: INFO: namespace crd-publish-openapi-3472 deletion completed in 6.088293838s

â€¢ [SLOW TEST:30.188 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:04:19.480: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4475
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4475.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4475.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4475.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4475.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 17:04:33.665: INFO: DNS probes using dns-test-0494b9f5-5fc4-4788-9436-7f41d242a9ca succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4475.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4475.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4475.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4475.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 17:04:47.738: INFO: DNS probes using dns-test-8aa2bc50-e7c3-49d1-be7f-299eb348e83a succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4475.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4475.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4475.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4475.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 17:04:49.816: INFO: DNS probes using dns-test-71388152-2874-408b-b899-845b0506338e succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:04:49.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4475" for this suite.
Nov  4 17:04:55.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:04:55.963: INFO: namespace dns-4475 deletion completed in 6.085393232s

â€¢ [SLOW TEST:36.484 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:04:55.964: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2465
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Nov  4 17:04:56.098: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:05:03.316: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:05:18.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2465" for this suite.
Nov  4 17:05:24.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:05:24.536: INFO: namespace crd-publish-openapi-2465 deletion completed in 6.084459074s

â€¢ [SLOW TEST:28.573 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:05:24.537: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9717
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 17:05:29.216: INFO: Successfully updated pod "labelsupdateda2f010f-79c6-4e6d-95c1-519aaf5df210"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:05:31.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9717" for this suite.
Nov  4 17:05:43.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:05:43.314: INFO: namespace downward-api-9717 deletion completed in 12.08353246s

â€¢ [SLOW TEST:18.777 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:05:43.314: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7332
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:05:43.817: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:05:46.838: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Nov  4 17:05:48.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 attach --namespace=webhook-7332 to-be-attached-pod -i -c=container1'
Nov  4 17:05:49.032: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:05:49.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7332" for this suite.
Nov  4 17:06:01.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:06:01.127: INFO: namespace webhook-7332 deletion completed in 12.084454076s
STEP: Destroying namespace "webhook-7332-markers" for this suite.
Nov  4 17:06:07.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:06:07.208: INFO: namespace webhook-7332-markers deletion completed in 6.080846165s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:23.908 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:06:07.222: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:06:09.400: INFO: Waiting up to 5m0s for pod "client-envvars-4912a589-1872-46b0-9710-c418e14116a3" in namespace "pods-423" to be "success or failure"
Nov  4 17:06:09.407: INFO: Pod "client-envvars-4912a589-1872-46b0-9710-c418e14116a3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.327567ms
Nov  4 17:06:11.411: INFO: Pod "client-envvars-4912a589-1872-46b0-9710-c418e14116a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010815556s
STEP: Saw pod success
Nov  4 17:06:11.411: INFO: Pod "client-envvars-4912a589-1872-46b0-9710-c418e14116a3" satisfied condition "success or failure"
Nov  4 17:06:11.414: INFO: Trying to get logs from node k8s-3 pod client-envvars-4912a589-1872-46b0-9710-c418e14116a3 container env3cont: <nil>
STEP: delete the pod
Nov  4 17:06:11.444: INFO: Waiting for pod client-envvars-4912a589-1872-46b0-9710-c418e14116a3 to disappear
Nov  4 17:06:11.447: INFO: Pod client-envvars-4912a589-1872-46b0-9710-c418e14116a3 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:06:11.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-423" for this suite.
Nov  4 17:06:39.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:06:39.533: INFO: namespace pods-423 deletion completed in 28.079931995s

â€¢ [SLOW TEST:32.311 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:06:39.534: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6448
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  4 17:06:39.728: INFO: Number of nodes with available pods: 0
Nov  4 17:06:39.728: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:06:40.735: INFO: Number of nodes with available pods: 0
Nov  4 17:06:40.735: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:06:41.735: INFO: Number of nodes with available pods: 0
Nov  4 17:06:41.735: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:06:42.744: INFO: Number of nodes with available pods: 0
Nov  4 17:06:42.744: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:06:43.738: INFO: Number of nodes with available pods: 0
Nov  4 17:06:43.738: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:06:44.734: INFO: Number of nodes with available pods: 0
Nov  4 17:06:44.734: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:06:45.736: INFO: Number of nodes with available pods: 0
Nov  4 17:06:45.736: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:06:46.734: INFO: Number of nodes with available pods: 1
Nov  4 17:06:46.734: INFO: Node k8s-2 is running more than one daemon pod
Nov  4 17:06:47.734: INFO: Number of nodes with available pods: 3
Nov  4 17:06:47.734: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov  4 17:06:47.756: INFO: Number of nodes with available pods: 2
Nov  4 17:06:47.756: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 17:06:48.763: INFO: Number of nodes with available pods: 2
Nov  4 17:06:48.763: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 17:06:49.764: INFO: Number of nodes with available pods: 3
Nov  4 17:06:49.764: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6448, will wait for the garbage collector to delete the pods
Nov  4 17:06:49.832: INFO: Deleting DaemonSet.extensions daemon-set took: 10.757031ms
Nov  4 17:06:50.132: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.10129ms
Nov  4 17:06:59.535: INFO: Number of nodes with available pods: 0
Nov  4 17:06:59.535: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 17:06:59.539: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6448/daemonsets","resourceVersion":"2685"},"items":null}

Nov  4 17:06:59.541: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6448/pods","resourceVersion":"2685"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:06:59.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6448" for this suite.
Nov  4 17:07:05.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:07:05.632: INFO: namespace daemonsets-6448 deletion completed in 6.077688699s

â€¢ [SLOW TEST:26.098 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:07:05.633: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2358
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:07:05.784: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov  4 17:07:05.807: INFO: Number of nodes with available pods: 0
Nov  4 17:07:05.807: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:07:06.813: INFO: Number of nodes with available pods: 1
Nov  4 17:07:06.813: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:07:07.814: INFO: Number of nodes with available pods: 2
Nov  4 17:07:07.814: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:07:08.815: INFO: Number of nodes with available pods: 3
Nov  4 17:07:08.815: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov  4 17:07:08.853: INFO: Wrong image for pod: daemon-set-52wv7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:08.853: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:08.853: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:09.862: INFO: Wrong image for pod: daemon-set-52wv7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:09.862: INFO: Pod daemon-set-52wv7 is not available
Nov  4 17:07:09.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:09.863: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:10.863: INFO: Wrong image for pod: daemon-set-52wv7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:10.863: INFO: Pod daemon-set-52wv7 is not available
Nov  4 17:07:10.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:10.863: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:11.863: INFO: Wrong image for pod: daemon-set-52wv7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:11.863: INFO: Pod daemon-set-52wv7 is not available
Nov  4 17:07:11.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:11.863: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:12.863: INFO: Wrong image for pod: daemon-set-52wv7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:12.863: INFO: Pod daemon-set-52wv7 is not available
Nov  4 17:07:12.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:12.863: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:13.862: INFO: Wrong image for pod: daemon-set-52wv7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:13.862: INFO: Pod daemon-set-52wv7 is not available
Nov  4 17:07:13.862: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:13.862: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:14.863: INFO: Wrong image for pod: daemon-set-52wv7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:14.863: INFO: Pod daemon-set-52wv7 is not available
Nov  4 17:07:14.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:14.863: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:15.863: INFO: Wrong image for pod: daemon-set-52wv7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:15.863: INFO: Pod daemon-set-52wv7 is not available
Nov  4 17:07:15.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:15.863: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:16.862: INFO: Wrong image for pod: daemon-set-52wv7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:16.862: INFO: Pod daemon-set-52wv7 is not available
Nov  4 17:07:16.862: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:16.862: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:17.866: INFO: Wrong image for pod: daemon-set-52wv7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:17.866: INFO: Pod daemon-set-52wv7 is not available
Nov  4 17:07:17.867: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:17.867: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:18.865: INFO: Wrong image for pod: daemon-set-52wv7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:18.865: INFO: Pod daemon-set-52wv7 is not available
Nov  4 17:07:18.869: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:18.869: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:19.862: INFO: Pod daemon-set-72sxh is not available
Nov  4 17:07:19.862: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:19.862: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:20.864: INFO: Pod daemon-set-72sxh is not available
Nov  4 17:07:20.864: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:20.864: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:21.862: INFO: Pod daemon-set-72sxh is not available
Nov  4 17:07:21.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:21.863: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:22.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:22.863: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:23.862: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:23.863: INFO: Wrong image for pod: daemon-set-x28cm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:23.863: INFO: Pod daemon-set-x28cm is not available
Nov  4 17:07:24.863: INFO: Pod daemon-set-8w2gh is not available
Nov  4 17:07:24.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:25.862: INFO: Pod daemon-set-8w2gh is not available
Nov  4 17:07:25.862: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:26.863: INFO: Pod daemon-set-8w2gh is not available
Nov  4 17:07:26.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:27.863: INFO: Pod daemon-set-8w2gh is not available
Nov  4 17:07:27.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:28.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:29.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:29.863: INFO: Pod daemon-set-bn7td is not available
Nov  4 17:07:30.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:30.863: INFO: Pod daemon-set-bn7td is not available
Nov  4 17:07:31.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:31.863: INFO: Pod daemon-set-bn7td is not available
Nov  4 17:07:32.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:32.863: INFO: Pod daemon-set-bn7td is not available
Nov  4 17:07:33.862: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:33.863: INFO: Pod daemon-set-bn7td is not available
Nov  4 17:07:34.862: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:34.862: INFO: Pod daemon-set-bn7td is not available
Nov  4 17:07:35.864: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:35.864: INFO: Pod daemon-set-bn7td is not available
Nov  4 17:07:36.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:36.863: INFO: Pod daemon-set-bn7td is not available
Nov  4 17:07:37.862: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:37.862: INFO: Pod daemon-set-bn7td is not available
Nov  4 17:07:38.863: INFO: Wrong image for pod: daemon-set-bn7td. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 17:07:38.863: INFO: Pod daemon-set-bn7td is not available
Nov  4 17:07:39.863: INFO: Pod daemon-set-9crnj is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Nov  4 17:07:39.872: INFO: Number of nodes with available pods: 2
Nov  4 17:07:39.872: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 17:07:40.881: INFO: Number of nodes with available pods: 2
Nov  4 17:07:40.881: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 17:07:41.881: INFO: Number of nodes with available pods: 2
Nov  4 17:07:41.881: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 17:07:42.878: INFO: Number of nodes with available pods: 3
Nov  4 17:07:42.878: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2358, will wait for the garbage collector to delete the pods
Nov  4 17:07:42.953: INFO: Deleting DaemonSet.extensions daemon-set took: 9.078676ms
Nov  4 17:07:43.253: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.139357ms
Nov  4 17:07:49.556: INFO: Number of nodes with available pods: 0
Nov  4 17:07:49.556: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 17:07:49.559: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2358/daemonsets","resourceVersion":"2922"},"items":null}

Nov  4 17:07:49.561: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2358/pods","resourceVersion":"2922"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:07:49.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2358" for this suite.
Nov  4 17:07:55.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:07:55.664: INFO: namespace daemonsets-2358 deletion completed in 6.088608892s

â€¢ [SLOW TEST:50.031 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:07:55.665: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7425
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Nov  4 17:07:56.343: INFO: created pod pod-service-account-defaultsa
Nov  4 17:07:56.343: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov  4 17:07:56.352: INFO: created pod pod-service-account-mountsa
Nov  4 17:07:56.352: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov  4 17:07:56.361: INFO: created pod pod-service-account-nomountsa
Nov  4 17:07:56.361: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov  4 17:07:56.367: INFO: created pod pod-service-account-defaultsa-mountspec
Nov  4 17:07:56.367: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov  4 17:07:56.372: INFO: created pod pod-service-account-mountsa-mountspec
Nov  4 17:07:56.372: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov  4 17:07:56.376: INFO: created pod pod-service-account-nomountsa-mountspec
Nov  4 17:07:56.376: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov  4 17:07:56.383: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov  4 17:07:56.383: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov  4 17:07:56.392: INFO: created pod pod-service-account-mountsa-nomountspec
Nov  4 17:07:56.392: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov  4 17:07:56.401: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov  4 17:07:56.401: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:07:56.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7425" for this suite.
Nov  4 17:08:02.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:08:02.517: INFO: namespace svcaccounts-7425 deletion completed in 6.104362713s

â€¢ [SLOW TEST:6.852 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:08:02.517: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6764
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  4 17:08:02.660: INFO: Waiting up to 5m0s for pod "pod-2f8c0e4c-5c8c-47bb-9e2f-3b12ced0bd07" in namespace "emptydir-6764" to be "success or failure"
Nov  4 17:08:02.666: INFO: Pod "pod-2f8c0e4c-5c8c-47bb-9e2f-3b12ced0bd07": Phase="Pending", Reason="", readiness=false. Elapsed: 6.36155ms
Nov  4 17:08:04.669: INFO: Pod "pod-2f8c0e4c-5c8c-47bb-9e2f-3b12ced0bd07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009574889s
STEP: Saw pod success
Nov  4 17:08:04.669: INFO: Pod "pod-2f8c0e4c-5c8c-47bb-9e2f-3b12ced0bd07" satisfied condition "success or failure"
Nov  4 17:08:04.672: INFO: Trying to get logs from node k8s-3 pod pod-2f8c0e4c-5c8c-47bb-9e2f-3b12ced0bd07 container test-container: <nil>
STEP: delete the pod
Nov  4 17:08:04.702: INFO: Waiting for pod pod-2f8c0e4c-5c8c-47bb-9e2f-3b12ced0bd07 to disappear
Nov  4 17:08:04.704: INFO: Pod pod-2f8c0e4c-5c8c-47bb-9e2f-3b12ced0bd07 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:08:04.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6764" for this suite.
Nov  4 17:08:10.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:08:10.785: INFO: namespace emptydir-6764 deletion completed in 6.078126468s

â€¢ [SLOW TEST:8.268 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:08:10.786: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8116
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1104 17:08:11.473331      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 17:08:11.473: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:08:11.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8116" for this suite.
Nov  4 17:08:17.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:08:17.553: INFO: namespace gc-8116 deletion completed in 6.07643153s

â€¢ [SLOW TEST:6.767 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:08:17.554: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-1
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:08:18.040: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov  4 17:08:20.048: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484098, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484098, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484098, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484097, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:08:23.062: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:08:23.065: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:08:29.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1" for this suite.
Nov  4 17:08:35.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:08:35.287: INFO: namespace crd-webhook-1 deletion completed in 6.081543996s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:17.749 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:08:35.303: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:08:35.446: INFO: Waiting up to 5m0s for pod "downwardapi-volume-11ceaae9-1852-450d-8f94-0cd4dd876f8d" in namespace "projected-5739" to be "success or failure"
Nov  4 17:08:35.456: INFO: Pod "downwardapi-volume-11ceaae9-1852-450d-8f94-0cd4dd876f8d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.780328ms
Nov  4 17:08:37.459: INFO: Pod "downwardapi-volume-11ceaae9-1852-450d-8f94-0cd4dd876f8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013273395s
STEP: Saw pod success
Nov  4 17:08:37.460: INFO: Pod "downwardapi-volume-11ceaae9-1852-450d-8f94-0cd4dd876f8d" satisfied condition "success or failure"
Nov  4 17:08:37.462: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-11ceaae9-1852-450d-8f94-0cd4dd876f8d container client-container: <nil>
STEP: delete the pod
Nov  4 17:08:37.480: INFO: Waiting for pod downwardapi-volume-11ceaae9-1852-450d-8f94-0cd4dd876f8d to disappear
Nov  4 17:08:37.486: INFO: Pod downwardapi-volume-11ceaae9-1852-450d-8f94-0cd4dd876f8d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:08:37.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5739" for this suite.
Nov  4 17:08:43.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:08:43.572: INFO: namespace projected-5739 deletion completed in 6.081956253s

â€¢ [SLOW TEST:8.269 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:08:43.573: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3378
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:08:43.710: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Nov  4 17:08:51.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3378 create -f -'
Nov  4 17:08:52.036: INFO: stderr: ""
Nov  4 17:08:52.036: INFO: stdout: "e2e-test-crd-publish-openapi-9708-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  4 17:08:52.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3378 delete e2e-test-crd-publish-openapi-9708-crds test-foo'
Nov  4 17:08:52.172: INFO: stderr: ""
Nov  4 17:08:52.172: INFO: stdout: "e2e-test-crd-publish-openapi-9708-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov  4 17:08:52.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3378 apply -f -'
Nov  4 17:08:52.423: INFO: stderr: ""
Nov  4 17:08:52.423: INFO: stdout: "e2e-test-crd-publish-openapi-9708-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  4 17:08:52.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3378 delete e2e-test-crd-publish-openapi-9708-crds test-foo'
Nov  4 17:08:52.508: INFO: stderr: ""
Nov  4 17:08:52.508: INFO: stdout: "e2e-test-crd-publish-openapi-9708-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Nov  4 17:08:52.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3378 create -f -'
Nov  4 17:08:52.725: INFO: rc: 1
Nov  4 17:08:52.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3378 apply -f -'
Nov  4 17:08:52.912: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Nov  4 17:08:52.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3378 create -f -'
Nov  4 17:08:53.102: INFO: rc: 1
Nov  4 17:08:53.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3378 apply -f -'
Nov  4 17:08:53.240: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Nov  4 17:08:53.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 explain e2e-test-crd-publish-openapi-9708-crds'
Nov  4 17:08:53.435: INFO: stderr: ""
Nov  4 17:08:53.435: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9708-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Nov  4 17:08:53.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 explain e2e-test-crd-publish-openapi-9708-crds.metadata'
Nov  4 17:08:53.584: INFO: stderr: ""
Nov  4 17:08:53.584: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9708-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov  4 17:08:53.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 explain e2e-test-crd-publish-openapi-9708-crds.spec'
Nov  4 17:08:53.776: INFO: stderr: ""
Nov  4 17:08:53.776: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9708-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov  4 17:08:53.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 explain e2e-test-crd-publish-openapi-9708-crds.spec.bars'
Nov  4 17:08:54.006: INFO: stderr: ""
Nov  4 17:08:54.006: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9708-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Nov  4 17:08:54.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 explain e2e-test-crd-publish-openapi-9708-crds.spec.bars2'
Nov  4 17:08:54.201: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:08:58.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3378" for this suite.
Nov  4 17:09:04.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:09:04.250: INFO: namespace crd-publish-openapi-3378 deletion completed in 6.109962693s

â€¢ [SLOW TEST:20.677 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:09:04.252: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6502
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 17:09:04.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-6502'
Nov  4 17:09:04.471: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 17:09:04.471: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Nov  4 17:09:04.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete jobs e2e-test-httpd-job --namespace=kubectl-6502'
Nov  4 17:09:04.585: INFO: stderr: ""
Nov  4 17:09:04.585: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:09:04.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6502" for this suite.
Nov  4 17:09:10.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:09:10.671: INFO: namespace kubectl-6502 deletion completed in 6.083318048s

â€¢ [SLOW TEST:6.420 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:09:10.672: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5916
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Nov  4 17:09:10.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-5916'
Nov  4 17:09:11.035: INFO: stderr: ""
Nov  4 17:09:11.035: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 17:09:11.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5916'
Nov  4 17:09:11.153: INFO: stderr: ""
Nov  4 17:09:11.153: INFO: stdout: "update-demo-nautilus-dp66f update-demo-nautilus-k4vgt "
Nov  4 17:09:11.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-dp66f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5916'
Nov  4 17:09:11.225: INFO: stderr: ""
Nov  4 17:09:11.225: INFO: stdout: ""
Nov  4 17:09:11.225: INFO: update-demo-nautilus-dp66f is created but not running
Nov  4 17:09:16.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5916'
Nov  4 17:09:16.301: INFO: stderr: ""
Nov  4 17:09:16.301: INFO: stdout: "update-demo-nautilus-dp66f update-demo-nautilus-k4vgt "
Nov  4 17:09:16.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-dp66f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5916'
Nov  4 17:09:16.372: INFO: stderr: ""
Nov  4 17:09:16.372: INFO: stdout: "true"
Nov  4 17:09:16.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-dp66f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5916'
Nov  4 17:09:16.445: INFO: stderr: ""
Nov  4 17:09:16.445: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 17:09:16.445: INFO: validating pod update-demo-nautilus-dp66f
Nov  4 17:09:16.449: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 17:09:16.450: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 17:09:16.450: INFO: update-demo-nautilus-dp66f is verified up and running
Nov  4 17:09:16.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-k4vgt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5916'
Nov  4 17:09:16.523: INFO: stderr: ""
Nov  4 17:09:16.524: INFO: stdout: "true"
Nov  4 17:09:16.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-k4vgt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5916'
Nov  4 17:09:16.599: INFO: stderr: ""
Nov  4 17:09:16.599: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 17:09:16.599: INFO: validating pod update-demo-nautilus-k4vgt
Nov  4 17:09:16.602: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 17:09:16.602: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 17:09:16.602: INFO: update-demo-nautilus-k4vgt is verified up and running
STEP: rolling-update to new replication controller
Nov  4 17:09:16.604: INFO: scanned /root for discovery docs: <nil>
Nov  4 17:09:16.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5916'
Nov  4 17:09:39.034: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  4 17:09:39.034: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 17:09:39.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5916'
Nov  4 17:09:39.118: INFO: stderr: ""
Nov  4 17:09:39.118: INFO: stdout: "update-demo-kitten-8mx7l update-demo-kitten-hpgpc "
Nov  4 17:09:39.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-kitten-8mx7l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5916'
Nov  4 17:09:39.221: INFO: stderr: ""
Nov  4 17:09:39.221: INFO: stdout: "true"
Nov  4 17:09:39.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-kitten-8mx7l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5916'
Nov  4 17:09:39.320: INFO: stderr: ""
Nov  4 17:09:39.320: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  4 17:09:39.320: INFO: validating pod update-demo-kitten-8mx7l
Nov  4 17:09:39.325: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  4 17:09:39.325: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  4 17:09:39.325: INFO: update-demo-kitten-8mx7l is verified up and running
Nov  4 17:09:39.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-kitten-hpgpc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5916'
Nov  4 17:09:39.411: INFO: stderr: ""
Nov  4 17:09:39.411: INFO: stdout: "true"
Nov  4 17:09:39.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-kitten-hpgpc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5916'
Nov  4 17:09:39.479: INFO: stderr: ""
Nov  4 17:09:39.479: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  4 17:09:39.479: INFO: validating pod update-demo-kitten-hpgpc
Nov  4 17:09:39.483: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  4 17:09:39.483: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  4 17:09:39.483: INFO: update-demo-kitten-hpgpc is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:09:39.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5916" for this suite.
Nov  4 17:09:51.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:09:51.573: INFO: namespace kubectl-5916 deletion completed in 12.08716247s

â€¢ [SLOW TEST:40.902 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:09:51.574: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3513
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  4 17:09:51.724: INFO: Waiting up to 5m0s for pod "pod-476d3e72-62be-4cc1-b69f-2de6ecff18f5" in namespace "emptydir-3513" to be "success or failure"
Nov  4 17:09:51.727: INFO: Pod "pod-476d3e72-62be-4cc1-b69f-2de6ecff18f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.824439ms
Nov  4 17:09:53.730: INFO: Pod "pod-476d3e72-62be-4cc1-b69f-2de6ecff18f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005404964s
STEP: Saw pod success
Nov  4 17:09:53.730: INFO: Pod "pod-476d3e72-62be-4cc1-b69f-2de6ecff18f5" satisfied condition "success or failure"
Nov  4 17:09:53.732: INFO: Trying to get logs from node k8s-3 pod pod-476d3e72-62be-4cc1-b69f-2de6ecff18f5 container test-container: <nil>
STEP: delete the pod
Nov  4 17:09:53.758: INFO: Waiting for pod pod-476d3e72-62be-4cc1-b69f-2de6ecff18f5 to disappear
Nov  4 17:09:53.761: INFO: Pod pod-476d3e72-62be-4cc1-b69f-2de6ecff18f5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:09:53.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3513" for this suite.
Nov  4 17:09:59.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:09:59.850: INFO: namespace emptydir-3513 deletion completed in 6.085494645s

â€¢ [SLOW TEST:8.276 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:09:59.850: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-714
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:09:59.991: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov  4 17:10:00.003: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  4 17:10:05.006: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  4 17:10:05.006: INFO: Creating deployment "test-rolling-update-deployment"
Nov  4 17:10:05.011: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov  4 17:10:05.016: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov  4 17:10:07.022: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov  4 17:10:07.024: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484205, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484205, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484205, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484205, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:10:09.027: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 17:10:09.034: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-714 /apis/apps/v1/namespaces/deployment-714/deployments/test-rolling-update-deployment 267af75d-036e-4d04-a20b-84c9a6dd1a10 3714 1 2019-11-04 17:10:05 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007fdf918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-04 17:10:05 +0000 UTC,LastTransitionTime:2019-11-04 17:10:05 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-11-04 17:10:07 +0000 UTC,LastTransitionTime:2019-11-04 17:10:05 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  4 17:10:09.037: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-714 /apis/apps/v1/namespaces/deployment-714/replicasets/test-rolling-update-deployment-55d946486 9870b9db-a848-419f-b7d9-f29d9883129f 3703 1 2019-11-04 17:10:05 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 267af75d-036e-4d04-a20b-84c9a6dd1a10 0xc007fdfeb0 0xc007fdfeb1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007fdff28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:10:09.037: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov  4 17:10:09.037: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-714 /apis/apps/v1/namespaces/deployment-714/replicasets/test-rolling-update-controller 8b9caec3-8993-4dce-a178-ba5c89ae45e7 3713 2 2019-11-04 17:09:59 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 267af75d-036e-4d04-a20b-84c9a6dd1a10 0xc007fdfddf 0xc007fdfdf0}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc007fdfe58 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:10:09.040: INFO: Pod "test-rolling-update-deployment-55d946486-9gx4t" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-9gx4t test-rolling-update-deployment-55d946486- deployment-714 /api/v1/namespaces/deployment-714/pods/test-rolling-update-deployment-55d946486-9gx4t 90ee6ab2-c719-4a6c-aa43-40805716c7f7 3702 0 2019-11-04 17:10:05 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 9870b9db-a848-419f-b7d9-f29d9883129f 0xc0050b0530 0xc0050b0531}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-s9tnj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-s9tnj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-s9tnj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:10:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:10:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:10:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:10:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.0.30,StartTime:2019-11-04 17:10:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:10:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://962f1c4ea52b05f2f12eb0ab828886c044c85fc715717e895173e36725a52900,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.30,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:10:09.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-714" for this suite.
Nov  4 17:10:15.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:10:15.129: INFO: namespace deployment-714 deletion completed in 6.085387157s

â€¢ [SLOW TEST:15.279 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:10:15.130: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2291
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 17:10:15.276: INFO: Waiting up to 5m0s for pod "downward-api-e28ec0e2-1d9e-467a-a0b3-0e42365e6487" in namespace "downward-api-2291" to be "success or failure"
Nov  4 17:10:15.287: INFO: Pod "downward-api-e28ec0e2-1d9e-467a-a0b3-0e42365e6487": Phase="Pending", Reason="", readiness=false. Elapsed: 11.493578ms
Nov  4 17:10:17.291: INFO: Pod "downward-api-e28ec0e2-1d9e-467a-a0b3-0e42365e6487": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014871725s
Nov  4 17:10:19.294: INFO: Pod "downward-api-e28ec0e2-1d9e-467a-a0b3-0e42365e6487": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018405736s
STEP: Saw pod success
Nov  4 17:10:19.294: INFO: Pod "downward-api-e28ec0e2-1d9e-467a-a0b3-0e42365e6487" satisfied condition "success or failure"
Nov  4 17:10:19.297: INFO: Trying to get logs from node k8s-1 pod downward-api-e28ec0e2-1d9e-467a-a0b3-0e42365e6487 container dapi-container: <nil>
STEP: delete the pod
Nov  4 17:10:19.326: INFO: Waiting for pod downward-api-e28ec0e2-1d9e-467a-a0b3-0e42365e6487 to disappear
Nov  4 17:10:19.340: INFO: Pod downward-api-e28ec0e2-1d9e-467a-a0b3-0e42365e6487 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:10:19.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2291" for this suite.
Nov  4 17:10:25.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:10:25.437: INFO: namespace downward-api-2291 deletion completed in 6.093140053s

â€¢ [SLOW TEST:10.307 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:10:25.437: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8824
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  4 17:10:28.104: INFO: Successfully updated pod "pod-update-activedeadlineseconds-fd125176-9c1b-4b36-a6f4-ffabff131f64"
Nov  4 17:10:28.104: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-fd125176-9c1b-4b36-a6f4-ffabff131f64" in namespace "pods-8824" to be "terminated due to deadline exceeded"
Nov  4 17:10:28.107: INFO: Pod "pod-update-activedeadlineseconds-fd125176-9c1b-4b36-a6f4-ffabff131f64": Phase="Running", Reason="", readiness=true. Elapsed: 2.670419ms
Nov  4 17:10:30.110: INFO: Pod "pod-update-activedeadlineseconds-fd125176-9c1b-4b36-a6f4-ffabff131f64": Phase="Running", Reason="", readiness=true. Elapsed: 2.005722507s
Nov  4 17:10:32.114: INFO: Pod "pod-update-activedeadlineseconds-fd125176-9c1b-4b36-a6f4-ffabff131f64": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009755628s
Nov  4 17:10:32.114: INFO: Pod "pod-update-activedeadlineseconds-fd125176-9c1b-4b36-a6f4-ffabff131f64" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:10:32.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8824" for this suite.
Nov  4 17:10:38.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:10:38.215: INFO: namespace pods-8824 deletion completed in 6.096916339s

â€¢ [SLOW TEST:12.778 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:10:38.216: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4411
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 17:10:38.361: INFO: Waiting up to 5m0s for pod "downward-api-b96cb401-fc40-47ef-acd0-a28800fd444a" in namespace "downward-api-4411" to be "success or failure"
Nov  4 17:10:38.364: INFO: Pod "downward-api-b96cb401-fc40-47ef-acd0-a28800fd444a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.100926ms
Nov  4 17:10:40.367: INFO: Pod "downward-api-b96cb401-fc40-47ef-acd0-a28800fd444a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005982591s
STEP: Saw pod success
Nov  4 17:10:40.367: INFO: Pod "downward-api-b96cb401-fc40-47ef-acd0-a28800fd444a" satisfied condition "success or failure"
Nov  4 17:10:40.370: INFO: Trying to get logs from node k8s-1 pod downward-api-b96cb401-fc40-47ef-acd0-a28800fd444a container dapi-container: <nil>
STEP: delete the pod
Nov  4 17:10:40.389: INFO: Waiting for pod downward-api-b96cb401-fc40-47ef-acd0-a28800fd444a to disappear
Nov  4 17:10:40.397: INFO: Pod downward-api-b96cb401-fc40-47ef-acd0-a28800fd444a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:10:40.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4411" for this suite.
Nov  4 17:10:46.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:10:46.492: INFO: namespace downward-api-4411 deletion completed in 6.090658989s

â€¢ [SLOW TEST:8.276 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:10:46.492: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1383
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-ffde455d-7f95-4c35-8ec0-4538e2c0765b
STEP: Creating a pod to test consume secrets
Nov  4 17:10:46.639: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-218df24b-3942-428f-a36b-b9fe0bd7c336" in namespace "projected-1383" to be "success or failure"
Nov  4 17:10:46.643: INFO: Pod "pod-projected-secrets-218df24b-3942-428f-a36b-b9fe0bd7c336": Phase="Pending", Reason="", readiness=false. Elapsed: 3.99443ms
Nov  4 17:10:48.646: INFO: Pod "pod-projected-secrets-218df24b-3942-428f-a36b-b9fe0bd7c336": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007128543s
STEP: Saw pod success
Nov  4 17:10:48.646: INFO: Pod "pod-projected-secrets-218df24b-3942-428f-a36b-b9fe0bd7c336" satisfied condition "success or failure"
Nov  4 17:10:48.648: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-218df24b-3942-428f-a36b-b9fe0bd7c336 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 17:10:48.665: INFO: Waiting for pod pod-projected-secrets-218df24b-3942-428f-a36b-b9fe0bd7c336 to disappear
Nov  4 17:10:48.667: INFO: Pod pod-projected-secrets-218df24b-3942-428f-a36b-b9fe0bd7c336 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:10:48.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1383" for this suite.
Nov  4 17:10:54.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:10:54.761: INFO: namespace projected-1383 deletion completed in 6.08805178s

â€¢ [SLOW TEST:8.269 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:10:54.762: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4589
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 17:10:57.430: INFO: Successfully updated pod "annotationupdate52ec3b85-0dbd-434f-852f-4befe1dfc422"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:11:01.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4589" for this suite.
Nov  4 17:11:23.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:11:23.560: INFO: namespace downward-api-4589 deletion completed in 22.094597753s

â€¢ [SLOW TEST:28.798 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:11:23.560: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-0a575cdf-bee4-4677-b370-a6f6984b4006
STEP: Creating a pod to test consume configMaps
Nov  4 17:11:23.720: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-01ea1086-4071-455b-9114-df2df3378e34" in namespace "projected-5239" to be "success or failure"
Nov  4 17:11:23.723: INFO: Pod "pod-projected-configmaps-01ea1086-4071-455b-9114-df2df3378e34": Phase="Pending", Reason="", readiness=false. Elapsed: 3.803799ms
Nov  4 17:11:25.726: INFO: Pod "pod-projected-configmaps-01ea1086-4071-455b-9114-df2df3378e34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006730504s
STEP: Saw pod success
Nov  4 17:11:25.726: INFO: Pod "pod-projected-configmaps-01ea1086-4071-455b-9114-df2df3378e34" satisfied condition "success or failure"
Nov  4 17:11:25.729: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-01ea1086-4071-455b-9114-df2df3378e34 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 17:11:25.751: INFO: Waiting for pod pod-projected-configmaps-01ea1086-4071-455b-9114-df2df3378e34 to disappear
Nov  4 17:11:25.756: INFO: Pod pod-projected-configmaps-01ea1086-4071-455b-9114-df2df3378e34 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:11:25.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5239" for this suite.
Nov  4 17:11:31.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:11:31.842: INFO: namespace projected-5239 deletion completed in 6.082793152s

â€¢ [SLOW TEST:8.282 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:11:31.842: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5055
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1104 17:12:02.510737      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 17:12:02.510: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:12:02.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5055" for this suite.
Nov  4 17:12:08.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:12:08.602: INFO: namespace gc-5055 deletion completed in 6.088413337s

â€¢ [SLOW TEST:36.760 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:12:08.603: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6109
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-tg96x in namespace proxy-6109
I1104 17:12:08.757656      19 runners.go:184] Created replication controller with name: proxy-service-tg96x, namespace: proxy-6109, replica count: 1
I1104 17:12:09.808091      19 runners.go:184] proxy-service-tg96x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 17:12:10.808220      19 runners.go:184] proxy-service-tg96x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 17:12:11.808401      19 runners.go:184] proxy-service-tg96x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 17:12:12.808574      19 runners.go:184] proxy-service-tg96x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 17:12:13.808785      19 runners.go:184] proxy-service-tg96x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 17:12:14.808957      19 runners.go:184] proxy-service-tg96x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 17:12:15.809162      19 runners.go:184] proxy-service-tg96x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 17:12:16.809348      19 runners.go:184] proxy-service-tg96x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 17:12:17.809530      19 runners.go:184] proxy-service-tg96x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 17:12:18.809706      19 runners.go:184] proxy-service-tg96x Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 17:12:18.812: INFO: setup took 10.073743457s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov  4 17:12:18.830: INFO: (0) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 17.326403ms)
Nov  4 17:12:18.832: INFO: (0) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 18.574689ms)
Nov  4 17:12:18.834: INFO: (0) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 22.080437ms)
Nov  4 17:12:18.835: INFO: (0) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 21.980629ms)
Nov  4 17:12:18.838: INFO: (0) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 24.586899ms)
Nov  4 17:12:18.838: INFO: (0) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 25.338088ms)
Nov  4 17:12:18.840: INFO: (0) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 27.275538ms)
Nov  4 17:12:18.841: INFO: (0) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 27.673231ms)
Nov  4 17:12:18.843: INFO: (0) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 29.246216ms)
Nov  4 17:12:18.845: INFO: (0) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 32.516025ms)
Nov  4 17:12:18.845: INFO: (0) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 32.592494ms)
Nov  4 17:12:18.846: INFO: (0) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 32.441804ms)
Nov  4 17:12:18.846: INFO: (0) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 33.412534ms)
Nov  4 17:12:18.846: INFO: (0) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 34.029492ms)
Nov  4 17:12:18.848: INFO: (0) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 34.801263ms)
Nov  4 17:12:18.848: INFO: (0) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 35.281191ms)
Nov  4 17:12:18.859: INFO: (1) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 10.344711ms)
Nov  4 17:12:18.861: INFO: (1) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 11.810337ms)
Nov  4 17:12:18.861: INFO: (1) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 12.930535ms)
Nov  4 17:12:18.862: INFO: (1) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 13.486038ms)
Nov  4 17:12:18.866: INFO: (1) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 17.349397ms)
Nov  4 17:12:18.866: INFO: (1) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 17.250361ms)
Nov  4 17:12:18.866: INFO: (1) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 17.465433ms)
Nov  4 17:12:18.867: INFO: (1) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 18.312772ms)
Nov  4 17:12:18.867: INFO: (1) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 19.053409ms)
Nov  4 17:12:18.868: INFO: (1) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 18.430486ms)
Nov  4 17:12:18.868: INFO: (1) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 19.269536ms)
Nov  4 17:12:18.868: INFO: (1) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 19.643327ms)
Nov  4 17:12:18.869: INFO: (1) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 20.081448ms)
Nov  4 17:12:18.870: INFO: (1) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 21.494903ms)
Nov  4 17:12:18.871: INFO: (1) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 21.614047ms)
Nov  4 17:12:18.871: INFO: (1) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 22.042445ms)
Nov  4 17:12:18.879: INFO: (2) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 7.498645ms)
Nov  4 17:12:18.885: INFO: (2) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 13.364949ms)
Nov  4 17:12:18.885: INFO: (2) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 13.80126ms)
Nov  4 17:12:18.886: INFO: (2) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 13.891782ms)
Nov  4 17:12:18.886: INFO: (2) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 13.79058ms)
Nov  4 17:12:18.886: INFO: (2) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 14.925184ms)
Nov  4 17:12:18.887: INFO: (2) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 14.827348ms)
Nov  4 17:12:18.888: INFO: (2) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 17.16424ms)
Nov  4 17:12:18.890: INFO: (2) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 18.273895ms)
Nov  4 17:12:18.891: INFO: (2) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 18.887099ms)
Nov  4 17:12:18.891: INFO: (2) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 19.322075ms)
Nov  4 17:12:18.892: INFO: (2) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 19.422065ms)
Nov  4 17:12:18.892: INFO: (2) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 20.236673ms)
Nov  4 17:12:18.893: INFO: (2) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 21.652664ms)
Nov  4 17:12:18.893: INFO: (2) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 22.027969ms)
Nov  4 17:12:18.894: INFO: (2) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 21.463414ms)
Nov  4 17:12:18.906: INFO: (3) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 11.442193ms)
Nov  4 17:12:18.908: INFO: (3) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 13.77584ms)
Nov  4 17:12:18.908: INFO: (3) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 13.919642ms)
Nov  4 17:12:18.909: INFO: (3) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 13.71985ms)
Nov  4 17:12:18.909: INFO: (3) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 14.665619ms)
Nov  4 17:12:18.909: INFO: (3) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 15.149016ms)
Nov  4 17:12:18.910: INFO: (3) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 15.364821ms)
Nov  4 17:12:18.912: INFO: (3) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 17.837663ms)
Nov  4 17:12:18.912: INFO: (3) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 17.836191ms)
Nov  4 17:12:18.913: INFO: (3) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 18.883482ms)
Nov  4 17:12:18.913: INFO: (3) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 18.235598ms)
Nov  4 17:12:18.915: INFO: (3) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 20.443718ms)
Nov  4 17:12:18.915: INFO: (3) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 20.104284ms)
Nov  4 17:12:18.915: INFO: (3) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 21.04985ms)
Nov  4 17:12:18.916: INFO: (3) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 20.973675ms)
Nov  4 17:12:18.916: INFO: (3) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 21.567701ms)
Nov  4 17:12:18.923: INFO: (4) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 6.894679ms)
Nov  4 17:12:18.926: INFO: (4) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 9.968439ms)
Nov  4 17:12:18.932: INFO: (4) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 15.288014ms)
Nov  4 17:12:18.932: INFO: (4) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 16.16486ms)
Nov  4 17:12:18.933: INFO: (4) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 15.77281ms)
Nov  4 17:12:18.933: INFO: (4) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 16.626366ms)
Nov  4 17:12:18.933: INFO: (4) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 16.722808ms)
Nov  4 17:12:18.933: INFO: (4) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 16.900636ms)
Nov  4 17:12:18.934: INFO: (4) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 16.904304ms)
Nov  4 17:12:18.934: INFO: (4) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 16.84493ms)
Nov  4 17:12:18.936: INFO: (4) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 19.167482ms)
Nov  4 17:12:18.937: INFO: (4) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 21.08508ms)
Nov  4 17:12:18.937: INFO: (4) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 20.205132ms)
Nov  4 17:12:18.938: INFO: (4) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 20.658108ms)
Nov  4 17:12:18.938: INFO: (4) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 20.841403ms)
Nov  4 17:12:18.938: INFO: (4) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 21.523099ms)
Nov  4 17:12:18.950: INFO: (5) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 10.637646ms)
Nov  4 17:12:18.952: INFO: (5) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 13.082363ms)
Nov  4 17:12:18.952: INFO: (5) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 13.90456ms)
Nov  4 17:12:18.953: INFO: (5) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 13.260574ms)
Nov  4 17:12:18.953: INFO: (5) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 14.163059ms)
Nov  4 17:12:18.953: INFO: (5) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 14.329782ms)
Nov  4 17:12:18.954: INFO: (5) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 15.120396ms)
Nov  4 17:12:18.955: INFO: (5) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 16.242687ms)
Nov  4 17:12:18.957: INFO: (5) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 17.539753ms)
Nov  4 17:12:18.957: INFO: (5) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 18.433957ms)
Nov  4 17:12:18.958: INFO: (5) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 18.726466ms)
Nov  4 17:12:18.959: INFO: (5) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 20.400638ms)
Nov  4 17:12:18.959: INFO: (5) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 20.460828ms)
Nov  4 17:12:18.960: INFO: (5) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 20.348397ms)
Nov  4 17:12:18.960: INFO: (5) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 21.66278ms)
Nov  4 17:12:18.961: INFO: (5) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 21.517002ms)
Nov  4 17:12:18.972: INFO: (6) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 10.645045ms)
Nov  4 17:12:18.973: INFO: (6) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 11.272054ms)
Nov  4 17:12:18.975: INFO: (6) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 14.100841ms)
Nov  4 17:12:18.977: INFO: (6) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 16.063535ms)
Nov  4 17:12:18.981: INFO: (6) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 20.331311ms)
Nov  4 17:12:18.982: INFO: (6) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 19.95312ms)
Nov  4 17:12:18.982: INFO: (6) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 20.871233ms)
Nov  4 17:12:18.982: INFO: (6) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 20.991027ms)
Nov  4 17:12:18.983: INFO: (6) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 21.853614ms)
Nov  4 17:12:18.983: INFO: (6) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 22.016219ms)
Nov  4 17:12:18.983: INFO: (6) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 22.190897ms)
Nov  4 17:12:18.984: INFO: (6) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 22.131556ms)
Nov  4 17:12:18.985: INFO: (6) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 23.656403ms)
Nov  4 17:12:18.986: INFO: (6) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 24.009692ms)
Nov  4 17:12:18.986: INFO: (6) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 24.310837ms)
Nov  4 17:12:18.986: INFO: (6) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 24.799414ms)
Nov  4 17:12:18.994: INFO: (7) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 7.376217ms)
Nov  4 17:12:18.998: INFO: (7) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 11.252683ms)
Nov  4 17:12:19.000: INFO: (7) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 12.578192ms)
Nov  4 17:12:19.000: INFO: (7) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 12.515463ms)
Nov  4 17:12:19.001: INFO: (7) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 14.639355ms)
Nov  4 17:12:19.003: INFO: (7) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 15.657617ms)
Nov  4 17:12:19.005: INFO: (7) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 18.55209ms)
Nov  4 17:12:19.006: INFO: (7) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 18.302189ms)
Nov  4 17:12:19.006: INFO: (7) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 18.808706ms)
Nov  4 17:12:19.007: INFO: (7) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 19.479746ms)
Nov  4 17:12:19.007: INFO: (7) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 20.144775ms)
Nov  4 17:12:19.008: INFO: (7) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 20.171254ms)
Nov  4 17:12:19.009: INFO: (7) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 21.652662ms)
Nov  4 17:12:19.009: INFO: (7) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 21.595194ms)
Nov  4 17:12:19.009: INFO: (7) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 22.479522ms)
Nov  4 17:12:19.010: INFO: (7) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 22.17535ms)
Nov  4 17:12:19.018: INFO: (8) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 8.03279ms)
Nov  4 17:12:19.021: INFO: (8) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 10.856588ms)
Nov  4 17:12:19.022: INFO: (8) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 12.112746ms)
Nov  4 17:12:19.028: INFO: (8) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 17.217937ms)
Nov  4 17:12:19.028: INFO: (8) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 17.882099ms)
Nov  4 17:12:19.028: INFO: (8) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 18.230664ms)
Nov  4 17:12:19.029: INFO: (8) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 18.106318ms)
Nov  4 17:12:19.029: INFO: (8) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 17.951267ms)
Nov  4 17:12:19.029: INFO: (8) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 18.749551ms)
Nov  4 17:12:19.030: INFO: (8) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 19.512113ms)
Nov  4 17:12:19.030: INFO: (8) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 19.116265ms)
Nov  4 17:12:19.030: INFO: (8) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 19.284838ms)
Nov  4 17:12:19.031: INFO: (8) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 20.819534ms)
Nov  4 17:12:19.032: INFO: (8) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 21.40882ms)
Nov  4 17:12:19.033: INFO: (8) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 21.836635ms)
Nov  4 17:12:19.033: INFO: (8) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 22.395302ms)
Nov  4 17:12:19.042: INFO: (9) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 8.883939ms)
Nov  4 17:12:19.045: INFO: (9) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 10.624327ms)
Nov  4 17:12:19.045: INFO: (9) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 12.089415ms)
Nov  4 17:12:19.048: INFO: (9) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 13.978007ms)
Nov  4 17:12:19.052: INFO: (9) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 17.086656ms)
Nov  4 17:12:19.052: INFO: (9) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 18.270652ms)
Nov  4 17:12:19.052: INFO: (9) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 18.183761ms)
Nov  4 17:12:19.053: INFO: (9) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 19.481528ms)
Nov  4 17:12:19.053: INFO: (9) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 19.6164ms)
Nov  4 17:12:19.054: INFO: (9) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 19.306996ms)
Nov  4 17:12:19.054: INFO: (9) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 20.453274ms)
Nov  4 17:12:19.055: INFO: (9) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 21.730659ms)
Nov  4 17:12:19.056: INFO: (9) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 22.382947ms)
Nov  4 17:12:19.057: INFO: (9) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 23.190504ms)
Nov  4 17:12:19.058: INFO: (9) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 23.899665ms)
Nov  4 17:12:19.058: INFO: (9) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 24.038784ms)
Nov  4 17:12:19.066: INFO: (10) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 7.465653ms)
Nov  4 17:12:19.074: INFO: (10) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 15.374677ms)
Nov  4 17:12:19.074: INFO: (10) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 15.831391ms)
Nov  4 17:12:19.075: INFO: (10) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 15.532313ms)
Nov  4 17:12:19.075: INFO: (10) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 16.151467ms)
Nov  4 17:12:19.075: INFO: (10) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 16.838144ms)
Nov  4 17:12:19.075: INFO: (10) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 16.050606ms)
Nov  4 17:12:19.077: INFO: (10) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 18.255067ms)
Nov  4 17:12:19.078: INFO: (10) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 19.367338ms)
Nov  4 17:12:19.078: INFO: (10) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 19.313974ms)
Nov  4 17:12:19.079: INFO: (10) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 19.45413ms)
Nov  4 17:12:19.079: INFO: (10) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 20.509401ms)
Nov  4 17:12:19.080: INFO: (10) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 20.682817ms)
Nov  4 17:12:19.081: INFO: (10) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 21.971732ms)
Nov  4 17:12:19.081: INFO: (10) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 21.859116ms)
Nov  4 17:12:19.081: INFO: (10) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 22.646314ms)
Nov  4 17:12:19.089: INFO: (11) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 7.964679ms)
Nov  4 17:12:19.093: INFO: (11) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 10.499425ms)
Nov  4 17:12:19.094: INFO: (11) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 11.896431ms)
Nov  4 17:12:19.097: INFO: (11) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 15.165917ms)
Nov  4 17:12:19.101: INFO: (11) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 19.142958ms)
Nov  4 17:12:19.102: INFO: (11) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 18.997139ms)
Nov  4 17:12:19.102: INFO: (11) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 20.21393ms)
Nov  4 17:12:19.102: INFO: (11) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 19.837146ms)
Nov  4 17:12:19.103: INFO: (11) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 20.739818ms)
Nov  4 17:12:19.103: INFO: (11) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 21.379856ms)
Nov  4 17:12:19.103: INFO: (11) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 21.567788ms)
Nov  4 17:12:19.104: INFO: (11) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 21.615896ms)
Nov  4 17:12:19.104: INFO: (11) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 21.812722ms)
Nov  4 17:12:19.105: INFO: (11) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 22.039907ms)
Nov  4 17:12:19.105: INFO: (11) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 22.76566ms)
Nov  4 17:12:19.106: INFO: (11) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 23.532299ms)
Nov  4 17:12:19.113: INFO: (12) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 6.789645ms)
Nov  4 17:12:19.114: INFO: (12) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 8.240346ms)
Nov  4 17:12:19.119: INFO: (12) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 12.63824ms)
Nov  4 17:12:19.121: INFO: (12) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 14.814661ms)
Nov  4 17:12:19.125: INFO: (12) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 18.813086ms)
Nov  4 17:12:19.125: INFO: (12) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 19.53017ms)
Nov  4 17:12:19.126: INFO: (12) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 19.202255ms)
Nov  4 17:12:19.126: INFO: (12) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 19.194522ms)
Nov  4 17:12:19.126: INFO: (12) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 20.657964ms)
Nov  4 17:12:19.127: INFO: (12) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 20.3403ms)
Nov  4 17:12:19.127: INFO: (12) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 20.837561ms)
Nov  4 17:12:19.128: INFO: (12) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 22.023473ms)
Nov  4 17:12:19.129: INFO: (12) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 22.79269ms)
Nov  4 17:12:19.129: INFO: (12) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 22.482179ms)
Nov  4 17:12:19.129: INFO: (12) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 23.212332ms)
Nov  4 17:12:19.130: INFO: (12) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 23.059829ms)
Nov  4 17:12:19.143: INFO: (13) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 13.676005ms)
Nov  4 17:12:19.155: INFO: (13) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 24.465562ms)
Nov  4 17:12:19.156: INFO: (13) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 24.765573ms)
Nov  4 17:12:19.156: INFO: (13) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 25.728077ms)
Nov  4 17:12:19.156: INFO: (13) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 26.138959ms)
Nov  4 17:12:19.157: INFO: (13) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 26.458091ms)
Nov  4 17:12:19.157: INFO: (13) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 26.345592ms)
Nov  4 17:12:19.157: INFO: (13) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 26.637937ms)
Nov  4 17:12:19.159: INFO: (13) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 28.293897ms)
Nov  4 17:12:19.159: INFO: (13) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 29.09064ms)
Nov  4 17:12:19.160: INFO: (13) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 29.272811ms)
Nov  4 17:12:19.160: INFO: (13) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 30.070489ms)
Nov  4 17:12:19.160: INFO: (13) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 29.734231ms)
Nov  4 17:12:19.163: INFO: (13) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 32.006634ms)
Nov  4 17:12:19.164: INFO: (13) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 33.454458ms)
Nov  4 17:12:19.164: INFO: (13) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 33.254219ms)
Nov  4 17:12:19.172: INFO: (14) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 8.413159ms)
Nov  4 17:12:19.175: INFO: (14) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 10.81156ms)
Nov  4 17:12:19.182: INFO: (14) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 17.236017ms)
Nov  4 17:12:19.182: INFO: (14) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 17.109218ms)
Nov  4 17:12:19.182: INFO: (14) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 17.010619ms)
Nov  4 17:12:19.182: INFO: (14) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 17.92753ms)
Nov  4 17:12:19.183: INFO: (14) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 18.608518ms)
Nov  4 17:12:19.183: INFO: (14) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 18.716804ms)
Nov  4 17:12:19.183: INFO: (14) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 18.310573ms)
Nov  4 17:12:19.184: INFO: (14) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 19.294619ms)
Nov  4 17:12:19.184: INFO: (14) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 18.986435ms)
Nov  4 17:12:19.184: INFO: (14) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 19.713585ms)
Nov  4 17:12:19.185: INFO: (14) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 20.335054ms)
Nov  4 17:12:19.186: INFO: (14) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 21.322273ms)
Nov  4 17:12:19.187: INFO: (14) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 22.608279ms)
Nov  4 17:12:19.187: INFO: (14) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 22.594473ms)
Nov  4 17:12:19.194: INFO: (15) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 6.661839ms)
Nov  4 17:12:19.200: INFO: (15) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 12.018073ms)
Nov  4 17:12:19.200: INFO: (15) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 11.976192ms)
Nov  4 17:12:19.201: INFO: (15) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 13.307564ms)
Nov  4 17:12:19.201: INFO: (15) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 13.859259ms)
Nov  4 17:12:19.205: INFO: (15) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 16.868233ms)
Nov  4 17:12:19.205: INFO: (15) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 17.091752ms)
Nov  4 17:12:19.206: INFO: (15) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 17.298797ms)
Nov  4 17:12:19.206: INFO: (15) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 18.378304ms)
Nov  4 17:12:19.206: INFO: (15) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 18.447017ms)
Nov  4 17:12:19.207: INFO: (15) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 19.346007ms)
Nov  4 17:12:19.208: INFO: (15) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 20.04949ms)
Nov  4 17:12:19.208: INFO: (15) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 20.627333ms)
Nov  4 17:12:19.209: INFO: (15) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 21.28007ms)
Nov  4 17:12:19.210: INFO: (15) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 21.289688ms)
Nov  4 17:12:19.210: INFO: (15) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 21.747715ms)
Nov  4 17:12:19.220: INFO: (16) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 8.60058ms)
Nov  4 17:12:19.223: INFO: (16) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 11.67536ms)
Nov  4 17:12:19.224: INFO: (16) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 12.851257ms)
Nov  4 17:12:19.224: INFO: (16) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 13.648817ms)
Nov  4 17:12:19.230: INFO: (16) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 19.076548ms)
Nov  4 17:12:19.230: INFO: (16) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 19.559387ms)
Nov  4 17:12:19.230: INFO: (16) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 19.530187ms)
Nov  4 17:12:19.230: INFO: (16) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 19.216635ms)
Nov  4 17:12:19.231: INFO: (16) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 19.680363ms)
Nov  4 17:12:19.231: INFO: (16) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 20.116296ms)
Nov  4 17:12:19.231: INFO: (16) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 20.470233ms)
Nov  4 17:12:19.232: INFO: (16) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 21.232075ms)
Nov  4 17:12:19.233: INFO: (16) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 21.657943ms)
Nov  4 17:12:19.234: INFO: (16) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 22.588107ms)
Nov  4 17:12:19.234: INFO: (16) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 22.735274ms)
Nov  4 17:12:19.234: INFO: (16) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 23.566202ms)
Nov  4 17:12:19.242: INFO: (17) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 7.845981ms)
Nov  4 17:12:19.247: INFO: (17) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 11.99566ms)
Nov  4 17:12:19.247: INFO: (17) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 12.558979ms)
Nov  4 17:12:19.250: INFO: (17) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 15.370975ms)
Nov  4 17:12:19.251: INFO: (17) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 14.875508ms)
Nov  4 17:12:19.251: INFO: (17) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 15.617549ms)
Nov  4 17:12:19.251: INFO: (17) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 15.747461ms)
Nov  4 17:12:19.252: INFO: (17) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 16.378872ms)
Nov  4 17:12:19.252: INFO: (17) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 16.710234ms)
Nov  4 17:12:19.254: INFO: (17) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 18.636415ms)
Nov  4 17:12:19.256: INFO: (17) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 21.510424ms)
Nov  4 17:12:19.257: INFO: (17) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 20.981079ms)
Nov  4 17:12:19.257: INFO: (17) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 21.808544ms)
Nov  4 17:12:19.257: INFO: (17) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 22.291652ms)
Nov  4 17:12:19.258: INFO: (17) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 22.610624ms)
Nov  4 17:12:19.258: INFO: (17) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 22.872232ms)
Nov  4 17:12:19.267: INFO: (18) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 8.329195ms)
Nov  4 17:12:19.270: INFO: (18) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 10.795049ms)
Nov  4 17:12:19.270: INFO: (18) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 11.792146ms)
Nov  4 17:12:19.272: INFO: (18) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 13.236675ms)
Nov  4 17:12:19.276: INFO: (18) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 17.662446ms)
Nov  4 17:12:19.277: INFO: (18) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 18.012615ms)
Nov  4 17:12:19.277: INFO: (18) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 17.562344ms)
Nov  4 17:12:19.277: INFO: (18) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 18.330766ms)
Nov  4 17:12:19.278: INFO: (18) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 18.434733ms)
Nov  4 17:12:19.278: INFO: (18) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 19.283001ms)
Nov  4 17:12:19.278: INFO: (18) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 19.364745ms)
Nov  4 17:12:19.279: INFO: (18) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 19.462455ms)
Nov  4 17:12:19.279: INFO: (18) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 20.06959ms)
Nov  4 17:12:19.280: INFO: (18) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 20.614732ms)
Nov  4 17:12:19.281: INFO: (18) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 21.423198ms)
Nov  4 17:12:19.281: INFO: (18) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 22.186474ms)
Nov  4 17:12:19.289: INFO: (19) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd/proxy/rewriteme">test</a> (200; 7.221506ms)
Nov  4 17:12:19.294: INFO: (19) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">... (200; 12.385267ms)
Nov  4 17:12:19.298: INFO: (19) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 15.763463ms)
Nov  4 17:12:19.298: INFO: (19) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 16.90712ms)
Nov  4 17:12:19.299: INFO: (19) /api/v1/namespaces/proxy-6109/pods/http:proxy-service-tg96x-k7xgd:160/proxy/: foo (200; 16.233148ms)
Nov  4 17:12:19.299: INFO: (19) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:1080/proxy/rewriteme">test<... (200; 16.652817ms)
Nov  4 17:12:19.299: INFO: (19) /api/v1/namespaces/proxy-6109/pods/proxy-service-tg96x-k7xgd:162/proxy/: bar (200; 17.76989ms)
Nov  4 17:12:19.300: INFO: (19) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/: <a href="/api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:443/proxy/tlsrewritem... (200; 17.993767ms)
Nov  4 17:12:19.300: INFO: (19) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:460/proxy/: tls baz (200; 18.05737ms)
Nov  4 17:12:19.300: INFO: (19) /api/v1/namespaces/proxy-6109/pods/https:proxy-service-tg96x-k7xgd:462/proxy/: tls qux (200; 18.862642ms)
Nov  4 17:12:19.302: INFO: (19) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname1/proxy/: tls baz (200; 19.857677ms)
Nov  4 17:12:19.302: INFO: (19) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname2/proxy/: bar (200; 20.007058ms)
Nov  4 17:12:19.302: INFO: (19) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname1/proxy/: foo (200; 20.519149ms)
Nov  4 17:12:19.303: INFO: (19) /api/v1/namespaces/proxy-6109/services/proxy-service-tg96x:portname2/proxy/: bar (200; 21.888626ms)
Nov  4 17:12:19.304: INFO: (19) /api/v1/namespaces/proxy-6109/services/http:proxy-service-tg96x:portname1/proxy/: foo (200; 22.927064ms)
Nov  4 17:12:19.305: INFO: (19) /api/v1/namespaces/proxy-6109/services/https:proxy-service-tg96x:tlsportname2/proxy/: tls qux (200; 23.263077ms)
STEP: deleting ReplicationController proxy-service-tg96x in namespace proxy-6109, will wait for the garbage collector to delete the pods
Nov  4 17:12:19.367: INFO: Deleting ReplicationController proxy-service-tg96x took: 9.141252ms
Nov  4 17:12:19.668: INFO: Terminating ReplicationController proxy-service-tg96x pods took: 300.206535ms
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:12:21.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6109" for this suite.
Nov  4 17:12:27.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:12:27.851: INFO: namespace proxy-6109 deletion completed in 6.080035791s

â€¢ [SLOW TEST:19.249 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:12:27.852: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7498
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 17:12:27.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-7498'
Nov  4 17:12:28.079: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 17:12:28.079: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Nov  4 17:12:28.101: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-k2bwt]
Nov  4 17:12:28.101: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-k2bwt" in namespace "kubectl-7498" to be "running and ready"
Nov  4 17:12:28.125: INFO: Pod "e2e-test-httpd-rc-k2bwt": Phase="Pending", Reason="", readiness=false. Elapsed: 23.77404ms
Nov  4 17:12:30.127: INFO: Pod "e2e-test-httpd-rc-k2bwt": Phase="Running", Reason="", readiness=true. Elapsed: 2.026355312s
Nov  4 17:12:30.127: INFO: Pod "e2e-test-httpd-rc-k2bwt" satisfied condition "running and ready"
Nov  4 17:12:30.127: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-k2bwt]
Nov  4 17:12:30.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 logs rc/e2e-test-httpd-rc --namespace=kubectl-7498'
Nov  4 17:12:30.222: INFO: stderr: ""
Nov  4 17:12:30.222: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.33.2.35. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.33.2.35. Set the 'ServerName' directive globally to suppress this message\n[Mon Nov 04 17:12:28.655290 2019] [mpm_event:notice] [pid 1:tid 139787213564776] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Nov 04 17:12:28.655381 2019] [core:notice] [pid 1:tid 139787213564776] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Nov  4 17:12:30.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete rc e2e-test-httpd-rc --namespace=kubectl-7498'
Nov  4 17:12:30.335: INFO: stderr: ""
Nov  4 17:12:30.335: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:12:30.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7498" for this suite.
Nov  4 17:12:42.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:12:42.432: INFO: namespace kubectl-7498 deletion completed in 12.091808074s

â€¢ [SLOW TEST:14.581 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:12:42.433: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-6787
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Nov  4 17:12:42.568: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  4 17:13:42.579: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:13:42.581: INFO: Starting informer...
STEP: Starting pod...
Nov  4 17:13:42.795: INFO: Pod is running on k8s-3. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Nov  4 17:13:42.808: INFO: Pod wasn't evicted. Proceeding
Nov  4 17:13:42.808: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Nov  4 17:14:57.833: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:14:57.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-6787" for this suite.
Nov  4 17:15:25.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:15:25.926: INFO: namespace taint-single-pod-6787 deletion completed in 28.088771185s

â€¢ [SLOW TEST:163.492 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:15:25.927: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8419
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:15:28.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8419" for this suite.
Nov  4 17:16:12.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:16:12.200: INFO: namespace kubelet-test-8419 deletion completed in 44.095847028s

â€¢ [SLOW TEST:46.273 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:16:12.201: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4302
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4302
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4302
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4302
Nov  4 17:16:12.350: INFO: Found 0 stateful pods, waiting for 1
Nov  4 17:16:22.353: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov  4 17:16:22.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-4302 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:16:22.610: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:16:22.610: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:16:22.610: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:16:22.613: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:16:22.613: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 17:16:22.629: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999282s
Nov  4 17:16:23.632: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994845801s
Nov  4 17:16:24.635: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991766391s
Nov  4 17:16:25.638: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988394701s
Nov  4 17:16:26.642: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.984962548s
Nov  4 17:16:27.645: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.981609249s
Nov  4 17:16:28.648: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.978501356s
Nov  4 17:16:29.652: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.975271363s
Nov  4 17:16:30.655: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.971839231s
Nov  4 17:16:31.658: INFO: Verifying statefulset ss doesn't scale past 1 for another 968.569322ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4302
Nov  4 17:16:32.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-4302 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 17:16:32.868: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 17:16:32.868: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 17:16:32.868: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 17:16:32.871: INFO: Found 1 stateful pods, waiting for 3
Nov  4 17:16:42.874: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 17:16:42.874: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 17:16:42.874: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov  4 17:16:42.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-4302 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:16:43.155: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:16:43.155: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:16:43.155: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:16:43.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-4302 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:16:43.379: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:16:43.379: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:16:43.379: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:16:43.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-4302 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:16:43.612: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:16:43.612: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:16:43.612: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:16:43.612: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 17:16:43.615: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Nov  4 17:16:53.622: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:16:53.622: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:16:53.622: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:16:53.631: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999205s
Nov  4 17:16:54.635: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995809631s
Nov  4 17:16:55.639: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991681598s
Nov  4 17:16:56.643: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988062617s
Nov  4 17:16:57.646: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98457529s
Nov  4 17:16:58.649: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.981050411s
Nov  4 17:16:59.660: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97786158s
Nov  4 17:17:00.668: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.963047888s
Nov  4 17:17:01.671: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.958734901s
Nov  4 17:17:02.675: INFO: Verifying statefulset ss doesn't scale past 3 for another 955.784541ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4302
Nov  4 17:17:03.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-4302 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 17:17:03.940: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 17:17:03.940: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 17:17:03.940: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 17:17:03.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-4302 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 17:17:04.166: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 17:17:04.166: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 17:17:04.166: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 17:17:04.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-4302 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 17:17:04.412: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 17:17:04.412: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 17:17:04.412: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 17:17:04.412: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 17:17:34.425: INFO: Deleting all statefulset in ns statefulset-4302
Nov  4 17:17:34.427: INFO: Scaling statefulset ss to 0
Nov  4 17:17:34.435: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 17:17:34.437: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:17:34.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4302" for this suite.
Nov  4 17:17:40.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:17:40.571: INFO: namespace statefulset-4302 deletion completed in 6.116908369s

â€¢ [SLOW TEST:88.371 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:17:40.573: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-810
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-92bc3e19-3554-4316-8b59-04584c25a4c6
STEP: Creating a pod to test consume configMaps
Nov  4 17:17:40.720: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4dfb0db9-c790-4d12-a4ff-256683701847" in namespace "projected-810" to be "success or failure"
Nov  4 17:17:40.726: INFO: Pod "pod-projected-configmaps-4dfb0db9-c790-4d12-a4ff-256683701847": Phase="Pending", Reason="", readiness=false. Elapsed: 5.801422ms
Nov  4 17:17:42.729: INFO: Pod "pod-projected-configmaps-4dfb0db9-c790-4d12-a4ff-256683701847": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009101843s
STEP: Saw pod success
Nov  4 17:17:42.729: INFO: Pod "pod-projected-configmaps-4dfb0db9-c790-4d12-a4ff-256683701847" satisfied condition "success or failure"
Nov  4 17:17:42.732: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-4dfb0db9-c790-4d12-a4ff-256683701847 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 17:17:42.759: INFO: Waiting for pod pod-projected-configmaps-4dfb0db9-c790-4d12-a4ff-256683701847 to disappear
Nov  4 17:17:42.766: INFO: Pod pod-projected-configmaps-4dfb0db9-c790-4d12-a4ff-256683701847 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:17:42.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-810" for this suite.
Nov  4 17:17:48.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:17:48.859: INFO: namespace projected-810 deletion completed in 6.089928768s

â€¢ [SLOW TEST:8.286 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:17:48.859: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-3588
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:17:49.436: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov  4 17:17:51.444: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484669, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484669, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484669, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484669, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:17:54.460: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:17:54.463: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:18:00.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3588" for this suite.
Nov  4 17:18:06.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:18:06.899: INFO: namespace crd-webhook-3588 deletion completed in 6.085533454s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:18.053 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:18:06.913: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-7567
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov  4 17:18:09.067: INFO: &Pod{ObjectMeta:{send-events-595371a9-b4ab-4241-9631-f16849185f02  events-7567 /api/v1/namespaces/events-7567/pods/send-events-595371a9-b4ab-4241-9631-f16849185f02 961fada4-bdd5-4cb8-b447-01d94cfd0a7c 5293 0 2019-11-04 17:18:07 +0000 UTC <nil> <nil> map[name:foo time:49102027] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-kmfpx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-kmfpx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-kmfpx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:18:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:18:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.2.41,StartTime:2019-11-04 17:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:18:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:containerd://688f413750a9cf0ea3333b735695124738bb3e18c515dd9dee8c7742b43e6ccb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Nov  4 17:18:11.070: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov  4 17:18:13.074: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:18:13.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7567" for this suite.
Nov  4 17:18:57.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:18:57.174: INFO: namespace events-7567 deletion completed in 44.089476595s

â€¢ [SLOW TEST:50.262 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:18:57.175: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3104
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-7af87019-0999-40c3-a7ab-9804d5a09695
Nov  4 17:18:57.318: INFO: Pod name my-hostname-basic-7af87019-0999-40c3-a7ab-9804d5a09695: Found 0 pods out of 1
Nov  4 17:19:02.330: INFO: Pod name my-hostname-basic-7af87019-0999-40c3-a7ab-9804d5a09695: Found 1 pods out of 1
Nov  4 17:19:02.330: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7af87019-0999-40c3-a7ab-9804d5a09695" are running
Nov  4 17:19:02.334: INFO: Pod "my-hostname-basic-7af87019-0999-40c3-a7ab-9804d5a09695-2mbn6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 17:18:57 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 17:18:59 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 17:18:59 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 17:18:57 +0000 UTC Reason: Message:}])
Nov  4 17:19:02.334: INFO: Trying to dial the pod
Nov  4 17:19:07.344: INFO: Controller my-hostname-basic-7af87019-0999-40c3-a7ab-9804d5a09695: Got expected result from replica 1 [my-hostname-basic-7af87019-0999-40c3-a7ab-9804d5a09695-2mbn6]: "my-hostname-basic-7af87019-0999-40c3-a7ab-9804d5a09695-2mbn6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:19:07.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3104" for this suite.
Nov  4 17:19:13.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:19:13.441: INFO: namespace replication-controller-3104 deletion completed in 6.093606803s

â€¢ [SLOW TEST:16.266 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:19:13.443: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7187
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  4 17:19:13.589: INFO: Waiting up to 5m0s for pod "pod-0da72f41-c92c-4b35-b1a1-a3bf17cc8a6a" in namespace "emptydir-7187" to be "success or failure"
Nov  4 17:19:13.603: INFO: Pod "pod-0da72f41-c92c-4b35-b1a1-a3bf17cc8a6a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.190276ms
Nov  4 17:19:15.606: INFO: Pod "pod-0da72f41-c92c-4b35-b1a1-a3bf17cc8a6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017139061s
STEP: Saw pod success
Nov  4 17:19:15.606: INFO: Pod "pod-0da72f41-c92c-4b35-b1a1-a3bf17cc8a6a" satisfied condition "success or failure"
Nov  4 17:19:15.610: INFO: Trying to get logs from node k8s-3 pod pod-0da72f41-c92c-4b35-b1a1-a3bf17cc8a6a container test-container: <nil>
STEP: delete the pod
Nov  4 17:19:15.636: INFO: Waiting for pod pod-0da72f41-c92c-4b35-b1a1-a3bf17cc8a6a to disappear
Nov  4 17:19:15.639: INFO: Pod pod-0da72f41-c92c-4b35-b1a1-a3bf17cc8a6a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:19:15.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7187" for this suite.
Nov  4 17:19:21.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:19:21.721: INFO: namespace emptydir-7187 deletion completed in 6.079731905s

â€¢ [SLOW TEST:8.278 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:19:21.722: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8799
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8799
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-8799
I1104 17:19:21.886766      19 runners.go:184] Created replication controller with name: externalname-service, namespace: services-8799, replica count: 2
Nov  4 17:19:24.937: INFO: Creating new exec pod
I1104 17:19:24.937228      19 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 17:19:27.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-8799 execpod5rkks -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov  4 17:19:28.220: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  4 17:19:28.220: INFO: stdout: ""
Nov  4 17:19:28.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-8799 execpod5rkks -- /bin/sh -x -c nc -zv -t -w 2 10.32.0.123 80'
Nov  4 17:19:28.439: INFO: stderr: "+ nc -zv -t -w 2 10.32.0.123 80\nConnection to 10.32.0.123 80 port [tcp/http] succeeded!\n"
Nov  4 17:19:28.439: INFO: stdout: ""
Nov  4 17:19:28.439: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:19:28.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8799" for this suite.
Nov  4 17:19:34.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:19:34.550: INFO: namespace services-8799 deletion completed in 6.081236396s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:12.828 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:19:34.551: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1966
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1966
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-1966
STEP: Creating statefulset with conflicting port in namespace statefulset-1966
STEP: Waiting until pod test-pod will start running in namespace statefulset-1966
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1966
Nov  4 17:19:36.721: INFO: Observed stateful pod in namespace: statefulset-1966, name: ss-0, uid: 11e52205-c7f7-47c8-9528-872f48d6a659, status phase: Pending. Waiting for statefulset controller to delete.
Nov  4 17:19:39.418: INFO: Observed stateful pod in namespace: statefulset-1966, name: ss-0, uid: 11e52205-c7f7-47c8-9528-872f48d6a659, status phase: Failed. Waiting for statefulset controller to delete.
Nov  4 17:19:39.425: INFO: Observed stateful pod in namespace: statefulset-1966, name: ss-0, uid: 11e52205-c7f7-47c8-9528-872f48d6a659, status phase: Failed. Waiting for statefulset controller to delete.
Nov  4 17:19:39.432: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1966
STEP: Removing pod with conflicting port in namespace statefulset-1966
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1966 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 17:19:41.462: INFO: Deleting all statefulset in ns statefulset-1966
Nov  4 17:19:41.465: INFO: Scaling statefulset ss to 0
Nov  4 17:19:51.481: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 17:19:51.484: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:19:51.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1966" for this suite.
Nov  4 17:19:57.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:19:57.588: INFO: namespace statefulset-1966 deletion completed in 6.084607303s

â€¢ [SLOW TEST:23.037 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:19:57.588: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7910
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-mhtj
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 17:19:57.741: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-mhtj" in namespace "subpath-7910" to be "success or failure"
Nov  4 17:19:57.745: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.355625ms
Nov  4 17:19:59.748: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Running", Reason="", readiness=true. Elapsed: 2.007365705s
Nov  4 17:20:01.751: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Running", Reason="", readiness=true. Elapsed: 4.010433167s
Nov  4 17:20:03.754: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Running", Reason="", readiness=true. Elapsed: 6.013511016s
Nov  4 17:20:05.758: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Running", Reason="", readiness=true. Elapsed: 8.016632161s
Nov  4 17:20:07.761: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Running", Reason="", readiness=true. Elapsed: 10.019759334s
Nov  4 17:20:09.764: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Running", Reason="", readiness=true. Elapsed: 12.022835561s
Nov  4 17:20:11.767: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Running", Reason="", readiness=true. Elapsed: 14.026007757s
Nov  4 17:20:13.770: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Running", Reason="", readiness=true. Elapsed: 16.028743425s
Nov  4 17:20:15.773: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Running", Reason="", readiness=true. Elapsed: 18.031684405s
Nov  4 17:20:17.776: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Running", Reason="", readiness=true. Elapsed: 20.035358221s
Nov  4 17:20:19.781: INFO: Pod "pod-subpath-test-downwardapi-mhtj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.039643143s
STEP: Saw pod success
Nov  4 17:20:19.781: INFO: Pod "pod-subpath-test-downwardapi-mhtj" satisfied condition "success or failure"
Nov  4 17:20:19.785: INFO: Trying to get logs from node k8s-3 pod pod-subpath-test-downwardapi-mhtj container test-container-subpath-downwardapi-mhtj: <nil>
STEP: delete the pod
Nov  4 17:20:19.813: INFO: Waiting for pod pod-subpath-test-downwardapi-mhtj to disappear
Nov  4 17:20:19.815: INFO: Pod pod-subpath-test-downwardapi-mhtj no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-mhtj
Nov  4 17:20:19.816: INFO: Deleting pod "pod-subpath-test-downwardapi-mhtj" in namespace "subpath-7910"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:20:19.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7910" for this suite.
Nov  4 17:20:25.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:20:25.928: INFO: namespace subpath-7910 deletion completed in 6.103643554s

â€¢ [SLOW TEST:28.339 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:20:25.929: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6723
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  4 17:20:28.589: INFO: Successfully updated pod "pod-update-b3fa851c-a44d-4447-b80c-90e21fe44360"
STEP: verifying the updated pod is in kubernetes
Nov  4 17:20:28.595: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:20:28.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6723" for this suite.
Nov  4 17:20:40.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:20:40.686: INFO: namespace pods-6723 deletion completed in 12.086876709s

â€¢ [SLOW TEST:14.757 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:20:40.686: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:20:40.833: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e82f4bfd-0bc3-4a6c-b723-3415d2dc3402" in namespace "projected-413" to be "success or failure"
Nov  4 17:20:40.837: INFO: Pod "downwardapi-volume-e82f4bfd-0bc3-4a6c-b723-3415d2dc3402": Phase="Pending", Reason="", readiness=false. Elapsed: 3.726413ms
Nov  4 17:20:42.840: INFO: Pod "downwardapi-volume-e82f4bfd-0bc3-4a6c-b723-3415d2dc3402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0067439s
STEP: Saw pod success
Nov  4 17:20:42.840: INFO: Pod "downwardapi-volume-e82f4bfd-0bc3-4a6c-b723-3415d2dc3402" satisfied condition "success or failure"
Nov  4 17:20:42.843: INFO: Trying to get logs from node k8s-3 pod downwardapi-volume-e82f4bfd-0bc3-4a6c-b723-3415d2dc3402 container client-container: <nil>
STEP: delete the pod
Nov  4 17:20:42.863: INFO: Waiting for pod downwardapi-volume-e82f4bfd-0bc3-4a6c-b723-3415d2dc3402 to disappear
Nov  4 17:20:42.865: INFO: Pod downwardapi-volume-e82f4bfd-0bc3-4a6c-b723-3415d2dc3402 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:20:42.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-413" for this suite.
Nov  4 17:20:48.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:20:48.955: INFO: namespace projected-413 deletion completed in 6.087114825s

â€¢ [SLOW TEST:8.270 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:20:48.956: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6659
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:21:02.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6659" for this suite.
Nov  4 17:21:08.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:21:08.241: INFO: namespace resourcequota-6659 deletion completed in 6.089030788s

â€¢ [SLOW TEST:19.285 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:21:08.241: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6164
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 17:21:08.379: INFO: PodSpec: initContainers in spec.initContainers
Nov  4 17:21:56.692: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-f47db417-04f4-4752-a200-d03daefbae03", GenerateName:"", Namespace:"init-container-6164", SelfLink:"/api/v1/namespaces/init-container-6164/pods/pod-init-f47db417-04f4-4752-a200-d03daefbae03", UID:"bf895677-ada9-430c-ab1d-bb8503f00051", ResourceVersion:"6065", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63708484868, loc:(*time.Location)(0x84c02a0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"379386112"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-5tbbq", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc006f23a00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5tbbq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5tbbq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-5tbbq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0049bb7a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0054b1620), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0049bb830)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0049bb850)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0049bb858), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0049bb85c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484868, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484868, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484868, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708484868, loc:(*time.Location)(0x84c02a0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.20.20.6", PodIP:"10.33.2.48", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.33.2.48"}}, StartTime:(*v1.Time)(0xc0026f1140), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001358460)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0013584d0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://ac5d059dd7ebc620d12fa8b74b0b622a11fcdab50d4b2b85018f068e1e84d378", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0026f1180), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0026f1160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0049bb8df)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:21:56.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6164" for this suite.
Nov  4 17:22:24.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:22:24.789: INFO: namespace init-container-6164 deletion completed in 28.091492569s

â€¢ [SLOW TEST:76.548 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:22:24.790: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-8480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Nov  4 17:22:24.926: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  4 17:23:24.936: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:23:24.939: INFO: Starting informer...
STEP: Starting pods...
Nov  4 17:23:25.157: INFO: Pod1 is running on k8s-1. Tainting Node
Nov  4 17:23:27.374: INFO: Pod2 is running on k8s-1. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Nov  4 17:23:39.464: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov  4 17:23:59.429: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:23:59.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8480" for this suite.
Nov  4 17:24:05.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:24:05.542: INFO: namespace taint-multiple-pods-8480 deletion completed in 6.094896872s

â€¢ [SLOW TEST:100.753 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:24:05.543: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-596
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:24:05.685: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4435cb2a-61bd-45e3-aa5b-c98c9696b8a6" in namespace "downward-api-596" to be "success or failure"
Nov  4 17:24:05.689: INFO: Pod "downwardapi-volume-4435cb2a-61bd-45e3-aa5b-c98c9696b8a6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.641983ms
Nov  4 17:24:07.692: INFO: Pod "downwardapi-volume-4435cb2a-61bd-45e3-aa5b-c98c9696b8a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007537157s
STEP: Saw pod success
Nov  4 17:24:07.692: INFO: Pod "downwardapi-volume-4435cb2a-61bd-45e3-aa5b-c98c9696b8a6" satisfied condition "success or failure"
Nov  4 17:24:07.695: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-4435cb2a-61bd-45e3-aa5b-c98c9696b8a6 container client-container: <nil>
STEP: delete the pod
Nov  4 17:24:07.729: INFO: Waiting for pod downwardapi-volume-4435cb2a-61bd-45e3-aa5b-c98c9696b8a6 to disappear
Nov  4 17:24:07.732: INFO: Pod downwardapi-volume-4435cb2a-61bd-45e3-aa5b-c98c9696b8a6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:24:07.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-596" for this suite.
Nov  4 17:24:13.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:24:13.821: INFO: namespace downward-api-596 deletion completed in 6.085548536s

â€¢ [SLOW TEST:8.278 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:24:13.823: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4603
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4603.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4603.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4603.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4603.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4603.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4603.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4603.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4603.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4603.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4603.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 17:24:15.984: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local from pod dns-4603/dns-test-110e901f-e0e0-415d-acea-236c571062ad: the server could not find the requested resource (get pods dns-test-110e901f-e0e0-415d-acea-236c571062ad)
Nov  4 17:24:15.987: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local from pod dns-4603/dns-test-110e901f-e0e0-415d-acea-236c571062ad: the server could not find the requested resource (get pods dns-test-110e901f-e0e0-415d-acea-236c571062ad)
Nov  4 17:24:15.990: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4603.svc.cluster.local from pod dns-4603/dns-test-110e901f-e0e0-415d-acea-236c571062ad: the server could not find the requested resource (get pods dns-test-110e901f-e0e0-415d-acea-236c571062ad)
Nov  4 17:24:15.994: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4603.svc.cluster.local from pod dns-4603/dns-test-110e901f-e0e0-415d-acea-236c571062ad: the server could not find the requested resource (get pods dns-test-110e901f-e0e0-415d-acea-236c571062ad)
Nov  4 17:24:16.006: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local from pod dns-4603/dns-test-110e901f-e0e0-415d-acea-236c571062ad: the server could not find the requested resource (get pods dns-test-110e901f-e0e0-415d-acea-236c571062ad)
Nov  4 17:24:16.015: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4603.svc.cluster.local from pod dns-4603/dns-test-110e901f-e0e0-415d-acea-236c571062ad: the server could not find the requested resource (get pods dns-test-110e901f-e0e0-415d-acea-236c571062ad)
Nov  4 17:24:16.018: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4603.svc.cluster.local from pod dns-4603/dns-test-110e901f-e0e0-415d-acea-236c571062ad: the server could not find the requested resource (get pods dns-test-110e901f-e0e0-415d-acea-236c571062ad)
Nov  4 17:24:16.027: INFO: Lookups using dns-4603/dns-test-110e901f-e0e0-415d-acea-236c571062ad failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4603.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4603.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4603.svc.cluster.local jessie_udp@dns-test-service-2.dns-4603.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4603.svc.cluster.local]

Nov  4 17:24:21.081: INFO: DNS probes using dns-4603/dns-test-110e901f-e0e0-415d-acea-236c571062ad succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:24:21.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4603" for this suite.
Nov  4 17:24:27.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:24:27.235: INFO: namespace dns-4603 deletion completed in 6.08814465s

â€¢ [SLOW TEST:13.412 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:24:27.235: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3346
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  4 17:24:31.419: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 17:24:31.423: INFO: Pod pod-with-poststart-http-hook still exists
Nov  4 17:24:33.423: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 17:24:33.426: INFO: Pod pod-with-poststart-http-hook still exists
Nov  4 17:24:35.423: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 17:24:35.426: INFO: Pod pod-with-poststart-http-hook still exists
Nov  4 17:24:37.423: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 17:24:37.432: INFO: Pod pod-with-poststart-http-hook still exists
Nov  4 17:24:39.423: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 17:24:39.426: INFO: Pod pod-with-poststart-http-hook still exists
Nov  4 17:24:41.423: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 17:24:41.426: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:24:41.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3346" for this suite.
Nov  4 17:25:09.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:25:09.516: INFO: namespace container-lifecycle-hook-3346 deletion completed in 28.086466244s

â€¢ [SLOW TEST:42.281 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:25:09.516: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:25:09.670: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov  4 17:25:09.679: INFO: Number of nodes with available pods: 0
Nov  4 17:25:09.679: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov  4 17:25:09.695: INFO: Number of nodes with available pods: 0
Nov  4 17:25:09.695: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:25:10.698: INFO: Number of nodes with available pods: 1
Nov  4 17:25:10.698: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov  4 17:25:10.719: INFO: Number of nodes with available pods: 1
Nov  4 17:25:10.719: INFO: Number of running nodes: 0, number of available pods: 1
Nov  4 17:25:11.722: INFO: Number of nodes with available pods: 0
Nov  4 17:25:11.723: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov  4 17:25:11.736: INFO: Number of nodes with available pods: 0
Nov  4 17:25:11.736: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:25:12.739: INFO: Number of nodes with available pods: 0
Nov  4 17:25:12.740: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:25:13.739: INFO: Number of nodes with available pods: 0
Nov  4 17:25:13.739: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:25:14.739: INFO: Number of nodes with available pods: 0
Nov  4 17:25:14.739: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:25:15.739: INFO: Number of nodes with available pods: 0
Nov  4 17:25:15.739: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:25:16.739: INFO: Number of nodes with available pods: 0
Nov  4 17:25:16.739: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:25:17.739: INFO: Number of nodes with available pods: 0
Nov  4 17:25:17.739: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:25:18.739: INFO: Number of nodes with available pods: 0
Nov  4 17:25:18.739: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:25:19.739: INFO: Number of nodes with available pods: 0
Nov  4 17:25:19.739: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:25:20.739: INFO: Number of nodes with available pods: 0
Nov  4 17:25:20.739: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:25:21.739: INFO: Number of nodes with available pods: 1
Nov  4 17:25:21.739: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4613, will wait for the garbage collector to delete the pods
Nov  4 17:25:21.803: INFO: Deleting DaemonSet.extensions daemon-set took: 6.46052ms
Nov  4 17:25:22.103: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.14173ms
Nov  4 17:25:29.506: INFO: Number of nodes with available pods: 0
Nov  4 17:25:29.506: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 17:25:29.509: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4613/daemonsets","resourceVersion":"6741"},"items":null}

Nov  4 17:25:29.512: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4613/pods","resourceVersion":"6741"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:25:29.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4613" for this suite.
Nov  4 17:25:35.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:25:35.629: INFO: namespace daemonsets-4613 deletion completed in 6.098043739s

â€¢ [SLOW TEST:26.113 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:25:35.630: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8500
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 17:25:35.766: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 17:25:59.859: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.0.54:8080/dial?request=hostName&protocol=http&host=10.33.1.14&port=8080&tries=1'] Namespace:pod-network-test-8500 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:25:59.859: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:26:00.008: INFO: Waiting for endpoints: map[]
Nov  4 17:26:00.011: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.0.54:8080/dial?request=hostName&protocol=http&host=10.33.0.53&port=8080&tries=1'] Namespace:pod-network-test-8500 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:26:00.011: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:26:00.153: INFO: Waiting for endpoints: map[]
Nov  4 17:26:00.156: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.0.54:8080/dial?request=hostName&protocol=http&host=10.33.2.50&port=8080&tries=1'] Namespace:pod-network-test-8500 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:26:00.156: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:26:00.301: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:26:00.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8500" for this suite.
Nov  4 17:26:12.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:26:12.393: INFO: namespace pod-network-test-8500 deletion completed in 12.088468243s

â€¢ [SLOW TEST:36.764 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:26:12.394: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4059
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-4cf70234-cd08-4eab-a49f-a9e965b3d32b
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:26:12.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4059" for this suite.
Nov  4 17:26:18.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:26:18.616: INFO: namespace configmap-4059 deletion completed in 6.081369475s

â€¢ [SLOW TEST:6.222 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:26:18.616: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-743
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:26:20.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-743" for this suite.
Nov  4 17:26:26.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:26:26.906: INFO: namespace emptydir-wrapper-743 deletion completed in 6.088210671s

â€¢ [SLOW TEST:8.290 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:26:26.907: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5391
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:26:27.052: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov  4 17:26:32.056: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  4 17:26:32.056: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov  4 17:26:34.059: INFO: Creating deployment "test-rollover-deployment"
Nov  4 17:26:34.066: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov  4 17:26:36.073: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov  4 17:26:36.078: INFO: Ensure that both replica sets have 1 created replica
Nov  4 17:26:36.083: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov  4 17:26:36.090: INFO: Updating deployment test-rollover-deployment
Nov  4 17:26:36.090: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov  4 17:26:38.100: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov  4 17:26:38.105: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov  4 17:26:38.110: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 17:26:38.110: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485197, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:26:40.116: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 17:26:40.116: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485197, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:26:42.116: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 17:26:42.116: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485197, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:26:44.116: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 17:26:44.116: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485197, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:26:46.116: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 17:26:46.116: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485197, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485194, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:26:48.116: INFO: 
Nov  4 17:26:48.116: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 17:26:48.123: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-5391 /apis/apps/v1/namespaces/deployment-5391/deployments/test-rollover-deployment ff668b8b-eedc-46c3-92d3-6ace0634340a 7096 2 2019-11-04 17:26:34 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002b070f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-04 17:26:34 +0000 UTC,LastTransitionTime:2019-11-04 17:26:34 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-11-04 17:26:47 +0000 UTC,LastTransitionTime:2019-11-04 17:26:34 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  4 17:26:48.126: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-5391 /apis/apps/v1/namespaces/deployment-5391/replicasets/test-rollover-deployment-7d7dc6548c a602a747-46f7-40b3-b867-9233060676ae 7085 2 2019-11-04 17:26:36 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment ff668b8b-eedc-46c3-92d3-6ace0634340a 0xc002b075a7 0xc002b075a8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002b07608 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:26:48.126: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov  4 17:26:48.126: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5391 /apis/apps/v1/namespaces/deployment-5391/replicasets/test-rollover-controller 4054f51e-4b3f-42e2-9991-692bdfa59161 7095 2 2019-11-04 17:26:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment ff668b8b-eedc-46c3-92d3-6ace0634340a 0xc002b074cf 0xc002b074e0}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002b07548 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:26:48.126: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-5391 /apis/apps/v1/namespaces/deployment-5391/replicasets/test-rollover-deployment-f6c94f66c c94c7609-be52-4a2e-9f1a-16773e1aba6e 7052 2 2019-11-04 17:26:34 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment ff668b8b-eedc-46c3-92d3-6ace0634340a 0xc002b07660 0xc002b07661}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002b076d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:26:48.130: INFO: Pod "test-rollover-deployment-7d7dc6548c-2jkq2" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-2jkq2 test-rollover-deployment-7d7dc6548c- deployment-5391 /api/v1/namespaces/deployment-5391/pods/test-rollover-deployment-7d7dc6548c-2jkq2 fef132a7-e627-478c-ac0c-9b6112642075 7066 0 2019-11-04 17:26:36 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c a602a747-46f7-40b3-b867-9233060676ae 0xc002b07d77 0xc002b07d78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zwqks,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zwqks,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zwqks,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:26:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:26:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:26:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:26:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.0.57,StartTime:2019-11-04 17:26:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:26:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://aeaa71e9d432c6fa873920eb5d4d3a18e6bd94166c0f491ff68fad98d5e8dcf1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.57,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:26:48.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5391" for this suite.
Nov  4 17:26:54.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:26:54.219: INFO: namespace deployment-5391 deletion completed in 6.085776644s

â€¢ [SLOW TEST:27.312 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:26:54.220: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4359
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:26:54.357: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  4 17:27:03.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-4359 create -f -'
Nov  4 17:27:03.698: INFO: stderr: ""
Nov  4 17:27:03.698: INFO: stdout: "e2e-test-crd-publish-openapi-9032-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  4 17:27:03.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-4359 delete e2e-test-crd-publish-openapi-9032-crds test-cr'
Nov  4 17:27:03.845: INFO: stderr: ""
Nov  4 17:27:03.845: INFO: stdout: "e2e-test-crd-publish-openapi-9032-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov  4 17:27:03.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-4359 apply -f -'
Nov  4 17:27:04.078: INFO: stderr: ""
Nov  4 17:27:04.079: INFO: stdout: "e2e-test-crd-publish-openapi-9032-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  4 17:27:04.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-4359 delete e2e-test-crd-publish-openapi-9032-crds test-cr'
Nov  4 17:27:04.159: INFO: stderr: ""
Nov  4 17:27:04.159: INFO: stdout: "e2e-test-crd-publish-openapi-9032-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov  4 17:27:04.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 explain e2e-test-crd-publish-openapi-9032-crds'
Nov  4 17:27:04.351: INFO: stderr: ""
Nov  4 17:27:04.351: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9032-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:27:07.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4359" for this suite.
Nov  4 17:27:13.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:27:13.901: INFO: namespace crd-publish-openapi-4359 deletion completed in 6.088992035s

â€¢ [SLOW TEST:19.682 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:27:13.902: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-150
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov  4 17:27:17.072: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:27:18.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-150" for this suite.
Nov  4 17:27:46.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:27:46.181: INFO: namespace replicaset-150 deletion completed in 28.090398331s

â€¢ [SLOW TEST:32.280 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:27:46.182: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3501
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 17:27:46.316: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 17:27:46.325: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 17:27:46.328: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Nov  4 17:27:46.341: INFO: kube-flannel-ds-amd64-bls8m from kube-system started at 2019-11-04 17:23:59 +0000 UTC (1 container statuses recorded)
Nov  4 17:27:46.341: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 17:27:46.341: INFO: traefik-ingress-controller-mccsj from kube-system started at 2019-11-04 17:23:59 +0000 UTC (1 container statuses recorded)
Nov  4 17:27:46.341: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 17:27:46.341: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-lpskk from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 17:27:46.341: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:27:46.341: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 17:27:46.341: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Nov  4 17:27:46.353: INFO: kube-flannel-ds-amd64-c6xnw from kube-system started at 2019-11-04 16:58:52 +0000 UTC (1 container statuses recorded)
Nov  4 17:27:46.353: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 17:27:46.353: INFO: traefik-ingress-controller-qqfzz from kube-system started at 2019-11-04 16:58:54 +0000 UTC (1 container statuses recorded)
Nov  4 17:27:46.353: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 17:27:46.353: INFO: sonobuoy from sonobuoy started at 2019-11-04 16:59:51 +0000 UTC (1 container statuses recorded)
Nov  4 17:27:46.353: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 17:27:46.353: INFO: sonobuoy-e2e-job-281da138127b42b3 from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 17:27:46.353: INFO: 	Container e2e ready: true, restart count 0
Nov  4 17:27:46.353: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:27:46.353: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-k67sr from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 17:27:46.353: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:27:46.353: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 17:27:46.353: INFO: coredns-b7f8c8654-4rcsc from kube-system started at 2019-11-04 17:23:27 +0000 UTC (1 container statuses recorded)
Nov  4 17:27:46.353: INFO: 	Container coredns ready: true, restart count 0
Nov  4 17:27:46.353: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Nov  4 17:27:46.370: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-vkd6f from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 17:27:46.370: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:27:46.370: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 17:27:46.370: INFO: coredns-b7f8c8654-68j25 from kube-system started at 2019-11-04 17:13:42 +0000 UTC (1 container statuses recorded)
Nov  4 17:27:46.370: INFO: 	Container coredns ready: true, restart count 0
Nov  4 17:27:46.370: INFO: kube-flannel-ds-amd64-s2gr4 from kube-system started at 2019-11-04 17:14:19 +0000 UTC (1 container statuses recorded)
Nov  4 17:27:46.370: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 17:27:46.370: INFO: traefik-ingress-controller-98f8s from kube-system started at 2019-11-04 17:13:49 +0000 UTC (1 container statuses recorded)
Nov  4 17:27:46.370: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5fa698bd-de61-445d-bedf-2da8f96ffdb9 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-5fa698bd-de61-445d-bedf-2da8f96ffdb9 off the node k8s-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5fa698bd-de61-445d-bedf-2da8f96ffdb9
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:27:56.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3501" for this suite.
Nov  4 17:28:14.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:28:14.554: INFO: namespace sched-pred-3501 deletion completed in 18.088846143s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:28.372 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:28:14.555: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6354
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Nov  4 17:28:16.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec pod-sharedvolume-1fc7dda4-fa76-489f-92cc-66998703ce9b -c busybox-main-container --namespace=emptydir-6354 -- cat /usr/share/volumeshare/shareddata.txt'
Nov  4 17:28:16.952: INFO: stderr: ""
Nov  4 17:28:16.952: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:28:16.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6354" for this suite.
Nov  4 17:28:22.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:28:23.070: INFO: namespace emptydir-6354 deletion completed in 6.115074742s

â€¢ [SLOW TEST:8.515 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:28:23.070: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1511
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:28:23.219: INFO: Waiting up to 5m0s for pod "downwardapi-volume-29a26b4b-9282-4649-b484-77f64829bfe9" in namespace "downward-api-1511" to be "success or failure"
Nov  4 17:28:23.223: INFO: Pod "downwardapi-volume-29a26b4b-9282-4649-b484-77f64829bfe9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.727183ms
Nov  4 17:28:25.225: INFO: Pod "downwardapi-volume-29a26b4b-9282-4649-b484-77f64829bfe9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006509738s
STEP: Saw pod success
Nov  4 17:28:25.226: INFO: Pod "downwardapi-volume-29a26b4b-9282-4649-b484-77f64829bfe9" satisfied condition "success or failure"
Nov  4 17:28:25.228: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-29a26b4b-9282-4649-b484-77f64829bfe9 container client-container: <nil>
STEP: delete the pod
Nov  4 17:28:25.248: INFO: Waiting for pod downwardapi-volume-29a26b4b-9282-4649-b484-77f64829bfe9 to disappear
Nov  4 17:28:25.252: INFO: Pod downwardapi-volume-29a26b4b-9282-4649-b484-77f64829bfe9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:28:25.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1511" for this suite.
Nov  4 17:28:31.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:28:31.355: INFO: namespace downward-api-1511 deletion completed in 6.099540785s

â€¢ [SLOW TEST:8.285 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:28:31.356: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4032
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-91b53a25-6c3f-4255-911b-cc63edf2aadc in namespace container-probe-4032
Nov  4 17:28:33.519: INFO: Started pod liveness-91b53a25-6c3f-4255-911b-cc63edf2aadc in namespace container-probe-4032
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 17:28:33.521: INFO: Initial restart count of pod liveness-91b53a25-6c3f-4255-911b-cc63edf2aadc is 0
Nov  4 17:28:57.558: INFO: Restart count of pod container-probe-4032/liveness-91b53a25-6c3f-4255-911b-cc63edf2aadc is now 1 (24.037242751s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:28:57.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4032" for this suite.
Nov  4 17:29:03.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:29:03.667: INFO: namespace container-probe-4032 deletion completed in 6.084904995s

â€¢ [SLOW TEST:32.312 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:29:03.668: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6473
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-6473/configmap-test-7492efce-1d1b-4449-9ee5-144bde1ead85
STEP: Creating a pod to test consume configMaps
Nov  4 17:29:03.831: INFO: Waiting up to 5m0s for pod "pod-configmaps-1457f25b-bf97-4de7-a3a0-edc98bc88b10" in namespace "configmap-6473" to be "success or failure"
Nov  4 17:29:03.834: INFO: Pod "pod-configmaps-1457f25b-bf97-4de7-a3a0-edc98bc88b10": Phase="Pending", Reason="", readiness=false. Elapsed: 3.276548ms
Nov  4 17:29:05.837: INFO: Pod "pod-configmaps-1457f25b-bf97-4de7-a3a0-edc98bc88b10": Phase="Running", Reason="", readiness=true. Elapsed: 2.006314609s
Nov  4 17:29:07.840: INFO: Pod "pod-configmaps-1457f25b-bf97-4de7-a3a0-edc98bc88b10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009337802s
STEP: Saw pod success
Nov  4 17:29:07.841: INFO: Pod "pod-configmaps-1457f25b-bf97-4de7-a3a0-edc98bc88b10" satisfied condition "success or failure"
Nov  4 17:29:07.843: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-1457f25b-bf97-4de7-a3a0-edc98bc88b10 container env-test: <nil>
STEP: delete the pod
Nov  4 17:29:07.867: INFO: Waiting for pod pod-configmaps-1457f25b-bf97-4de7-a3a0-edc98bc88b10 to disappear
Nov  4 17:29:07.869: INFO: Pod pod-configmaps-1457f25b-bf97-4de7-a3a0-edc98bc88b10 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:29:07.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6473" for this suite.
Nov  4 17:29:13.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:29:13.956: INFO: namespace configmap-6473 deletion completed in 6.083253322s

â€¢ [SLOW TEST:10.289 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:29:13.957: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4067
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Nov  4 17:29:14.104: INFO: Waiting up to 5m0s for pod "var-expansion-d000ed4a-fc8a-4f75-af01-3f86398fb95f" in namespace "var-expansion-4067" to be "success or failure"
Nov  4 17:29:14.107: INFO: Pod "var-expansion-d000ed4a-fc8a-4f75-af01-3f86398fb95f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.968724ms
Nov  4 17:29:16.110: INFO: Pod "var-expansion-d000ed4a-fc8a-4f75-af01-3f86398fb95f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006002248s
STEP: Saw pod success
Nov  4 17:29:16.110: INFO: Pod "var-expansion-d000ed4a-fc8a-4f75-af01-3f86398fb95f" satisfied condition "success or failure"
Nov  4 17:29:16.113: INFO: Trying to get logs from node k8s-1 pod var-expansion-d000ed4a-fc8a-4f75-af01-3f86398fb95f container dapi-container: <nil>
STEP: delete the pod
Nov  4 17:29:16.133: INFO: Waiting for pod var-expansion-d000ed4a-fc8a-4f75-af01-3f86398fb95f to disappear
Nov  4 17:29:16.138: INFO: Pod var-expansion-d000ed4a-fc8a-4f75-af01-3f86398fb95f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:29:16.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4067" for this suite.
Nov  4 17:29:22.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:29:22.229: INFO: namespace var-expansion-4067 deletion completed in 6.087607311s

â€¢ [SLOW TEST:8.272 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:29:22.229: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1198
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-jjk9
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 17:29:22.381: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jjk9" in namespace "subpath-1198" to be "success or failure"
Nov  4 17:29:22.394: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.339181ms
Nov  4 17:29:24.397: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Running", Reason="", readiness=true. Elapsed: 2.016242788s
Nov  4 17:29:26.400: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Running", Reason="", readiness=true. Elapsed: 4.01899123s
Nov  4 17:29:28.403: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Running", Reason="", readiness=true. Elapsed: 6.022084447s
Nov  4 17:29:30.406: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Running", Reason="", readiness=true. Elapsed: 8.024910819s
Nov  4 17:29:32.409: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Running", Reason="", readiness=true. Elapsed: 10.028253026s
Nov  4 17:29:34.413: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Running", Reason="", readiness=true. Elapsed: 12.031562277s
Nov  4 17:29:36.417: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Running", Reason="", readiness=true. Elapsed: 14.035951677s
Nov  4 17:29:38.420: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Running", Reason="", readiness=true. Elapsed: 16.039311799s
Nov  4 17:29:40.425: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Running", Reason="", readiness=true. Elapsed: 18.043690959s
Nov  4 17:29:42.428: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Running", Reason="", readiness=true. Elapsed: 20.046659038s
Nov  4 17:29:44.431: INFO: Pod "pod-subpath-test-configmap-jjk9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.049472742s
STEP: Saw pod success
Nov  4 17:29:44.431: INFO: Pod "pod-subpath-test-configmap-jjk9" satisfied condition "success or failure"
Nov  4 17:29:44.433: INFO: Trying to get logs from node k8s-1 pod pod-subpath-test-configmap-jjk9 container test-container-subpath-configmap-jjk9: <nil>
STEP: delete the pod
Nov  4 17:29:44.452: INFO: Waiting for pod pod-subpath-test-configmap-jjk9 to disappear
Nov  4 17:29:44.464: INFO: Pod pod-subpath-test-configmap-jjk9 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jjk9
Nov  4 17:29:44.464: INFO: Deleting pod "pod-subpath-test-configmap-jjk9" in namespace "subpath-1198"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:29:44.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1198" for this suite.
Nov  4 17:29:50.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:29:50.558: INFO: namespace subpath-1198 deletion completed in 6.087868099s

â€¢ [SLOW TEST:28.329 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:29:50.559: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1834
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:29:51.359: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 17:29:53.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485391, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485391, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485391, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485391, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:29:56.384: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:29:56.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1834" for this suite.
Nov  4 17:30:02.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:30:02.766: INFO: namespace webhook-1834 deletion completed in 6.088282741s
STEP: Destroying namespace "webhook-1834-markers" for this suite.
Nov  4 17:30:08.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:30:08.861: INFO: namespace webhook-1834-markers deletion completed in 6.094325948s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:18.314 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:30:08.874: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  4 17:30:09.043: INFO: Number of nodes with available pods: 0
Nov  4 17:30:09.043: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:30:10.050: INFO: Number of nodes with available pods: 0
Nov  4 17:30:10.050: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:30:11.050: INFO: Number of nodes with available pods: 1
Nov  4 17:30:11.050: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 17:30:12.050: INFO: Number of nodes with available pods: 3
Nov  4 17:30:12.050: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov  4 17:30:12.069: INFO: Number of nodes with available pods: 2
Nov  4 17:30:12.069: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 17:30:13.075: INFO: Number of nodes with available pods: 2
Nov  4 17:30:13.076: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 17:30:14.075: INFO: Number of nodes with available pods: 2
Nov  4 17:30:14.075: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 17:30:15.076: INFO: Number of nodes with available pods: 2
Nov  4 17:30:15.076: INFO: Node k8s-3 is running more than one daemon pod
Nov  4 17:30:16.075: INFO: Number of nodes with available pods: 3
Nov  4 17:30:16.075: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9535, will wait for the garbage collector to delete the pods
Nov  4 17:30:16.139: INFO: Deleting DaemonSet.extensions daemon-set took: 8.924876ms
Nov  4 17:30:16.439: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.157947ms
Nov  4 17:30:29.542: INFO: Number of nodes with available pods: 0
Nov  4 17:30:29.542: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 17:30:29.544: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9535/daemonsets","resourceVersion":"8003"},"items":null}

Nov  4 17:30:29.546: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9535/pods","resourceVersion":"8003"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:30:29.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9535" for this suite.
Nov  4 17:30:35.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:30:35.645: INFO: namespace daemonsets-9535 deletion completed in 6.083790259s

â€¢ [SLOW TEST:26.772 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:30:35.646: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1032
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  4 17:30:35.802: INFO: Waiting up to 5m0s for pod "pod-b547ceb5-d3d4-4d3c-b27a-7aa5a8994499" in namespace "emptydir-1032" to be "success or failure"
Nov  4 17:30:35.809: INFO: Pod "pod-b547ceb5-d3d4-4d3c-b27a-7aa5a8994499": Phase="Pending", Reason="", readiness=false. Elapsed: 6.50293ms
Nov  4 17:30:37.812: INFO: Pod "pod-b547ceb5-d3d4-4d3c-b27a-7aa5a8994499": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009816854s
STEP: Saw pod success
Nov  4 17:30:37.812: INFO: Pod "pod-b547ceb5-d3d4-4d3c-b27a-7aa5a8994499" satisfied condition "success or failure"
Nov  4 17:30:37.815: INFO: Trying to get logs from node k8s-1 pod pod-b547ceb5-d3d4-4d3c-b27a-7aa5a8994499 container test-container: <nil>
STEP: delete the pod
Nov  4 17:30:37.831: INFO: Waiting for pod pod-b547ceb5-d3d4-4d3c-b27a-7aa5a8994499 to disappear
Nov  4 17:30:37.834: INFO: Pod pod-b547ceb5-d3d4-4d3c-b27a-7aa5a8994499 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:30:37.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1032" for this suite.
Nov  4 17:30:43.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:30:43.924: INFO: namespace emptydir-1032 deletion completed in 6.086383533s

â€¢ [SLOW TEST:8.278 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:30:43.925: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9320
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Nov  4 17:30:46.095: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-430892974 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  4 17:31:01.166: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:31:01.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9320" for this suite.
Nov  4 17:31:07.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:31:07.260: INFO: namespace pods-9320 deletion completed in 6.08661313s

â€¢ [SLOW TEST:23.335 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:31:07.260: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:31:07.838: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:31:10.856: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:31:11.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6252" for this suite.
Nov  4 17:31:17.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:31:17.191: INFO: namespace webhook-6252 deletion completed in 6.090953744s
STEP: Destroying namespace "webhook-6252-markers" for this suite.
Nov  4 17:31:23.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:31:23.272: INFO: namespace webhook-6252-markers deletion completed in 6.081099507s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:16.025 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:31:23.285: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8377
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8377.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8377.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 17:31:27.460: INFO: DNS probes using dns-8377/dns-test-dfee2429-2612-487a-8f34-2432353cf995 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:31:27.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8377" for this suite.
Nov  4 17:31:33.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:31:33.577: INFO: namespace dns-8377 deletion completed in 6.09124424s

â€¢ [SLOW TEST:10.291 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:31:33.577: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8358
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8358
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8358
STEP: creating replication controller externalsvc in namespace services-8358
I1104 17:31:33.745885      19 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8358, replica count: 2
I1104 17:31:36.796329      19 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Nov  4 17:31:36.812: INFO: Creating new exec pod
Nov  4 17:31:38.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-8358 execpods4m2h -- /bin/sh -x -c nslookup clusterip-service'
Nov  4 17:31:39.064: INFO: stderr: "+ nslookup clusterip-service\n"
Nov  4 17:31:39.064: INFO: stdout: "Server:\t\t10.32.0.10\nAddress:\t10.32.0.10#53\n\nclusterip-service.services-8358.svc.cluster.local\tcanonical name = externalsvc.services-8358.svc.cluster.local.\nName:\texternalsvc.services-8358.svc.cluster.local\nAddress: 10.32.0.170\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8358, will wait for the garbage collector to delete the pods
Nov  4 17:31:39.127: INFO: Deleting ReplicationController externalsvc took: 9.278725ms
Nov  4 17:31:39.427: INFO: Terminating ReplicationController externalsvc pods took: 300.213708ms
Nov  4 17:31:49.552: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:31:49.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8358" for this suite.
Nov  4 17:31:55.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:31:55.661: INFO: namespace services-8358 deletion completed in 6.090859183s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:22.084 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:31:55.661: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1872
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1872
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 17:31:55.810: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 17:32:17.895: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.33.1.16 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1872 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:32:17.895: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:32:19.046: INFO: Found all expected endpoints: [netserver-0]
Nov  4 17:32:19.049: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.33.0.80 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1872 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:32:19.049: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:32:20.185: INFO: Found all expected endpoints: [netserver-1]
Nov  4 17:32:20.188: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.33.2.55 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1872 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:32:20.188: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 17:32:21.325: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:32:21.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1872" for this suite.
Nov  4 17:32:33.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:32:33.426: INFO: namespace pod-network-test-1872 deletion completed in 12.09659269s

â€¢ [SLOW TEST:37.765 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:32:33.427: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7112
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Nov  4 17:32:33.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 api-versions'
Nov  4 17:32:33.632: INFO: stderr: ""
Nov  4 17:32:33.632: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:32:33.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7112" for this suite.
Nov  4 17:32:39.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:32:39.764: INFO: namespace kubectl-7112 deletion completed in 6.128602944s

â€¢ [SLOW TEST:6.338 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:32:39.765: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-86l9
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 17:32:39.915: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-86l9" in namespace "subpath-6699" to be "success or failure"
Nov  4 17:32:39.920: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.22243ms
Nov  4 17:32:41.924: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Running", Reason="", readiness=true. Elapsed: 2.008389415s
Nov  4 17:32:43.927: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Running", Reason="", readiness=true. Elapsed: 4.011726622s
Nov  4 17:32:45.930: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Running", Reason="", readiness=true. Elapsed: 6.014877965s
Nov  4 17:32:47.934: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Running", Reason="", readiness=true. Elapsed: 8.01915802s
Nov  4 17:32:49.943: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Running", Reason="", readiness=true. Elapsed: 10.028052754s
Nov  4 17:32:51.946: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Running", Reason="", readiness=true. Elapsed: 12.030763032s
Nov  4 17:32:53.949: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Running", Reason="", readiness=true. Elapsed: 14.03390201s
Nov  4 17:32:55.952: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Running", Reason="", readiness=true. Elapsed: 16.036931642s
Nov  4 17:32:57.955: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Running", Reason="", readiness=true. Elapsed: 18.039759166s
Nov  4 17:32:59.958: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Running", Reason="", readiness=true. Elapsed: 20.042823246s
Nov  4 17:33:01.961: INFO: Pod "pod-subpath-test-secret-86l9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.045875059s
STEP: Saw pod success
Nov  4 17:33:01.961: INFO: Pod "pod-subpath-test-secret-86l9" satisfied condition "success or failure"
Nov  4 17:33:01.964: INFO: Trying to get logs from node k8s-1 pod pod-subpath-test-secret-86l9 container test-container-subpath-secret-86l9: <nil>
STEP: delete the pod
Nov  4 17:33:01.990: INFO: Waiting for pod pod-subpath-test-secret-86l9 to disappear
Nov  4 17:33:01.997: INFO: Pod pod-subpath-test-secret-86l9 no longer exists
STEP: Deleting pod pod-subpath-test-secret-86l9
Nov  4 17:33:01.997: INFO: Deleting pod "pod-subpath-test-secret-86l9" in namespace "subpath-6699"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:33:02.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6699" for this suite.
Nov  4 17:33:08.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:33:08.088: INFO: namespace subpath-6699 deletion completed in 6.085568907s

â€¢ [SLOW TEST:28.323 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:33:08.089: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4248
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-ad59512a-cabe-48e4-bd7c-44962ae906fa
STEP: Creating a pod to test consume configMaps
Nov  4 17:33:08.232: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-50be9156-74ad-44a7-a834-606da9f53bf9" in namespace "projected-4248" to be "success or failure"
Nov  4 17:33:08.238: INFO: Pod "pod-projected-configmaps-50be9156-74ad-44a7-a834-606da9f53bf9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.473978ms
Nov  4 17:33:10.242: INFO: Pod "pod-projected-configmaps-50be9156-74ad-44a7-a834-606da9f53bf9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009563582s
Nov  4 17:33:12.244: INFO: Pod "pod-projected-configmaps-50be9156-74ad-44a7-a834-606da9f53bf9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012203852s
STEP: Saw pod success
Nov  4 17:33:12.244: INFO: Pod "pod-projected-configmaps-50be9156-74ad-44a7-a834-606da9f53bf9" satisfied condition "success or failure"
Nov  4 17:33:12.247: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-50be9156-74ad-44a7-a834-606da9f53bf9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 17:33:12.266: INFO: Waiting for pod pod-projected-configmaps-50be9156-74ad-44a7-a834-606da9f53bf9 to disappear
Nov  4 17:33:12.270: INFO: Pod pod-projected-configmaps-50be9156-74ad-44a7-a834-606da9f53bf9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:33:12.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4248" for this suite.
Nov  4 17:33:18.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:33:18.360: INFO: namespace projected-4248 deletion completed in 6.086663869s

â€¢ [SLOW TEST:10.271 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:33:18.360: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-2354
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov  4 17:33:21.020: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2354 pod-service-account-c7a83e1b-856b-4372-a502-eaa6add5f082 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov  4 17:33:21.236: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2354 pod-service-account-c7a83e1b-856b-4372-a502-eaa6add5f082 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov  4 17:33:21.457: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2354 pod-service-account-c7a83e1b-856b-4372-a502-eaa6add5f082 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:33:21.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2354" for this suite.
Nov  4 17:33:27.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:33:27.793: INFO: namespace svcaccounts-2354 deletion completed in 6.093187471s

â€¢ [SLOW TEST:9.433 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:33:27.794: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2367
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-2367
I1104 17:33:27.968768      19 runners.go:184] Created replication controller with name: externalname-service, namespace: services-2367, replica count: 2
Nov  4 17:33:31.019: INFO: Creating new exec pod
I1104 17:33:31.019176      19 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 17:33:34.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-2367 execpodhqm77 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov  4 17:33:34.257: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  4 17:33:34.257: INFO: stdout: ""
Nov  4 17:33:34.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-2367 execpodhqm77 -- /bin/sh -x -c nc -zv -t -w 2 10.32.0.64 80'
Nov  4 17:33:34.477: INFO: stderr: "+ nc -zv -t -w 2 10.32.0.64 80\nConnection to 10.32.0.64 80 port [tcp/http] succeeded!\n"
Nov  4 17:33:34.477: INFO: stdout: ""
Nov  4 17:33:34.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-2367 execpodhqm77 -- /bin/sh -x -c nc -zv -t -w 2 10.20.20.4 31536'
Nov  4 17:33:34.699: INFO: stderr: "+ nc -zv -t -w 2 10.20.20.4 31536\nConnection to 10.20.20.4 31536 port [tcp/31536] succeeded!\n"
Nov  4 17:33:34.699: INFO: stdout: ""
Nov  4 17:33:34.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-2367 execpodhqm77 -- /bin/sh -x -c nc -zv -t -w 2 10.20.20.5 31536'
Nov  4 17:33:34.921: INFO: stderr: "+ nc -zv -t -w 2 10.20.20.5 31536\nConnection to 10.20.20.5 31536 port [tcp/31536] succeeded!\n"
Nov  4 17:33:34.921: INFO: stdout: ""
Nov  4 17:33:34.921: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:33:34.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2367" for this suite.
Nov  4 17:33:40.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:33:41.046: INFO: namespace services-2367 deletion completed in 6.090007603s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:13.252 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:33:41.046: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3609
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:33:41.196: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa7617be-4e2a-4db3-a610-6ab14fef607e" in namespace "downward-api-3609" to be "success or failure"
Nov  4 17:33:41.207: INFO: Pod "downwardapi-volume-fa7617be-4e2a-4db3-a610-6ab14fef607e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.016261ms
Nov  4 17:33:43.210: INFO: Pod "downwardapi-volume-fa7617be-4e2a-4db3-a610-6ab14fef607e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014054651s
STEP: Saw pod success
Nov  4 17:33:43.210: INFO: Pod "downwardapi-volume-fa7617be-4e2a-4db3-a610-6ab14fef607e" satisfied condition "success or failure"
Nov  4 17:33:43.212: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-fa7617be-4e2a-4db3-a610-6ab14fef607e container client-container: <nil>
STEP: delete the pod
Nov  4 17:33:43.231: INFO: Waiting for pod downwardapi-volume-fa7617be-4e2a-4db3-a610-6ab14fef607e to disappear
Nov  4 17:33:43.236: INFO: Pod downwardapi-volume-fa7617be-4e2a-4db3-a610-6ab14fef607e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:33:43.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3609" for this suite.
Nov  4 17:33:49.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:33:49.320: INFO: namespace downward-api-3609 deletion completed in 6.081304288s

â€¢ [SLOW TEST:8.274 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:33:49.320: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9922
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9922
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-9922
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9922
Nov  4 17:33:49.472: INFO: Found 0 stateful pods, waiting for 1
Nov  4 17:33:59.475: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov  4 17:33:59.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-9922 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:33:59.698: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:33:59.698: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:33:59.698: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:33:59.708: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  4 17:34:09.711: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:34:09.711: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 17:34:09.725: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 17:34:09.725: INFO: ss-0  k8s-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:33:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:33:49 +0000 UTC  }]
Nov  4 17:34:09.725: INFO: 
Nov  4 17:34:09.725: INFO: StatefulSet ss has not reached scale 3, at 1
Nov  4 17:34:10.732: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99572364s
Nov  4 17:34:11.735: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988674599s
Nov  4 17:34:12.739: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985328429s
Nov  4 17:34:13.742: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981442456s
Nov  4 17:34:14.746: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978071561s
Nov  4 17:34:15.749: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.974667431s
Nov  4 17:34:16.753: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.97129827s
Nov  4 17:34:17.757: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967615094s
Nov  4 17:34:18.760: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.942558ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9922
Nov  4 17:34:19.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-9922 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 17:34:19.987: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 17:34:19.987: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 17:34:19.987: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 17:34:19.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-9922 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 17:34:20.236: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  4 17:34:20.236: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 17:34:20.236: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 17:34:20.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-9922 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 17:34:20.482: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  4 17:34:20.482: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 17:34:20.482: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 17:34:20.486: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 17:34:20.486: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 17:34:20.486: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov  4 17:34:20.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-9922 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:34:20.723: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:34:20.723: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:34:20.723: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:34:20.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-9922 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:34:20.977: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:34:20.977: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:34:20.977: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:34:20.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-9922 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:34:21.221: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:34:21.221: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:34:21.221: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:34:21.221: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 17:34:21.223: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Nov  4 17:34:31.229: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:34:31.229: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:34:31.229: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:34:31.240: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 17:34:31.240: INFO: ss-0  k8s-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:33:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:33:49 +0000 UTC  }]
Nov  4 17:34:31.240: INFO: ss-1  k8s-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:31.240: INFO: ss-2  k8s-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:31.240: INFO: 
Nov  4 17:34:31.240: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 17:34:32.244: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 17:34:32.244: INFO: ss-0  k8s-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:33:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:33:49 +0000 UTC  }]
Nov  4 17:34:32.244: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:32.245: INFO: ss-2  k8s-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:32.245: INFO: 
Nov  4 17:34:32.245: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 17:34:33.248: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 17:34:33.248: INFO: ss-0  k8s-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:33:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:33:49 +0000 UTC  }]
Nov  4 17:34:33.248: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:33.248: INFO: ss-2  k8s-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:33.248: INFO: 
Nov  4 17:34:33.248: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 17:34:34.251: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 17:34:34.251: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:34.251: INFO: ss-2  k8s-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:34.251: INFO: 
Nov  4 17:34:34.251: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  4 17:34:35.255: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 17:34:35.255: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:35.255: INFO: ss-2  k8s-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:35.255: INFO: 
Nov  4 17:34:35.255: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  4 17:34:36.258: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 17:34:36.258: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:36.258: INFO: ss-2  k8s-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:36.258: INFO: 
Nov  4 17:34:36.258: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  4 17:34:37.261: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 17:34:37.262: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:37.262: INFO: ss-2  k8s-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:37.262: INFO: 
Nov  4 17:34:37.262: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  4 17:34:38.265: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 17:34:38.265: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:38.265: INFO: ss-2  k8s-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:38.265: INFO: 
Nov  4 17:34:38.265: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  4 17:34:39.268: INFO: POD   NODE   PHASE    GRACE  CONDITIONS
Nov  4 17:34:39.268: INFO: ss-1  k8s-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:39.269: INFO: ss-2  k8s-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:34:09 +0000 UTC  }]
Nov  4 17:34:39.269: INFO: 
Nov  4 17:34:39.269: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  4 17:34:40.272: INFO: Verifying statefulset ss doesn't scale past 0 for another 967.082423ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9922
Nov  4 17:34:41.275: INFO: Scaling statefulset ss to 0
Nov  4 17:34:41.283: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 17:34:41.285: INFO: Deleting all statefulset in ns statefulset-9922
Nov  4 17:34:41.287: INFO: Scaling statefulset ss to 0
Nov  4 17:34:41.295: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 17:34:41.297: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:34:41.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9922" for this suite.
Nov  4 17:34:47.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:34:47.415: INFO: namespace statefulset-9922 deletion completed in 6.099191399s

â€¢ [SLOW TEST:58.095 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:34:47.416: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2903
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-c9a46360-a1c2-4517-91be-a6d7aad6cf8a
STEP: Creating a pod to test consume secrets
Nov  4 17:34:47.564: INFO: Waiting up to 5m0s for pod "pod-secrets-608f037f-cb36-4af0-b1e4-3c7a0385e344" in namespace "secrets-2903" to be "success or failure"
Nov  4 17:34:47.568: INFO: Pod "pod-secrets-608f037f-cb36-4af0-b1e4-3c7a0385e344": Phase="Pending", Reason="", readiness=false. Elapsed: 4.690027ms
Nov  4 17:34:49.572: INFO: Pod "pod-secrets-608f037f-cb36-4af0-b1e4-3c7a0385e344": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007791959s
STEP: Saw pod success
Nov  4 17:34:49.572: INFO: Pod "pod-secrets-608f037f-cb36-4af0-b1e4-3c7a0385e344" satisfied condition "success or failure"
Nov  4 17:34:49.574: INFO: Trying to get logs from node k8s-1 pod pod-secrets-608f037f-cb36-4af0-b1e4-3c7a0385e344 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 17:34:49.598: INFO: Waiting for pod pod-secrets-608f037f-cb36-4af0-b1e4-3c7a0385e344 to disappear
Nov  4 17:34:49.604: INFO: Pod pod-secrets-608f037f-cb36-4af0-b1e4-3c7a0385e344 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:34:49.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2903" for this suite.
Nov  4 17:34:55.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:34:55.724: INFO: namespace secrets-2903 deletion completed in 6.116287095s

â€¢ [SLOW TEST:8.308 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:34:55.724: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8725
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov  4 17:34:55.879: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8725 /api/v1/namespaces/watch-8725/configmaps/e2e-watch-test-label-changed 5f8e927c-9d9e-47ba-a16c-e0f83f0c6d8b 9245 0 2019-11-04 17:34:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 17:34:55.879: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8725 /api/v1/namespaces/watch-8725/configmaps/e2e-watch-test-label-changed 5f8e927c-9d9e-47ba-a16c-e0f83f0c6d8b 9246 0 2019-11-04 17:34:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  4 17:34:55.879: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8725 /api/v1/namespaces/watch-8725/configmaps/e2e-watch-test-label-changed 5f8e927c-9d9e-47ba-a16c-e0f83f0c6d8b 9247 0 2019-11-04 17:34:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov  4 17:35:05.904: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8725 /api/v1/namespaces/watch-8725/configmaps/e2e-watch-test-label-changed 5f8e927c-9d9e-47ba-a16c-e0f83f0c6d8b 9265 0 2019-11-04 17:34:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 17:35:05.904: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8725 /api/v1/namespaces/watch-8725/configmaps/e2e-watch-test-label-changed 5f8e927c-9d9e-47ba-a16c-e0f83f0c6d8b 9266 0 2019-11-04 17:34:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov  4 17:35:05.904: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8725 /api/v1/namespaces/watch-8725/configmaps/e2e-watch-test-label-changed 5f8e927c-9d9e-47ba-a16c-e0f83f0c6d8b 9267 0 2019-11-04 17:34:55 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:35:05.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8725" for this suite.
Nov  4 17:35:11.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:35:11.995: INFO: namespace watch-8725 deletion completed in 6.087286911s

â€¢ [SLOW TEST:16.271 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:35:11.996: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6695
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:35:14.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6695" for this suite.
Nov  4 17:35:22.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:35:22.245: INFO: namespace containers-6695 deletion completed in 8.090989967s

â€¢ [SLOW TEST:10.249 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:35:22.245: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3280
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-519bb82a-d587-410b-ba62-bb131f32d029
STEP: Creating a pod to test consume configMaps
Nov  4 17:35:22.391: INFO: Waiting up to 5m0s for pod "pod-configmaps-f377d00c-ef36-4dd3-ad7f-d8d4cc9588f2" in namespace "configmap-3280" to be "success or failure"
Nov  4 17:35:22.416: INFO: Pod "pod-configmaps-f377d00c-ef36-4dd3-ad7f-d8d4cc9588f2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.093382ms
Nov  4 17:35:24.419: INFO: Pod "pod-configmaps-f377d00c-ef36-4dd3-ad7f-d8d4cc9588f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028019851s
STEP: Saw pod success
Nov  4 17:35:24.419: INFO: Pod "pod-configmaps-f377d00c-ef36-4dd3-ad7f-d8d4cc9588f2" satisfied condition "success or failure"
Nov  4 17:35:24.422: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-f377d00c-ef36-4dd3-ad7f-d8d4cc9588f2 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 17:35:24.449: INFO: Waiting for pod pod-configmaps-f377d00c-ef36-4dd3-ad7f-d8d4cc9588f2 to disappear
Nov  4 17:35:24.453: INFO: Pod pod-configmaps-f377d00c-ef36-4dd3-ad7f-d8d4cc9588f2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:35:24.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3280" for this suite.
Nov  4 17:35:30.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:35:30.547: INFO: namespace configmap-3280 deletion completed in 6.091044481s

â€¢ [SLOW TEST:8.302 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:35:30.547: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7387
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:35:30.693: INFO: Waiting up to 5m0s for pod "downwardapi-volume-08b98158-a87c-481f-9782-5c071abfb58d" in namespace "projected-7387" to be "success or failure"
Nov  4 17:35:30.699: INFO: Pod "downwardapi-volume-08b98158-a87c-481f-9782-5c071abfb58d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.819516ms
Nov  4 17:35:32.702: INFO: Pod "downwardapi-volume-08b98158-a87c-481f-9782-5c071abfb58d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009562538s
STEP: Saw pod success
Nov  4 17:35:32.703: INFO: Pod "downwardapi-volume-08b98158-a87c-481f-9782-5c071abfb58d" satisfied condition "success or failure"
Nov  4 17:35:32.705: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-08b98158-a87c-481f-9782-5c071abfb58d container client-container: <nil>
STEP: delete the pod
Nov  4 17:35:32.726: INFO: Waiting for pod downwardapi-volume-08b98158-a87c-481f-9782-5c071abfb58d to disappear
Nov  4 17:35:32.733: INFO: Pod downwardapi-volume-08b98158-a87c-481f-9782-5c071abfb58d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:35:32.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7387" for this suite.
Nov  4 17:35:38.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:35:38.835: INFO: namespace projected-7387 deletion completed in 6.097974555s

â€¢ [SLOW TEST:8.288 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:35:38.836: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5584
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Nov  4 17:35:38.977: INFO: Waiting up to 5m0s for pod "client-containers-3d388ca0-95b0-4a90-9ad1-f0143ceb2cab" in namespace "containers-5584" to be "success or failure"
Nov  4 17:35:38.980: INFO: Pod "client-containers-3d388ca0-95b0-4a90-9ad1-f0143ceb2cab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.72756ms
Nov  4 17:35:40.983: INFO: Pod "client-containers-3d388ca0-95b0-4a90-9ad1-f0143ceb2cab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005436873s
STEP: Saw pod success
Nov  4 17:35:40.983: INFO: Pod "client-containers-3d388ca0-95b0-4a90-9ad1-f0143ceb2cab" satisfied condition "success or failure"
Nov  4 17:35:40.985: INFO: Trying to get logs from node k8s-1 pod client-containers-3d388ca0-95b0-4a90-9ad1-f0143ceb2cab container test-container: <nil>
STEP: delete the pod
Nov  4 17:35:41.002: INFO: Waiting for pod client-containers-3d388ca0-95b0-4a90-9ad1-f0143ceb2cab to disappear
Nov  4 17:35:41.005: INFO: Pod client-containers-3d388ca0-95b0-4a90-9ad1-f0143ceb2cab no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:35:41.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5584" for this suite.
Nov  4 17:35:47.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:35:47.089: INFO: namespace containers-5584 deletion completed in 6.080457315s

â€¢ [SLOW TEST:8.253 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:35:47.089: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3564
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  4 17:35:51.260: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:35:51.266: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:35:53.266: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:35:53.269: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:35:55.266: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:35:55.269: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:35:57.266: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:35:57.272: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:35:59.266: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:35:59.269: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:36:01.266: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:36:01.270: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:36:01.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3564" for this suite.
Nov  4 17:36:23.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:36:23.375: INFO: namespace container-lifecycle-hook-3564 deletion completed in 22.095006592s

â€¢ [SLOW TEST:36.285 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:36:23.375: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5827
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-d5333e34-54ac-4eca-8859-82b7a23f8f76
STEP: Creating configMap with name cm-test-opt-upd-30a05439-5484-43c6-a851-57fe35a8f23e
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d5333e34-54ac-4eca-8859-82b7a23f8f76
STEP: Updating configmap cm-test-opt-upd-30a05439-5484-43c6-a851-57fe35a8f23e
STEP: Creating configMap with name cm-test-opt-create-293ec575-4cba-4c49-9f19-4be1e430df72
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:36:27.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5827" for this suite.
Nov  4 17:36:41.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:36:41.744: INFO: namespace configmap-5827 deletion completed in 14.100441254s

â€¢ [SLOW TEST:18.369 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:36:41.744: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3123
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:36:41.890: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d2d20115-065f-422c-92c2-8f9457c1c59a" in namespace "projected-3123" to be "success or failure"
Nov  4 17:36:41.894: INFO: Pod "downwardapi-volume-d2d20115-065f-422c-92c2-8f9457c1c59a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.074947ms
Nov  4 17:36:43.897: INFO: Pod "downwardapi-volume-d2d20115-065f-422c-92c2-8f9457c1c59a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006237327s
STEP: Saw pod success
Nov  4 17:36:43.897: INFO: Pod "downwardapi-volume-d2d20115-065f-422c-92c2-8f9457c1c59a" satisfied condition "success or failure"
Nov  4 17:36:43.899: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-d2d20115-065f-422c-92c2-8f9457c1c59a container client-container: <nil>
STEP: delete the pod
Nov  4 17:36:43.916: INFO: Waiting for pod downwardapi-volume-d2d20115-065f-422c-92c2-8f9457c1c59a to disappear
Nov  4 17:36:43.920: INFO: Pod downwardapi-volume-d2d20115-065f-422c-92c2-8f9457c1c59a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:36:43.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3123" for this suite.
Nov  4 17:36:49.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:36:50.018: INFO: namespace projected-3123 deletion completed in 6.094719251s

â€¢ [SLOW TEST:8.273 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:36:50.019: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2872
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  4 17:36:50.161: INFO: Waiting up to 5m0s for pod "pod-ba4ed07f-0c21-47a7-a0e4-e284a01667ef" in namespace "emptydir-2872" to be "success or failure"
Nov  4 17:36:50.164: INFO: Pod "pod-ba4ed07f-0c21-47a7-a0e4-e284a01667ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.743517ms
Nov  4 17:36:52.166: INFO: Pod "pod-ba4ed07f-0c21-47a7-a0e4-e284a01667ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005543119s
STEP: Saw pod success
Nov  4 17:36:52.167: INFO: Pod "pod-ba4ed07f-0c21-47a7-a0e4-e284a01667ef" satisfied condition "success or failure"
Nov  4 17:36:52.170: INFO: Trying to get logs from node k8s-1 pod pod-ba4ed07f-0c21-47a7-a0e4-e284a01667ef container test-container: <nil>
STEP: delete the pod
Nov  4 17:36:52.191: INFO: Waiting for pod pod-ba4ed07f-0c21-47a7-a0e4-e284a01667ef to disappear
Nov  4 17:36:52.194: INFO: Pod pod-ba4ed07f-0c21-47a7-a0e4-e284a01667ef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:36:52.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2872" for this suite.
Nov  4 17:36:58.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:36:58.295: INFO: namespace emptydir-2872 deletion completed in 6.097402617s

â€¢ [SLOW TEST:8.276 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:36:58.296: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7254
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:36:58.812: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 17:37:00.820: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485818, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485818, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485818, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485818, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:37:03.833: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
Nov  4 17:37:03.866: INFO: Waiting for webhook configuration to be ready...
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:37:03.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7254" for this suite.
Nov  4 17:37:10.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:37:10.081: INFO: namespace webhook-7254 deletion completed in 6.086759443s
STEP: Destroying namespace "webhook-7254-markers" for this suite.
Nov  4 17:37:16.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:37:16.170: INFO: namespace webhook-7254-markers deletion completed in 6.088766004s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.888 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:37:16.184: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6900
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-38193429-c945-4c7d-a555-bfb09e51492a
STEP: Creating a pod to test consume secrets
Nov  4 17:37:16.331: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2bbcd7c7-ee75-4f10-914c-75e4d70d2b4f" in namespace "projected-6900" to be "success or failure"
Nov  4 17:37:16.334: INFO: Pod "pod-projected-secrets-2bbcd7c7-ee75-4f10-914c-75e4d70d2b4f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.024888ms
Nov  4 17:37:18.338: INFO: Pod "pod-projected-secrets-2bbcd7c7-ee75-4f10-914c-75e4d70d2b4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00645787s
STEP: Saw pod success
Nov  4 17:37:18.338: INFO: Pod "pod-projected-secrets-2bbcd7c7-ee75-4f10-914c-75e4d70d2b4f" satisfied condition "success or failure"
Nov  4 17:37:18.340: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-2bbcd7c7-ee75-4f10-914c-75e4d70d2b4f container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 17:37:18.363: INFO: Waiting for pod pod-projected-secrets-2bbcd7c7-ee75-4f10-914c-75e4d70d2b4f to disappear
Nov  4 17:37:18.367: INFO: Pod pod-projected-secrets-2bbcd7c7-ee75-4f10-914c-75e4d70d2b4f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:37:18.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6900" for this suite.
Nov  4 17:37:24.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:37:24.455: INFO: namespace projected-6900 deletion completed in 6.08455116s

â€¢ [SLOW TEST:8.270 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:37:24.455: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8095
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8095
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8095
STEP: creating replication controller externalsvc in namespace services-8095
I1104 17:37:24.622083      19 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8095, replica count: 2
I1104 17:37:27.672495      19 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Nov  4 17:37:27.725: INFO: Creating new exec pod
Nov  4 17:37:29.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-8095 execpodx5n48 -- /bin/sh -x -c nslookup nodeport-service'
Nov  4 17:37:30.085: INFO: stderr: "+ nslookup nodeport-service\n"
Nov  4 17:37:30.085: INFO: stdout: "Server:\t\t10.32.0.10\nAddress:\t10.32.0.10#53\n\nnodeport-service.services-8095.svc.cluster.local\tcanonical name = externalsvc.services-8095.svc.cluster.local.\nName:\texternalsvc.services-8095.svc.cluster.local\nAddress: 10.32.0.161\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8095, will wait for the garbage collector to delete the pods
Nov  4 17:37:30.147: INFO: Deleting ReplicationController externalsvc took: 8.482707ms
Nov  4 17:37:30.447: INFO: Terminating ReplicationController externalsvc pods took: 300.174042ms
Nov  4 17:37:33.875: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:37:33.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8095" for this suite.
Nov  4 17:37:39.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:37:39.983: INFO: namespace services-8095 deletion completed in 6.089627837s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:15.528 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:37:39.984: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-3808
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:37:40.124: INFO: Waiting up to 5m0s for pod "busybox-user-65534-67288936-a4b8-47ac-89d5-3f26c6782111" in namespace "security-context-test-3808" to be "success or failure"
Nov  4 17:37:40.128: INFO: Pod "busybox-user-65534-67288936-a4b8-47ac-89d5-3f26c6782111": Phase="Pending", Reason="", readiness=false. Elapsed: 4.365545ms
Nov  4 17:37:42.131: INFO: Pod "busybox-user-65534-67288936-a4b8-47ac-89d5-3f26c6782111": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007754601s
Nov  4 17:37:42.132: INFO: Pod "busybox-user-65534-67288936-a4b8-47ac-89d5-3f26c6782111" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:37:42.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3808" for this suite.
Nov  4 17:37:48.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:37:48.227: INFO: namespace security-context-test-3808 deletion completed in 6.091673221s

â€¢ [SLOW TEST:8.243 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:37:48.228: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8677
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-eb30bd21-11db-4b36-9b3e-243fd42e177d
STEP: Creating a pod to test consume secrets
Nov  4 17:37:48.372: INFO: Waiting up to 5m0s for pod "pod-secrets-011b9837-09a1-46e7-91ef-75bf2bd1a87f" in namespace "secrets-8677" to be "success or failure"
Nov  4 17:37:48.378: INFO: Pod "pod-secrets-011b9837-09a1-46e7-91ef-75bf2bd1a87f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.066676ms
Nov  4 17:37:50.381: INFO: Pod "pod-secrets-011b9837-09a1-46e7-91ef-75bf2bd1a87f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009239385s
STEP: Saw pod success
Nov  4 17:37:50.381: INFO: Pod "pod-secrets-011b9837-09a1-46e7-91ef-75bf2bd1a87f" satisfied condition "success or failure"
Nov  4 17:37:50.384: INFO: Trying to get logs from node k8s-1 pod pod-secrets-011b9837-09a1-46e7-91ef-75bf2bd1a87f container secret-env-test: <nil>
STEP: delete the pod
Nov  4 17:37:50.400: INFO: Waiting for pod pod-secrets-011b9837-09a1-46e7-91ef-75bf2bd1a87f to disappear
Nov  4 17:37:50.405: INFO: Pod pod-secrets-011b9837-09a1-46e7-91ef-75bf2bd1a87f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:37:50.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8677" for this suite.
Nov  4 17:37:56.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:37:56.495: INFO: namespace secrets-8677 deletion completed in 6.086806486s

â€¢ [SLOW TEST:8.267 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:37:56.495: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7901
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Nov  4 17:37:56.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-7901'
Nov  4 17:37:56.820: INFO: stderr: ""
Nov  4 17:37:56.820: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 17:37:56.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7901'
Nov  4 17:37:56.917: INFO: stderr: ""
Nov  4 17:37:56.917: INFO: stdout: "update-demo-nautilus-2f8ds update-demo-nautilus-v52zm "
Nov  4 17:37:56.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-2f8ds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7901'
Nov  4 17:37:56.994: INFO: stderr: ""
Nov  4 17:37:56.994: INFO: stdout: ""
Nov  4 17:37:56.994: INFO: update-demo-nautilus-2f8ds is created but not running
Nov  4 17:38:01.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7901'
Nov  4 17:38:02.079: INFO: stderr: ""
Nov  4 17:38:02.079: INFO: stdout: "update-demo-nautilus-2f8ds update-demo-nautilus-v52zm "
Nov  4 17:38:02.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-2f8ds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7901'
Nov  4 17:38:02.168: INFO: stderr: ""
Nov  4 17:38:02.168: INFO: stdout: "true"
Nov  4 17:38:02.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-2f8ds -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7901'
Nov  4 17:38:02.241: INFO: stderr: ""
Nov  4 17:38:02.241: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 17:38:02.241: INFO: validating pod update-demo-nautilus-2f8ds
Nov  4 17:38:02.245: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 17:38:02.245: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 17:38:02.245: INFO: update-demo-nautilus-2f8ds is verified up and running
Nov  4 17:38:02.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-v52zm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7901'
Nov  4 17:38:02.314: INFO: stderr: ""
Nov  4 17:38:02.314: INFO: stdout: "true"
Nov  4 17:38:02.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-v52zm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7901'
Nov  4 17:38:02.384: INFO: stderr: ""
Nov  4 17:38:02.384: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 17:38:02.384: INFO: validating pod update-demo-nautilus-v52zm
Nov  4 17:38:02.388: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 17:38:02.388: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 17:38:02.388: INFO: update-demo-nautilus-v52zm is verified up and running
STEP: scaling down the replication controller
Nov  4 17:38:02.389: INFO: scanned /root for discovery docs: <nil>
Nov  4 17:38:02.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7901'
Nov  4 17:38:03.492: INFO: stderr: ""
Nov  4 17:38:03.492: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 17:38:03.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7901'
Nov  4 17:38:03.566: INFO: stderr: ""
Nov  4 17:38:03.566: INFO: stdout: "update-demo-nautilus-2f8ds update-demo-nautilus-v52zm "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  4 17:38:08.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7901'
Nov  4 17:38:08.649: INFO: stderr: ""
Nov  4 17:38:08.649: INFO: stdout: "update-demo-nautilus-2f8ds "
Nov  4 17:38:08.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-2f8ds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7901'
Nov  4 17:38:08.723: INFO: stderr: ""
Nov  4 17:38:08.723: INFO: stdout: "true"
Nov  4 17:38:08.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-2f8ds -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7901'
Nov  4 17:38:08.794: INFO: stderr: ""
Nov  4 17:38:08.794: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 17:38:08.794: INFO: validating pod update-demo-nautilus-2f8ds
Nov  4 17:38:08.798: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 17:38:08.798: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 17:38:08.798: INFO: update-demo-nautilus-2f8ds is verified up and running
STEP: scaling up the replication controller
Nov  4 17:38:08.800: INFO: scanned /root for discovery docs: <nil>
Nov  4 17:38:08.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7901'
Nov  4 17:38:09.903: INFO: stderr: ""
Nov  4 17:38:09.903: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 17:38:09.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7901'
Nov  4 17:38:09.992: INFO: stderr: ""
Nov  4 17:38:09.992: INFO: stdout: "update-demo-nautilus-2f8ds update-demo-nautilus-jxgrs "
Nov  4 17:38:09.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-2f8ds -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7901'
Nov  4 17:38:10.067: INFO: stderr: ""
Nov  4 17:38:10.067: INFO: stdout: "true"
Nov  4 17:38:10.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-2f8ds -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7901'
Nov  4 17:38:10.136: INFO: stderr: ""
Nov  4 17:38:10.136: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 17:38:10.136: INFO: validating pod update-demo-nautilus-2f8ds
Nov  4 17:38:10.139: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 17:38:10.139: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 17:38:10.139: INFO: update-demo-nautilus-2f8ds is verified up and running
Nov  4 17:38:10.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-jxgrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7901'
Nov  4 17:38:10.208: INFO: stderr: ""
Nov  4 17:38:10.208: INFO: stdout: "true"
Nov  4 17:38:10.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-jxgrs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7901'
Nov  4 17:38:10.279: INFO: stderr: ""
Nov  4 17:38:10.280: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 17:38:10.280: INFO: validating pod update-demo-nautilus-jxgrs
Nov  4 17:38:10.284: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 17:38:10.284: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 17:38:10.284: INFO: update-demo-nautilus-jxgrs is verified up and running
STEP: using delete to clean up resources
Nov  4 17:38:10.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete --grace-period=0 --force -f - --namespace=kubectl-7901'
Nov  4 17:38:10.359: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 17:38:10.359: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  4 17:38:10.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7901'
Nov  4 17:38:10.446: INFO: stderr: "No resources found in kubectl-7901 namespace.\n"
Nov  4 17:38:10.446: INFO: stdout: ""
Nov  4 17:38:10.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -l name=update-demo --namespace=kubectl-7901 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 17:38:10.527: INFO: stderr: ""
Nov  4 17:38:10.527: INFO: stdout: "update-demo-nautilus-2f8ds\nupdate-demo-nautilus-jxgrs\n"
Nov  4 17:38:11.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7901'
Nov  4 17:38:11.109: INFO: stderr: "No resources found in kubectl-7901 namespace.\n"
Nov  4 17:38:11.109: INFO: stdout: ""
Nov  4 17:38:11.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -l name=update-demo --namespace=kubectl-7901 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 17:38:11.184: INFO: stderr: ""
Nov  4 17:38:11.184: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:38:11.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7901" for this suite.
Nov  4 17:38:23.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:38:23.272: INFO: namespace kubectl-7901 deletion completed in 12.084958521s

â€¢ [SLOW TEST:26.777 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:38:23.273: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6302
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:38:23.416: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4aaeea55-75fc-4bfd-a7dd-23cce438f96d" in namespace "downward-api-6302" to be "success or failure"
Nov  4 17:38:23.418: INFO: Pod "downwardapi-volume-4aaeea55-75fc-4bfd-a7dd-23cce438f96d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069208ms
Nov  4 17:38:25.421: INFO: Pod "downwardapi-volume-4aaeea55-75fc-4bfd-a7dd-23cce438f96d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005022276s
STEP: Saw pod success
Nov  4 17:38:25.422: INFO: Pod "downwardapi-volume-4aaeea55-75fc-4bfd-a7dd-23cce438f96d" satisfied condition "success or failure"
Nov  4 17:38:25.424: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-4aaeea55-75fc-4bfd-a7dd-23cce438f96d container client-container: <nil>
STEP: delete the pod
Nov  4 17:38:25.442: INFO: Waiting for pod downwardapi-volume-4aaeea55-75fc-4bfd-a7dd-23cce438f96d to disappear
Nov  4 17:38:25.446: INFO: Pod downwardapi-volume-4aaeea55-75fc-4bfd-a7dd-23cce438f96d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:38:25.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6302" for this suite.
Nov  4 17:38:31.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:38:31.532: INFO: namespace downward-api-6302 deletion completed in 6.082972338s

â€¢ [SLOW TEST:8.259 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:38:31.533: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2468
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-c596ae7a-8196-4293-938f-184909aead59 in namespace container-probe-2468
Nov  4 17:38:33.691: INFO: Started pod busybox-c596ae7a-8196-4293-938f-184909aead59 in namespace container-probe-2468
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 17:38:33.694: INFO: Initial restart count of pod busybox-c596ae7a-8196-4293-938f-184909aead59 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:42:34.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2468" for this suite.
Nov  4 17:42:40.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:42:40.179: INFO: namespace container-probe-2468 deletion completed in 6.094530007s

â€¢ [SLOW TEST:248.646 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:42:40.180: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8951
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:42:40.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-8951'
Nov  4 17:42:40.565: INFO: stderr: ""
Nov  4 17:42:40.565: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov  4 17:42:40.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-8951'
Nov  4 17:42:40.801: INFO: stderr: ""
Nov  4 17:42:40.801: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  4 17:42:41.804: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 17:42:41.804: INFO: Found 0 / 1
Nov  4 17:42:42.804: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 17:42:42.804: INFO: Found 0 / 1
Nov  4 17:42:43.804: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 17:42:43.804: INFO: Found 1 / 1
Nov  4 17:42:43.804: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  4 17:42:43.807: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 17:42:43.807: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  4 17:42:43.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 describe pod redis-master-k7skc --namespace=kubectl-8951'
Nov  4 17:42:43.892: INFO: stderr: ""
Nov  4 17:42:43.892: INFO: stdout: "Name:         redis-master-k7skc\nNamespace:    kubectl-8951\nPriority:     0\nNode:         k8s-1/10.20.20.4\nStart Time:   Mon, 04 Nov 2019 17:42:40 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.33.0.108\nIPs:\n  IP:           10.33.0.108\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://0f0eea2d171143e9de1049b45bebcb79b4404c9bea484e0d95f60c011a22baf3\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 04 Nov 2019 17:42:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-sw7pn (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-sw7pn:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-sw7pn\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From               Message\n  ----    ------     ----       ----               -------\n  Normal  Scheduled  <unknown>  default-scheduler  Successfully assigned kubectl-8951/redis-master-k7skc to k8s-1\n  Normal  Pulled     2s         kubelet, k8s-1     Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s         kubelet, k8s-1     Created container redis-master\n  Normal  Started    1s         kubelet, k8s-1     Started container redis-master\n"
Nov  4 17:42:43.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 describe rc redis-master --namespace=kubectl-8951'
Nov  4 17:42:43.983: INFO: stderr: ""
Nov  4 17:42:43.984: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8951\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-k7skc\n"
Nov  4 17:42:43.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 describe service redis-master --namespace=kubectl-8951'
Nov  4 17:42:44.071: INFO: stderr: ""
Nov  4 17:42:44.071: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8951\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.32.0.44\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.33.0.108:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov  4 17:42:44.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 describe node k8s-1'
Nov  4 17:42:44.169: INFO: stderr: ""
Nov  4 17:42:44.169: INFO: stdout: "Name:               k8s-1\nRoles:              worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=k8s-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/worker=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"4a:3d:6a:c4:36:f1\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.20.20.4\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 04 Nov 2019 16:56:49 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 04 Nov 2019 17:42:21 +0000   Mon, 04 Nov 2019 16:56:49 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 04 Nov 2019 17:42:21 +0000   Mon, 04 Nov 2019 16:56:49 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 04 Nov 2019 17:42:21 +0000   Mon, 04 Nov 2019 16:56:49 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 04 Nov 2019 17:42:21 +0000   Mon, 04 Nov 2019 16:56:49 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.20.20.4\n  Hostname:    k8s-1\nCapacity:\n cpu:                1\n ephemeral-storage:  50633164Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3941368Ki\n pods:               110\nAllocatable:\n cpu:                1\n ephemeral-storage:  46663523866\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3838968Ki\n pods:               110\nSystem Info:\n Machine ID:                 cc2068ba24d3480bbedd969acc9f4cd8\n System UUID:                CC2068BA-24D3-480B-BEDD-969ACC9F4CD8\n Boot ID:                    49488a96-40a0-4884-bcc5-bf7c84299649\n Kernel Version:             4.15.0-38-generic\n OS Image:                   Ubuntu 18.04.1 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.10\n Kubelet Version:            v1.16.2\n Kube-Proxy Version:         v1.16.2\nPodCIDR:                     10.33.0.0/24\nPodCIDRs:                    10.33.0.0/24\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                kube-flannel-ds-amd64-bls8m                                100m (10%)    100m (10%)  50Mi (1%)        50Mi (1%)      18m\n  kube-system                traefik-ingress-controller-mccsj                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         18m\n  kubectl-8951               redis-master-k7skc                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-23fc508521714957-lpskk    0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                100m (10%)  100m (10%)\n  memory             50Mi (1%)   50Mi (1%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age   From               Message\n  ----     ------                   ----  ----               -------\n  Normal   Starting                 45m   kubelet, k8s-1     Starting kubelet.\n  Warning  InvalidDiskCapacity      45m   kubelet, k8s-1     invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  45m   kubelet, k8s-1     Node k8s-1 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    45m   kubelet, k8s-1     Node k8s-1 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     45m   kubelet, k8s-1     Node k8s-1 status is now: NodeHasSufficientPID\n  Normal   Starting                 45m   kube-proxy, k8s-1  Starting kube-proxy.\n  Normal   NodeAllocatableEnforced  45m   kubelet, k8s-1     Updated Node Allocatable limit across pods\n  Normal   NodeReady                45m   kubelet, k8s-1     Node k8s-1 status is now: NodeReady\n"
Nov  4 17:42:44.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 describe namespace kubectl-8951'
Nov  4 17:42:44.247: INFO: stderr: ""
Nov  4 17:42:44.247: INFO: stdout: "Name:         kubectl-8951\nLabels:       e2e-framework=kubectl\n              e2e-run=a5f2f8f2-2f36-4d74-b0f3-69aef67339f0\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:42:44.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8951" for this suite.
Nov  4 17:43:12.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:43:12.340: INFO: namespace kubectl-8951 deletion completed in 28.089395225s

â€¢ [SLOW TEST:32.161 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:43:12.341: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6889
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:43:12.477: INFO: Creating deployment "test-recreate-deployment"
Nov  4 17:43:12.482: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov  4 17:43:12.490: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov  4 17:43:14.495: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov  4 17:43:14.498: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov  4 17:43:14.504: INFO: Updating deployment test-recreate-deployment
Nov  4 17:43:14.504: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 17:43:14.607: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-6889 /apis/apps/v1/namespaces/deployment-6889/deployments/test-recreate-deployment d29f5283-4f04-43a0-9397-93d3160c5848 10799 2 2019-11-04 17:43:12 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006971bc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-11-04 17:43:14 +0000 UTC,LastTransitionTime:2019-11-04 17:43:14 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-11-04 17:43:14 +0000 UTC,LastTransitionTime:2019-11-04 17:43:12 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov  4 17:43:14.613: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-6889 /apis/apps/v1/namespaces/deployment-6889/replicasets/test-recreate-deployment-5f94c574ff 5c19a06f-47fb-4a5c-9d5a-e06df1f5e494 10796 1 2019-11-04 17:43:14 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment d29f5283-4f04-43a0-9397-93d3160c5848 0xc006971fa7 0xc006971fa8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0037d2008 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:43:14.613: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov  4 17:43:14.613: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-6889 /apis/apps/v1/namespaces/deployment-6889/replicasets/test-recreate-deployment-68fc85c7bb 0832c443-7996-47dd-867d-d0e5274c2ce7 10788 2 2019-11-04 17:43:12 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment d29f5283-4f04-43a0-9397-93d3160c5848 0xc0037d2077 0xc0037d2078}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0037d20d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:43:14.616: INFO: Pod "test-recreate-deployment-5f94c574ff-fkm98" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-fkm98 test-recreate-deployment-5f94c574ff- deployment-6889 /api/v1/namespaces/deployment-6889/pods/test-recreate-deployment-5f94c574ff-fkm98 499a9531-1e44-471a-bcdc-430a18ed14bd 10800 0 2019-11-04 17:43:14 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 5c19a06f-47fb-4a5c-9d5a-e06df1f5e494 0xc0037d2577 0xc0037d2578}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qdvnl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qdvnl,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qdvnl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:43:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:43:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:43:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:43:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 17:43:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:43:14.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6889" for this suite.
Nov  4 17:43:20.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:43:20.713: INFO: namespace deployment-6889 deletion completed in 6.094103298s

â€¢ [SLOW TEST:8.373 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:43:20.715: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9339
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-84061580-b2ba-4279-a832-fcc85132ed2c
STEP: Creating a pod to test consume secrets
Nov  4 17:43:20.863: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-19253235-0fae-4b95-ad9b-70167626c21e" in namespace "projected-9339" to be "success or failure"
Nov  4 17:43:20.866: INFO: Pod "pod-projected-secrets-19253235-0fae-4b95-ad9b-70167626c21e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.328903ms
Nov  4 17:43:22.869: INFO: Pod "pod-projected-secrets-19253235-0fae-4b95-ad9b-70167626c21e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006288389s
STEP: Saw pod success
Nov  4 17:43:22.869: INFO: Pod "pod-projected-secrets-19253235-0fae-4b95-ad9b-70167626c21e" satisfied condition "success or failure"
Nov  4 17:43:22.872: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-19253235-0fae-4b95-ad9b-70167626c21e container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 17:43:22.897: INFO: Waiting for pod pod-projected-secrets-19253235-0fae-4b95-ad9b-70167626c21e to disappear
Nov  4 17:43:22.900: INFO: Pod pod-projected-secrets-19253235-0fae-4b95-ad9b-70167626c21e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:43:22.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9339" for this suite.
Nov  4 17:43:28.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:43:28.997: INFO: namespace projected-9339 deletion completed in 6.09391858s

â€¢ [SLOW TEST:8.282 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:43:28.997: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-718
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-c9ea8128-596e-4287-b973-38ae20a9341e
STEP: Creating secret with name secret-projected-all-test-volume-b3d42eb9-c324-4ba9-a5b9-3d358f4f2636
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov  4 17:43:29.147: INFO: Waiting up to 5m0s for pod "projected-volume-3ed4b862-0172-4c54-bbb7-4783afd424d8" in namespace "projected-718" to be "success or failure"
Nov  4 17:43:29.153: INFO: Pod "projected-volume-3ed4b862-0172-4c54-bbb7-4783afd424d8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.681591ms
Nov  4 17:43:31.155: INFO: Pod "projected-volume-3ed4b862-0172-4c54-bbb7-4783afd424d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008422694s
STEP: Saw pod success
Nov  4 17:43:31.156: INFO: Pod "projected-volume-3ed4b862-0172-4c54-bbb7-4783afd424d8" satisfied condition "success or failure"
Nov  4 17:43:31.158: INFO: Trying to get logs from node k8s-1 pod projected-volume-3ed4b862-0172-4c54-bbb7-4783afd424d8 container projected-all-volume-test: <nil>
STEP: delete the pod
Nov  4 17:43:31.175: INFO: Waiting for pod projected-volume-3ed4b862-0172-4c54-bbb7-4783afd424d8 to disappear
Nov  4 17:43:31.180: INFO: Pod projected-volume-3ed4b862-0172-4c54-bbb7-4783afd424d8 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:43:31.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-718" for this suite.
Nov  4 17:43:37.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:43:37.272: INFO: namespace projected-718 deletion completed in 6.089091057s

â€¢ [SLOW TEST:8.275 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:43:37.272: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5545
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:43:38.046: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 17:43:40.053: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486218, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486218, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486218, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486218, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:43:43.065: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:43:43.068: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2390-crds.webhook.example.com via the AdmissionRegistration API
Nov  4 17:43:48.150: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:43:49.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5545" for this suite.
Nov  4 17:43:55.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:43:55.819: INFO: namespace webhook-5545 deletion completed in 6.095494505s
STEP: Destroying namespace "webhook-5545-markers" for this suite.
Nov  4 17:44:01.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:44:01.904: INFO: namespace webhook-5545-markers deletion completed in 6.085254786s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:24.646 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:44:01.919: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-6399
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Nov  4 17:44:06.575: INFO: Successfully updated pod "adopt-release-j8zrq"
STEP: Checking that the Job readopts the Pod
Nov  4 17:44:06.575: INFO: Waiting up to 15m0s for pod "adopt-release-j8zrq" in namespace "job-6399" to be "adopted"
Nov  4 17:44:06.577: INFO: Pod "adopt-release-j8zrq": Phase="Running", Reason="", readiness=true. Elapsed: 2.732405ms
Nov  4 17:44:08.581: INFO: Pod "adopt-release-j8zrq": Phase="Running", Reason="", readiness=true. Elapsed: 2.005959589s
Nov  4 17:44:08.581: INFO: Pod "adopt-release-j8zrq" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Nov  4 17:44:09.088: INFO: Successfully updated pod "adopt-release-j8zrq"
STEP: Checking that the Job releases the Pod
Nov  4 17:44:09.088: INFO: Waiting up to 15m0s for pod "adopt-release-j8zrq" in namespace "job-6399" to be "released"
Nov  4 17:44:09.092: INFO: Pod "adopt-release-j8zrq": Phase="Running", Reason="", readiness=true. Elapsed: 4.417142ms
Nov  4 17:44:11.096: INFO: Pod "adopt-release-j8zrq": Phase="Running", Reason="", readiness=true. Elapsed: 2.008121448s
Nov  4 17:44:11.096: INFO: Pod "adopt-release-j8zrq" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:44:11.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6399" for this suite.
Nov  4 17:44:55.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:44:55.186: INFO: namespace job-6399 deletion completed in 44.086727718s

â€¢ [SLOW TEST:53.267 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:44:55.187: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4715
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-da71292e-0c2b-4680-b09a-a724e7133944
STEP: Creating a pod to test consume configMaps
Nov  4 17:44:55.337: INFO: Waiting up to 5m0s for pod "pod-configmaps-1d818842-3292-4de5-96ef-ac10a4d0c12a" in namespace "configmap-4715" to be "success or failure"
Nov  4 17:44:55.345: INFO: Pod "pod-configmaps-1d818842-3292-4de5-96ef-ac10a4d0c12a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.423686ms
Nov  4 17:44:57.348: INFO: Pod "pod-configmaps-1d818842-3292-4de5-96ef-ac10a4d0c12a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011067313s
STEP: Saw pod success
Nov  4 17:44:57.348: INFO: Pod "pod-configmaps-1d818842-3292-4de5-96ef-ac10a4d0c12a" satisfied condition "success or failure"
Nov  4 17:44:57.350: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-1d818842-3292-4de5-96ef-ac10a4d0c12a container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 17:44:57.376: INFO: Waiting for pod pod-configmaps-1d818842-3292-4de5-96ef-ac10a4d0c12a to disappear
Nov  4 17:44:57.378: INFO: Pod pod-configmaps-1d818842-3292-4de5-96ef-ac10a4d0c12a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:44:57.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4715" for this suite.
Nov  4 17:45:03.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:45:03.472: INFO: namespace configmap-4715 deletion completed in 6.090696074s

â€¢ [SLOW TEST:8.285 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:45:03.472: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7521
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 17:45:03.607: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:45:05.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7521" for this suite.
Nov  4 17:45:11.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:45:11.412: INFO: namespace init-container-7521 deletion completed in 6.107544626s

â€¢ [SLOW TEST:7.939 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:45:11.412: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4304
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1104 17:45:51.576101      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 17:45:51.576: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:45:51.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4304" for this suite.
Nov  4 17:45:57.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:45:57.674: INFO: namespace gc-4304 deletion completed in 6.094276064s

â€¢ [SLOW TEST:46.261 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:45:57.674: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4074
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-430
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5973
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:46:04.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4074" for this suite.
Nov  4 17:46:10.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:46:10.207: INFO: namespace namespaces-4074 deletion completed in 6.089065199s
STEP: Destroying namespace "nsdeletetest-430" for this suite.
Nov  4 17:46:10.210: INFO: Namespace nsdeletetest-430 was already deleted
STEP: Destroying namespace "nsdeletetest-5973" for this suite.
Nov  4 17:46:16.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:46:16.293: INFO: namespace nsdeletetest-5973 deletion completed in 6.083365262s

â€¢ [SLOW TEST:18.619 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:46:16.295: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3005
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:46:16.437: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b94ed32-ce55-48fa-8e14-cb2daead9574" in namespace "projected-3005" to be "success or failure"
Nov  4 17:46:16.440: INFO: Pod "downwardapi-volume-1b94ed32-ce55-48fa-8e14-cb2daead9574": Phase="Pending", Reason="", readiness=false. Elapsed: 2.948765ms
Nov  4 17:46:18.444: INFO: Pod "downwardapi-volume-1b94ed32-ce55-48fa-8e14-cb2daead9574": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006413951s
STEP: Saw pod success
Nov  4 17:46:18.444: INFO: Pod "downwardapi-volume-1b94ed32-ce55-48fa-8e14-cb2daead9574" satisfied condition "success or failure"
Nov  4 17:46:18.446: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-1b94ed32-ce55-48fa-8e14-cb2daead9574 container client-container: <nil>
STEP: delete the pod
Nov  4 17:46:18.471: INFO: Waiting for pod downwardapi-volume-1b94ed32-ce55-48fa-8e14-cb2daead9574 to disappear
Nov  4 17:46:18.478: INFO: Pod downwardapi-volume-1b94ed32-ce55-48fa-8e14-cb2daead9574 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:46:18.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3005" for this suite.
Nov  4 17:46:24.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:46:24.572: INFO: namespace projected-3005 deletion completed in 6.090802488s

â€¢ [SLOW TEST:8.278 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:46:24.573: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8564
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 17:46:24.710: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 17:46:24.719: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 17:46:24.722: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Nov  4 17:46:24.726: INFO: kube-flannel-ds-amd64-bls8m from kube-system started at 2019-11-04 17:23:59 +0000 UTC (1 container statuses recorded)
Nov  4 17:46:24.726: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 17:46:24.726: INFO: traefik-ingress-controller-mccsj from kube-system started at 2019-11-04 17:23:59 +0000 UTC (1 container statuses recorded)
Nov  4 17:46:24.726: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 17:46:24.726: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-lpskk from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 17:46:24.726: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:46:24.726: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 17:46:24.726: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Nov  4 17:46:24.739: INFO: sonobuoy-e2e-job-281da138127b42b3 from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 17:46:24.739: INFO: 	Container e2e ready: true, restart count 0
Nov  4 17:46:24.739: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:46:24.739: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-k67sr from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 17:46:24.739: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:46:24.740: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 17:46:24.740: INFO: coredns-b7f8c8654-4rcsc from kube-system started at 2019-11-04 17:23:27 +0000 UTC (1 container statuses recorded)
Nov  4 17:46:24.740: INFO: 	Container coredns ready: true, restart count 0
Nov  4 17:46:24.740: INFO: kube-flannel-ds-amd64-c6xnw from kube-system started at 2019-11-04 16:58:52 +0000 UTC (1 container statuses recorded)
Nov  4 17:46:24.740: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 17:46:24.740: INFO: traefik-ingress-controller-qqfzz from kube-system started at 2019-11-04 16:58:54 +0000 UTC (1 container statuses recorded)
Nov  4 17:46:24.740: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 17:46:24.740: INFO: sonobuoy from sonobuoy started at 2019-11-04 16:59:51 +0000 UTC (1 container statuses recorded)
Nov  4 17:46:24.740: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 17:46:24.740: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Nov  4 17:46:24.755: INFO: traefik-ingress-controller-98f8s from kube-system started at 2019-11-04 17:13:49 +0000 UTC (1 container statuses recorded)
Nov  4 17:46:24.755: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 17:46:24.755: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-vkd6f from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 17:46:24.755: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:46:24.755: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 17:46:24.755: INFO: coredns-b7f8c8654-68j25 from kube-system started at 2019-11-04 17:13:42 +0000 UTC (1 container statuses recorded)
Nov  4 17:46:24.755: INFO: 	Container coredns ready: true, restart count 0
Nov  4 17:46:24.755: INFO: kube-flannel-ds-amd64-s2gr4 from kube-system started at 2019-11-04 17:14:19 +0000 UTC (1 container statuses recorded)
Nov  4 17:46:24.755: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-2901f3fc-1828-4675-8912-5ae8291d6904 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-2901f3fc-1828-4675-8912-5ae8291d6904 off the node k8s-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-2901f3fc-1828-4675-8912-5ae8291d6904
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:51:28.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8564" for this suite.
Nov  4 17:51:36.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:51:36.948: INFO: namespace sched-pred-8564 deletion completed in 8.086232119s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:312.375 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:51:36.949: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-47
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:51:44.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-47" for this suite.
Nov  4 17:51:50.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:51:50.190: INFO: namespace resourcequota-47 deletion completed in 6.090491572s

â€¢ [SLOW TEST:13.242 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:51:50.192: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-830
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:51:50.327: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:52:51.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-830" for this suite.
Nov  4 17:52:57.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:52:57.567: INFO: namespace custom-resource-definition-830 deletion completed in 6.089658256s

â€¢ [SLOW TEST:67.376 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:52:57.568: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:52:57.704: INFO: Creating ReplicaSet my-hostname-basic-e9041c60-a38e-451b-adce-3e00faeebf9c
Nov  4 17:52:57.712: INFO: Pod name my-hostname-basic-e9041c60-a38e-451b-adce-3e00faeebf9c: Found 0 pods out of 1
Nov  4 17:53:02.715: INFO: Pod name my-hostname-basic-e9041c60-a38e-451b-adce-3e00faeebf9c: Found 1 pods out of 1
Nov  4 17:53:02.716: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e9041c60-a38e-451b-adce-3e00faeebf9c" is running
Nov  4 17:53:02.718: INFO: Pod "my-hostname-basic-e9041c60-a38e-451b-adce-3e00faeebf9c-dpqhr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 17:52:57 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 17:52:59 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 17:52:59 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 17:52:57 +0000 UTC Reason: Message:}])
Nov  4 17:53:02.718: INFO: Trying to dial the pod
Nov  4 17:53:07.728: INFO: Controller my-hostname-basic-e9041c60-a38e-451b-adce-3e00faeebf9c: Got expected result from replica 1 [my-hostname-basic-e9041c60-a38e-451b-adce-3e00faeebf9c-dpqhr]: "my-hostname-basic-e9041c60-a38e-451b-adce-3e00faeebf9c-dpqhr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:53:07.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5576" for this suite.
Nov  4 17:53:13.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:53:13.831: INFO: namespace replicaset-5576 deletion completed in 6.099638643s

â€¢ [SLOW TEST:16.263 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:53:13.832: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6223
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  4 17:53:18.012: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 17:53:18.017: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 17:53:20.017: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 17:53:20.020: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 17:53:22.017: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 17:53:22.021: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 17:53:24.017: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 17:53:24.021: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 17:53:26.017: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 17:53:26.021: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 17:53:28.017: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 17:53:28.020: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 17:53:30.017: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 17:53:30.020: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:53:30.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6223" for this suite.
Nov  4 17:53:42.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:53:42.140: INFO: namespace container-lifecycle-hook-6223 deletion completed in 12.101905341s

â€¢ [SLOW TEST:28.308 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:53:42.141: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6129
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-9ed0cdfa-7e62-4f98-b7f9-e7223088853d
STEP: Creating a pod to test consume secrets
Nov  4 17:53:42.290: INFO: Waiting up to 5m0s for pod "pod-secrets-e9910c17-9c96-4631-baae-ab9f35718842" in namespace "secrets-6129" to be "success or failure"
Nov  4 17:53:42.293: INFO: Pod "pod-secrets-e9910c17-9c96-4631-baae-ab9f35718842": Phase="Pending", Reason="", readiness=false. Elapsed: 3.824866ms
Nov  4 17:53:44.297: INFO: Pod "pod-secrets-e9910c17-9c96-4631-baae-ab9f35718842": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006901536s
STEP: Saw pod success
Nov  4 17:53:44.297: INFO: Pod "pod-secrets-e9910c17-9c96-4631-baae-ab9f35718842" satisfied condition "success or failure"
Nov  4 17:53:44.299: INFO: Trying to get logs from node k8s-1 pod pod-secrets-e9910c17-9c96-4631-baae-ab9f35718842 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 17:53:44.320: INFO: Waiting for pod pod-secrets-e9910c17-9c96-4631-baae-ab9f35718842 to disappear
Nov  4 17:53:44.327: INFO: Pod pod-secrets-e9910c17-9c96-4631-baae-ab9f35718842 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:53:44.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6129" for this suite.
Nov  4 17:53:50.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:53:50.415: INFO: namespace secrets-6129 deletion completed in 6.084734335s

â€¢ [SLOW TEST:8.274 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:53:50.416: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9609
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 17:53:53.083: INFO: Successfully updated pod "annotationupdate55cf6846-de4e-4341-92fc-22acea8f2c08"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:53:57.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9609" for this suite.
Nov  4 17:54:09.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:54:09.190: INFO: namespace projected-9609 deletion completed in 12.085837547s

â€¢ [SLOW TEST:18.774 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:54:09.191: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2980
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:54:09.331: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-69f00cb7-8809-462a-88d4-f252a9f44a25" in namespace "security-context-test-2980" to be "success or failure"
Nov  4 17:54:09.335: INFO: Pod "busybox-privileged-false-69f00cb7-8809-462a-88d4-f252a9f44a25": Phase="Pending", Reason="", readiness=false. Elapsed: 3.830849ms
Nov  4 17:54:11.338: INFO: Pod "busybox-privileged-false-69f00cb7-8809-462a-88d4-f252a9f44a25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006828948s
Nov  4 17:54:11.338: INFO: Pod "busybox-privileged-false-69f00cb7-8809-462a-88d4-f252a9f44a25" satisfied condition "success or failure"
Nov  4 17:54:11.344: INFO: Got logs for pod "busybox-privileged-false-69f00cb7-8809-462a-88d4-f252a9f44a25": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:54:11.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2980" for this suite.
Nov  4 17:54:17.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:54:17.440: INFO: namespace security-context-test-2980 deletion completed in 6.092374579s

â€¢ [SLOW TEST:8.249 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:54:17.440: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9676
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Nov  4 17:54:17.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 cluster-info'
Nov  4 17:54:17.752: INFO: stderr: ""
Nov  4 17:54:17.752: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:54:17.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9676" for this suite.
Nov  4 17:54:23.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:54:23.853: INFO: namespace kubectl-9676 deletion completed in 6.097764727s

â€¢ [SLOW TEST:6.413 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:54:23.853: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1506
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-0798a3cc-a166-4878-9ef8-435d9fce10f7 in namespace container-probe-1506
Nov  4 17:54:26.000: INFO: Started pod busybox-0798a3cc-a166-4878-9ef8-435d9fce10f7 in namespace container-probe-1506
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 17:54:26.003: INFO: Initial restart count of pod busybox-0798a3cc-a166-4878-9ef8-435d9fce10f7 is 0
Nov  4 17:55:12.082: INFO: Restart count of pod container-probe-1506/busybox-0798a3cc-a166-4878-9ef8-435d9fce10f7 is now 1 (46.078696004s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:55:12.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1506" for this suite.
Nov  4 17:55:18.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:55:18.204: INFO: namespace container-probe-1506 deletion completed in 6.102713014s

â€¢ [SLOW TEST:54.351 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:55:18.205: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7994
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov  4 17:55:18.350: INFO: Pod name pod-release: Found 0 pods out of 1
Nov  4 17:55:23.353: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:55:24.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7994" for this suite.
Nov  4 17:55:30.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:55:30.457: INFO: namespace replication-controller-7994 deletion completed in 6.087957424s

â€¢ [SLOW TEST:12.252 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:55:30.458: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6825
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-6e990681-dad7-4c89-922a-38d34fb3df53 in namespace container-probe-6825
Nov  4 17:55:32.611: INFO: Started pod liveness-6e990681-dad7-4c89-922a-38d34fb3df53 in namespace container-probe-6825
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 17:55:32.613: INFO: Initial restart count of pod liveness-6e990681-dad7-4c89-922a-38d34fb3df53 is 0
Nov  4 17:55:46.636: INFO: Restart count of pod container-probe-6825/liveness-6e990681-dad7-4c89-922a-38d34fb3df53 is now 1 (14.023077058s elapsed)
Nov  4 17:56:06.666: INFO: Restart count of pod container-probe-6825/liveness-6e990681-dad7-4c89-922a-38d34fb3df53 is now 2 (34.05253237s elapsed)
Nov  4 17:56:26.697: INFO: Restart count of pod container-probe-6825/liveness-6e990681-dad7-4c89-922a-38d34fb3df53 is now 3 (54.083992969s elapsed)
Nov  4 17:56:46.735: INFO: Restart count of pod container-probe-6825/liveness-6e990681-dad7-4c89-922a-38d34fb3df53 is now 4 (1m14.121898084s elapsed)
Nov  4 17:58:00.845: INFO: Restart count of pod container-probe-6825/liveness-6e990681-dad7-4c89-922a-38d34fb3df53 is now 5 (2m28.231724026s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:58:00.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6825" for this suite.
Nov  4 17:58:06.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:58:06.962: INFO: namespace container-probe-6825 deletion completed in 6.092743372s

â€¢ [SLOW TEST:156.505 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:58:06.963: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8199
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:58:10.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8199" for this suite.
Nov  4 17:58:22.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:58:22.235: INFO: namespace replication-controller-8199 deletion completed in 12.101122713s

â€¢ [SLOW TEST:15.273 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:58:22.236: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-6267
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Nov  4 17:58:22.380: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-6267" to be "success or failure"
Nov  4 17:58:22.385: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.244848ms
Nov  4 17:58:24.388: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008345123s
STEP: Saw pod success
Nov  4 17:58:24.388: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov  4 17:58:24.390: INFO: Trying to get logs from node k8s-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov  4 17:58:24.415: INFO: Waiting for pod pod-host-path-test to disappear
Nov  4 17:58:24.423: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:58:24.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-6267" for this suite.
Nov  4 17:58:30.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:58:30.516: INFO: namespace hostpath-6267 deletion completed in 6.089482815s

â€¢ [SLOW TEST:8.279 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:58:30.516: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6817
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-f062d713-8cd2-496e-8586-16abfabb82ac
STEP: Creating a pod to test consume secrets
Nov  4 17:58:30.664: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-62ab9f1c-c5e6-417c-aef8-fc9958c31d7e" in namespace "projected-6817" to be "success or failure"
Nov  4 17:58:30.678: INFO: Pod "pod-projected-secrets-62ab9f1c-c5e6-417c-aef8-fc9958c31d7e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.218819ms
Nov  4 17:58:32.681: INFO: Pod "pod-projected-secrets-62ab9f1c-c5e6-417c-aef8-fc9958c31d7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017173828s
STEP: Saw pod success
Nov  4 17:58:32.681: INFO: Pod "pod-projected-secrets-62ab9f1c-c5e6-417c-aef8-fc9958c31d7e" satisfied condition "success or failure"
Nov  4 17:58:32.683: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-62ab9f1c-c5e6-417c-aef8-fc9958c31d7e container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 17:58:32.701: INFO: Waiting for pod pod-projected-secrets-62ab9f1c-c5e6-417c-aef8-fc9958c31d7e to disappear
Nov  4 17:58:32.707: INFO: Pod pod-projected-secrets-62ab9f1c-c5e6-417c-aef8-fc9958c31d7e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:58:32.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6817" for this suite.
Nov  4 17:58:38.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:58:38.801: INFO: namespace projected-6817 deletion completed in 6.090321717s

â€¢ [SLOW TEST:8.285 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:58:38.801: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5057
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  4 17:58:38.942: INFO: Waiting up to 5m0s for pod "pod-f200e3d5-8552-4a14-9d6b-8c2647e73f28" in namespace "emptydir-5057" to be "success or failure"
Nov  4 17:58:38.955: INFO: Pod "pod-f200e3d5-8552-4a14-9d6b-8c2647e73f28": Phase="Pending", Reason="", readiness=false. Elapsed: 13.414282ms
Nov  4 17:58:40.958: INFO: Pod "pod-f200e3d5-8552-4a14-9d6b-8c2647e73f28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016094061s
STEP: Saw pod success
Nov  4 17:58:40.958: INFO: Pod "pod-f200e3d5-8552-4a14-9d6b-8c2647e73f28" satisfied condition "success or failure"
Nov  4 17:58:40.961: INFO: Trying to get logs from node k8s-1 pod pod-f200e3d5-8552-4a14-9d6b-8c2647e73f28 container test-container: <nil>
STEP: delete the pod
Nov  4 17:58:40.984: INFO: Waiting for pod pod-f200e3d5-8552-4a14-9d6b-8c2647e73f28 to disappear
Nov  4 17:58:40.992: INFO: Pod pod-f200e3d5-8552-4a14-9d6b-8c2647e73f28 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:58:40.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5057" for this suite.
Nov  4 17:58:47.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:58:47.077: INFO: namespace emptydir-5057 deletion completed in 6.081578303s

â€¢ [SLOW TEST:8.276 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:58:47.078: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-3829
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:58:47.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-3829" for this suite.
Nov  4 17:58:53.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:58:53.306: INFO: namespace tables-3829 deletion completed in 6.088606887s

â€¢ [SLOW TEST:6.228 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:58:53.307: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1398
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:58:53.481: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b4b2ea05-be8d-487f-a3d3-328b00e57bca", Controller:(*bool)(0xc00193c2e6), BlockOwnerDeletion:(*bool)(0xc00193c2e7)}}
Nov  4 17:58:53.485: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"89d058c2-1b76-475d-b0a4-c3b30756af4e", Controller:(*bool)(0xc00193c4c6), BlockOwnerDeletion:(*bool)(0xc00193c4c7)}}
Nov  4 17:58:53.489: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"8c3f0cc9-e9c2-4901-a4ab-3cb296515205", Controller:(*bool)(0xc00193c696), BlockOwnerDeletion:(*bool)(0xc00193c697)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:58:58.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1398" for this suite.
Nov  4 17:59:04.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:59:04.598: INFO: namespace gc-1398 deletion completed in 6.094628675s

â€¢ [SLOW TEST:11.291 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:59:04.599: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5814
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 17:59:04.742: INFO: Waiting up to 5m0s for pod "downward-api-58721aac-8bfd-4a00-8c9e-9553df70f2ff" in namespace "downward-api-5814" to be "success or failure"
Nov  4 17:59:04.745: INFO: Pod "downward-api-58721aac-8bfd-4a00-8c9e-9553df70f2ff": Phase="Pending", Reason="", readiness=false. Elapsed: 3.442952ms
Nov  4 17:59:06.748: INFO: Pod "downward-api-58721aac-8bfd-4a00-8c9e-9553df70f2ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006637423s
STEP: Saw pod success
Nov  4 17:59:06.748: INFO: Pod "downward-api-58721aac-8bfd-4a00-8c9e-9553df70f2ff" satisfied condition "success or failure"
Nov  4 17:59:06.751: INFO: Trying to get logs from node k8s-1 pod downward-api-58721aac-8bfd-4a00-8c9e-9553df70f2ff container dapi-container: <nil>
STEP: delete the pod
Nov  4 17:59:06.774: INFO: Waiting for pod downward-api-58721aac-8bfd-4a00-8c9e-9553df70f2ff to disappear
Nov  4 17:59:06.777: INFO: Pod downward-api-58721aac-8bfd-4a00-8c9e-9553df70f2ff no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:59:06.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5814" for this suite.
Nov  4 17:59:12.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:59:12.867: INFO: namespace downward-api-5814 deletion completed in 6.086229647s

â€¢ [SLOW TEST:8.268 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:59:12.867: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5683
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 17:59:13.002: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:59:16.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5683" for this suite.
Nov  4 17:59:22.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:59:22.463: INFO: namespace init-container-5683 deletion completed in 6.085356374s

â€¢ [SLOW TEST:9.596 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:59:22.464: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Nov  4 17:59:22.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-616'
Nov  4 17:59:22.809: INFO: stderr: ""
Nov  4 17:59:22.809: INFO: stdout: "pod/pause created\n"
Nov  4 17:59:22.809: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov  4 17:59:22.809: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-616" to be "running and ready"
Nov  4 17:59:22.812: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.625413ms
Nov  4 17:59:24.814: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.005349581s
Nov  4 17:59:24.814: INFO: Pod "pause" satisfied condition "running and ready"
Nov  4 17:59:24.814: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Nov  4 17:59:24.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 label pods pause testing-label=testing-label-value --namespace=kubectl-616'
Nov  4 17:59:24.899: INFO: stderr: ""
Nov  4 17:59:24.899: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov  4 17:59:24.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pod pause -L testing-label --namespace=kubectl-616'
Nov  4 17:59:24.971: INFO: stderr: ""
Nov  4 17:59:24.971: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov  4 17:59:24.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 label pods pause testing-label- --namespace=kubectl-616'
Nov  4 17:59:25.048: INFO: stderr: ""
Nov  4 17:59:25.048: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov  4 17:59:25.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pod pause -L testing-label --namespace=kubectl-616'
Nov  4 17:59:25.122: INFO: stderr: ""
Nov  4 17:59:25.122: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Nov  4 17:59:25.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete --grace-period=0 --force -f - --namespace=kubectl-616'
Nov  4 17:59:25.215: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 17:59:25.215: INFO: stdout: "pod \"pause\" force deleted\n"
Nov  4 17:59:25.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get rc,svc -l name=pause --no-headers --namespace=kubectl-616'
Nov  4 17:59:25.311: INFO: stderr: "No resources found in kubectl-616 namespace.\n"
Nov  4 17:59:25.311: INFO: stdout: ""
Nov  4 17:59:25.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -l name=pause --namespace=kubectl-616 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 17:59:25.394: INFO: stderr: ""
Nov  4 17:59:25.394: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:59:25.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-616" for this suite.
Nov  4 17:59:31.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:59:31.485: INFO: namespace kubectl-616 deletion completed in 6.088375527s

â€¢ [SLOW TEST:9.021 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:59:31.486: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5706
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-5706
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5706 to expose endpoints map[]
Nov  4 17:59:31.638: INFO: Get endpoints failed (10.133482ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Nov  4 17:59:32.640: INFO: successfully validated that service multi-endpoint-test in namespace services-5706 exposes endpoints map[] (1.012613927s elapsed)
STEP: Creating pod pod1 in namespace services-5706
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5706 to expose endpoints map[pod1:[100]]
Nov  4 17:59:33.658: INFO: successfully validated that service multi-endpoint-test in namespace services-5706 exposes endpoints map[pod1:[100]] (1.011851872s elapsed)
STEP: Creating pod pod2 in namespace services-5706
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5706 to expose endpoints map[pod1:[100] pod2:[101]]
Nov  4 17:59:35.693: INFO: successfully validated that service multi-endpoint-test in namespace services-5706 exposes endpoints map[pod1:[100] pod2:[101]] (2.030955592s elapsed)
STEP: Deleting pod pod1 in namespace services-5706
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5706 to expose endpoints map[pod2:[101]]
Nov  4 17:59:36.754: INFO: successfully validated that service multi-endpoint-test in namespace services-5706 exposes endpoints map[pod2:[101]] (1.054311772s elapsed)
STEP: Deleting pod pod2 in namespace services-5706
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5706 to expose endpoints map[]
Nov  4 17:59:37.766: INFO: successfully validated that service multi-endpoint-test in namespace services-5706 exposes endpoints map[] (1.006453747s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:59:37.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5706" for this suite.
Nov  4 18:00:05.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:00:05.885: INFO: namespace services-5706 deletion completed in 28.088467935s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:34.400 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:00:05.888: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9131
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-bc0c8622-aef1-4c4f-8e73-774c065161e2
STEP: Creating a pod to test consume configMaps
Nov  4 18:00:06.036: INFO: Waiting up to 5m0s for pod "pod-configmaps-265c917b-98e2-49f7-a3cb-6ce803bf2068" in namespace "configmap-9131" to be "success or failure"
Nov  4 18:00:06.039: INFO: Pod "pod-configmaps-265c917b-98e2-49f7-a3cb-6ce803bf2068": Phase="Pending", Reason="", readiness=false. Elapsed: 3.687731ms
Nov  4 18:00:08.042: INFO: Pod "pod-configmaps-265c917b-98e2-49f7-a3cb-6ce803bf2068": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006676244s
STEP: Saw pod success
Nov  4 18:00:08.043: INFO: Pod "pod-configmaps-265c917b-98e2-49f7-a3cb-6ce803bf2068" satisfied condition "success or failure"
Nov  4 18:00:08.045: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-265c917b-98e2-49f7-a3cb-6ce803bf2068 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:00:08.086: INFO: Waiting for pod pod-configmaps-265c917b-98e2-49f7-a3cb-6ce803bf2068 to disappear
Nov  4 18:00:08.101: INFO: Pod pod-configmaps-265c917b-98e2-49f7-a3cb-6ce803bf2068 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:00:08.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9131" for this suite.
Nov  4 18:00:14.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:00:14.199: INFO: namespace configmap-9131 deletion completed in 6.094624564s

â€¢ [SLOW TEST:8.311 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:00:14.199: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8053
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:00:16.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8053" for this suite.
Nov  4 18:01:00.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:01:00.462: INFO: namespace kubelet-test-8053 deletion completed in 44.095804838s

â€¢ [SLOW TEST:46.263 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:01:00.462: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2262.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-2262.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2262.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-2262.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-2262.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2262.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 18:01:02.643: INFO: DNS probes using dns-2262/dns-test-e7e3e3fd-b5ac-434b-a335-8bc3bbed4a75 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:01:02.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2262" for this suite.
Nov  4 18:01:08.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:01:08.784: INFO: namespace dns-2262 deletion completed in 6.094487885s

â€¢ [SLOW TEST:8.322 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:01:08.785: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6899
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:02:08.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6899" for this suite.
Nov  4 18:02:20.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:02:21.019: INFO: namespace container-probe-6899 deletion completed in 12.088490783s

â€¢ [SLOW TEST:72.234 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:02:21.020: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7881
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7881.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7881.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7881.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7881.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7881.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7881.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7881.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7881.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7881.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7881.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7881.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 138.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.138_udp@PTR;check="$$(dig +tcp +noall +answer +search 138.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.138_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7881.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7881.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7881.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7881.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7881.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7881.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7881.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7881.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7881.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7881.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7881.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 138.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.138_udp@PTR;check="$$(dig +tcp +noall +answer +search 138.0.32.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.32.0.138_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 18:02:23.199: INFO: Unable to read wheezy_udp@dns-test-service.dns-7881.svc.cluster.local from pod dns-7881/dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307: the server could not find the requested resource (get pods dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307)
Nov  4 18:02:23.202: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7881.svc.cluster.local from pod dns-7881/dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307: the server could not find the requested resource (get pods dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307)
Nov  4 18:02:23.205: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local from pod dns-7881/dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307: the server could not find the requested resource (get pods dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307)
Nov  4 18:02:23.208: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local from pod dns-7881/dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307: the server could not find the requested resource (get pods dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307)
Nov  4 18:02:23.229: INFO: Unable to read jessie_udp@dns-test-service.dns-7881.svc.cluster.local from pod dns-7881/dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307: the server could not find the requested resource (get pods dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307)
Nov  4 18:02:23.232: INFO: Unable to read jessie_tcp@dns-test-service.dns-7881.svc.cluster.local from pod dns-7881/dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307: the server could not find the requested resource (get pods dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307)
Nov  4 18:02:23.240: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local from pod dns-7881/dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307: the server could not find the requested resource (get pods dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307)
Nov  4 18:02:23.243: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local from pod dns-7881/dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307: the server could not find the requested resource (get pods dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307)
Nov  4 18:02:23.270: INFO: Lookups using dns-7881/dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307 failed for: [wheezy_udp@dns-test-service.dns-7881.svc.cluster.local wheezy_tcp@dns-test-service.dns-7881.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local jessie_udp@dns-test-service.dns-7881.svc.cluster.local jessie_tcp@dns-test-service.dns-7881.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7881.svc.cluster.local]

Nov  4 18:02:28.327: INFO: DNS probes using dns-7881/dns-test-2767bbef-6de7-4905-a605-8b49c8ec1307 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:02:28.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7881" for this suite.
Nov  4 18:02:34.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:02:34.567: INFO: namespace dns-7881 deletion completed in 6.125863966s

â€¢ [SLOW TEST:13.547 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:02:34.567: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4718
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 18:02:34.713: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 18:02:34.722: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 18:02:34.725: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Nov  4 18:02:34.737: INFO: kube-flannel-ds-amd64-bls8m from kube-system started at 2019-11-04 17:23:59 +0000 UTC (1 container statuses recorded)
Nov  4 18:02:34.737: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 18:02:34.737: INFO: traefik-ingress-controller-mccsj from kube-system started at 2019-11-04 17:23:59 +0000 UTC (1 container statuses recorded)
Nov  4 18:02:34.737: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 18:02:34.737: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-lpskk from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:02:34.737: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:02:34.737: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 18:02:34.737: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Nov  4 18:02:34.750: INFO: kube-flannel-ds-amd64-c6xnw from kube-system started at 2019-11-04 16:58:52 +0000 UTC (1 container statuses recorded)
Nov  4 18:02:34.751: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 18:02:34.751: INFO: traefik-ingress-controller-qqfzz from kube-system started at 2019-11-04 16:58:54 +0000 UTC (1 container statuses recorded)
Nov  4 18:02:34.751: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 18:02:34.751: INFO: sonobuoy from sonobuoy started at 2019-11-04 16:59:51 +0000 UTC (1 container statuses recorded)
Nov  4 18:02:34.751: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 18:02:34.751: INFO: sonobuoy-e2e-job-281da138127b42b3 from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:02:34.751: INFO: 	Container e2e ready: true, restart count 0
Nov  4 18:02:34.751: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 18:02:34.751: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-k67sr from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:02:34.751: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:02:34.751: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 18:02:34.751: INFO: coredns-b7f8c8654-4rcsc from kube-system started at 2019-11-04 17:23:27 +0000 UTC (1 container statuses recorded)
Nov  4 18:02:34.751: INFO: 	Container coredns ready: true, restart count 0
Nov  4 18:02:34.751: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Nov  4 18:02:34.766: INFO: coredns-b7f8c8654-68j25 from kube-system started at 2019-11-04 17:13:42 +0000 UTC (1 container statuses recorded)
Nov  4 18:02:34.766: INFO: 	Container coredns ready: true, restart count 0
Nov  4 18:02:34.766: INFO: kube-flannel-ds-amd64-s2gr4 from kube-system started at 2019-11-04 17:14:19 +0000 UTC (1 container statuses recorded)
Nov  4 18:02:34.766: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 18:02:34.766: INFO: traefik-ingress-controller-98f8s from kube-system started at 2019-11-04 17:13:49 +0000 UTC (1 container statuses recorded)
Nov  4 18:02:34.766: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 18:02:34.766: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-vkd6f from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:02:34.766: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:02:34.766: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node k8s-1
STEP: verifying the node has the label node k8s-2
STEP: verifying the node has the label node k8s-3
Nov  4 18:02:34.806: INFO: Pod coredns-b7f8c8654-4rcsc requesting resource cpu=100m on Node k8s-2
Nov  4 18:02:34.806: INFO: Pod coredns-b7f8c8654-68j25 requesting resource cpu=100m on Node k8s-3
Nov  4 18:02:34.806: INFO: Pod kube-flannel-ds-amd64-bls8m requesting resource cpu=100m on Node k8s-1
Nov  4 18:02:34.806: INFO: Pod kube-flannel-ds-amd64-c6xnw requesting resource cpu=100m on Node k8s-2
Nov  4 18:02:34.806: INFO: Pod kube-flannel-ds-amd64-s2gr4 requesting resource cpu=100m on Node k8s-3
Nov  4 18:02:34.806: INFO: Pod traefik-ingress-controller-98f8s requesting resource cpu=0m on Node k8s-3
Nov  4 18:02:34.806: INFO: Pod traefik-ingress-controller-mccsj requesting resource cpu=0m on Node k8s-1
Nov  4 18:02:34.806: INFO: Pod traefik-ingress-controller-qqfzz requesting resource cpu=0m on Node k8s-2
Nov  4 18:02:34.806: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-2
Nov  4 18:02:34.806: INFO: Pod sonobuoy-e2e-job-281da138127b42b3 requesting resource cpu=0m on Node k8s-2
Nov  4 18:02:34.806: INFO: Pod sonobuoy-systemd-logs-daemon-set-23fc508521714957-k67sr requesting resource cpu=0m on Node k8s-2
Nov  4 18:02:34.806: INFO: Pod sonobuoy-systemd-logs-daemon-set-23fc508521714957-lpskk requesting resource cpu=0m on Node k8s-1
Nov  4 18:02:34.806: INFO: Pod sonobuoy-systemd-logs-daemon-set-23fc508521714957-vkd6f requesting resource cpu=0m on Node k8s-3
STEP: Starting Pods to consume most of the cluster CPU.
Nov  4 18:02:34.806: INFO: Creating a pod which consumes cpu=630m on Node k8s-1
Nov  4 18:02:34.812: INFO: Creating a pod which consumes cpu=560m on Node k8s-2
Nov  4 18:02:34.818: INFO: Creating a pod which consumes cpu=560m on Node k8s-3
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e29d3c9-bb5e-43a2-864e-4a8e279ebca4.15d407a0476dd8d7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4718/filler-pod-1e29d3c9-bb5e-43a2-864e-4a8e279ebca4 to k8s-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e29d3c9-bb5e-43a2-864e-4a8e279ebca4.15d407a0619cea0a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e29d3c9-bb5e-43a2-864e-4a8e279ebca4.15d407a0637d9780], Reason = [Created], Message = [Created container filler-pod-1e29d3c9-bb5e-43a2-864e-4a8e279ebca4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1e29d3c9-bb5e-43a2-864e-4a8e279ebca4.15d407a069096e96], Reason = [Started], Message = [Started container filler-pod-1e29d3c9-bb5e-43a2-864e-4a8e279ebca4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-705767ea-2930-45aa-a6ca-68b5bfbfeb7b.15d407a046848bf9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4718/filler-pod-705767ea-2930-45aa-a6ca-68b5bfbfeb7b to k8s-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-705767ea-2930-45aa-a6ca-68b5bfbfeb7b.15d407a060ddb76b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-705767ea-2930-45aa-a6ca-68b5bfbfeb7b.15d407a063370ac9], Reason = [Created], Message = [Created container filler-pod-705767ea-2930-45aa-a6ca-68b5bfbfeb7b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-705767ea-2930-45aa-a6ca-68b5bfbfeb7b.15d407a0689ba435], Reason = [Started], Message = [Started container filler-pod-705767ea-2930-45aa-a6ca-68b5bfbfeb7b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87c24cbd-b945-4662-a328-7bef89269597.15d407a0481e87a1], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4718/filler-pod-87c24cbd-b945-4662-a328-7bef89269597 to k8s-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87c24cbd-b945-4662-a328-7bef89269597.15d407a09a4630e7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87c24cbd-b945-4662-a328-7bef89269597.15d407a09dac66be], Reason = [Created], Message = [Created container filler-pod-87c24cbd-b945-4662-a328-7bef89269597]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-87c24cbd-b945-4662-a328-7bef89269597.15d407a0a2d99560], Reason = [Started], Message = [Started container filler-pod-87c24cbd-b945-4662-a328-7bef89269597]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d407a0c0134d9e], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node k8s-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:02:37.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4718" for this suite.
Nov  4 18:02:43.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:02:43.987: INFO: namespace sched-pred-4718 deletion completed in 6.085538352s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:9.420 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:02:43.988: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5726
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:02:44.618: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:02:47.633: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:02:47.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5726" for this suite.
Nov  4 18:02:53.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:02:53.824: INFO: namespace webhook-5726 deletion completed in 6.087915358s
STEP: Destroying namespace "webhook-5726-markers" for this suite.
Nov  4 18:02:59.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:02:59.911: INFO: namespace webhook-5726-markers deletion completed in 6.086893444s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:15.935 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:02:59.924: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-46
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Nov  4 18:03:00.064: INFO: Waiting up to 5m0s for pod "var-expansion-d5008970-fe0e-4245-a74e-be6d377ecf89" in namespace "var-expansion-46" to be "success or failure"
Nov  4 18:03:00.070: INFO: Pod "var-expansion-d5008970-fe0e-4245-a74e-be6d377ecf89": Phase="Pending", Reason="", readiness=false. Elapsed: 5.543703ms
Nov  4 18:03:02.072: INFO: Pod "var-expansion-d5008970-fe0e-4245-a74e-be6d377ecf89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008262551s
STEP: Saw pod success
Nov  4 18:03:02.073: INFO: Pod "var-expansion-d5008970-fe0e-4245-a74e-be6d377ecf89" satisfied condition "success or failure"
Nov  4 18:03:02.075: INFO: Trying to get logs from node k8s-1 pod var-expansion-d5008970-fe0e-4245-a74e-be6d377ecf89 container dapi-container: <nil>
STEP: delete the pod
Nov  4 18:03:02.091: INFO: Waiting for pod var-expansion-d5008970-fe0e-4245-a74e-be6d377ecf89 to disappear
Nov  4 18:03:02.099: INFO: Pod var-expansion-d5008970-fe0e-4245-a74e-be6d377ecf89 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:03:02.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-46" for this suite.
Nov  4 18:03:08.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:03:08.220: INFO: namespace var-expansion-46 deletion completed in 6.117114168s

â€¢ [SLOW TEST:8.296 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:03:08.221: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5791
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-2900a197-acf5-407a-bccb-5b773b7956a1
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-2900a197-acf5-407a-bccb-5b773b7956a1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:03:12.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5791" for this suite.
Nov  4 18:03:24.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:03:24.485: INFO: namespace configmap-5791 deletion completed in 12.084989379s

â€¢ [SLOW TEST:16.264 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:03:24.485: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8168
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-796
STEP: Creating secret with name secret-test-ae01d4a6-63b4-4581-9dd2-babac2b21743
STEP: Creating a pod to test consume secrets
Nov  4 18:03:24.767: INFO: Waiting up to 5m0s for pod "pod-secrets-929a7f43-2005-4868-9f98-856d08b721e0" in namespace "secrets-8168" to be "success or failure"
Nov  4 18:03:24.772: INFO: Pod "pod-secrets-929a7f43-2005-4868-9f98-856d08b721e0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019222ms
Nov  4 18:03:26.774: INFO: Pod "pod-secrets-929a7f43-2005-4868-9f98-856d08b721e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006724928s
STEP: Saw pod success
Nov  4 18:03:26.774: INFO: Pod "pod-secrets-929a7f43-2005-4868-9f98-856d08b721e0" satisfied condition "success or failure"
Nov  4 18:03:26.777: INFO: Trying to get logs from node k8s-1 pod pod-secrets-929a7f43-2005-4868-9f98-856d08b721e0 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:03:26.798: INFO: Waiting for pod pod-secrets-929a7f43-2005-4868-9f98-856d08b721e0 to disappear
Nov  4 18:03:26.803: INFO: Pod pod-secrets-929a7f43-2005-4868-9f98-856d08b721e0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:03:26.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8168" for this suite.
Nov  4 18:03:32.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:03:32.891: INFO: namespace secrets-8168 deletion completed in 6.086011573s
STEP: Destroying namespace "secret-namespace-796" for this suite.
Nov  4 18:03:38.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:03:38.981: INFO: namespace secret-namespace-796 deletion completed in 6.089113104s

â€¢ [SLOW TEST:14.495 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:03:38.981: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8851
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:03:39.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 version'
Nov  4 18:03:39.188: INFO: stderr: ""
Nov  4 18:03:39.188: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:18:23Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:09:08Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:03:39.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8851" for this suite.
Nov  4 18:03:45.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:03:45.273: INFO: namespace kubectl-8851 deletion completed in 6.081127969s

â€¢ [SLOW TEST:6.292 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:03:45.273: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2646
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Nov  4 18:03:45.424: INFO: Waiting up to 5m0s for pod "client-containers-e17b27d4-acdf-4b44-84aa-9c622e64ac8b" in namespace "containers-2646" to be "success or failure"
Nov  4 18:03:45.428: INFO: Pod "client-containers-e17b27d4-acdf-4b44-84aa-9c622e64ac8b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.46912ms
Nov  4 18:03:47.432: INFO: Pod "client-containers-e17b27d4-acdf-4b44-84aa-9c622e64ac8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007588536s
STEP: Saw pod success
Nov  4 18:03:47.432: INFO: Pod "client-containers-e17b27d4-acdf-4b44-84aa-9c622e64ac8b" satisfied condition "success or failure"
Nov  4 18:03:47.434: INFO: Trying to get logs from node k8s-1 pod client-containers-e17b27d4-acdf-4b44-84aa-9c622e64ac8b container test-container: <nil>
STEP: delete the pod
Nov  4 18:03:47.452: INFO: Waiting for pod client-containers-e17b27d4-acdf-4b44-84aa-9c622e64ac8b to disappear
Nov  4 18:03:47.458: INFO: Pod client-containers-e17b27d4-acdf-4b44-84aa-9c622e64ac8b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:03:47.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2646" for this suite.
Nov  4 18:03:53.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:03:53.544: INFO: namespace containers-2646 deletion completed in 6.083537317s

â€¢ [SLOW TEST:8.271 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:03:53.545: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-868/configmap-test-7daa1e77-d659-47d8-a844-626d7b70adf9
STEP: Creating a pod to test consume configMaps
Nov  4 18:03:53.693: INFO: Waiting up to 5m0s for pod "pod-configmaps-844d4f1a-9d39-4d5b-8f34-d729a795ce45" in namespace "configmap-868" to be "success or failure"
Nov  4 18:03:53.697: INFO: Pod "pod-configmaps-844d4f1a-9d39-4d5b-8f34-d729a795ce45": Phase="Pending", Reason="", readiness=false. Elapsed: 4.197456ms
Nov  4 18:03:55.702: INFO: Pod "pod-configmaps-844d4f1a-9d39-4d5b-8f34-d729a795ce45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009155297s
STEP: Saw pod success
Nov  4 18:03:55.702: INFO: Pod "pod-configmaps-844d4f1a-9d39-4d5b-8f34-d729a795ce45" satisfied condition "success or failure"
Nov  4 18:03:55.708: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-844d4f1a-9d39-4d5b-8f34-d729a795ce45 container env-test: <nil>
STEP: delete the pod
Nov  4 18:03:55.729: INFO: Waiting for pod pod-configmaps-844d4f1a-9d39-4d5b-8f34-d729a795ce45 to disappear
Nov  4 18:03:55.733: INFO: Pod pod-configmaps-844d4f1a-9d39-4d5b-8f34-d729a795ce45 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:03:55.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-868" for this suite.
Nov  4 18:04:01.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:04:01.823: INFO: namespace configmap-868 deletion completed in 6.086805679s

â€¢ [SLOW TEST:8.278 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:04:01.823: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6810
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-b2edd32d-3229-4c1b-b822-73e4dc00c2a5
STEP: Creating configMap with name cm-test-opt-upd-b60f4d3f-1f98-42e1-be50-b2056e83d509
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b2edd32d-3229-4c1b-b822-73e4dc00c2a5
STEP: Updating configmap cm-test-opt-upd-b60f4d3f-1f98-42e1-be50-b2056e83d509
STEP: Creating configMap with name cm-test-opt-create-bdc0240d-4256-4c93-9941-b4d3d0d63c81
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:04:08.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6810" for this suite.
Nov  4 18:04:20.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:04:20.127: INFO: namespace projected-6810 deletion completed in 12.081786324s

â€¢ [SLOW TEST:18.303 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:04:20.127: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8869
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  4 18:04:20.269: INFO: Waiting up to 5m0s for pod "pod-7bccf4ef-fdc1-41fd-abbd-3f4dfb9ef2df" in namespace "emptydir-8869" to be "success or failure"
Nov  4 18:04:20.274: INFO: Pod "pod-7bccf4ef-fdc1-41fd-abbd-3f4dfb9ef2df": Phase="Pending", Reason="", readiness=false. Elapsed: 5.012167ms
Nov  4 18:04:22.277: INFO: Pod "pod-7bccf4ef-fdc1-41fd-abbd-3f4dfb9ef2df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007746481s
STEP: Saw pod success
Nov  4 18:04:22.277: INFO: Pod "pod-7bccf4ef-fdc1-41fd-abbd-3f4dfb9ef2df" satisfied condition "success or failure"
Nov  4 18:04:22.279: INFO: Trying to get logs from node k8s-1 pod pod-7bccf4ef-fdc1-41fd-abbd-3f4dfb9ef2df container test-container: <nil>
STEP: delete the pod
Nov  4 18:04:22.296: INFO: Waiting for pod pod-7bccf4ef-fdc1-41fd-abbd-3f4dfb9ef2df to disappear
Nov  4 18:04:22.299: INFO: Pod pod-7bccf4ef-fdc1-41fd-abbd-3f4dfb9ef2df no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:04:22.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8869" for this suite.
Nov  4 18:04:28.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:04:28.390: INFO: namespace emptydir-8869 deletion completed in 6.088525022s

â€¢ [SLOW TEST:8.263 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:04:28.391: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7660
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-457f04ec-3cc6-40ba-8626-de9b930e1e65
STEP: Creating a pod to test consume secrets
Nov  4 18:04:28.537: INFO: Waiting up to 5m0s for pod "pod-secrets-fab50e8f-9c0a-434b-9f98-969d3ebbc2a9" in namespace "secrets-7660" to be "success or failure"
Nov  4 18:04:28.540: INFO: Pod "pod-secrets-fab50e8f-9c0a-434b-9f98-969d3ebbc2a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.797202ms
Nov  4 18:04:30.543: INFO: Pod "pod-secrets-fab50e8f-9c0a-434b-9f98-969d3ebbc2a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005701044s
STEP: Saw pod success
Nov  4 18:04:30.543: INFO: Pod "pod-secrets-fab50e8f-9c0a-434b-9f98-969d3ebbc2a9" satisfied condition "success or failure"
Nov  4 18:04:30.545: INFO: Trying to get logs from node k8s-1 pod pod-secrets-fab50e8f-9c0a-434b-9f98-969d3ebbc2a9 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:04:30.569: INFO: Waiting for pod pod-secrets-fab50e8f-9c0a-434b-9f98-969d3ebbc2a9 to disappear
Nov  4 18:04:30.575: INFO: Pod pod-secrets-fab50e8f-9c0a-434b-9f98-969d3ebbc2a9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:04:30.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7660" for this suite.
Nov  4 18:04:36.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:04:36.668: INFO: namespace secrets-7660 deletion completed in 6.087400745s

â€¢ [SLOW TEST:8.277 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:04:36.669: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Nov  4 18:04:36.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-8739'
Nov  4 18:04:37.064: INFO: stderr: ""
Nov  4 18:04:37.064: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 18:04:37.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8739'
Nov  4 18:04:37.156: INFO: stderr: ""
Nov  4 18:04:37.156: INFO: stdout: "update-demo-nautilus-2wc2s update-demo-nautilus-66f7l "
Nov  4 18:04:37.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-2wc2s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8739'
Nov  4 18:04:37.225: INFO: stderr: ""
Nov  4 18:04:37.225: INFO: stdout: ""
Nov  4 18:04:37.225: INFO: update-demo-nautilus-2wc2s is created but not running
Nov  4 18:04:42.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8739'
Nov  4 18:04:42.304: INFO: stderr: ""
Nov  4 18:04:42.304: INFO: stdout: "update-demo-nautilus-2wc2s update-demo-nautilus-66f7l "
Nov  4 18:04:42.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-2wc2s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8739'
Nov  4 18:04:42.379: INFO: stderr: ""
Nov  4 18:04:42.379: INFO: stdout: "true"
Nov  4 18:04:42.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-2wc2s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8739'
Nov  4 18:04:42.452: INFO: stderr: ""
Nov  4 18:04:42.452: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 18:04:42.452: INFO: validating pod update-demo-nautilus-2wc2s
Nov  4 18:04:42.456: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 18:04:42.456: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 18:04:42.456: INFO: update-demo-nautilus-2wc2s is verified up and running
Nov  4 18:04:42.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-66f7l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8739'
Nov  4 18:04:42.533: INFO: stderr: ""
Nov  4 18:04:42.533: INFO: stdout: "true"
Nov  4 18:04:42.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods update-demo-nautilus-66f7l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8739'
Nov  4 18:04:42.607: INFO: stderr: ""
Nov  4 18:04:42.607: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 18:04:42.607: INFO: validating pod update-demo-nautilus-66f7l
Nov  4 18:04:42.611: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 18:04:42.611: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 18:04:42.611: INFO: update-demo-nautilus-66f7l is verified up and running
STEP: using delete to clean up resources
Nov  4 18:04:42.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete --grace-period=0 --force -f - --namespace=kubectl-8739'
Nov  4 18:04:42.687: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 18:04:42.687: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  4 18:04:42.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8739'
Nov  4 18:04:42.767: INFO: stderr: "No resources found in kubectl-8739 namespace.\n"
Nov  4 18:04:42.767: INFO: stdout: ""
Nov  4 18:04:42.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -l name=update-demo --namespace=kubectl-8739 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 18:04:42.839: INFO: stderr: ""
Nov  4 18:04:42.839: INFO: stdout: "update-demo-nautilus-2wc2s\nupdate-demo-nautilus-66f7l\n"
Nov  4 18:04:43.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8739'
Nov  4 18:04:43.425: INFO: stderr: "No resources found in kubectl-8739 namespace.\n"
Nov  4 18:04:43.425: INFO: stdout: ""
Nov  4 18:04:43.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -l name=update-demo --namespace=kubectl-8739 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 18:04:43.494: INFO: stderr: ""
Nov  4 18:04:43.494: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:04:43.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8739" for this suite.
Nov  4 18:04:55.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:04:55.587: INFO: namespace kubectl-8739 deletion completed in 12.088726059s

â€¢ [SLOW TEST:18.918 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:04:55.587: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7015
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:04:55.739: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e4e06c9-4c66-4a5e-8ef2-f964b1217ce8" in namespace "downward-api-7015" to be "success or failure"
Nov  4 18:04:55.741: INFO: Pod "downwardapi-volume-6e4e06c9-4c66-4a5e-8ef2-f964b1217ce8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.214353ms
Nov  4 18:04:57.744: INFO: Pod "downwardapi-volume-6e4e06c9-4c66-4a5e-8ef2-f964b1217ce8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005096675s
Nov  4 18:04:59.747: INFO: Pod "downwardapi-volume-6e4e06c9-4c66-4a5e-8ef2-f964b1217ce8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008730834s
STEP: Saw pod success
Nov  4 18:04:59.747: INFO: Pod "downwardapi-volume-6e4e06c9-4c66-4a5e-8ef2-f964b1217ce8" satisfied condition "success or failure"
Nov  4 18:04:59.750: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-6e4e06c9-4c66-4a5e-8ef2-f964b1217ce8 container client-container: <nil>
STEP: delete the pod
Nov  4 18:04:59.772: INFO: Waiting for pod downwardapi-volume-6e4e06c9-4c66-4a5e-8ef2-f964b1217ce8 to disappear
Nov  4 18:04:59.776: INFO: Pod downwardapi-volume-6e4e06c9-4c66-4a5e-8ef2-f964b1217ce8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:04:59.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7015" for this suite.
Nov  4 18:05:05.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:05:05.865: INFO: namespace downward-api-7015 deletion completed in 6.085444528s

â€¢ [SLOW TEST:10.278 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:05:05.866: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-6014
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:05:06.001: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Creating first CR 
Nov  4 18:05:11.570: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:05:11Z generation:1 name:name1 resourceVersion:15077 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:0fb51743-3d74-426e-a58c-72a5860e047d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Nov  4 18:05:21.576: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:05:21Z generation:1 name:name2 resourceVersion:15094 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9a1a60db-7d88-4d2b-9bc5-637962f2f71c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Nov  4 18:05:31.581: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:05:11Z generation:2 name:name1 resourceVersion:15113 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:0fb51743-3d74-426e-a58c-72a5860e047d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Nov  4 18:05:41.587: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:05:21Z generation:2 name:name2 resourceVersion:15130 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9a1a60db-7d88-4d2b-9bc5-637962f2f71c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Nov  4 18:05:51.595: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:05:11Z generation:2 name:name1 resourceVersion:15148 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:0fb51743-3d74-426e-a58c-72a5860e047d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Nov  4 18:06:01.603: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:05:21Z generation:2 name:name2 resourceVersion:15166 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:9a1a60db-7d88-4d2b-9bc5-637962f2f71c] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:06:12.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-6014" for this suite.
Nov  4 18:06:18.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:06:18.211: INFO: namespace crd-watch-6014 deletion completed in 6.095107547s

â€¢ [SLOW TEST:72.345 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:06:18.212: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8268
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:06:18.355: INFO: Waiting up to 5m0s for pod "downwardapi-volume-caf890c3-6a8c-456d-a296-49a158732463" in namespace "projected-8268" to be "success or failure"
Nov  4 18:06:18.359: INFO: Pod "downwardapi-volume-caf890c3-6a8c-456d-a296-49a158732463": Phase="Pending", Reason="", readiness=false. Elapsed: 4.534183ms
Nov  4 18:06:20.362: INFO: Pod "downwardapi-volume-caf890c3-6a8c-456d-a296-49a158732463": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007500606s
STEP: Saw pod success
Nov  4 18:06:20.362: INFO: Pod "downwardapi-volume-caf890c3-6a8c-456d-a296-49a158732463" satisfied condition "success or failure"
Nov  4 18:06:20.365: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-caf890c3-6a8c-456d-a296-49a158732463 container client-container: <nil>
STEP: delete the pod
Nov  4 18:06:20.386: INFO: Waiting for pod downwardapi-volume-caf890c3-6a8c-456d-a296-49a158732463 to disappear
Nov  4 18:06:20.394: INFO: Pod downwardapi-volume-caf890c3-6a8c-456d-a296-49a158732463 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:06:20.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8268" for this suite.
Nov  4 18:06:26.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:06:26.489: INFO: namespace projected-8268 deletion completed in 6.092311822s

â€¢ [SLOW TEST:8.278 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:06:26.490: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9205
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 18:06:29.157: INFO: Successfully updated pod "labelsupdate8d6fbb1b-e27d-4248-94c3-a2fb5f6a5941"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:06:33.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9205" for this suite.
Nov  4 18:06:45.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:06:45.266: INFO: namespace projected-9205 deletion completed in 12.085751291s

â€¢ [SLOW TEST:18.776 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:06:45.266: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5491
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:06:45.402: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:06:47.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5491" for this suite.
Nov  4 18:07:31.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:07:31.639: INFO: namespace pods-5491 deletion completed in 44.083756267s

â€¢ [SLOW TEST:46.372 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:07:31.639: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4516
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:07:35.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4516" for this suite.
Nov  4 18:07:41.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:07:41.883: INFO: namespace kubelet-test-4516 deletion completed in 6.092020208s

â€¢ [SLOW TEST:10.244 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:07:41.884: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6302
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:07:42.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6302" for this suite.
Nov  4 18:07:54.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:07:54.117: INFO: namespace pods-6302 deletion completed in 12.08537998s

â€¢ [SLOW TEST:12.233 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:07:54.118: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9901
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1104 18:08:04.281592      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 18:08:04.281: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:08:04.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9901" for this suite.
Nov  4 18:08:10.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:08:10.373: INFO: namespace gc-9901 deletion completed in 6.088522626s

â€¢ [SLOW TEST:16.255 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:08:10.373: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8415
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Nov  4 18:08:12.525: INFO: Pod pod-hostip-ebef921d-2798-4717-9eb8-fbfbccaff733 has hostIP: 10.20.20.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:08:12.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8415" for this suite.
Nov  4 18:08:40.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:08:40.620: INFO: namespace pods-8415 deletion completed in 28.089947766s

â€¢ [SLOW TEST:30.246 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:08:40.620: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Nov  4 18:08:40.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-3416'
Nov  4 18:08:40.959: INFO: stderr: ""
Nov  4 18:08:40.959: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  4 18:08:41.962: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:08:41.962: INFO: Found 0 / 1
Nov  4 18:08:42.962: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:08:42.962: INFO: Found 0 / 1
Nov  4 18:08:43.962: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:08:43.962: INFO: Found 1 / 1
Nov  4 18:08:43.962: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov  4 18:08:43.964: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:08:43.964: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  4 18:08:43.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 patch pod redis-master-vg68p --namespace=kubectl-3416 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov  4 18:08:44.048: INFO: stderr: ""
Nov  4 18:08:44.049: INFO: stdout: "pod/redis-master-vg68p patched\n"
STEP: checking annotations
Nov  4 18:08:44.052: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:08:44.052: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:08:44.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3416" for this suite.
Nov  4 18:09:12.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:09:12.142: INFO: namespace kubectl-3416 deletion completed in 28.086523599s

â€¢ [SLOW TEST:31.522 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:09:12.143: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2942
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-bb890cf8-6da0-4c79-af1d-5aaa84bdbc26
STEP: Creating a pod to test consume secrets
Nov  4 18:09:12.291: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1a7b3a28-1ddd-48ac-a6a4-65146fce0e29" in namespace "projected-2942" to be "success or failure"
Nov  4 18:09:12.297: INFO: Pod "pod-projected-secrets-1a7b3a28-1ddd-48ac-a6a4-65146fce0e29": Phase="Pending", Reason="", readiness=false. Elapsed: 5.927959ms
Nov  4 18:09:14.300: INFO: Pod "pod-projected-secrets-1a7b3a28-1ddd-48ac-a6a4-65146fce0e29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009046287s
STEP: Saw pod success
Nov  4 18:09:14.300: INFO: Pod "pod-projected-secrets-1a7b3a28-1ddd-48ac-a6a4-65146fce0e29" satisfied condition "success or failure"
Nov  4 18:09:14.303: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-1a7b3a28-1ddd-48ac-a6a4-65146fce0e29 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:09:14.331: INFO: Waiting for pod pod-projected-secrets-1a7b3a28-1ddd-48ac-a6a4-65146fce0e29 to disappear
Nov  4 18:09:14.334: INFO: Pod pod-projected-secrets-1a7b3a28-1ddd-48ac-a6a4-65146fce0e29 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:09:14.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2942" for this suite.
Nov  4 18:09:20.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:09:20.424: INFO: namespace projected-2942 deletion completed in 6.08732547s

â€¢ [SLOW TEST:8.282 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:09:20.426: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7621
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-9747e141-7c91-4628-aa3a-845b60771a20
STEP: Creating a pod to test consume configMaps
Nov  4 18:09:20.570: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-86683513-d653-44fd-86ac-ea8839b2953e" in namespace "projected-7621" to be "success or failure"
Nov  4 18:09:20.575: INFO: Pod "pod-projected-configmaps-86683513-d653-44fd-86ac-ea8839b2953e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.022735ms
Nov  4 18:09:22.578: INFO: Pod "pod-projected-configmaps-86683513-d653-44fd-86ac-ea8839b2953e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007936299s
STEP: Saw pod success
Nov  4 18:09:22.578: INFO: Pod "pod-projected-configmaps-86683513-d653-44fd-86ac-ea8839b2953e" satisfied condition "success or failure"
Nov  4 18:09:22.582: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-86683513-d653-44fd-86ac-ea8839b2953e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:09:22.600: INFO: Waiting for pod pod-projected-configmaps-86683513-d653-44fd-86ac-ea8839b2953e to disappear
Nov  4 18:09:22.605: INFO: Pod pod-projected-configmaps-86683513-d653-44fd-86ac-ea8839b2953e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:09:22.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7621" for this suite.
Nov  4 18:09:28.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:09:28.695: INFO: namespace projected-7621 deletion completed in 6.087020229s

â€¢ [SLOW TEST:8.269 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:09:28.695: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3226
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:09:50.846: INFO: Container started at 2019-11-04 18:09:29 +0000 UTC, pod became ready at 2019-11-04 18:09:50 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:09:50.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3226" for this suite.
Nov  4 18:10:02.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:10:02.940: INFO: namespace container-probe-3226 deletion completed in 12.091288844s

â€¢ [SLOW TEST:34.245 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:10:02.941: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-3666
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-3666, will wait for the garbage collector to delete the pods
Nov  4 18:10:05.146: INFO: Deleting Job.batch foo took: 7.314485ms
Nov  4 18:10:05.446: INFO: Terminating Job.batch foo pods took: 300.221032ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:10:38.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3666" for this suite.
Nov  4 18:10:44.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:10:44.438: INFO: namespace job-3666 deletion completed in 6.085858519s

â€¢ [SLOW TEST:41.497 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:10:44.439: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3439
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:10:44.573: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Nov  4 18:10:45.599: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:10:46.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3439" for this suite.
Nov  4 18:10:52.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:10:52.700: INFO: namespace replication-controller-3439 deletion completed in 6.091575196s

â€¢ [SLOW TEST:8.262 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:10:52.701: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5412
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Nov  4 18:10:52.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-5412 -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov  4 18:10:52.926: INFO: stderr: ""
Nov  4 18:10:52.926: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Nov  4 18:10:52.926: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov  4 18:10:52.926: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5412" to be "running and ready, or succeeded"
Nov  4 18:10:52.928: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.340591ms
Nov  4 18:10:54.932: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.005885754s
Nov  4 18:10:54.932: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov  4 18:10:54.932: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Nov  4 18:10:54.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 logs logs-generator logs-generator --namespace=kubectl-5412'
Nov  4 18:10:55.021: INFO: stderr: ""
Nov  4 18:10:55.021: INFO: stdout: "I1104 18:10:53.531032       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/tbn 478\nI1104 18:10:53.731254       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/cs7 229\nI1104 18:10:53.931227       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/wpvf 467\nI1104 18:10:54.131178       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/pkg9 377\nI1104 18:10:54.331209       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/qjg5 588\nI1104 18:10:54.531141       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/gqc 442\nI1104 18:10:54.731183       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/9m7q 442\nI1104 18:10:54.931172       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/x87m 412\n"
STEP: limiting log lines
Nov  4 18:10:55.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 logs logs-generator logs-generator --namespace=kubectl-5412 --tail=1'
Nov  4 18:10:55.104: INFO: stderr: ""
Nov  4 18:10:55.104: INFO: stdout: "I1104 18:10:54.931172       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/x87m 412\n"
STEP: limiting log bytes
Nov  4 18:10:55.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 logs logs-generator logs-generator --namespace=kubectl-5412 --limit-bytes=1'
Nov  4 18:10:55.178: INFO: stderr: ""
Nov  4 18:10:55.178: INFO: stdout: "I"
STEP: exposing timestamps
Nov  4 18:10:55.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 logs logs-generator logs-generator --namespace=kubectl-5412 --tail=1 --timestamps'
Nov  4 18:10:55.265: INFO: stderr: ""
Nov  4 18:10:55.265: INFO: stdout: "2019-11-04T18:10:55.13151786Z I1104 18:10:55.131269       1 logs_generator.go:76] 8 POST /api/v1/namespaces/kube-system/pods/rrx6 216\n"
STEP: restricting to a time range
Nov  4 18:10:57.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 logs logs-generator logs-generator --namespace=kubectl-5412 --since=1s'
Nov  4 18:10:57.854: INFO: stderr: ""
Nov  4 18:10:57.854: INFO: stdout: "I1104 18:10:56.931200       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/x72p 231\nI1104 18:10:57.131257       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/s4w 591\nI1104 18:10:57.331158       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/r6d 268\nI1104 18:10:57.531174       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/d7xs 501\nI1104 18:10:57.731180       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/7xmp 344\n"
Nov  4 18:10:57.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 logs logs-generator logs-generator --namespace=kubectl-5412 --since=24h'
Nov  4 18:10:57.936: INFO: stderr: ""
Nov  4 18:10:57.936: INFO: stdout: "I1104 18:10:53.531032       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/tbn 478\nI1104 18:10:53.731254       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/cs7 229\nI1104 18:10:53.931227       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/wpvf 467\nI1104 18:10:54.131178       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/pkg9 377\nI1104 18:10:54.331209       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/qjg5 588\nI1104 18:10:54.531141       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/gqc 442\nI1104 18:10:54.731183       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/9m7q 442\nI1104 18:10:54.931172       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/x87m 412\nI1104 18:10:55.131269       1 logs_generator.go:76] 8 POST /api/v1/namespaces/kube-system/pods/rrx6 216\nI1104 18:10:55.331201       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/nqmk 443\nI1104 18:10:55.531201       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/lzp6 382\nI1104 18:10:55.731201       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/nfp 260\nI1104 18:10:55.931202       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/m2sh 528\nI1104 18:10:56.131153       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/p62 244\nI1104 18:10:56.331151       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/48x 348\nI1104 18:10:56.531213       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/978n 272\nI1104 18:10:56.731177       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/c4p 527\nI1104 18:10:56.931200       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/x72p 231\nI1104 18:10:57.131257       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/s4w 591\nI1104 18:10:57.331158       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/r6d 268\nI1104 18:10:57.531174       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/d7xs 501\nI1104 18:10:57.731180       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/7xmp 344\nI1104 18:10:57.931188       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/w26 222\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Nov  4 18:10:57.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete pod logs-generator --namespace=kubectl-5412'
Nov  4 18:11:09.430: INFO: stderr: ""
Nov  4 18:11:09.430: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:11:09.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5412" for this suite.
Nov  4 18:11:15.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:11:15.520: INFO: namespace kubectl-5412 deletion completed in 6.085780942s

â€¢ [SLOW TEST:22.819 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:11:15.521: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5948
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:11:31.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5948" for this suite.
Nov  4 18:11:37.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:11:37.869: INFO: namespace resourcequota-5948 deletion completed in 6.088724765s

â€¢ [SLOW TEST:22.348 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:11:37.870: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-4644
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Nov  4 18:11:38.007: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Nov  4 18:11:38.474: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov  4 18:11:40.518: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 18:11:42.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 18:11:44.524: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 18:11:46.523: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 18:11:48.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 18:11:50.523: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487898, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 18:11:53.169: INFO: Waited 642.761868ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:11:54.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4644" for this suite.
Nov  4 18:12:00.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:12:00.221: INFO: namespace aggregator-4644 deletion completed in 6.090603358s

â€¢ [SLOW TEST:22.352 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:12:00.222: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-913
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-e1e9e092-7e26-4c23-87c3-0d5e610612a6
STEP: Creating a pod to test consume configMaps
Nov  4 18:12:00.368: INFO: Waiting up to 5m0s for pod "pod-configmaps-a1b45353-8c70-4025-b736-0deab7e6492b" in namespace "configmap-913" to be "success or failure"
Nov  4 18:12:00.372: INFO: Pod "pod-configmaps-a1b45353-8c70-4025-b736-0deab7e6492b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.456082ms
Nov  4 18:12:02.376: INFO: Pod "pod-configmaps-a1b45353-8c70-4025-b736-0deab7e6492b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008220878s
STEP: Saw pod success
Nov  4 18:12:02.376: INFO: Pod "pod-configmaps-a1b45353-8c70-4025-b736-0deab7e6492b" satisfied condition "success or failure"
Nov  4 18:12:02.378: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-a1b45353-8c70-4025-b736-0deab7e6492b container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:12:02.395: INFO: Waiting for pod pod-configmaps-a1b45353-8c70-4025-b736-0deab7e6492b to disappear
Nov  4 18:12:02.402: INFO: Pod pod-configmaps-a1b45353-8c70-4025-b736-0deab7e6492b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:12:02.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-913" for this suite.
Nov  4 18:12:08.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:12:08.509: INFO: namespace configmap-913 deletion completed in 6.100712095s

â€¢ [SLOW TEST:8.287 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:12:08.510: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2822
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov  4 18:12:08.670: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2822 /api/v1/namespaces/watch-2822/configmaps/e2e-watch-test-resource-version 1704a5f8-c60a-4219-8afd-40514f1e86cb 16445 0 2019-11-04 18:12:08 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 18:12:08.670: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2822 /api/v1/namespaces/watch-2822/configmaps/e2e-watch-test-resource-version 1704a5f8-c60a-4219-8afd-40514f1e86cb 16446 0 2019-11-04 18:12:08 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:12:08.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2822" for this suite.
Nov  4 18:12:14.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:12:14.759: INFO: namespace watch-2822 deletion completed in 6.085247089s

â€¢ [SLOW TEST:6.249 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:12:14.759: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7993
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:12:14.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6872dd0-2147-45f0-bd69-a7c2f6b7163e" in namespace "downward-api-7993" to be "success or failure"
Nov  4 18:12:14.903: INFO: Pod "downwardapi-volume-e6872dd0-2147-45f0-bd69-a7c2f6b7163e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.324409ms
Nov  4 18:12:16.906: INFO: Pod "downwardapi-volume-e6872dd0-2147-45f0-bd69-a7c2f6b7163e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006943275s
STEP: Saw pod success
Nov  4 18:12:16.906: INFO: Pod "downwardapi-volume-e6872dd0-2147-45f0-bd69-a7c2f6b7163e" satisfied condition "success or failure"
Nov  4 18:12:16.909: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-e6872dd0-2147-45f0-bd69-a7c2f6b7163e container client-container: <nil>
STEP: delete the pod
Nov  4 18:12:16.930: INFO: Waiting for pod downwardapi-volume-e6872dd0-2147-45f0-bd69-a7c2f6b7163e to disappear
Nov  4 18:12:16.938: INFO: Pod downwardapi-volume-e6872dd0-2147-45f0-bd69-a7c2f6b7163e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:12:16.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7993" for this suite.
Nov  4 18:12:22.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:12:23.025: INFO: namespace downward-api-7993 deletion completed in 6.083668634s

â€¢ [SLOW TEST:8.266 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:12:23.027: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-982
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-8a3b234e-daeb-445d-b02b-95fe0eff8b7d
STEP: Creating a pod to test consume secrets
Nov  4 18:12:23.171: INFO: Waiting up to 5m0s for pod "pod-secrets-9eef6495-fc9a-4be3-83ce-13646c49c9a9" in namespace "secrets-982" to be "success or failure"
Nov  4 18:12:23.175: INFO: Pod "pod-secrets-9eef6495-fc9a-4be3-83ce-13646c49c9a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.359005ms
Nov  4 18:12:25.179: INFO: Pod "pod-secrets-9eef6495-fc9a-4be3-83ce-13646c49c9a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007605147s
STEP: Saw pod success
Nov  4 18:12:25.179: INFO: Pod "pod-secrets-9eef6495-fc9a-4be3-83ce-13646c49c9a9" satisfied condition "success or failure"
Nov  4 18:12:25.181: INFO: Trying to get logs from node k8s-1 pod pod-secrets-9eef6495-fc9a-4be3-83ce-13646c49c9a9 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:12:25.198: INFO: Waiting for pod pod-secrets-9eef6495-fc9a-4be3-83ce-13646c49c9a9 to disappear
Nov  4 18:12:25.201: INFO: Pod pod-secrets-9eef6495-fc9a-4be3-83ce-13646c49c9a9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:12:25.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-982" for this suite.
Nov  4 18:12:31.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:12:31.292: INFO: namespace secrets-982 deletion completed in 6.08769646s

â€¢ [SLOW TEST:8.265 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:12:31.292: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4778
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov  4 18:12:31.432: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:12:39.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4778" for this suite.
Nov  4 18:12:45.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:12:45.512: INFO: namespace pods-4778 deletion completed in 6.081189283s

â€¢ [SLOW TEST:14.220 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:12:45.513: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2097
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2097.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2097.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2097.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2097.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2097.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2097.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 18:12:47.705: INFO: DNS probes using dns-2097/dns-test-5f5da63e-e0dd-4235-86fe-9d268820e310 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:12:47.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2097" for this suite.
Nov  4 18:12:53.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:12:53.831: INFO: namespace dns-2097 deletion completed in 6.099078215s

â€¢ [SLOW TEST:8.318 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:12:53.832: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8736
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Nov  4 18:12:53.968: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov  4 18:12:53.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-8736'
Nov  4 18:12:54.186: INFO: stderr: ""
Nov  4 18:12:54.186: INFO: stdout: "service/redis-slave created\n"
Nov  4 18:12:54.186: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov  4 18:12:54.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-8736'
Nov  4 18:12:54.382: INFO: stderr: ""
Nov  4 18:12:54.382: INFO: stdout: "service/redis-master created\n"
Nov  4 18:12:54.382: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov  4 18:12:54.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-8736'
Nov  4 18:12:54.623: INFO: stderr: ""
Nov  4 18:12:54.623: INFO: stdout: "service/frontend created\n"
Nov  4 18:12:54.623: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov  4 18:12:54.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-8736'
Nov  4 18:12:54.881: INFO: stderr: ""
Nov  4 18:12:54.881: INFO: stdout: "deployment.apps/frontend created\n"
Nov  4 18:12:54.881: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  4 18:12:54.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-8736'
Nov  4 18:12:55.071: INFO: stderr: ""
Nov  4 18:12:55.071: INFO: stdout: "deployment.apps/redis-master created\n"
Nov  4 18:12:55.071: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov  4 18:12:55.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-8736'
Nov  4 18:12:55.303: INFO: stderr: ""
Nov  4 18:12:55.303: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Nov  4 18:12:55.303: INFO: Waiting for all frontend pods to be Running.
Nov  4 18:13:15.354: INFO: Waiting for frontend to serve content.
Nov  4 18:13:15.367: INFO: Trying to add a new entry to the guestbook.
Nov  4 18:13:15.384: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Nov  4 18:13:15.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete --grace-period=0 --force -f - --namespace=kubectl-8736'
Nov  4 18:13:15.490: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 18:13:15.491: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 18:13:15.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete --grace-period=0 --force -f - --namespace=kubectl-8736'
Nov  4 18:13:15.610: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 18:13:15.610: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 18:13:15.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete --grace-period=0 --force -f - --namespace=kubectl-8736'
Nov  4 18:13:15.750: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 18:13:15.750: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 18:13:15.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete --grace-period=0 --force -f - --namespace=kubectl-8736'
Nov  4 18:13:15.851: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 18:13:15.851: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 18:13:15.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete --grace-period=0 --force -f - --namespace=kubectl-8736'
Nov  4 18:13:15.922: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 18:13:15.922: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 18:13:15.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete --grace-period=0 --force -f - --namespace=kubectl-8736'
Nov  4 18:13:15.995: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 18:13:15.995: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:13:15.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8736" for this suite.
Nov  4 18:13:22.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:13:22.089: INFO: namespace kubectl-8736 deletion completed in 6.090309937s

â€¢ [SLOW TEST:28.258 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:13:22.091: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:13:28.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9404" for this suite.
Nov  4 18:13:34.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:13:34.319: INFO: namespace job-9404 deletion completed in 6.084886505s

â€¢ [SLOW TEST:12.228 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:13:34.320: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8616
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Nov  4 18:13:34.456: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:13:58.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8616" for this suite.
Nov  4 18:14:04.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:14:05.070: INFO: namespace crd-publish-openapi-8616 deletion completed in 6.102556013s

â€¢ [SLOW TEST:30.750 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:14:05.071: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8772
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov  4 18:14:05.218: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8772 /api/v1/namespaces/watch-8772/configmaps/e2e-watch-test-watch-closed 8b8e26cf-b145-4aef-99c5-c569b0e346d3 17107 0 2019-11-04 18:14:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 18:14:05.218: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8772 /api/v1/namespaces/watch-8772/configmaps/e2e-watch-test-watch-closed 8b8e26cf-b145-4aef-99c5-c569b0e346d3 17108 0 2019-11-04 18:14:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov  4 18:14:05.231: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8772 /api/v1/namespaces/watch-8772/configmaps/e2e-watch-test-watch-closed 8b8e26cf-b145-4aef-99c5-c569b0e346d3 17109 0 2019-11-04 18:14:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 18:14:05.231: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8772 /api/v1/namespaces/watch-8772/configmaps/e2e-watch-test-watch-closed 8b8e26cf-b145-4aef-99c5-c569b0e346d3 17110 0 2019-11-04 18:14:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:14:05.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8772" for this suite.
Nov  4 18:14:11.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:14:11.323: INFO: namespace watch-8772 deletion completed in 6.088733803s

â€¢ [SLOW TEST:6.253 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:14:11.324: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7023
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:14:11.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7023" for this suite.
Nov  4 18:14:17.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:14:17.585: INFO: namespace kubelet-test-7023 deletion completed in 6.091951146s

â€¢ [SLOW TEST:6.262 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:14:17.586: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2214
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-cb46b819-4cce-4c75-84a3-8e2f21d60153
STEP: Creating a pod to test consume configMaps
Nov  4 18:14:17.734: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a8ec063c-f642-4334-a66b-c25e2db5d71e" in namespace "projected-2214" to be "success or failure"
Nov  4 18:14:17.739: INFO: Pod "pod-projected-configmaps-a8ec063c-f642-4334-a66b-c25e2db5d71e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.48231ms
Nov  4 18:14:19.742: INFO: Pod "pod-projected-configmaps-a8ec063c-f642-4334-a66b-c25e2db5d71e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008296993s
STEP: Saw pod success
Nov  4 18:14:19.742: INFO: Pod "pod-projected-configmaps-a8ec063c-f642-4334-a66b-c25e2db5d71e" satisfied condition "success or failure"
Nov  4 18:14:19.745: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-a8ec063c-f642-4334-a66b-c25e2db5d71e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:14:19.772: INFO: Waiting for pod pod-projected-configmaps-a8ec063c-f642-4334-a66b-c25e2db5d71e to disappear
Nov  4 18:14:19.775: INFO: Pod pod-projected-configmaps-a8ec063c-f642-4334-a66b-c25e2db5d71e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:14:19.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2214" for this suite.
Nov  4 18:14:25.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:14:25.861: INFO: namespace projected-2214 deletion completed in 6.082337511s

â€¢ [SLOW TEST:8.274 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:14:25.861: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7360
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 18:14:25.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-7360'
Nov  4 18:14:26.089: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 18:14:26.089: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Nov  4 18:14:28.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete deployment e2e-test-httpd-deployment --namespace=kubectl-7360'
Nov  4 18:14:28.189: INFO: stderr: ""
Nov  4 18:14:28.189: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:14:28.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7360" for this suite.
Nov  4 18:14:56.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:14:56.281: INFO: namespace kubectl-7360 deletion completed in 28.088317369s

â€¢ [SLOW TEST:30.419 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:14:56.281: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5892
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-3e5c3ca0-def9-46d3-a3cb-2fa004783b88
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:14:58.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5892" for this suite.
Nov  4 18:15:10.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:15:10.546: INFO: namespace configmap-5892 deletion completed in 12.088897139s

â€¢ [SLOW TEST:14.265 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:15:10.547: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8068
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:15:11.263: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 18:15:13.272: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488111, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488111, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488111, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488111, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:15:16.283: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:15:16.287: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7093-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:15:22.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8068" for this suite.
Nov  4 18:15:28.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:15:28.538: INFO: namespace webhook-8068 deletion completed in 6.088115379s
STEP: Destroying namespace "webhook-8068-markers" for this suite.
Nov  4 18:15:34.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:15:34.625: INFO: namespace webhook-8068-markers deletion completed in 6.087087275s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:24.092 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:15:34.639: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6185
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Nov  4 18:15:34.789: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-430892974 proxy --unix-socket=/tmp/kubectl-proxy-unix926932965/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:15:34.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6185" for this suite.
Nov  4 18:15:40.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:15:40.934: INFO: namespace kubectl-6185 deletion completed in 6.088894853s

â€¢ [SLOW TEST:6.295 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:15:40.935: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9622
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  4 18:15:41.081: INFO: Waiting up to 5m0s for pod "pod-cb104ea6-902e-4e2c-aec0-c362abff7c34" in namespace "emptydir-9622" to be "success or failure"
Nov  4 18:15:41.086: INFO: Pod "pod-cb104ea6-902e-4e2c-aec0-c362abff7c34": Phase="Pending", Reason="", readiness=false. Elapsed: 5.601489ms
Nov  4 18:15:43.089: INFO: Pod "pod-cb104ea6-902e-4e2c-aec0-c362abff7c34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008705119s
STEP: Saw pod success
Nov  4 18:15:43.090: INFO: Pod "pod-cb104ea6-902e-4e2c-aec0-c362abff7c34" satisfied condition "success or failure"
Nov  4 18:15:43.092: INFO: Trying to get logs from node k8s-1 pod pod-cb104ea6-902e-4e2c-aec0-c362abff7c34 container test-container: <nil>
STEP: delete the pod
Nov  4 18:15:43.111: INFO: Waiting for pod pod-cb104ea6-902e-4e2c-aec0-c362abff7c34 to disappear
Nov  4 18:15:43.115: INFO: Pod pod-cb104ea6-902e-4e2c-aec0-c362abff7c34 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:15:43.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9622" for this suite.
Nov  4 18:15:49.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:15:49.222: INFO: namespace emptydir-9622 deletion completed in 6.103932147s

â€¢ [SLOW TEST:8.287 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:15:49.224: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-552
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-552
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-552 to expose endpoints map[]
Nov  4 18:15:49.380: INFO: Get endpoints failed (12.496851ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Nov  4 18:15:50.382: INFO: successfully validated that service endpoint-test2 in namespace services-552 exposes endpoints map[] (1.015338211s elapsed)
STEP: Creating pod pod1 in namespace services-552
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-552 to expose endpoints map[pod1:[80]]
Nov  4 18:15:52.407: INFO: successfully validated that service endpoint-test2 in namespace services-552 exposes endpoints map[pod1:[80]] (2.017973818s elapsed)
STEP: Creating pod pod2 in namespace services-552
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-552 to expose endpoints map[pod1:[80] pod2:[80]]
Nov  4 18:15:54.438: INFO: successfully validated that service endpoint-test2 in namespace services-552 exposes endpoints map[pod1:[80] pod2:[80]] (2.026322575s elapsed)
STEP: Deleting pod pod1 in namespace services-552
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-552 to expose endpoints map[pod2:[80]]
Nov  4 18:15:55.462: INFO: successfully validated that service endpoint-test2 in namespace services-552 exposes endpoints map[pod2:[80]] (1.018747223s elapsed)
STEP: Deleting pod pod2 in namespace services-552
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-552 to expose endpoints map[]
Nov  4 18:15:56.473: INFO: successfully validated that service endpoint-test2 in namespace services-552 exposes endpoints map[] (1.006698271s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:15:56.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-552" for this suite.
Nov  4 18:16:02.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:16:02.601: INFO: namespace services-552 deletion completed in 6.097655172s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:13.377 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:16:02.601: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7536
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:16:18.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7536" for this suite.
Nov  4 18:16:24.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:16:24.876: INFO: namespace resourcequota-7536 deletion completed in 6.088600343s

â€¢ [SLOW TEST:22.275 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:16:24.877: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3020
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:16:25.019: INFO: (0) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.677682ms)
Nov  4 18:16:25.022: INFO: (1) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.908818ms)
Nov  4 18:16:25.025: INFO: (2) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.819521ms)
Nov  4 18:16:25.028: INFO: (3) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.426798ms)
Nov  4 18:16:25.031: INFO: (4) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.583683ms)
Nov  4 18:16:25.034: INFO: (5) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.942827ms)
Nov  4 18:16:25.037: INFO: (6) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.294308ms)
Nov  4 18:16:25.040: INFO: (7) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.858932ms)
Nov  4 18:16:25.043: INFO: (8) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.866552ms)
Nov  4 18:16:25.046: INFO: (9) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.017413ms)
Nov  4 18:16:25.050: INFO: (10) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.240231ms)
Nov  4 18:16:25.053: INFO: (11) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.898805ms)
Nov  4 18:16:25.056: INFO: (12) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.072925ms)
Nov  4 18:16:25.058: INFO: (13) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.63529ms)
Nov  4 18:16:25.061: INFO: (14) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.930831ms)
Nov  4 18:16:25.064: INFO: (15) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.928537ms)
Nov  4 18:16:25.068: INFO: (16) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.765253ms)
Nov  4 18:16:25.071: INFO: (17) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.970612ms)
Nov  4 18:16:25.075: INFO: (18) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.150884ms)
Nov  4 18:16:25.077: INFO: (19) /api/v1/nodes/k8s-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.605657ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:16:25.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3020" for this suite.
Nov  4 18:16:31.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:16:31.167: INFO: namespace proxy-3020 deletion completed in 6.087322777s

â€¢ [SLOW TEST:6.291 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:16:31.168: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3067
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 18:16:31.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-3067'
Nov  4 18:16:31.453: INFO: stderr: ""
Nov  4 18:16:31.453: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Nov  4 18:16:31.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete pods e2e-test-httpd-pod --namespace=kubectl-3067'
Nov  4 18:16:39.425: INFO: stderr: ""
Nov  4 18:16:39.425: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:16:39.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3067" for this suite.
Nov  4 18:16:45.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:16:45.515: INFO: namespace kubectl-3067 deletion completed in 6.086486542s

â€¢ [SLOW TEST:14.348 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:16:45.516: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6362
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-087cf5a1-44ed-4d97-8939-e914bf76d7dc
STEP: Creating secret with name s-test-opt-upd-ded16f73-fa2b-4932-87ee-6a248fadc2a3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-087cf5a1-44ed-4d97-8939-e914bf76d7dc
STEP: Updating secret s-test-opt-upd-ded16f73-fa2b-4932-87ee-6a248fadc2a3
STEP: Creating secret with name s-test-opt-create-c19e7e05-069f-4a67-8795-a8ae9fee82ef
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:16:51.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6362" for this suite.
Nov  4 18:17:15.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:17:15.853: INFO: namespace secrets-6362 deletion completed in 24.088379604s

â€¢ [SLOW TEST:30.337 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:17:15.856: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5271
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5271
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Nov  4 18:17:16.004: INFO: Found 0 stateful pods, waiting for 3
Nov  4 18:17:26.007: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 18:17:26.007: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 18:17:26.007: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov  4 18:17:26.031: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov  4 18:17:36.059: INFO: Updating stateful set ss2
Nov  4 18:17:36.077: INFO: Waiting for Pod statefulset-5271/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Nov  4 18:17:46.128: INFO: Found 1 stateful pods, waiting for 3
Nov  4 18:17:56.131: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 18:17:56.132: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 18:17:56.132: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov  4 18:17:56.153: INFO: Updating stateful set ss2
Nov  4 18:17:56.159: INFO: Waiting for Pod statefulset-5271/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  4 18:18:06.182: INFO: Updating stateful set ss2
Nov  4 18:18:06.191: INFO: Waiting for StatefulSet statefulset-5271/ss2 to complete update
Nov  4 18:18:06.191: INFO: Waiting for Pod statefulset-5271/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 18:18:16.196: INFO: Deleting all statefulset in ns statefulset-5271
Nov  4 18:18:16.199: INFO: Scaling statefulset ss2 to 0
Nov  4 18:18:56.211: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 18:18:56.214: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:18:56.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5271" for this suite.
Nov  4 18:19:02.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:19:02.325: INFO: namespace statefulset-5271 deletion completed in 6.092325032s

â€¢ [SLOW TEST:106.470 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:19:02.326: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2165
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:19:02.467: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:19:08.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2165" for this suite.
Nov  4 18:19:14.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:19:14.142: INFO: namespace custom-resource-definition-2165 deletion completed in 6.101581247s

â€¢ [SLOW TEST:11.816 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:19:14.143: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2648
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-bf0661fd-6402-4123-9f40-1e59fdeabe56
STEP: Creating a pod to test consume configMaps
Nov  4 18:19:14.287: INFO: Waiting up to 5m0s for pod "pod-configmaps-3f0313d3-3b72-4e41-b3bd-0aea112c2c1c" in namespace "configmap-2648" to be "success or failure"
Nov  4 18:19:14.292: INFO: Pod "pod-configmaps-3f0313d3-3b72-4e41-b3bd-0aea112c2c1c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.917466ms
Nov  4 18:19:16.295: INFO: Pod "pod-configmaps-3f0313d3-3b72-4e41-b3bd-0aea112c2c1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007775817s
STEP: Saw pod success
Nov  4 18:19:16.295: INFO: Pod "pod-configmaps-3f0313d3-3b72-4e41-b3bd-0aea112c2c1c" satisfied condition "success or failure"
Nov  4 18:19:16.297: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-3f0313d3-3b72-4e41-b3bd-0aea112c2c1c container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:19:16.323: INFO: Waiting for pod pod-configmaps-3f0313d3-3b72-4e41-b3bd-0aea112c2c1c to disappear
Nov  4 18:19:16.325: INFO: Pod pod-configmaps-3f0313d3-3b72-4e41-b3bd-0aea112c2c1c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:19:16.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2648" for this suite.
Nov  4 18:19:22.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:19:22.468: INFO: namespace configmap-2648 deletion completed in 6.139919539s

â€¢ [SLOW TEST:8.325 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:19:22.469: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1656
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:19:22.639: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-7d2e9972-9a3b-40f1-8d43-4dc667c413ca" in namespace "security-context-test-1656" to be "success or failure"
Nov  4 18:19:22.641: INFO: Pod "alpine-nnp-false-7d2e9972-9a3b-40f1-8d43-4dc667c413ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.314685ms
Nov  4 18:19:24.644: INFO: Pod "alpine-nnp-false-7d2e9972-9a3b-40f1-8d43-4dc667c413ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005430147s
Nov  4 18:19:26.647: INFO: Pod "alpine-nnp-false-7d2e9972-9a3b-40f1-8d43-4dc667c413ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008666541s
Nov  4 18:19:26.648: INFO: Pod "alpine-nnp-false-7d2e9972-9a3b-40f1-8d43-4dc667c413ca" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:19:26.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1656" for this suite.
Nov  4 18:19:32.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:19:32.754: INFO: namespace security-context-test-1656 deletion completed in 6.097125953s

â€¢ [SLOW TEST:10.286 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:19:32.755: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-8243
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8243
I1104 18:19:32.909855      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8243, replica count: 1
I1104 18:19:33.960267      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 18:19:34.073: INFO: Created: latency-svc-rvw2n
Nov  4 18:19:34.078: INFO: Got endpoints: latency-svc-rvw2n [17.660623ms]
Nov  4 18:19:34.096: INFO: Created: latency-svc-nfsqt
Nov  4 18:19:34.100: INFO: Got endpoints: latency-svc-nfsqt [22.368495ms]
Nov  4 18:19:34.104: INFO: Created: latency-svc-8sp7h
Nov  4 18:19:34.109: INFO: Got endpoints: latency-svc-8sp7h [29.86147ms]
Nov  4 18:19:34.114: INFO: Created: latency-svc-knlwh
Nov  4 18:19:34.118: INFO: Got endpoints: latency-svc-knlwh [39.943732ms]
Nov  4 18:19:34.123: INFO: Created: latency-svc-k4z9m
Nov  4 18:19:34.129: INFO: Got endpoints: latency-svc-k4z9m [51.092306ms]
Nov  4 18:19:34.133: INFO: Created: latency-svc-nzjt6
Nov  4 18:19:34.139: INFO: Got endpoints: latency-svc-nzjt6 [61.01131ms]
Nov  4 18:19:34.142: INFO: Created: latency-svc-5r8n8
Nov  4 18:19:34.146: INFO: Got endpoints: latency-svc-5r8n8 [67.959596ms]
Nov  4 18:19:34.149: INFO: Created: latency-svc-wdz5j
Nov  4 18:19:34.157: INFO: Got endpoints: latency-svc-wdz5j [78.309451ms]
Nov  4 18:19:34.158: INFO: Created: latency-svc-xtrr4
Nov  4 18:19:34.163: INFO: Got endpoints: latency-svc-xtrr4 [84.344919ms]
Nov  4 18:19:34.169: INFO: Created: latency-svc-gg592
Nov  4 18:19:34.175: INFO: Got endpoints: latency-svc-gg592 [96.584544ms]
Nov  4 18:19:34.178: INFO: Created: latency-svc-m54k4
Nov  4 18:19:34.184: INFO: Got endpoints: latency-svc-m54k4 [104.785416ms]
Nov  4 18:19:34.185: INFO: Created: latency-svc-p7c5x
Nov  4 18:19:34.206: INFO: Got endpoints: latency-svc-p7c5x [127.292852ms]
Nov  4 18:19:34.232: INFO: Created: latency-svc-cpdxd
Nov  4 18:19:34.238: INFO: Got endpoints: latency-svc-cpdxd [159.304719ms]
Nov  4 18:19:34.240: INFO: Created: latency-svc-8ksxn
Nov  4 18:19:34.248: INFO: Created: latency-svc-9ddvg
Nov  4 18:19:34.257: INFO: Got endpoints: latency-svc-9ddvg [177.924281ms]
Nov  4 18:19:34.260: INFO: Got endpoints: latency-svc-8ksxn [180.63439ms]
Nov  4 18:19:34.270: INFO: Created: latency-svc-jw8dd
Nov  4 18:19:34.273: INFO: Created: latency-svc-m92hk
Nov  4 18:19:34.277: INFO: Got endpoints: latency-svc-jw8dd [197.299316ms]
Nov  4 18:19:34.281: INFO: Created: latency-svc-pvmvw
Nov  4 18:19:34.285: INFO: Got endpoints: latency-svc-m92hk [185.177202ms]
Nov  4 18:19:34.292: INFO: Got endpoints: latency-svc-pvmvw [183.064411ms]
Nov  4 18:19:34.294: INFO: Created: latency-svc-gb4sk
Nov  4 18:19:34.304: INFO: Created: latency-svc-f69j6
Nov  4 18:19:34.306: INFO: Got endpoints: latency-svc-gb4sk [188.39219ms]
Nov  4 18:19:34.309: INFO: Got endpoints: latency-svc-f69j6 [179.994586ms]
Nov  4 18:19:34.320: INFO: Created: latency-svc-47rvc
Nov  4 18:19:34.320: INFO: Got endpoints: latency-svc-47rvc [180.60637ms]
Nov  4 18:19:34.332: INFO: Created: latency-svc-rlglg
Nov  4 18:19:34.332: INFO: Got endpoints: latency-svc-rlglg [185.727668ms]
Nov  4 18:19:34.338: INFO: Created: latency-svc-f2hmp
Nov  4 18:19:34.343: INFO: Got endpoints: latency-svc-f2hmp [186.233853ms]
Nov  4 18:19:34.348: INFO: Created: latency-svc-skz7c
Nov  4 18:19:34.354: INFO: Got endpoints: latency-svc-skz7c [190.968463ms]
Nov  4 18:19:34.359: INFO: Created: latency-svc-hgwjx
Nov  4 18:19:34.365: INFO: Got endpoints: latency-svc-hgwjx [189.300556ms]
Nov  4 18:19:34.369: INFO: Created: latency-svc-jkbzg
Nov  4 18:19:34.374: INFO: Got endpoints: latency-svc-jkbzg [190.094251ms]
Nov  4 18:19:34.377: INFO: Created: latency-svc-58lt7
Nov  4 18:19:34.381: INFO: Got endpoints: latency-svc-58lt7 [174.924765ms]
Nov  4 18:19:34.386: INFO: Created: latency-svc-6fj6g
Nov  4 18:19:34.391: INFO: Got endpoints: latency-svc-6fj6g [152.139324ms]
Nov  4 18:19:34.395: INFO: Created: latency-svc-x95t7
Nov  4 18:19:34.402: INFO: Got endpoints: latency-svc-x95t7 [20.726342ms]
Nov  4 18:19:34.404: INFO: Created: latency-svc-ptmfr
Nov  4 18:19:34.409: INFO: Got endpoints: latency-svc-ptmfr [151.601239ms]
Nov  4 18:19:34.413: INFO: Created: latency-svc-qhc7h
Nov  4 18:19:34.419: INFO: Got endpoints: latency-svc-qhc7h [159.198096ms]
Nov  4 18:19:34.422: INFO: Created: latency-svc-6jrkp
Nov  4 18:19:34.428: INFO: Got endpoints: latency-svc-6jrkp [151.398183ms]
Nov  4 18:19:34.433: INFO: Created: latency-svc-mh6nl
Nov  4 18:19:34.439: INFO: Got endpoints: latency-svc-mh6nl [153.89518ms]
Nov  4 18:19:34.443: INFO: Created: latency-svc-cxjwf
Nov  4 18:19:34.446: INFO: Got endpoints: latency-svc-cxjwf [153.336896ms]
Nov  4 18:19:34.451: INFO: Created: latency-svc-s4jn7
Nov  4 18:19:34.459: INFO: Got endpoints: latency-svc-s4jn7 [152.691007ms]
Nov  4 18:19:34.464: INFO: Created: latency-svc-n68pj
Nov  4 18:19:34.468: INFO: Got endpoints: latency-svc-n68pj [158.477614ms]
Nov  4 18:19:34.471: INFO: Created: latency-svc-lpdzb
Nov  4 18:19:34.474: INFO: Got endpoints: latency-svc-lpdzb [153.747254ms]
Nov  4 18:19:34.479: INFO: Created: latency-svc-vk76h
Nov  4 18:19:34.486: INFO: Got endpoints: latency-svc-vk76h [153.370509ms]
Nov  4 18:19:34.487: INFO: Created: latency-svc-69bq5
Nov  4 18:19:34.494: INFO: Created: latency-svc-45lg5
Nov  4 18:19:34.502: INFO: Created: latency-svc-w2hgr
Nov  4 18:19:34.509: INFO: Created: latency-svc-vkhzf
Nov  4 18:19:34.517: INFO: Created: latency-svc-xwngs
Nov  4 18:19:34.524: INFO: Created: latency-svc-5hph7
Nov  4 18:19:34.530: INFO: Got endpoints: latency-svc-69bq5 [186.50265ms]
Nov  4 18:19:34.536: INFO: Created: latency-svc-9rsrj
Nov  4 18:19:34.540: INFO: Created: latency-svc-78czr
Nov  4 18:19:34.547: INFO: Created: latency-svc-dgvfn
Nov  4 18:19:34.552: INFO: Created: latency-svc-kqlbf
Nov  4 18:19:34.559: INFO: Created: latency-svc-4747c
Nov  4 18:19:34.563: INFO: Created: latency-svc-p6b4d
Nov  4 18:19:34.569: INFO: Created: latency-svc-rkrgm
Nov  4 18:19:34.577: INFO: Got endpoints: latency-svc-45lg5 [222.525343ms]
Nov  4 18:19:34.579: INFO: Created: latency-svc-dgh4z
Nov  4 18:19:34.586: INFO: Created: latency-svc-txk67
Nov  4 18:19:34.593: INFO: Created: latency-svc-nrjwf
Nov  4 18:19:34.599: INFO: Created: latency-svc-9m8vt
Nov  4 18:19:34.625: INFO: Got endpoints: latency-svc-w2hgr [260.555572ms]
Nov  4 18:19:34.633: INFO: Created: latency-svc-6km5w
Nov  4 18:19:34.675: INFO: Got endpoints: latency-svc-vkhzf [301.074973ms]
Nov  4 18:19:34.682: INFO: Created: latency-svc-v4vv5
Nov  4 18:19:34.726: INFO: Got endpoints: latency-svc-xwngs [334.920932ms]
Nov  4 18:19:34.734: INFO: Created: latency-svc-w6th6
Nov  4 18:19:34.776: INFO: Got endpoints: latency-svc-5hph7 [374.303679ms]
Nov  4 18:19:34.787: INFO: Created: latency-svc-hnscl
Nov  4 18:19:34.826: INFO: Got endpoints: latency-svc-9rsrj [417.441029ms]
Nov  4 18:19:34.837: INFO: Created: latency-svc-sfv2c
Nov  4 18:19:34.876: INFO: Got endpoints: latency-svc-78czr [456.86531ms]
Nov  4 18:19:34.884: INFO: Created: latency-svc-n688g
Nov  4 18:19:34.925: INFO: Got endpoints: latency-svc-dgvfn [497.008747ms]
Nov  4 18:19:34.932: INFO: Created: latency-svc-vkz22
Nov  4 18:19:34.975: INFO: Got endpoints: latency-svc-kqlbf [535.932521ms]
Nov  4 18:19:34.983: INFO: Created: latency-svc-hz8b9
Nov  4 18:19:35.025: INFO: Got endpoints: latency-svc-4747c [579.297552ms]
Nov  4 18:19:35.033: INFO: Created: latency-svc-brz2x
Nov  4 18:19:35.075: INFO: Got endpoints: latency-svc-p6b4d [615.890308ms]
Nov  4 18:19:35.082: INFO: Created: latency-svc-gr977
Nov  4 18:19:35.126: INFO: Got endpoints: latency-svc-rkrgm [657.958745ms]
Nov  4 18:19:35.136: INFO: Created: latency-svc-xtjdl
Nov  4 18:19:35.175: INFO: Got endpoints: latency-svc-dgh4z [701.072369ms]
Nov  4 18:19:35.183: INFO: Created: latency-svc-2dksz
Nov  4 18:19:35.225: INFO: Got endpoints: latency-svc-txk67 [739.501875ms]
Nov  4 18:19:35.232: INFO: Created: latency-svc-b5ks6
Nov  4 18:19:35.276: INFO: Got endpoints: latency-svc-nrjwf [745.905436ms]
Nov  4 18:19:35.283: INFO: Created: latency-svc-2b4qt
Nov  4 18:19:35.325: INFO: Got endpoints: latency-svc-9m8vt [748.689812ms]
Nov  4 18:19:35.334: INFO: Created: latency-svc-6jhqt
Nov  4 18:19:35.376: INFO: Got endpoints: latency-svc-6km5w [750.433042ms]
Nov  4 18:19:35.384: INFO: Created: latency-svc-hxshc
Nov  4 18:19:35.425: INFO: Got endpoints: latency-svc-v4vv5 [750.283317ms]
Nov  4 18:19:35.434: INFO: Created: latency-svc-dgtqq
Nov  4 18:19:35.476: INFO: Got endpoints: latency-svc-w6th6 [750.105039ms]
Nov  4 18:19:35.484: INFO: Created: latency-svc-ndctq
Nov  4 18:19:35.526: INFO: Got endpoints: latency-svc-hnscl [749.205845ms]
Nov  4 18:19:35.533: INFO: Created: latency-svc-tbbjs
Nov  4 18:19:35.576: INFO: Got endpoints: latency-svc-sfv2c [749.653249ms]
Nov  4 18:19:35.591: INFO: Created: latency-svc-rjb6b
Nov  4 18:19:35.636: INFO: Got endpoints: latency-svc-n688g [759.520283ms]
Nov  4 18:19:35.645: INFO: Created: latency-svc-b7r7m
Nov  4 18:19:35.681: INFO: Got endpoints: latency-svc-vkz22 [755.886234ms]
Nov  4 18:19:35.696: INFO: Created: latency-svc-nw6m8
Nov  4 18:19:35.727: INFO: Got endpoints: latency-svc-hz8b9 [751.979516ms]
Nov  4 18:19:35.738: INFO: Created: latency-svc-6wld8
Nov  4 18:19:35.775: INFO: Got endpoints: latency-svc-brz2x [749.986711ms]
Nov  4 18:19:35.784: INFO: Created: latency-svc-mfb9n
Nov  4 18:19:35.826: INFO: Got endpoints: latency-svc-gr977 [750.7661ms]
Nov  4 18:19:35.834: INFO: Created: latency-svc-88g2v
Nov  4 18:19:35.876: INFO: Got endpoints: latency-svc-xtjdl [749.794474ms]
Nov  4 18:19:35.883: INFO: Created: latency-svc-4vlbw
Nov  4 18:19:35.925: INFO: Got endpoints: latency-svc-2dksz [750.386116ms]
Nov  4 18:19:35.935: INFO: Created: latency-svc-x9gdn
Nov  4 18:19:35.976: INFO: Got endpoints: latency-svc-b5ks6 [750.946352ms]
Nov  4 18:19:35.985: INFO: Created: latency-svc-26576
Nov  4 18:19:36.025: INFO: Got endpoints: latency-svc-2b4qt [749.627932ms]
Nov  4 18:19:36.033: INFO: Created: latency-svc-nls9v
Nov  4 18:19:36.076: INFO: Got endpoints: latency-svc-6jhqt [749.982887ms]
Nov  4 18:19:36.084: INFO: Created: latency-svc-2wnx7
Nov  4 18:19:36.126: INFO: Got endpoints: latency-svc-hxshc [749.735174ms]
Nov  4 18:19:36.139: INFO: Created: latency-svc-nm9x6
Nov  4 18:19:36.175: INFO: Got endpoints: latency-svc-dgtqq [750.005255ms]
Nov  4 18:19:36.184: INFO: Created: latency-svc-wkt5c
Nov  4 18:19:36.225: INFO: Got endpoints: latency-svc-ndctq [749.624357ms]
Nov  4 18:19:36.234: INFO: Created: latency-svc-cgs98
Nov  4 18:19:36.276: INFO: Got endpoints: latency-svc-tbbjs [750.677164ms]
Nov  4 18:19:36.287: INFO: Created: latency-svc-grtx2
Nov  4 18:19:36.325: INFO: Got endpoints: latency-svc-rjb6b [749.258608ms]
Nov  4 18:19:36.333: INFO: Created: latency-svc-76ptc
Nov  4 18:19:36.375: INFO: Got endpoints: latency-svc-b7r7m [739.634624ms]
Nov  4 18:19:36.384: INFO: Created: latency-svc-gw6s9
Nov  4 18:19:36.426: INFO: Got endpoints: latency-svc-nw6m8 [744.522139ms]
Nov  4 18:19:36.434: INFO: Created: latency-svc-5xjq4
Nov  4 18:19:36.476: INFO: Got endpoints: latency-svc-6wld8 [747.96668ms]
Nov  4 18:19:36.483: INFO: Created: latency-svc-xw88p
Nov  4 18:19:36.525: INFO: Got endpoints: latency-svc-mfb9n [749.838014ms]
Nov  4 18:19:36.534: INFO: Created: latency-svc-jkjqz
Nov  4 18:19:36.575: INFO: Got endpoints: latency-svc-88g2v [748.899661ms]
Nov  4 18:19:36.583: INFO: Created: latency-svc-s2msx
Nov  4 18:19:36.626: INFO: Got endpoints: latency-svc-4vlbw [749.793773ms]
Nov  4 18:19:36.633: INFO: Created: latency-svc-dbgms
Nov  4 18:19:36.676: INFO: Got endpoints: latency-svc-x9gdn [750.64684ms]
Nov  4 18:19:36.684: INFO: Created: latency-svc-msccz
Nov  4 18:19:36.725: INFO: Got endpoints: latency-svc-26576 [748.752067ms]
Nov  4 18:19:36.732: INFO: Created: latency-svc-5h2gd
Nov  4 18:19:36.776: INFO: Got endpoints: latency-svc-nls9v [749.968233ms]
Nov  4 18:19:36.782: INFO: Created: latency-svc-868rk
Nov  4 18:19:36.825: INFO: Got endpoints: latency-svc-2wnx7 [749.786632ms]
Nov  4 18:19:36.834: INFO: Created: latency-svc-jrwrr
Nov  4 18:19:36.875: INFO: Got endpoints: latency-svc-nm9x6 [749.4404ms]
Nov  4 18:19:36.883: INFO: Created: latency-svc-6vfgk
Nov  4 18:19:36.925: INFO: Got endpoints: latency-svc-wkt5c [749.347599ms]
Nov  4 18:19:36.932: INFO: Created: latency-svc-k2cqf
Nov  4 18:19:36.975: INFO: Got endpoints: latency-svc-cgs98 [749.838605ms]
Nov  4 18:19:36.984: INFO: Created: latency-svc-k9lks
Nov  4 18:19:37.025: INFO: Got endpoints: latency-svc-grtx2 [748.832351ms]
Nov  4 18:19:37.033: INFO: Created: latency-svc-7hqhp
Nov  4 18:19:37.075: INFO: Got endpoints: latency-svc-76ptc [749.618862ms]
Nov  4 18:19:37.083: INFO: Created: latency-svc-hmt6w
Nov  4 18:19:37.125: INFO: Got endpoints: latency-svc-gw6s9 [749.947035ms]
Nov  4 18:19:37.133: INFO: Created: latency-svc-k5nsl
Nov  4 18:19:37.175: INFO: Got endpoints: latency-svc-5xjq4 [749.387861ms]
Nov  4 18:19:37.182: INFO: Created: latency-svc-6qr4g
Nov  4 18:19:37.225: INFO: Got endpoints: latency-svc-xw88p [749.735267ms]
Nov  4 18:19:37.233: INFO: Created: latency-svc-qlp8x
Nov  4 18:19:37.276: INFO: Got endpoints: latency-svc-jkjqz [750.287325ms]
Nov  4 18:19:37.284: INFO: Created: latency-svc-c8dqr
Nov  4 18:19:37.325: INFO: Got endpoints: latency-svc-s2msx [750.375842ms]
Nov  4 18:19:37.333: INFO: Created: latency-svc-gcz66
Nov  4 18:19:37.375: INFO: Got endpoints: latency-svc-dbgms [749.750729ms]
Nov  4 18:19:37.384: INFO: Created: latency-svc-wmxj7
Nov  4 18:19:37.425: INFO: Got endpoints: latency-svc-msccz [748.970134ms]
Nov  4 18:19:37.433: INFO: Created: latency-svc-trgh4
Nov  4 18:19:37.476: INFO: Got endpoints: latency-svc-5h2gd [750.598636ms]
Nov  4 18:19:37.483: INFO: Created: latency-svc-7cljq
Nov  4 18:19:37.526: INFO: Got endpoints: latency-svc-868rk [750.14267ms]
Nov  4 18:19:37.533: INFO: Created: latency-svc-z256z
Nov  4 18:19:37.575: INFO: Got endpoints: latency-svc-jrwrr [749.583202ms]
Nov  4 18:19:37.584: INFO: Created: latency-svc-787s8
Nov  4 18:19:37.626: INFO: Got endpoints: latency-svc-6vfgk [750.394082ms]
Nov  4 18:19:37.633: INFO: Created: latency-svc-gd6jg
Nov  4 18:19:37.676: INFO: Got endpoints: latency-svc-k2cqf [750.746725ms]
Nov  4 18:19:37.683: INFO: Created: latency-svc-bs78r
Nov  4 18:19:37.726: INFO: Got endpoints: latency-svc-k9lks [750.219174ms]
Nov  4 18:19:37.734: INFO: Created: latency-svc-z5qnt
Nov  4 18:19:37.776: INFO: Got endpoints: latency-svc-7hqhp [750.431698ms]
Nov  4 18:19:37.784: INFO: Created: latency-svc-dhzwv
Nov  4 18:19:37.825: INFO: Got endpoints: latency-svc-hmt6w [750.240515ms]
Nov  4 18:19:37.833: INFO: Created: latency-svc-lcd9t
Nov  4 18:19:37.876: INFO: Got endpoints: latency-svc-k5nsl [750.437626ms]
Nov  4 18:19:37.885: INFO: Created: latency-svc-5bfvm
Nov  4 18:19:37.926: INFO: Got endpoints: latency-svc-6qr4g [750.442788ms]
Nov  4 18:19:37.934: INFO: Created: latency-svc-lqbf2
Nov  4 18:19:37.975: INFO: Got endpoints: latency-svc-qlp8x [749.894261ms]
Nov  4 18:19:37.983: INFO: Created: latency-svc-ktvmz
Nov  4 18:19:38.025: INFO: Got endpoints: latency-svc-c8dqr [749.576365ms]
Nov  4 18:19:38.034: INFO: Created: latency-svc-qhpkq
Nov  4 18:19:38.076: INFO: Got endpoints: latency-svc-gcz66 [750.320135ms]
Nov  4 18:19:38.083: INFO: Created: latency-svc-sdshz
Nov  4 18:19:38.125: INFO: Got endpoints: latency-svc-wmxj7 [749.64945ms]
Nov  4 18:19:38.133: INFO: Created: latency-svc-gcz9s
Nov  4 18:19:38.175: INFO: Got endpoints: latency-svc-trgh4 [749.732365ms]
Nov  4 18:19:38.185: INFO: Created: latency-svc-98w7v
Nov  4 18:19:38.226: INFO: Got endpoints: latency-svc-7cljq [749.902812ms]
Nov  4 18:19:38.233: INFO: Created: latency-svc-7r8tm
Nov  4 18:19:38.275: INFO: Got endpoints: latency-svc-z256z [749.576436ms]
Nov  4 18:19:38.283: INFO: Created: latency-svc-kj8t4
Nov  4 18:19:38.325: INFO: Got endpoints: latency-svc-787s8 [749.979927ms]
Nov  4 18:19:38.348: INFO: Created: latency-svc-l6mjd
Nov  4 18:19:38.376: INFO: Got endpoints: latency-svc-gd6jg [749.866387ms]
Nov  4 18:19:38.384: INFO: Created: latency-svc-v42kh
Nov  4 18:19:38.425: INFO: Got endpoints: latency-svc-bs78r [749.062258ms]
Nov  4 18:19:38.432: INFO: Created: latency-svc-4psgb
Nov  4 18:19:38.475: INFO: Got endpoints: latency-svc-z5qnt [749.457098ms]
Nov  4 18:19:38.484: INFO: Created: latency-svc-hv5tp
Nov  4 18:19:38.526: INFO: Got endpoints: latency-svc-dhzwv [750.486516ms]
Nov  4 18:19:38.534: INFO: Created: latency-svc-dcc4p
Nov  4 18:19:38.576: INFO: Got endpoints: latency-svc-lcd9t [750.005796ms]
Nov  4 18:19:38.584: INFO: Created: latency-svc-c2s9d
Nov  4 18:19:38.625: INFO: Got endpoints: latency-svc-5bfvm [749.470231ms]
Nov  4 18:19:38.634: INFO: Created: latency-svc-lk7bs
Nov  4 18:19:38.675: INFO: Got endpoints: latency-svc-lqbf2 [749.587175ms]
Nov  4 18:19:38.683: INFO: Created: latency-svc-vm74g
Nov  4 18:19:38.725: INFO: Got endpoints: latency-svc-ktvmz [749.928679ms]
Nov  4 18:19:38.733: INFO: Created: latency-svc-m4ww2
Nov  4 18:19:38.775: INFO: Got endpoints: latency-svc-qhpkq [749.952944ms]
Nov  4 18:19:38.783: INFO: Created: latency-svc-cmsqh
Nov  4 18:19:38.825: INFO: Got endpoints: latency-svc-sdshz [749.457023ms]
Nov  4 18:19:38.834: INFO: Created: latency-svc-v2c2w
Nov  4 18:19:38.876: INFO: Got endpoints: latency-svc-gcz9s [750.567753ms]
Nov  4 18:19:38.884: INFO: Created: latency-svc-xt4t4
Nov  4 18:19:38.926: INFO: Got endpoints: latency-svc-98w7v [751.125262ms]
Nov  4 18:19:38.937: INFO: Created: latency-svc-8xpz7
Nov  4 18:19:38.975: INFO: Got endpoints: latency-svc-7r8tm [749.630925ms]
Nov  4 18:19:38.983: INFO: Created: latency-svc-2qrdt
Nov  4 18:19:39.025: INFO: Got endpoints: latency-svc-kj8t4 [749.589181ms]
Nov  4 18:19:39.037: INFO: Created: latency-svc-snn9r
Nov  4 18:19:39.082: INFO: Got endpoints: latency-svc-l6mjd [757.120485ms]
Nov  4 18:19:39.102: INFO: Created: latency-svc-x2g4x
Nov  4 18:19:39.125: INFO: Got endpoints: latency-svc-v42kh [749.136271ms]
Nov  4 18:19:39.133: INFO: Created: latency-svc-z56vm
Nov  4 18:19:39.175: INFO: Got endpoints: latency-svc-4psgb [750.027315ms]
Nov  4 18:19:39.183: INFO: Created: latency-svc-4tkbl
Nov  4 18:19:39.226: INFO: Got endpoints: latency-svc-hv5tp [750.335247ms]
Nov  4 18:19:39.233: INFO: Created: latency-svc-5mrhb
Nov  4 18:19:39.275: INFO: Got endpoints: latency-svc-dcc4p [748.6284ms]
Nov  4 18:19:39.283: INFO: Created: latency-svc-2sqrs
Nov  4 18:19:39.325: INFO: Got endpoints: latency-svc-c2s9d [749.348296ms]
Nov  4 18:19:39.333: INFO: Created: latency-svc-4qhvq
Nov  4 18:19:39.375: INFO: Got endpoints: latency-svc-lk7bs [749.876461ms]
Nov  4 18:19:39.383: INFO: Created: latency-svc-m5wbs
Nov  4 18:19:39.426: INFO: Got endpoints: latency-svc-vm74g [750.099532ms]
Nov  4 18:19:39.434: INFO: Created: latency-svc-zw6cr
Nov  4 18:19:39.476: INFO: Got endpoints: latency-svc-m4ww2 [750.373995ms]
Nov  4 18:19:39.485: INFO: Created: latency-svc-78lhv
Nov  4 18:19:39.525: INFO: Got endpoints: latency-svc-cmsqh [749.949576ms]
Nov  4 18:19:39.533: INFO: Created: latency-svc-l459m
Nov  4 18:19:39.576: INFO: Got endpoints: latency-svc-v2c2w [751.005069ms]
Nov  4 18:19:39.585: INFO: Created: latency-svc-h5pk4
Nov  4 18:19:39.625: INFO: Got endpoints: latency-svc-xt4t4 [749.286405ms]
Nov  4 18:19:39.633: INFO: Created: latency-svc-c2w6d
Nov  4 18:19:39.679: INFO: Got endpoints: latency-svc-8xpz7 [753.123673ms]
Nov  4 18:19:39.699: INFO: Created: latency-svc-mz29b
Nov  4 18:19:39.728: INFO: Got endpoints: latency-svc-2qrdt [752.703262ms]
Nov  4 18:19:39.741: INFO: Created: latency-svc-rm6cc
Nov  4 18:19:39.776: INFO: Got endpoints: latency-svc-snn9r [750.561555ms]
Nov  4 18:19:39.784: INFO: Created: latency-svc-8bb6f
Nov  4 18:19:39.826: INFO: Got endpoints: latency-svc-x2g4x [743.042793ms]
Nov  4 18:19:39.833: INFO: Created: latency-svc-rww65
Nov  4 18:19:39.876: INFO: Got endpoints: latency-svc-z56vm [750.868044ms]
Nov  4 18:19:39.883: INFO: Created: latency-svc-vlfm8
Nov  4 18:19:39.926: INFO: Got endpoints: latency-svc-4tkbl [750.672536ms]
Nov  4 18:19:39.935: INFO: Created: latency-svc-n2h9k
Nov  4 18:19:39.975: INFO: Got endpoints: latency-svc-5mrhb [749.381583ms]
Nov  4 18:19:39.983: INFO: Created: latency-svc-jcmdx
Nov  4 18:19:40.026: INFO: Got endpoints: latency-svc-2sqrs [750.297761ms]
Nov  4 18:19:40.034: INFO: Created: latency-svc-dd8qr
Nov  4 18:19:40.075: INFO: Got endpoints: latency-svc-4qhvq [749.977374ms]
Nov  4 18:19:40.084: INFO: Created: latency-svc-h6scm
Nov  4 18:19:40.126: INFO: Got endpoints: latency-svc-m5wbs [750.546578ms]
Nov  4 18:19:40.133: INFO: Created: latency-svc-69hhh
Nov  4 18:19:40.176: INFO: Got endpoints: latency-svc-zw6cr [750.438111ms]
Nov  4 18:19:40.184: INFO: Created: latency-svc-q5nz9
Nov  4 18:19:40.230: INFO: Got endpoints: latency-svc-78lhv [754.345716ms]
Nov  4 18:19:40.239: INFO: Created: latency-svc-8j8nl
Nov  4 18:19:40.276: INFO: Got endpoints: latency-svc-l459m [750.823918ms]
Nov  4 18:19:40.291: INFO: Created: latency-svc-nd94f
Nov  4 18:19:40.326: INFO: Got endpoints: latency-svc-h5pk4 [749.417757ms]
Nov  4 18:19:40.334: INFO: Created: latency-svc-fbx88
Nov  4 18:19:40.375: INFO: Got endpoints: latency-svc-c2w6d [749.736994ms]
Nov  4 18:19:40.384: INFO: Created: latency-svc-f9t9j
Nov  4 18:19:40.425: INFO: Got endpoints: latency-svc-mz29b [745.869787ms]
Nov  4 18:19:40.433: INFO: Created: latency-svc-292zx
Nov  4 18:19:40.476: INFO: Got endpoints: latency-svc-rm6cc [747.467893ms]
Nov  4 18:19:40.484: INFO: Created: latency-svc-kjws9
Nov  4 18:19:40.525: INFO: Got endpoints: latency-svc-8bb6f [749.698688ms]
Nov  4 18:19:40.536: INFO: Created: latency-svc-xjrdt
Nov  4 18:19:40.576: INFO: Got endpoints: latency-svc-rww65 [749.95025ms]
Nov  4 18:19:40.583: INFO: Created: latency-svc-hvbt5
Nov  4 18:19:40.626: INFO: Got endpoints: latency-svc-vlfm8 [749.732631ms]
Nov  4 18:19:40.633: INFO: Created: latency-svc-hzd9r
Nov  4 18:19:40.675: INFO: Got endpoints: latency-svc-n2h9k [749.105798ms]
Nov  4 18:19:40.684: INFO: Created: latency-svc-fgb9x
Nov  4 18:19:40.726: INFO: Got endpoints: latency-svc-jcmdx [750.597757ms]
Nov  4 18:19:40.733: INFO: Created: latency-svc-zwfcr
Nov  4 18:19:40.776: INFO: Got endpoints: latency-svc-dd8qr [749.960704ms]
Nov  4 18:19:40.784: INFO: Created: latency-svc-vx4jd
Nov  4 18:19:40.825: INFO: Got endpoints: latency-svc-h6scm [750.089449ms]
Nov  4 18:19:40.834: INFO: Created: latency-svc-h4z6t
Nov  4 18:19:40.876: INFO: Got endpoints: latency-svc-69hhh [750.371032ms]
Nov  4 18:19:40.884: INFO: Created: latency-svc-wvqc9
Nov  4 18:19:40.926: INFO: Got endpoints: latency-svc-q5nz9 [749.660911ms]
Nov  4 18:19:40.935: INFO: Created: latency-svc-prsqt
Nov  4 18:19:40.976: INFO: Got endpoints: latency-svc-8j8nl [745.742126ms]
Nov  4 18:19:40.985: INFO: Created: latency-svc-p8wxz
Nov  4 18:19:41.036: INFO: Got endpoints: latency-svc-nd94f [759.197077ms]
Nov  4 18:19:41.043: INFO: Created: latency-svc-vkg9h
Nov  4 18:19:41.076: INFO: Got endpoints: latency-svc-fbx88 [749.74021ms]
Nov  4 18:19:41.084: INFO: Created: latency-svc-bfj5c
Nov  4 18:19:41.125: INFO: Got endpoints: latency-svc-f9t9j [749.94768ms]
Nov  4 18:19:41.135: INFO: Created: latency-svc-mkb5b
Nov  4 18:19:41.176: INFO: Got endpoints: latency-svc-292zx [750.146526ms]
Nov  4 18:19:41.183: INFO: Created: latency-svc-ldnwx
Nov  4 18:19:41.226: INFO: Got endpoints: latency-svc-kjws9 [750.254406ms]
Nov  4 18:19:41.243: INFO: Created: latency-svc-dbxvl
Nov  4 18:19:41.276: INFO: Got endpoints: latency-svc-xjrdt [749.905991ms]
Nov  4 18:19:41.285: INFO: Created: latency-svc-vm854
Nov  4 18:19:41.326: INFO: Got endpoints: latency-svc-hvbt5 [749.937829ms]
Nov  4 18:19:41.333: INFO: Created: latency-svc-2vvtg
Nov  4 18:19:41.377: INFO: Got endpoints: latency-svc-hzd9r [750.757276ms]
Nov  4 18:19:41.386: INFO: Created: latency-svc-7sm9d
Nov  4 18:19:41.426: INFO: Got endpoints: latency-svc-fgb9x [750.349668ms]
Nov  4 18:19:41.435: INFO: Created: latency-svc-gkwvm
Nov  4 18:19:41.475: INFO: Got endpoints: latency-svc-zwfcr [749.446289ms]
Nov  4 18:19:41.483: INFO: Created: latency-svc-4cz86
Nov  4 18:19:41.525: INFO: Got endpoints: latency-svc-vx4jd [749.606634ms]
Nov  4 18:19:41.533: INFO: Created: latency-svc-rz4d8
Nov  4 18:19:41.576: INFO: Got endpoints: latency-svc-h4z6t [750.312961ms]
Nov  4 18:19:41.584: INFO: Created: latency-svc-v59zn
Nov  4 18:19:41.625: INFO: Got endpoints: latency-svc-wvqc9 [748.899236ms]
Nov  4 18:19:41.632: INFO: Created: latency-svc-q4wbg
Nov  4 18:19:41.676: INFO: Got endpoints: latency-svc-prsqt [749.877117ms]
Nov  4 18:19:41.684: INFO: Created: latency-svc-v4cwm
Nov  4 18:19:41.725: INFO: Got endpoints: latency-svc-p8wxz [749.423153ms]
Nov  4 18:19:41.735: INFO: Created: latency-svc-x6vl5
Nov  4 18:19:41.775: INFO: Got endpoints: latency-svc-vkg9h [739.575303ms]
Nov  4 18:19:41.783: INFO: Created: latency-svc-hgvlw
Nov  4 18:19:41.826: INFO: Got endpoints: latency-svc-bfj5c [750.014585ms]
Nov  4 18:19:41.835: INFO: Created: latency-svc-rg9tg
Nov  4 18:19:41.876: INFO: Got endpoints: latency-svc-mkb5b [750.013511ms]
Nov  4 18:19:41.885: INFO: Created: latency-svc-7ngds
Nov  4 18:19:41.926: INFO: Got endpoints: latency-svc-ldnwx [750.188221ms]
Nov  4 18:19:41.976: INFO: Got endpoints: latency-svc-dbxvl [749.868136ms]
Nov  4 18:19:42.026: INFO: Got endpoints: latency-svc-vm854 [749.961596ms]
Nov  4 18:19:42.076: INFO: Got endpoints: latency-svc-2vvtg [750.09697ms]
Nov  4 18:19:42.126: INFO: Got endpoints: latency-svc-7sm9d [749.078276ms]
Nov  4 18:19:42.176: INFO: Got endpoints: latency-svc-gkwvm [750.047093ms]
Nov  4 18:19:42.226: INFO: Got endpoints: latency-svc-4cz86 [750.161032ms]
Nov  4 18:19:42.276: INFO: Got endpoints: latency-svc-rz4d8 [750.6465ms]
Nov  4 18:19:42.326: INFO: Got endpoints: latency-svc-v59zn [750.278298ms]
Nov  4 18:19:42.376: INFO: Got endpoints: latency-svc-q4wbg [750.740251ms]
Nov  4 18:19:42.427: INFO: Got endpoints: latency-svc-v4cwm [750.728177ms]
Nov  4 18:19:42.476: INFO: Got endpoints: latency-svc-x6vl5 [750.302391ms]
Nov  4 18:19:42.526: INFO: Got endpoints: latency-svc-hgvlw [750.680099ms]
Nov  4 18:19:42.576: INFO: Got endpoints: latency-svc-rg9tg [749.980458ms]
Nov  4 18:19:42.625: INFO: Got endpoints: latency-svc-7ngds [749.27386ms]
Nov  4 18:19:42.625: INFO: Latencies: [20.726342ms 22.368495ms 29.86147ms 39.943732ms 51.092306ms 61.01131ms 67.959596ms 78.309451ms 84.344919ms 96.584544ms 104.785416ms 127.292852ms 151.398183ms 151.601239ms 152.139324ms 152.691007ms 153.336896ms 153.370509ms 153.747254ms 153.89518ms 158.477614ms 159.198096ms 159.304719ms 174.924765ms 177.924281ms 179.994586ms 180.60637ms 180.63439ms 183.064411ms 185.177202ms 185.727668ms 186.233853ms 186.50265ms 188.39219ms 189.300556ms 190.094251ms 190.968463ms 197.299316ms 222.525343ms 260.555572ms 301.074973ms 334.920932ms 374.303679ms 417.441029ms 456.86531ms 497.008747ms 535.932521ms 579.297552ms 615.890308ms 657.958745ms 701.072369ms 739.501875ms 739.575303ms 739.634624ms 743.042793ms 744.522139ms 745.742126ms 745.869787ms 745.905436ms 747.467893ms 747.96668ms 748.6284ms 748.689812ms 748.752067ms 748.832351ms 748.899236ms 748.899661ms 748.970134ms 749.062258ms 749.078276ms 749.105798ms 749.136271ms 749.205845ms 749.258608ms 749.27386ms 749.286405ms 749.347599ms 749.348296ms 749.381583ms 749.387861ms 749.417757ms 749.423153ms 749.4404ms 749.446289ms 749.457023ms 749.457098ms 749.470231ms 749.576365ms 749.576436ms 749.583202ms 749.587175ms 749.589181ms 749.606634ms 749.618862ms 749.624357ms 749.627932ms 749.630925ms 749.64945ms 749.653249ms 749.660911ms 749.698688ms 749.732365ms 749.732631ms 749.735174ms 749.735267ms 749.736994ms 749.74021ms 749.750729ms 749.786632ms 749.793773ms 749.794474ms 749.838014ms 749.838605ms 749.866387ms 749.868136ms 749.876461ms 749.877117ms 749.894261ms 749.902812ms 749.905991ms 749.928679ms 749.937829ms 749.947035ms 749.94768ms 749.949576ms 749.95025ms 749.952944ms 749.960704ms 749.961596ms 749.968233ms 749.977374ms 749.979927ms 749.980458ms 749.982887ms 749.986711ms 750.005255ms 750.005796ms 750.013511ms 750.014585ms 750.027315ms 750.047093ms 750.089449ms 750.09697ms 750.099532ms 750.105039ms 750.14267ms 750.146526ms 750.161032ms 750.188221ms 750.219174ms 750.240515ms 750.254406ms 750.278298ms 750.283317ms 750.287325ms 750.297761ms 750.302391ms 750.312961ms 750.320135ms 750.335247ms 750.349668ms 750.371032ms 750.373995ms 750.375842ms 750.386116ms 750.394082ms 750.431698ms 750.433042ms 750.437626ms 750.438111ms 750.442788ms 750.486516ms 750.546578ms 750.561555ms 750.567753ms 750.597757ms 750.598636ms 750.6465ms 750.64684ms 750.672536ms 750.677164ms 750.680099ms 750.728177ms 750.740251ms 750.746725ms 750.757276ms 750.7661ms 750.823918ms 750.868044ms 750.946352ms 751.005069ms 751.125262ms 751.979516ms 752.703262ms 753.123673ms 754.345716ms 755.886234ms 757.120485ms 759.197077ms 759.520283ms]
Nov  4 18:19:42.625: INFO: 50 %ile: 749.698688ms
Nov  4 18:19:42.625: INFO: 90 %ile: 750.677164ms
Nov  4 18:19:42.625: INFO: 99 %ile: 759.197077ms
Nov  4 18:19:42.626: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:19:42.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8243" for this suite.
Nov  4 18:20:04.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:20:04.718: INFO: namespace svc-latency-8243 deletion completed in 22.088688013s

â€¢ [SLOW TEST:31.963 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:20:04.718: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9308
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:20:04.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9308" for this suite.
Nov  4 18:20:10.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:20:10.952: INFO: namespace services-9308 deletion completed in 6.092155947s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:6.234 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:20:10.953: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4438
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:20:11.100: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c91ec989-f94c-415f-bafd-b4ce67f6f9d1" in namespace "downward-api-4438" to be "success or failure"
Nov  4 18:20:11.105: INFO: Pod "downwardapi-volume-c91ec989-f94c-415f-bafd-b4ce67f6f9d1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.106866ms
Nov  4 18:20:13.108: INFO: Pod "downwardapi-volume-c91ec989-f94c-415f-bafd-b4ce67f6f9d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008495168s
STEP: Saw pod success
Nov  4 18:20:13.108: INFO: Pod "downwardapi-volume-c91ec989-f94c-415f-bafd-b4ce67f6f9d1" satisfied condition "success or failure"
Nov  4 18:20:13.111: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-c91ec989-f94c-415f-bafd-b4ce67f6f9d1 container client-container: <nil>
STEP: delete the pod
Nov  4 18:20:13.128: INFO: Waiting for pod downwardapi-volume-c91ec989-f94c-415f-bafd-b4ce67f6f9d1 to disappear
Nov  4 18:20:13.130: INFO: Pod downwardapi-volume-c91ec989-f94c-415f-bafd-b4ce67f6f9d1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:20:13.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4438" for this suite.
Nov  4 18:20:19.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:20:19.237: INFO: namespace downward-api-4438 deletion completed in 6.102423829s

â€¢ [SLOW TEST:8.285 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:20:19.238: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9575
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:20:19.384: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov  4 18:20:24.387: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  4 18:20:24.388: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 18:20:24.405: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9575 /apis/apps/v1/namespaces/deployment-9575/deployments/test-cleanup-deployment d993fe7d-9171-4f6d-93a3-8d8685c47e48 19879 1 2019-11-04 18:20:24 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0034b28f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Nov  4 18:20:24.408: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-9575 /apis/apps/v1/namespaces/deployment-9575/replicasets/test-cleanup-deployment-65db99849b 9e3223bd-bc28-4e66-8edc-eef41aa995ed 19881 1 2019-11-04 18:20:24 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment d993fe7d-9171-4f6d-93a3-8d8685c47e48 0xc0034b3507 0xc0034b3508}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0034b3568 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 18:20:24.408: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov  4 18:20:24.408: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-9575 /apis/apps/v1/namespaces/deployment-9575/replicasets/test-cleanup-controller 5b548a50-34d9-4f6a-b606-ee6b943e7f01 19880 1 2019-11-04 18:20:19 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment d993fe7d-9171-4f6d-93a3-8d8685c47e48 0xc0034b2c87 0xc0034b2c88}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0034b2ce8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  4 18:20:24.412: INFO: Pod "test-cleanup-controller-w2r9n" is available:
&Pod{ObjectMeta:{test-cleanup-controller-w2r9n test-cleanup-controller- deployment-9575 /api/v1/namespaces/deployment-9575/pods/test-cleanup-controller-w2r9n 38b7e5c5-2fec-46ed-92a9-358b783659b6 19870 0 2019-11-04 18:20:19 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 5b548a50-34d9-4f6a-b606-ee6b943e7f01 0xc0034b3a57 0xc0034b3a58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4nlfv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4nlfv,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4nlfv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:20:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:20:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:20:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.0.205,StartTime:2019-11-04 18:20:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 18:20:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://ba9ff42b04e284605f0357938c8f20ee3d232686df60226f3f43c40fdf2d5954,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.205,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:20:24.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9575" for this suite.
Nov  4 18:20:30.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:20:30.508: INFO: namespace deployment-9575 deletion completed in 6.091841609s

â€¢ [SLOW TEST:11.270 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:20:30.509: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2665
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:20:31.359: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 18:20:33.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488431, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488431, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488431, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488431, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:20:36.384: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Nov  4 18:20:36.403: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:20:36.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2665" for this suite.
Nov  4 18:20:42.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:20:42.508: INFO: namespace webhook-2665 deletion completed in 6.086487606s
STEP: Destroying namespace "webhook-2665-markers" for this suite.
Nov  4 18:20:48.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:20:48.599: INFO: namespace webhook-2665-markers deletion completed in 6.091210249s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:18.103 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:20:48.613: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4898
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-c663d291-04cb-41f2-864a-759da0298907
STEP: Creating a pod to test consume configMaps
Nov  4 18:20:48.760: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-610a4a7a-3c08-4ef3-be04-c47a5be85e1f" in namespace "projected-4898" to be "success or failure"
Nov  4 18:20:48.763: INFO: Pod "pod-projected-configmaps-610a4a7a-3c08-4ef3-be04-c47a5be85e1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.915911ms
Nov  4 18:20:50.766: INFO: Pod "pod-projected-configmaps-610a4a7a-3c08-4ef3-be04-c47a5be85e1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005777066s
STEP: Saw pod success
Nov  4 18:20:50.766: INFO: Pod "pod-projected-configmaps-610a4a7a-3c08-4ef3-be04-c47a5be85e1f" satisfied condition "success or failure"
Nov  4 18:20:50.768: INFO: Trying to get logs from node k8s-1 pod pod-projected-configmaps-610a4a7a-3c08-4ef3-be04-c47a5be85e1f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:20:50.786: INFO: Waiting for pod pod-projected-configmaps-610a4a7a-3c08-4ef3-be04-c47a5be85e1f to disappear
Nov  4 18:20:50.794: INFO: Pod pod-projected-configmaps-610a4a7a-3c08-4ef3-be04-c47a5be85e1f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:20:50.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4898" for this suite.
Nov  4 18:20:56.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:20:56.897: INFO: namespace projected-4898 deletion completed in 6.098175301s

â€¢ [SLOW TEST:8.285 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:20:56.899: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3966
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 18:20:57.048: INFO: Waiting up to 5m0s for pod "downward-api-b0c20f82-6739-47d2-ad2c-bfff6614748b" in namespace "downward-api-3966" to be "success or failure"
Nov  4 18:20:57.053: INFO: Pod "downward-api-b0c20f82-6739-47d2-ad2c-bfff6614748b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.713069ms
Nov  4 18:20:59.056: INFO: Pod "downward-api-b0c20f82-6739-47d2-ad2c-bfff6614748b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007629988s
STEP: Saw pod success
Nov  4 18:20:59.056: INFO: Pod "downward-api-b0c20f82-6739-47d2-ad2c-bfff6614748b" satisfied condition "success or failure"
Nov  4 18:20:59.059: INFO: Trying to get logs from node k8s-1 pod downward-api-b0c20f82-6739-47d2-ad2c-bfff6614748b container dapi-container: <nil>
STEP: delete the pod
Nov  4 18:20:59.084: INFO: Waiting for pod downward-api-b0c20f82-6739-47d2-ad2c-bfff6614748b to disappear
Nov  4 18:20:59.088: INFO: Pod downward-api-b0c20f82-6739-47d2-ad2c-bfff6614748b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:20:59.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3966" for this suite.
Nov  4 18:21:05.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:21:05.177: INFO: namespace downward-api-3966 deletion completed in 6.085352263s

â€¢ [SLOW TEST:8.277 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:21:05.177: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5958
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:21:05.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5958" for this suite.
Nov  4 18:21:11.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:21:11.439: INFO: namespace resourcequota-5958 deletion completed in 6.097415738s

â€¢ [SLOW TEST:6.262 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:21:11.441: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:21:11.610: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-6f3071bf-c532-4fd4-b045-c1a90595f40a" in namespace "security-context-test-5113" to be "success or failure"
Nov  4 18:21:11.613: INFO: Pod "busybox-readonly-false-6f3071bf-c532-4fd4-b045-c1a90595f40a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.353984ms
Nov  4 18:21:13.616: INFO: Pod "busybox-readonly-false-6f3071bf-c532-4fd4-b045-c1a90595f40a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006499178s
Nov  4 18:21:13.616: INFO: Pod "busybox-readonly-false-6f3071bf-c532-4fd4-b045-c1a90595f40a" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:21:13.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5113" for this suite.
Nov  4 18:21:19.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:21:19.727: INFO: namespace security-context-test-5113 deletion completed in 6.106992417s

â€¢ [SLOW TEST:8.286 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:21:19.728: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:21:19.876: INFO: Waiting up to 5m0s for pod "downwardapi-volume-acf72450-4977-4c8e-b530-ad2ba27e20ba" in namespace "projected-6849" to be "success or failure"
Nov  4 18:21:19.882: INFO: Pod "downwardapi-volume-acf72450-4977-4c8e-b530-ad2ba27e20ba": Phase="Pending", Reason="", readiness=false. Elapsed: 5.955322ms
Nov  4 18:21:21.886: INFO: Pod "downwardapi-volume-acf72450-4977-4c8e-b530-ad2ba27e20ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009100717s
STEP: Saw pod success
Nov  4 18:21:21.886: INFO: Pod "downwardapi-volume-acf72450-4977-4c8e-b530-ad2ba27e20ba" satisfied condition "success or failure"
Nov  4 18:21:21.888: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-acf72450-4977-4c8e-b530-ad2ba27e20ba container client-container: <nil>
STEP: delete the pod
Nov  4 18:21:21.905: INFO: Waiting for pod downwardapi-volume-acf72450-4977-4c8e-b530-ad2ba27e20ba to disappear
Nov  4 18:21:21.909: INFO: Pod downwardapi-volume-acf72450-4977-4c8e-b530-ad2ba27e20ba no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:21:21.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6849" for this suite.
Nov  4 18:21:27.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:21:28.000: INFO: namespace projected-6849 deletion completed in 6.088032981s

â€¢ [SLOW TEST:8.273 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:21:28.001: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7093
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Nov  4 18:21:28.144: INFO: Waiting up to 5m0s for pod "pod-bdacb783-a14d-4d03-bf29-cded3951efdf" in namespace "emptydir-7093" to be "success or failure"
Nov  4 18:21:28.147: INFO: Pod "pod-bdacb783-a14d-4d03-bf29-cded3951efdf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.177539ms
Nov  4 18:21:30.150: INFO: Pod "pod-bdacb783-a14d-4d03-bf29-cded3951efdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006444425s
STEP: Saw pod success
Nov  4 18:21:30.151: INFO: Pod "pod-bdacb783-a14d-4d03-bf29-cded3951efdf" satisfied condition "success or failure"
Nov  4 18:21:30.153: INFO: Trying to get logs from node k8s-1 pod pod-bdacb783-a14d-4d03-bf29-cded3951efdf container test-container: <nil>
STEP: delete the pod
Nov  4 18:21:30.175: INFO: Waiting for pod pod-bdacb783-a14d-4d03-bf29-cded3951efdf to disappear
Nov  4 18:21:30.178: INFO: Pod pod-bdacb783-a14d-4d03-bf29-cded3951efdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:21:30.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7093" for this suite.
Nov  4 18:21:36.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:21:36.267: INFO: namespace emptydir-7093 deletion completed in 6.085155973s

â€¢ [SLOW TEST:8.266 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:21:36.269: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-449
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:21:47.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-449" for this suite.
Nov  4 18:21:53.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:21:53.580: INFO: namespace resourcequota-449 deletion completed in 6.090295792s

â€¢ [SLOW TEST:17.312 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:21:53.581: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3194
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 18:21:53.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3194'
Nov  4 18:21:53.798: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 18:21:53.798: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Nov  4 18:21:53.805: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov  4 18:21:53.816: INFO: scanned /root for discovery docs: <nil>
Nov  4 18:21:53.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-3194'
Nov  4 18:22:09.604: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  4 18:22:09.604: INFO: stdout: "Created e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f\nScaling up e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Nov  4 18:22:09.604: INFO: stdout: "Created e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f\nScaling up e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Nov  4 18:22:09.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-3194'
Nov  4 18:22:09.682: INFO: stderr: ""
Nov  4 18:22:09.683: INFO: stdout: "e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f-wrvm5 "
Nov  4 18:22:09.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f-wrvm5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3194'
Nov  4 18:22:09.753: INFO: stderr: ""
Nov  4 18:22:09.753: INFO: stdout: "true"
Nov  4 18:22:09.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pods e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f-wrvm5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3194'
Nov  4 18:22:09.823: INFO: stderr: ""
Nov  4 18:22:09.823: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Nov  4 18:22:09.823: INFO: e2e-test-httpd-rc-8bd2c0d8978b09759a5420bdd881bb9f-wrvm5 is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Nov  4 18:22:09.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete rc e2e-test-httpd-rc --namespace=kubectl-3194'
Nov  4 18:22:09.904: INFO: stderr: ""
Nov  4 18:22:09.904: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:22:09.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3194" for this suite.
Nov  4 18:22:15.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:22:16.005: INFO: namespace kubectl-3194 deletion completed in 6.097491712s

â€¢ [SLOW TEST:22.425 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:22:16.006: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4975
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 18:22:16.141: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 18:22:16.151: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 18:22:16.154: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Nov  4 18:22:16.158: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-lpskk from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:22:16.158: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:22:16.158: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 18:22:16.158: INFO: kube-flannel-ds-amd64-bls8m from kube-system started at 2019-11-04 17:23:59 +0000 UTC (1 container statuses recorded)
Nov  4 18:22:16.158: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 18:22:16.158: INFO: traefik-ingress-controller-mccsj from kube-system started at 2019-11-04 17:23:59 +0000 UTC (1 container statuses recorded)
Nov  4 18:22:16.158: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 18:22:16.158: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Nov  4 18:22:16.172: INFO: sonobuoy-e2e-job-281da138127b42b3 from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:22:16.172: INFO: 	Container e2e ready: true, restart count 0
Nov  4 18:22:16.172: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 18:22:16.172: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-k67sr from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:22:16.172: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:22:16.172: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 18:22:16.172: INFO: coredns-b7f8c8654-4rcsc from kube-system started at 2019-11-04 17:23:27 +0000 UTC (1 container statuses recorded)
Nov  4 18:22:16.172: INFO: 	Container coredns ready: true, restart count 0
Nov  4 18:22:16.172: INFO: kube-flannel-ds-amd64-c6xnw from kube-system started at 2019-11-04 16:58:52 +0000 UTC (1 container statuses recorded)
Nov  4 18:22:16.172: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 18:22:16.172: INFO: traefik-ingress-controller-qqfzz from kube-system started at 2019-11-04 16:58:54 +0000 UTC (1 container statuses recorded)
Nov  4 18:22:16.172: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 18:22:16.172: INFO: sonobuoy from sonobuoy started at 2019-11-04 16:59:51 +0000 UTC (1 container statuses recorded)
Nov  4 18:22:16.172: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 18:22:16.172: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Nov  4 18:22:16.186: INFO: kube-flannel-ds-amd64-s2gr4 from kube-system started at 2019-11-04 17:14:19 +0000 UTC (1 container statuses recorded)
Nov  4 18:22:16.186: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 18:22:16.186: INFO: traefik-ingress-controller-98f8s from kube-system started at 2019-11-04 17:13:49 +0000 UTC (1 container statuses recorded)
Nov  4 18:22:16.186: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 18:22:16.186: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-vkd6f from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:22:16.186: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:22:16.186: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 18:22:16.186: INFO: coredns-b7f8c8654-68j25 from kube-system started at 2019-11-04 17:13:42 +0000 UTC (1 container statuses recorded)
Nov  4 18:22:16.186: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d408b3568c8620], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d408b357280380], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:22:17.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4975" for this suite.
Nov  4 18:22:23.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:22:23.303: INFO: namespace sched-pred-4975 deletion completed in 6.092951891s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:7.298 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:22:23.304: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4179
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:22:34.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4179" for this suite.
Nov  4 18:22:40.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:22:40.561: INFO: namespace resourcequota-4179 deletion completed in 6.085353569s

â€¢ [SLOW TEST:17.257 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:22:40.561: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6842
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6842
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-6842
Nov  4 18:22:40.714: INFO: Found 0 stateful pods, waiting for 1
Nov  4 18:22:50.718: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 18:22:50.737: INFO: Deleting all statefulset in ns statefulset-6842
Nov  4 18:22:50.740: INFO: Scaling statefulset ss to 0
Nov  4 18:23:00.755: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 18:23:00.758: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:23:00.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6842" for this suite.
Nov  4 18:23:06.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:23:06.864: INFO: namespace statefulset-6842 deletion completed in 6.088835566s

â€¢ [SLOW TEST:26.303 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:23:06.864: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9279
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  4 18:23:07.009: INFO: Waiting up to 5m0s for pod "pod-662a585d-6015-4fd3-8706-7661831a5d19" in namespace "emptydir-9279" to be "success or failure"
Nov  4 18:23:07.011: INFO: Pod "pod-662a585d-6015-4fd3-8706-7661831a5d19": Phase="Pending", Reason="", readiness=false. Elapsed: 2.27392ms
Nov  4 18:23:09.014: INFO: Pod "pod-662a585d-6015-4fd3-8706-7661831a5d19": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004922038s
STEP: Saw pod success
Nov  4 18:23:09.014: INFO: Pod "pod-662a585d-6015-4fd3-8706-7661831a5d19" satisfied condition "success or failure"
Nov  4 18:23:09.022: INFO: Trying to get logs from node k8s-1 pod pod-662a585d-6015-4fd3-8706-7661831a5d19 container test-container: <nil>
STEP: delete the pod
Nov  4 18:23:09.041: INFO: Waiting for pod pod-662a585d-6015-4fd3-8706-7661831a5d19 to disappear
Nov  4 18:23:09.045: INFO: Pod pod-662a585d-6015-4fd3-8706-7661831a5d19 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:23:09.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9279" for this suite.
Nov  4 18:23:15.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:23:15.131: INFO: namespace emptydir-9279 deletion completed in 6.082658467s

â€¢ [SLOW TEST:8.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:23:15.132: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-154
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-154/secret-test-4d3b7560-a4cc-48d4-8936-09b78365659f
STEP: Creating a pod to test consume secrets
Nov  4 18:23:15.292: INFO: Waiting up to 5m0s for pod "pod-configmaps-b15238fb-ab61-45ab-a9b4-24bb00e74110" in namespace "secrets-154" to be "success or failure"
Nov  4 18:23:15.297: INFO: Pod "pod-configmaps-b15238fb-ab61-45ab-a9b4-24bb00e74110": Phase="Pending", Reason="", readiness=false. Elapsed: 4.408042ms
Nov  4 18:23:17.299: INFO: Pod "pod-configmaps-b15238fb-ab61-45ab-a9b4-24bb00e74110": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007077813s
STEP: Saw pod success
Nov  4 18:23:17.299: INFO: Pod "pod-configmaps-b15238fb-ab61-45ab-a9b4-24bb00e74110" satisfied condition "success or failure"
Nov  4 18:23:17.302: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-b15238fb-ab61-45ab-a9b4-24bb00e74110 container env-test: <nil>
STEP: delete the pod
Nov  4 18:23:17.321: INFO: Waiting for pod pod-configmaps-b15238fb-ab61-45ab-a9b4-24bb00e74110 to disappear
Nov  4 18:23:17.325: INFO: Pod pod-configmaps-b15238fb-ab61-45ab-a9b4-24bb00e74110 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:23:17.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-154" for this suite.
Nov  4 18:23:23.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:23:23.425: INFO: namespace secrets-154 deletion completed in 6.096109207s

â€¢ [SLOW TEST:8.293 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:23:23.426: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3581
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:23:24.170: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:23:27.186: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:23:27.188: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Registering the custom resource webhook via the AdmissionRegistration API
Nov  4 18:23:32.801: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:23:33.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3581" for this suite.
Nov  4 18:23:39.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:23:39.600: INFO: namespace webhook-3581 deletion completed in 6.090441147s
STEP: Destroying namespace "webhook-3581-markers" for this suite.
Nov  4 18:23:45.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:23:45.681: INFO: namespace webhook-3581-markers deletion completed in 6.081566401s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:22.269 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:23:45.697: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6037
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 18:23:45.835: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 18:23:45.845: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 18:23:45.848: INFO: 
Logging pods the kubelet thinks is on node k8s-1 before test
Nov  4 18:23:45.852: INFO: kube-flannel-ds-amd64-bls8m from kube-system started at 2019-11-04 17:23:59 +0000 UTC (1 container statuses recorded)
Nov  4 18:23:45.852: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 18:23:45.852: INFO: traefik-ingress-controller-mccsj from kube-system started at 2019-11-04 17:23:59 +0000 UTC (1 container statuses recorded)
Nov  4 18:23:45.853: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 18:23:45.853: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-lpskk from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:23:45.853: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:23:45.853: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 18:23:45.853: INFO: 
Logging pods the kubelet thinks is on node k8s-2 before test
Nov  4 18:23:45.858: INFO: sonobuoy-e2e-job-281da138127b42b3 from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:23:45.858: INFO: 	Container e2e ready: true, restart count 0
Nov  4 18:23:45.858: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 18:23:45.858: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-k67sr from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:23:45.858: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:23:45.858: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 18:23:45.858: INFO: coredns-b7f8c8654-4rcsc from kube-system started at 2019-11-04 17:23:27 +0000 UTC (1 container statuses recorded)
Nov  4 18:23:45.858: INFO: 	Container coredns ready: true, restart count 0
Nov  4 18:23:45.858: INFO: kube-flannel-ds-amd64-c6xnw from kube-system started at 2019-11-04 16:58:52 +0000 UTC (1 container statuses recorded)
Nov  4 18:23:45.858: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 18:23:45.858: INFO: traefik-ingress-controller-qqfzz from kube-system started at 2019-11-04 16:58:54 +0000 UTC (1 container statuses recorded)
Nov  4 18:23:45.858: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
Nov  4 18:23:45.858: INFO: sonobuoy from sonobuoy started at 2019-11-04 16:59:51 +0000 UTC (1 container statuses recorded)
Nov  4 18:23:45.858: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 18:23:45.858: INFO: 
Logging pods the kubelet thinks is on node k8s-3 before test
Nov  4 18:23:45.863: INFO: sonobuoy-systemd-logs-daemon-set-23fc508521714957-vkd6f from sonobuoy started at 2019-11-04 16:59:55 +0000 UTC (2 container statuses recorded)
Nov  4 18:23:45.863: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:23:45.863: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 18:23:45.863: INFO: coredns-b7f8c8654-68j25 from kube-system started at 2019-11-04 17:13:42 +0000 UTC (1 container statuses recorded)
Nov  4 18:23:45.863: INFO: 	Container coredns ready: true, restart count 0
Nov  4 18:23:45.863: INFO: kube-flannel-ds-amd64-s2gr4 from kube-system started at 2019-11-04 17:14:19 +0000 UTC (1 container statuses recorded)
Nov  4 18:23:45.863: INFO: 	Container kube-flannel ready: true, restart count 0
Nov  4 18:23:45.863: INFO: traefik-ingress-controller-98f8s from kube-system started at 2019-11-04 17:13:49 +0000 UTC (1 container statuses recorded)
Nov  4 18:23:45.863: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5a760e7f-e779-4898-8659-31d32fc6bf4f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-5a760e7f-e779-4898-8659-31d32fc6bf4f off the node k8s-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5a760e7f-e779-4898-8659-31d32fc6bf4f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:23:49.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6037" for this suite.
Nov  4 18:24:03.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:24:04.026: INFO: namespace sched-pred-6037 deletion completed in 14.088983264s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:18.329 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:24:04.026: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5796
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:24:04.161: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  4 18:24:11.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-5796 create -f -'
Nov  4 18:24:11.481: INFO: stderr: ""
Nov  4 18:24:11.481: INFO: stdout: "e2e-test-crd-publish-openapi-8211-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  4 18:24:11.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-5796 delete e2e-test-crd-publish-openapi-8211-crds test-cr'
Nov  4 18:24:11.598: INFO: stderr: ""
Nov  4 18:24:11.598: INFO: stdout: "e2e-test-crd-publish-openapi-8211-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov  4 18:24:11.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-5796 apply -f -'
Nov  4 18:24:11.824: INFO: stderr: ""
Nov  4 18:24:11.824: INFO: stdout: "e2e-test-crd-publish-openapi-8211-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  4 18:24:11.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-5796 delete e2e-test-crd-publish-openapi-8211-crds test-cr'
Nov  4 18:24:11.908: INFO: stderr: ""
Nov  4 18:24:11.908: INFO: stdout: "e2e-test-crd-publish-openapi-8211-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Nov  4 18:24:11.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 explain e2e-test-crd-publish-openapi-8211-crds'
Nov  4 18:24:12.099: INFO: stderr: ""
Nov  4 18:24:12.099: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8211-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:24:16.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5796" for this suite.
Nov  4 18:24:22.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:24:22.135: INFO: namespace crd-publish-openapi-5796 deletion completed in 6.088915738s

â€¢ [SLOW TEST:18.109 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:24:22.135: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4948
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:24:22.276: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7ac01d81-4686-49c6-a35f-2a6ccf8ba243" in namespace "projected-4948" to be "success or failure"
Nov  4 18:24:22.281: INFO: Pod "downwardapi-volume-7ac01d81-4686-49c6-a35f-2a6ccf8ba243": Phase="Pending", Reason="", readiness=false. Elapsed: 5.539337ms
Nov  4 18:24:24.284: INFO: Pod "downwardapi-volume-7ac01d81-4686-49c6-a35f-2a6ccf8ba243": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00807138s
STEP: Saw pod success
Nov  4 18:24:24.284: INFO: Pod "downwardapi-volume-7ac01d81-4686-49c6-a35f-2a6ccf8ba243" satisfied condition "success or failure"
Nov  4 18:24:24.286: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-7ac01d81-4686-49c6-a35f-2a6ccf8ba243 container client-container: <nil>
STEP: delete the pod
Nov  4 18:24:24.306: INFO: Waiting for pod downwardapi-volume-7ac01d81-4686-49c6-a35f-2a6ccf8ba243 to disappear
Nov  4 18:24:24.310: INFO: Pod downwardapi-volume-7ac01d81-4686-49c6-a35f-2a6ccf8ba243 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:24:24.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4948" for this suite.
Nov  4 18:24:30.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:24:30.407: INFO: namespace projected-4948 deletion completed in 6.092453175s

â€¢ [SLOW TEST:8.272 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:24:30.408: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4117
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2536
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6128
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:24:59.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4117" for this suite.
Nov  4 18:25:05.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:25:05.939: INFO: namespace namespaces-4117 deletion completed in 6.09010293s
STEP: Destroying namespace "nsdeletetest-2536" for this suite.
Nov  4 18:25:05.942: INFO: Namespace nsdeletetest-2536 was already deleted
STEP: Destroying namespace "nsdeletetest-6128" for this suite.
Nov  4 18:25:11.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:25:12.033: INFO: namespace nsdeletetest-6128 deletion completed in 6.090853725s

â€¢ [SLOW TEST:41.625 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:25:12.033: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5612
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:25:12.171: INFO: Creating deployment "webserver-deployment"
Nov  4 18:25:12.176: INFO: Waiting for observed generation 1
Nov  4 18:25:14.182: INFO: Waiting for all required pods to come up
Nov  4 18:25:14.185: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov  4 18:25:16.195: INFO: Waiting for deployment "webserver-deployment" to complete
Nov  4 18:25:16.200: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov  4 18:25:16.208: INFO: Updating deployment webserver-deployment
Nov  4 18:25:16.208: INFO: Waiting for observed generation 2
Nov  4 18:25:18.214: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov  4 18:25:18.217: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov  4 18:25:18.218: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  4 18:25:18.229: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov  4 18:25:18.229: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov  4 18:25:18.232: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  4 18:25:18.238: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov  4 18:25:18.238: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov  4 18:25:18.249: INFO: Updating deployment webserver-deployment
Nov  4 18:25:18.249: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov  4 18:25:18.259: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov  4 18:25:20.280: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 18:25:20.291: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-5612 /apis/apps/v1/namespaces/deployment-5612/deployments/webserver-deployment 4c04431d-227c-4efd-accf-7777c9023f1d 21404 3 2019-11-04 18:25:12 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002146988 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-11-04 18:25:18 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-11-04 18:25:18 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov  4 18:25:20.293: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-5612 /apis/apps/v1/namespaces/deployment-5612/replicasets/webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 21385 3 2019-11-04 18:25:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 4c04431d-227c-4efd-accf-7777c9023f1d 0xc002146f37 0xc002146f38}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002146fa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 18:25:20.293: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov  4 18:25:20.293: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-5612 /apis/apps/v1/namespaces/deployment-5612/replicasets/webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 21398 3 2019-11-04 18:25:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 4c04431d-227c-4efd-accf-7777c9023f1d 0xc002146e77 0xc002146e78}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002146ed8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov  4 18:25:20.300: INFO: Pod "webserver-deployment-595b5b9587-48flv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-48flv webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-48flv 57611ae9-8c05-4400-89fd-f9e083658a10 21435 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc002147537 0xc002147538}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.301: INFO: Pod "webserver-deployment-595b5b9587-5zwhs" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5zwhs webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-5zwhs f3f763f1-4565-4e41-967f-fe0a41e0fda9 21401 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc002147690 0xc002147691}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.301: INFO: Pod "webserver-deployment-595b5b9587-7mklt" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7mklt webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-7mklt 03ca0729-4ca2-48e7-a1ab-68fba5dc41bb 21425 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0021477e0 0xc0021477e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.301: INFO: Pod "webserver-deployment-595b5b9587-85v8q" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-85v8q webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-85v8q 103d8a6d-0b30-4366-8a66-b059767111b7 21229 0 2019-11-04 18:25:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc002147930 0xc002147931}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.0.224,StartTime:2019-11-04 18:25:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 18:25:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://68e2264b2ec686a78f8c2dff65a42e1a9746543e18f383689754cf09fa0fe89f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.224,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.301: INFO: Pod "webserver-deployment-595b5b9587-8bsdb" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8bsdb webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-8bsdb cd958760-1fe0-4fa7-8c98-2d07c1397e4e 21409 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc002147ae0 0xc002147ae1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.301: INFO: Pod "webserver-deployment-595b5b9587-b6vf9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-b6vf9 webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-b6vf9 97138991-0272-4607-a4e4-f77213251df8 21406 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc002147c80 0xc002147c81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.302: INFO: Pod "webserver-deployment-595b5b9587-c76z7" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-c76z7 webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-c76z7 1fba32e5-dc2b-4cce-ad95-927577c48ee7 21423 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc002147de0 0xc002147de1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.302: INFO: Pod "webserver-deployment-595b5b9587-kx9sv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kx9sv webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-kx9sv fb69182b-2500-46a7-888e-a76deee28734 21390 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc002147f30 0xc002147f31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.302: INFO: Pod "webserver-deployment-595b5b9587-l56tw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-l56tw webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-l56tw ea7904f7-3d07-44c9-bf5a-fffdc4b54fae 21338 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c2100 0xc0023c2101}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.302: INFO: Pod "webserver-deployment-595b5b9587-lg2tk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-lg2tk webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-lg2tk 76119fd1-d544-48ce-8440-7e58c0000d07 21216 0 2019-11-04 18:25:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c2280 0xc0023c2281}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.2.86,StartTime:2019-11-04 18:25:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 18:25:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://9f6f3388d10418a1fc23c2c90f99e58878edf73d7985100f038d18c79db5461c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.86,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.302: INFO: Pod "webserver-deployment-595b5b9587-mnqzf" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mnqzf webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-mnqzf 7b72c224-617b-45c6-9579-2877453a256f 21400 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c2430 0xc0023c2431}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.303: INFO: Pod "webserver-deployment-595b5b9587-pgtqw" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pgtqw webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-pgtqw 2355bd9c-a1cc-4004-b8a4-8096c2471410 21211 0 2019-11-04 18:25:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c2600 0xc0023c2601}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.2.85,StartTime:2019-11-04 18:25:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 18:25:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://3c271597fb8a6b6b555b74bb79e3ad0ed7aadc9c3df5bf05fb4b25840ba2d195,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.303: INFO: Pod "webserver-deployment-595b5b9587-pnqmm" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pnqmm webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-pnqmm 37c9de77-aa80-44ad-a167-608655e1e92e 21367 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c27a0 0xc0023c27a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.303: INFO: Pod "webserver-deployment-595b5b9587-r4x87" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r4x87 webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-r4x87 e6b46229-043f-4c17-ab24-75e8cb0f68d6 21208 0 2019-11-04 18:25:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c2940 0xc0023c2941}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.2.84,StartTime:2019-11-04 18:25:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 18:25:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://3bc742a0b9e32be1d56a5f7396c385c11fa35b8c2d698082cb604e0826c4cffb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.84,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.303: INFO: Pod "webserver-deployment-595b5b9587-rbsv9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rbsv9 webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-rbsv9 a1fb67c1-d78b-44cd-994a-aae96b0be2a3 21206 0 2019-11-04 18:25:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c2b70 0xc0023c2b71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.2.83,StartTime:2019-11-04 18:25:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 18:25:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://8704ccabf671866150b3f43cbbbe6ffe4d9993521a7a7926407062744f3481a0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.83,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.303: INFO: Pod "webserver-deployment-595b5b9587-sl4z9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sl4z9 webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-sl4z9 e7b4fcad-a38a-4eb6-ae5f-5ed6567c10b0 21214 0 2019-11-04 18:25:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c2d50 0xc0023c2d51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:10.33.1.25,StartTime:2019-11-04 18:25:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 18:25:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://ae05e940b07e83b1842cfe9e404f9e2b4b6407e3fed692d466b1d24e141a69e5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.1.25,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.303: INFO: Pod "webserver-deployment-595b5b9587-tlvvv" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tlvvv webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-tlvvv ff1bbacd-1f2a-49c6-8f96-dff07974cac9 21236 0 2019-11-04 18:25:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c2f70 0xc0023c2f71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.0.223,StartTime:2019-11-04 18:25:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 18:25:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://ef86b7cfb4e3759b7b3d47ae89a969f1998c0513274bba0bd4334c31b1da9361,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.223,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.304: INFO: Pod "webserver-deployment-595b5b9587-vpwtq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vpwtq webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-vpwtq 7e7d8022-4cc4-4625-b313-5b6595ba2d19 21402 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c3100 0xc0023c3101}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.306: INFO: Pod "webserver-deployment-595b5b9587-wp99t" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wp99t webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-wp99t f6842d6b-e452-4590-ac64-3203a3f1bdff 21420 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c3260 0xc0023c3261}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.307: INFO: Pod "webserver-deployment-595b5b9587-x7s87" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-x7s87 webserver-deployment-595b5b9587- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-595b5b9587-x7s87 8880344a-a50d-4d0f-9a33-f2b727aa8e16 21219 0 2019-11-04 18:25:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 0f2ba26d-4688-4ccd-935f-8485ee8354c8 0xc0023c3420 0xc0023c3421}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:10.33.1.26,StartTime:2019-11-04 18:25:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 18:25:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://22fb43a02e29055b5c3a95be758e7ffc65828b320673e91e88dd54c7dbff4cb5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.1.26,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.307: INFO: Pod "webserver-deployment-c7997dcc8-92cqn" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-92cqn webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-92cqn 7809df20-5938-40dd-905d-42c23a24c837 21424 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc0023c3640 0xc0023c3641}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.307: INFO: Pod "webserver-deployment-c7997dcc8-ckvds" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ckvds webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-ckvds 7ef820ed-8655-4acf-9457-ff73ea0416fc 21444 0 2019-11-04 18:25:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc0023c3820 0xc0023c3821}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.0.227,StartTime:2019-11-04 18:25:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.227,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.307: INFO: Pod "webserver-deployment-c7997dcc8-gk7gh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gk7gh webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-gk7gh 56e581f6-be2b-45f7-9414-8ac2c89ac834 21418 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc0023c3a50 0xc0023c3a51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.307: INFO: Pod "webserver-deployment-c7997dcc8-jf2fg" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-jf2fg webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-jf2fg 86390bad-3a7f-42a9-9b19-116cde8d14f0 21462 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc0023c3bf0 0xc0023c3bf1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.2.89,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.89,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.308: INFO: Pod "webserver-deployment-c7997dcc8-jh998" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-jh998 webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-jh998 813d4048-341a-4dd3-8b8c-d5167be91e53 21389 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc0023c3d90 0xc0023c3d91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.308: INFO: Pod "webserver-deployment-c7997dcc8-jlrqb" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-jlrqb webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-jlrqb 5d0ec3ef-a21d-4ac3-80d1-8b666c8ce08d 21291 0 2019-11-04 18:25:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc0023c3fe0 0xc0023c3fe1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 18:25:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.308: INFO: Pod "webserver-deployment-c7997dcc8-kbq78" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kbq78 webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-kbq78 4297fb63-06b2-4a1e-a731-fc543483fb87 21436 0 2019-11-04 18:25:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc0025681d0 0xc0025681d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:10.33.0.229,StartTime:2019-11-04 18:25:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.0.229,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.308: INFO: Pod "webserver-deployment-c7997dcc8-kldsc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kldsc webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-kldsc 383ef2a4-03c4-4084-a1f2-1560e9bf896b 21438 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc0025683a0 0xc0025683a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.308: INFO: Pod "webserver-deployment-c7997dcc8-lf9kr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lf9kr webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-lf9kr a22758cb-482f-4532-a881-f67bcaaa0bc8 21414 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc002568510 0xc002568511}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.308: INFO: Pod "webserver-deployment-c7997dcc8-mzxn6" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-mzxn6 webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-mzxn6 ba27ccef-641d-43c0-bfaa-68cfa548a63b 21305 0 2019-11-04 18:25:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc0025686c0 0xc0025686c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.2.87,StartTime:2019-11-04 18:25:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.87,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.308: INFO: Pod "webserver-deployment-c7997dcc8-st8g9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-st8g9 webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-st8g9 732438d8-552d-401b-9010-8fd01dbd6417 21411 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc0025688b0 0xc0025688b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.4,PodIP:,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.308: INFO: Pod "webserver-deployment-c7997dcc8-t2bwg" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-t2bwg webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-t2bwg 21d9a91f-4d45-4c2e-8ed8-ba1199f31707 21308 0 2019-11-04 18:25:16 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc002568a40 0xc002568a41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.5,PodIP:10.33.1.27,StartTime:2019-11-04 18:25:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.1.27,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 18:25:20.309: INFO: Pod "webserver-deployment-c7997dcc8-x7wr9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-x7wr9 webserver-deployment-c7997dcc8- deployment-5612 /api/v1/namespaces/deployment-5612/pods/webserver-deployment-c7997dcc8-x7wr9 b4aa08cb-7919-45cb-b2ce-0542ce2a4866 21459 0 2019-11-04 18:25:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 333b1dd8-2fa6-4a9d-b4c5-d5b683dd5956 0xc002568be0 0xc002568be1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9x4rd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9x4rd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9x4rd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:25:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.20.20.6,PodIP:10.33.2.88,StartTime:2019-11-04 18:25:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.33.2.88,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:25:20.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5612" for this suite.
Nov  4 18:25:28.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:25:28.430: INFO: namespace deployment-5612 deletion completed in 8.11349294s

â€¢ [SLOW TEST:16.397 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:25:28.431: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6027
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:25:33.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6027" for this suite.
Nov  4 18:25:39.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:25:39.572: INFO: namespace watch-6027 deletion completed in 6.186420697s

â€¢ [SLOW TEST:11.141 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:25:39.573: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-7981
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov  4 18:25:39.927: INFO: Pod name wrapped-volume-race-399b487d-87c3-4527-9834-a191eb1fc39a: Found 1 pods out of 5
Nov  4 18:25:44.933: INFO: Pod name wrapped-volume-race-399b487d-87c3-4527-9834-a191eb1fc39a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-399b487d-87c3-4527-9834-a191eb1fc39a in namespace emptydir-wrapper-7981, will wait for the garbage collector to delete the pods
Nov  4 18:25:55.010: INFO: Deleting ReplicationController wrapped-volume-race-399b487d-87c3-4527-9834-a191eb1fc39a took: 8.163337ms
Nov  4 18:25:55.311: INFO: Terminating ReplicationController wrapped-volume-race-399b487d-87c3-4527-9834-a191eb1fc39a pods took: 300.346509ms
STEP: Creating RC which spawns configmap-volume pods
Nov  4 18:26:39.925: INFO: Pod name wrapped-volume-race-351c6957-c96c-4ae8-9fbc-4b11861e27b2: Found 0 pods out of 5
Nov  4 18:26:44.931: INFO: Pod name wrapped-volume-race-351c6957-c96c-4ae8-9fbc-4b11861e27b2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-351c6957-c96c-4ae8-9fbc-4b11861e27b2 in namespace emptydir-wrapper-7981, will wait for the garbage collector to delete the pods
Nov  4 18:26:55.010: INFO: Deleting ReplicationController wrapped-volume-race-351c6957-c96c-4ae8-9fbc-4b11861e27b2 took: 9.412311ms
Nov  4 18:26:55.310: INFO: Terminating ReplicationController wrapped-volume-race-351c6957-c96c-4ae8-9fbc-4b11861e27b2 pods took: 300.216126ms
STEP: Creating RC which spawns configmap-volume pods
Nov  4 18:27:39.529: INFO: Pod name wrapped-volume-race-de493aa7-c8ba-43d0-bf09-0877e7e65ba7: Found 0 pods out of 5
Nov  4 18:27:44.535: INFO: Pod name wrapped-volume-race-de493aa7-c8ba-43d0-bf09-0877e7e65ba7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-de493aa7-c8ba-43d0-bf09-0877e7e65ba7 in namespace emptydir-wrapper-7981, will wait for the garbage collector to delete the pods
Nov  4 18:27:54.615: INFO: Deleting ReplicationController wrapped-volume-race-de493aa7-c8ba-43d0-bf09-0877e7e65ba7 took: 9.164191ms
Nov  4 18:27:54.915: INFO: Terminating ReplicationController wrapped-volume-race-de493aa7-c8ba-43d0-bf09-0877e7e65ba7 pods took: 300.207922ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:28:39.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7981" for this suite.
Nov  4 18:28:47.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:28:47.922: INFO: namespace emptydir-wrapper-7981 deletion completed in 8.084387601s

â€¢ [SLOW TEST:188.349 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:28:47.922: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3186
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-09d6216e-328c-43fd-81e5-74081736853c
STEP: Creating a pod to test consume secrets
Nov  4 18:28:48.069: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-343b971a-11b2-41dc-add5-6fe58645b1b6" in namespace "projected-3186" to be "success or failure"
Nov  4 18:28:48.078: INFO: Pod "pod-projected-secrets-343b971a-11b2-41dc-add5-6fe58645b1b6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.632627ms
Nov  4 18:28:50.081: INFO: Pod "pod-projected-secrets-343b971a-11b2-41dc-add5-6fe58645b1b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011552054s
STEP: Saw pod success
Nov  4 18:28:50.081: INFO: Pod "pod-projected-secrets-343b971a-11b2-41dc-add5-6fe58645b1b6" satisfied condition "success or failure"
Nov  4 18:28:50.083: INFO: Trying to get logs from node k8s-1 pod pod-projected-secrets-343b971a-11b2-41dc-add5-6fe58645b1b6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:28:50.109: INFO: Waiting for pod pod-projected-secrets-343b971a-11b2-41dc-add5-6fe58645b1b6 to disappear
Nov  4 18:28:50.112: INFO: Pod pod-projected-secrets-343b971a-11b2-41dc-add5-6fe58645b1b6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:28:50.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3186" for this suite.
Nov  4 18:28:56.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:28:56.201: INFO: namespace projected-3186 deletion completed in 6.085816538s

â€¢ [SLOW TEST:8.279 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:28:56.202: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2997
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 18:28:57.351: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:28:57.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2997" for this suite.
Nov  4 18:29:03.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:29:03.473: INFO: namespace container-runtime-2997 deletion completed in 6.090737813s

â€¢ [SLOW TEST:7.271 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:29:03.474: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-444
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Nov  4 18:29:03.610: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Nov  4 18:29:19.494: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:29:27.446: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:29:45.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-444" for this suite.
Nov  4 18:29:51.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:29:51.939: INFO: namespace crd-publish-openapi-444 deletion completed in 6.089121714s

â€¢ [SLOW TEST:48.466 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:29:51.940: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6727
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-cd7d001d-54dd-4f74-81c6-43fa7d33c57d
STEP: Creating a pod to test consume secrets
Nov  4 18:29:52.089: INFO: Waiting up to 5m0s for pod "pod-secrets-3a824a75-311e-4c2f-855b-6e46f9a583f2" in namespace "secrets-6727" to be "success or failure"
Nov  4 18:29:52.093: INFO: Pod "pod-secrets-3a824a75-311e-4c2f-855b-6e46f9a583f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.519714ms
Nov  4 18:29:54.097: INFO: Pod "pod-secrets-3a824a75-311e-4c2f-855b-6e46f9a583f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007768395s
STEP: Saw pod success
Nov  4 18:29:54.097: INFO: Pod "pod-secrets-3a824a75-311e-4c2f-855b-6e46f9a583f2" satisfied condition "success or failure"
Nov  4 18:29:54.099: INFO: Trying to get logs from node k8s-1 pod pod-secrets-3a824a75-311e-4c2f-855b-6e46f9a583f2 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:29:54.120: INFO: Waiting for pod pod-secrets-3a824a75-311e-4c2f-855b-6e46f9a583f2 to disappear
Nov  4 18:29:54.123: INFO: Pod pod-secrets-3a824a75-311e-4c2f-855b-6e46f9a583f2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:29:54.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6727" for this suite.
Nov  4 18:30:00.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:30:00.215: INFO: namespace secrets-6727 deletion completed in 6.088735772s

â€¢ [SLOW TEST:8.274 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:30:00.215: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-839
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-839
STEP: creating replication controller nodeport-test in namespace services-839
I1104 18:30:00.373648      19 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-839, replica count: 2
Nov  4 18:30:03.424: INFO: Creating new exec pod
I1104 18:30:03.424109      19 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 18:30:06.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-839 execpodrhct6 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Nov  4 18:30:06.663: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov  4 18:30:06.663: INFO: stdout: ""
Nov  4 18:30:06.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-839 execpodrhct6 -- /bin/sh -x -c nc -zv -t -w 2 10.32.0.71 80'
Nov  4 18:30:06.887: INFO: stderr: "+ nc -zv -t -w 2 10.32.0.71 80\nConnection to 10.32.0.71 80 port [tcp/http] succeeded!\n"
Nov  4 18:30:06.887: INFO: stdout: ""
Nov  4 18:30:06.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-839 execpodrhct6 -- /bin/sh -x -c nc -zv -t -w 2 10.20.20.4 32224'
Nov  4 18:30:07.121: INFO: stderr: "+ nc -zv -t -w 2 10.20.20.4 32224\nConnection to 10.20.20.4 32224 port [tcp/32224] succeeded!\n"
Nov  4 18:30:07.121: INFO: stdout: ""
Nov  4 18:30:07.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=services-839 execpodrhct6 -- /bin/sh -x -c nc -zv -t -w 2 10.20.20.5 32224'
Nov  4 18:30:07.349: INFO: stderr: "+ nc -zv -t -w 2 10.20.20.5 32224\nConnection to 10.20.20.5 32224 port [tcp/32224] succeeded!\n"
Nov  4 18:30:07.349: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:30:07.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-839" for this suite.
Nov  4 18:30:13.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:30:13.459: INFO: namespace services-839 deletion completed in 6.105512042s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:13.244 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:30:13.460: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8266
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8266
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 18:30:13.595: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 18:30:35.692: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.0.4:8080/dial?request=hostName&protocol=udp&host=10.33.2.95&port=8081&tries=1'] Namespace:pod-network-test-8266 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:30:35.692: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:30:35.882: INFO: Waiting for endpoints: map[]
Nov  4 18:30:35.886: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.0.4:8080/dial?request=hostName&protocol=udp&host=10.33.1.36&port=8081&tries=1'] Namespace:pod-network-test-8266 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:30:35.887: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:30:36.061: INFO: Waiting for endpoints: map[]
Nov  4 18:30:36.065: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.33.0.4:8080/dial?request=hostName&protocol=udp&host=10.33.0.3&port=8081&tries=1'] Namespace:pod-network-test-8266 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:30:36.065: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:30:36.215: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:30:36.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8266" for this suite.
Nov  4 18:30:48.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:30:48.310: INFO: namespace pod-network-test-8266 deletion completed in 12.089687552s

â€¢ [SLOW TEST:34.850 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:30:48.311: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4140
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:30:48.448: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:30:50.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4140" for this suite.
Nov  4 18:31:34.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:31:34.588: INFO: namespace pods-4140 deletion completed in 44.100768184s

â€¢ [SLOW TEST:46.277 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:31:34.590: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9409
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:31:35.010: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:31:38.027: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
Nov  4 18:31:38.052: INFO: Waiting for webhook configuration to be ready...
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:31:38.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9409" for this suite.
Nov  4 18:31:44.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:31:44.545: INFO: namespace webhook-9409 deletion completed in 6.085352022s
STEP: Destroying namespace "webhook-9409-markers" for this suite.
Nov  4 18:31:50.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:31:50.632: INFO: namespace webhook-9409-markers deletion completed in 6.087160337s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:16.057 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:31:50.646: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3117
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:31:51.150: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:31:54.168: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
Nov  4 18:31:55.214: INFO: Waiting for webhook configuration to be ready...
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
Nov  4 18:31:56.355: INFO: Waiting for webhook configuration to be ready...
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:32:06.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3117" for this suite.
Nov  4 18:32:12.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:32:12.611: INFO: namespace webhook-3117 deletion completed in 6.094479228s
STEP: Destroying namespace "webhook-3117-markers" for this suite.
Nov  4 18:32:18.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:32:18.693: INFO: namespace webhook-3117-markers deletion completed in 6.081314653s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:28.058 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:32:18.705: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9487
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-baaad8ab-d7fc-408e-825e-e7fe321294e9
STEP: Creating a pod to test consume configMaps
Nov  4 18:32:18.853: INFO: Waiting up to 5m0s for pod "pod-configmaps-b8206791-d113-46d5-a562-85527a707c04" in namespace "configmap-9487" to be "success or failure"
Nov  4 18:32:18.857: INFO: Pod "pod-configmaps-b8206791-d113-46d5-a562-85527a707c04": Phase="Pending", Reason="", readiness=false. Elapsed: 3.618988ms
Nov  4 18:32:20.859: INFO: Pod "pod-configmaps-b8206791-d113-46d5-a562-85527a707c04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006454613s
STEP: Saw pod success
Nov  4 18:32:20.860: INFO: Pod "pod-configmaps-b8206791-d113-46d5-a562-85527a707c04" satisfied condition "success or failure"
Nov  4 18:32:20.862: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-b8206791-d113-46d5-a562-85527a707c04 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:32:20.890: INFO: Waiting for pod pod-configmaps-b8206791-d113-46d5-a562-85527a707c04 to disappear
Nov  4 18:32:20.896: INFO: Pod pod-configmaps-b8206791-d113-46d5-a562-85527a707c04 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:32:20.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9487" for this suite.
Nov  4 18:32:26.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:32:26.988: INFO: namespace configmap-9487 deletion completed in 6.08830869s

â€¢ [SLOW TEST:8.283 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:32:26.989: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5667
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov  4 18:32:27.133: INFO: Waiting up to 5m0s for pod "pod-390651ed-7d73-4dc8-9e65-5fee8d4b1bb8" in namespace "emptydir-5667" to be "success or failure"
Nov  4 18:32:27.135: INFO: Pod "pod-390651ed-7d73-4dc8-9e65-5fee8d4b1bb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.170547ms
Nov  4 18:32:29.138: INFO: Pod "pod-390651ed-7d73-4dc8-9e65-5fee8d4b1bb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004889173s
STEP: Saw pod success
Nov  4 18:32:29.138: INFO: Pod "pod-390651ed-7d73-4dc8-9e65-5fee8d4b1bb8" satisfied condition "success or failure"
Nov  4 18:32:29.141: INFO: Trying to get logs from node k8s-1 pod pod-390651ed-7d73-4dc8-9e65-5fee8d4b1bb8 container test-container: <nil>
STEP: delete the pod
Nov  4 18:32:29.160: INFO: Waiting for pod pod-390651ed-7d73-4dc8-9e65-5fee8d4b1bb8 to disappear
Nov  4 18:32:29.163: INFO: Pod pod-390651ed-7d73-4dc8-9e65-5fee8d4b1bb8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:32:29.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5667" for this suite.
Nov  4 18:32:35.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:32:35.251: INFO: namespace emptydir-5667 deletion completed in 6.085692319s

â€¢ [SLOW TEST:8.262 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:32:35.253: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9842
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1104 18:32:45.450413      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 18:32:45.450: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:32:45.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9842" for this suite.
Nov  4 18:32:51.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:32:51.538: INFO: namespace gc-9842 deletion completed in 6.084715529s

â€¢ [SLOW TEST:16.285 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:32:51.539: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-324
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov  4 18:32:55.710: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-324 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:32:55.710: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:32:55.850: INFO: Exec stderr: ""
Nov  4 18:32:55.850: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-324 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:32:55.850: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:32:55.984: INFO: Exec stderr: ""
Nov  4 18:32:55.984: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-324 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:32:55.984: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:32:56.125: INFO: Exec stderr: ""
Nov  4 18:32:56.125: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-324 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:32:56.125: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:32:56.260: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov  4 18:32:56.261: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-324 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:32:56.261: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:32:56.401: INFO: Exec stderr: ""
Nov  4 18:32:56.401: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-324 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:32:56.401: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:32:56.539: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov  4 18:32:56.539: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-324 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:32:56.539: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:32:56.679: INFO: Exec stderr: ""
Nov  4 18:32:56.679: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-324 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:32:56.679: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:32:56.830: INFO: Exec stderr: ""
Nov  4 18:32:56.830: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-324 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:32:56.830: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:32:56.968: INFO: Exec stderr: ""
Nov  4 18:32:56.969: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-324 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:32:56.969: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
Nov  4 18:32:57.107: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:32:57.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-324" for this suite.
Nov  4 18:33:41.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:33:41.200: INFO: namespace e2e-kubelet-etc-hosts-324 deletion completed in 44.088387082s

â€¢ [SLOW TEST:49.661 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:33:41.201: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5405
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-57c97799-c48b-42a8-9904-f306f7ab4a09
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:33:41.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5405" for this suite.
Nov  4 18:33:47.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:33:47.447: INFO: namespace secrets-5405 deletion completed in 6.094689085s

â€¢ [SLOW TEST:6.247 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:33:47.448: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9795
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:34:09.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9795" for this suite.
Nov  4 18:34:15.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:34:15.894: INFO: namespace container-runtime-9795 deletion completed in 6.087508308s

â€¢ [SLOW TEST:28.446 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:34:15.895: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8369
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  4 18:34:16.035: INFO: Waiting up to 5m0s for pod "pod-7e5629ad-0376-4024-9728-3aeaa5b9b69a" in namespace "emptydir-8369" to be "success or failure"
Nov  4 18:34:16.038: INFO: Pod "pod-7e5629ad-0376-4024-9728-3aeaa5b9b69a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.82207ms
Nov  4 18:34:18.041: INFO: Pod "pod-7e5629ad-0376-4024-9728-3aeaa5b9b69a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006383106s
STEP: Saw pod success
Nov  4 18:34:18.041: INFO: Pod "pod-7e5629ad-0376-4024-9728-3aeaa5b9b69a" satisfied condition "success or failure"
Nov  4 18:34:18.044: INFO: Trying to get logs from node k8s-1 pod pod-7e5629ad-0376-4024-9728-3aeaa5b9b69a container test-container: <nil>
STEP: delete the pod
Nov  4 18:34:18.071: INFO: Waiting for pod pod-7e5629ad-0376-4024-9728-3aeaa5b9b69a to disappear
Nov  4 18:34:18.073: INFO: Pod pod-7e5629ad-0376-4024-9728-3aeaa5b9b69a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:34:18.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8369" for this suite.
Nov  4 18:34:24.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:34:24.163: INFO: namespace emptydir-8369 deletion completed in 6.086068271s

â€¢ [SLOW TEST:8.268 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:34:24.163: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3691
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:34:24.299: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  4 18:34:31.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3691 create -f -'
Nov  4 18:34:31.653: INFO: stderr: ""
Nov  4 18:34:31.653: INFO: stdout: "e2e-test-crd-publish-openapi-154-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  4 18:34:31.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3691 delete e2e-test-crd-publish-openapi-154-crds test-cr'
Nov  4 18:34:31.758: INFO: stderr: ""
Nov  4 18:34:31.758: INFO: stdout: "e2e-test-crd-publish-openapi-154-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov  4 18:34:31.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3691 apply -f -'
Nov  4 18:34:32.001: INFO: stderr: ""
Nov  4 18:34:32.001: INFO: stdout: "e2e-test-crd-publish-openapi-154-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  4 18:34:32.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=crd-publish-openapi-3691 delete e2e-test-crd-publish-openapi-154-crds test-cr'
Nov  4 18:34:32.129: INFO: stderr: ""
Nov  4 18:34:32.129: INFO: stdout: "e2e-test-crd-publish-openapi-154-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov  4 18:34:32.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 explain e2e-test-crd-publish-openapi-154-crds'
Nov  4 18:34:32.455: INFO: stderr: ""
Nov  4 18:34:32.455: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-154-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:34:35.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3691" for this suite.
Nov  4 18:34:41.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:34:41.505: INFO: namespace crd-publish-openapi-3691 deletion completed in 6.091784402s

â€¢ [SLOW TEST:17.342 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:34:41.506: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8750
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:34:52.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8750" for this suite.
Nov  4 18:34:58.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:34:58.769: INFO: namespace resourcequota-8750 deletion completed in 6.087059302s

â€¢ [SLOW TEST:17.263 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:34:58.769: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2233
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:34:58.909: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dfe016cd-359e-4aa6-ae7f-77601161461e" in namespace "projected-2233" to be "success or failure"
Nov  4 18:34:58.915: INFO: Pod "downwardapi-volume-dfe016cd-359e-4aa6-ae7f-77601161461e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021883ms
Nov  4 18:35:00.917: INFO: Pod "downwardapi-volume-dfe016cd-359e-4aa6-ae7f-77601161461e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008696798s
STEP: Saw pod success
Nov  4 18:35:00.917: INFO: Pod "downwardapi-volume-dfe016cd-359e-4aa6-ae7f-77601161461e" satisfied condition "success or failure"
Nov  4 18:35:00.919: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-dfe016cd-359e-4aa6-ae7f-77601161461e container client-container: <nil>
STEP: delete the pod
Nov  4 18:35:00.941: INFO: Waiting for pod downwardapi-volume-dfe016cd-359e-4aa6-ae7f-77601161461e to disappear
Nov  4 18:35:00.944: INFO: Pod downwardapi-volume-dfe016cd-359e-4aa6-ae7f-77601161461e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:35:00.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2233" for this suite.
Nov  4 18:35:06.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:35:07.037: INFO: namespace projected-2233 deletion completed in 6.088377358s

â€¢ [SLOW TEST:8.268 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:35:07.038: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4051
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 18:35:09.203: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:35:09.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4051" for this suite.
Nov  4 18:35:15.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:35:15.327: INFO: namespace container-runtime-4051 deletion completed in 6.095159588s

â€¢ [SLOW TEST:8.289 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:35:15.328: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5506
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Nov  4 18:35:15.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 --namespace=kubectl-5506 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov  4 18:35:16.853: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov  4 18:35:16.854: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:35:18.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5506" for this suite.
Nov  4 18:35:30.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:35:30.947: INFO: namespace kubectl-5506 deletion completed in 12.085153892s

â€¢ [SLOW TEST:15.619 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:35:30.948: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6050
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Nov  4 18:35:31.084: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:35:54.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6050" for this suite.
Nov  4 18:36:00.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:36:00.416: INFO: namespace crd-publish-openapi-6050 deletion completed in 6.086847399s

â€¢ [SLOW TEST:29.469 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:36:00.418: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1052
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 18:36:02.573: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:36:02.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1052" for this suite.
Nov  4 18:36:08.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:36:08.687: INFO: namespace container-runtime-1052 deletion completed in 6.093512265s

â€¢ [SLOW TEST:8.270 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:36:08.688: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1960
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Nov  4 18:36:08.837: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-430892974 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:36:08.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1960" for this suite.
Nov  4 18:36:14.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:36:14.991: INFO: namespace kubectl-1960 deletion completed in 6.090757329s

â€¢ [SLOW TEST:6.304 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:36:14.992: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-992
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 18:36:15.133: INFO: Waiting up to 5m0s for pod "downward-api-c6cdcde7-4677-4138-b17d-5a24d3925f8c" in namespace "downward-api-992" to be "success or failure"
Nov  4 18:36:15.136: INFO: Pod "downward-api-c6cdcde7-4677-4138-b17d-5a24d3925f8c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.64833ms
Nov  4 18:36:17.138: INFO: Pod "downward-api-c6cdcde7-4677-4138-b17d-5a24d3925f8c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005381352s
STEP: Saw pod success
Nov  4 18:36:17.138: INFO: Pod "downward-api-c6cdcde7-4677-4138-b17d-5a24d3925f8c" satisfied condition "success or failure"
Nov  4 18:36:17.141: INFO: Trying to get logs from node k8s-1 pod downward-api-c6cdcde7-4677-4138-b17d-5a24d3925f8c container dapi-container: <nil>
STEP: delete the pod
Nov  4 18:36:17.161: INFO: Waiting for pod downward-api-c6cdcde7-4677-4138-b17d-5a24d3925f8c to disappear
Nov  4 18:36:17.164: INFO: Pod downward-api-c6cdcde7-4677-4138-b17d-5a24d3925f8c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:36:17.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-992" for this suite.
Nov  4 18:36:23.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:36:23.251: INFO: namespace downward-api-992 deletion completed in 6.083931147s

â€¢ [SLOW TEST:8.259 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:36:23.252: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4998
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov  4 18:36:23.394: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-a 865ec066-5a7a-46ce-b4b0-04ad9747a08a 24969 0 2019-11-04 18:36:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 18:36:23.394: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-a 865ec066-5a7a-46ce-b4b0-04ad9747a08a 24969 0 2019-11-04 18:36:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov  4 18:36:33.402: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-a 865ec066-5a7a-46ce-b4b0-04ad9747a08a 24986 0 2019-11-04 18:36:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  4 18:36:33.402: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-a 865ec066-5a7a-46ce-b4b0-04ad9747a08a 24986 0 2019-11-04 18:36:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov  4 18:36:43.409: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-a 865ec066-5a7a-46ce-b4b0-04ad9747a08a 25003 0 2019-11-04 18:36:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 18:36:43.410: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-a 865ec066-5a7a-46ce-b4b0-04ad9747a08a 25003 0 2019-11-04 18:36:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov  4 18:36:53.418: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-a 865ec066-5a7a-46ce-b4b0-04ad9747a08a 25022 0 2019-11-04 18:36:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 18:36:53.418: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-a 865ec066-5a7a-46ce-b4b0-04ad9747a08a 25022 0 2019-11-04 18:36:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov  4 18:37:03.427: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-b 6f2d4da5-79a6-4957-b316-23beb784f2f7 25039 0 2019-11-04 18:37:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 18:37:03.427: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-b 6f2d4da5-79a6-4957-b316-23beb784f2f7 25039 0 2019-11-04 18:37:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov  4 18:37:13.435: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-b 6f2d4da5-79a6-4957-b316-23beb784f2f7 25056 0 2019-11-04 18:37:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 18:37:13.435: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4998 /api/v1/namespaces/watch-4998/configmaps/e2e-watch-test-configmap-b 6f2d4da5-79a6-4957-b316-23beb784f2f7 25056 0 2019-11-04 18:37:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:37:23.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4998" for this suite.
Nov  4 18:37:29.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:37:29.533: INFO: namespace watch-4998 deletion completed in 6.094447838s

â€¢ [SLOW TEST:66.282 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:37:29.534: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8397
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:37:30.461: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 18:37:32.469: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489450, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489450, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489450, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489450, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:37:35.480: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
Nov  4 18:37:35.501: INFO: Waiting for webhook configuration to be ready...
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:37:35.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8397" for this suite.
Nov  4 18:37:41.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:37:41.736: INFO: namespace webhook-8397 deletion completed in 6.083804784s
STEP: Destroying namespace "webhook-8397-markers" for this suite.
Nov  4 18:37:47.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:37:47.828: INFO: namespace webhook-8397-markers deletion completed in 6.092046703s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:18.308 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:37:47.843: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-95
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-95
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Nov  4 18:37:47.992: INFO: Found 0 stateful pods, waiting for 3
Nov  4 18:37:57.996: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 18:37:57.996: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 18:37:57.996: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 18:37:58.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-95 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 18:37:58.223: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 18:37:58.223: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 18:37:58.223: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov  4 18:38:08.251: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov  4 18:38:18.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-95 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 18:38:18.494: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 18:38:18.494: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 18:38:18.494: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 18:38:28.512: INFO: Waiting for StatefulSet statefulset-95/ss2 to complete update
Nov  4 18:38:28.512: INFO: Waiting for Pod statefulset-95/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  4 18:38:28.512: INFO: Waiting for Pod statefulset-95/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  4 18:38:28.512: INFO: Waiting for Pod statefulset-95/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  4 18:38:38.519: INFO: Waiting for StatefulSet statefulset-95/ss2 to complete update
STEP: Rolling back to a previous revision
Nov  4 18:38:48.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-95 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 18:38:48.759: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 18:38:48.759: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 18:38:48.759: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 18:38:58.790: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov  4 18:39:08.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 exec --namespace=statefulset-95 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 18:39:09.039: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 18:39:09.039: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 18:39:09.039: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 18:39:19.056: INFO: Waiting for StatefulSet statefulset-95/ss2 to complete update
Nov  4 18:39:19.056: INFO: Waiting for Pod statefulset-95/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  4 18:39:29.061: INFO: Waiting for StatefulSet statefulset-95/ss2 to complete update
Nov  4 18:39:29.062: INFO: Waiting for Pod statefulset-95/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 18:39:39.062: INFO: Deleting all statefulset in ns statefulset-95
Nov  4 18:39:39.064: INFO: Scaling statefulset ss2 to 0
Nov  4 18:40:19.082: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 18:40:19.084: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:40:19.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-95" for this suite.
Nov  4 18:40:25.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:40:25.188: INFO: namespace statefulset-95 deletion completed in 6.088836351s

â€¢ [SLOW TEST:157.345 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:40:25.188: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Nov  4 18:40:25.330: INFO: Waiting up to 5m0s for pod "var-expansion-4623364b-2ed8-4efe-a4cc-84d0c23995a1" in namespace "var-expansion-1108" to be "success or failure"
Nov  4 18:40:25.334: INFO: Pod "var-expansion-4623364b-2ed8-4efe-a4cc-84d0c23995a1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016249ms
Nov  4 18:40:27.337: INFO: Pod "var-expansion-4623364b-2ed8-4efe-a4cc-84d0c23995a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006818393s
STEP: Saw pod success
Nov  4 18:40:27.337: INFO: Pod "var-expansion-4623364b-2ed8-4efe-a4cc-84d0c23995a1" satisfied condition "success or failure"
Nov  4 18:40:27.339: INFO: Trying to get logs from node k8s-1 pod var-expansion-4623364b-2ed8-4efe-a4cc-84d0c23995a1 container dapi-container: <nil>
STEP: delete the pod
Nov  4 18:40:27.367: INFO: Waiting for pod var-expansion-4623364b-2ed8-4efe-a4cc-84d0c23995a1 to disappear
Nov  4 18:40:27.375: INFO: Pod var-expansion-4623364b-2ed8-4efe-a4cc-84d0c23995a1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:40:27.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1108" for this suite.
Nov  4 18:40:33.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:40:33.466: INFO: namespace var-expansion-1108 deletion completed in 6.087193906s

â€¢ [SLOW TEST:8.278 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:40:33.466: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 18:40:33.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-6432'
Nov  4 18:40:33.689: INFO: stderr: ""
Nov  4 18:40:33.689: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Nov  4 18:40:38.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 get pod e2e-test-httpd-pod --namespace=kubectl-6432 -o json'
Nov  4 18:40:38.814: INFO: stderr: ""
Nov  4 18:40:38.814: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-11-04T18:40:33Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6432\",\n        \"resourceVersion\": \"25881\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6432/pods/e2e-test-httpd-pod\",\n        \"uid\": \"4dc17b2a-b0b3-4a07-a94c-5c56c36ad3f4\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-kcvbg\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-kcvbg\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-kcvbg\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T18:40:33Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T18:40:35Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T18:40:35Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T18:40:33Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://10835701788dfebc3f6d3a1a8ff013f421b391e2907d644c81b7ba305cf3d7c5\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-11-04T18:40:34Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.20.20.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.33.0.29\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.33.0.29\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-11-04T18:40:33Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov  4 18:40:38.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 replace -f - --namespace=kubectl-6432'
Nov  4 18:40:39.013: INFO: stderr: ""
Nov  4 18:40:39.013: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Nov  4 18:40:39.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete pods e2e-test-httpd-pod --namespace=kubectl-6432'
Nov  4 18:40:49.425: INFO: stderr: ""
Nov  4 18:40:49.425: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:40:49.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6432" for this suite.
Nov  4 18:40:55.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:40:55.513: INFO: namespace kubectl-6432 deletion completed in 6.084540429s

â€¢ [SLOW TEST:22.047 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:40:55.514: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3438
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:40:55.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3438" for this suite.
Nov  4 18:41:01.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:41:01.742: INFO: namespace custom-resource-definition-3438 deletion completed in 6.084991522s

â€¢ [SLOW TEST:6.229 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:41:01.743: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:41:01.896: INFO: Create a RollingUpdate DaemonSet
Nov  4 18:41:01.900: INFO: Check that daemon pods launch on every node of the cluster
Nov  4 18:41:01.909: INFO: Number of nodes with available pods: 0
Nov  4 18:41:01.909: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 18:41:02.916: INFO: Number of nodes with available pods: 0
Nov  4 18:41:02.916: INFO: Node k8s-1 is running more than one daemon pod
Nov  4 18:41:03.915: INFO: Number of nodes with available pods: 3
Nov  4 18:41:03.915: INFO: Number of running nodes: 3, number of available pods: 3
Nov  4 18:41:03.915: INFO: Update the DaemonSet to trigger a rollout
Nov  4 18:41:03.923: INFO: Updating DaemonSet daemon-set
Nov  4 18:41:09.937: INFO: Roll back the DaemonSet before rollout is complete
Nov  4 18:41:09.944: INFO: Updating DaemonSet daemon-set
Nov  4 18:41:09.944: INFO: Make sure DaemonSet rollback is complete
Nov  4 18:41:09.948: INFO: Wrong image for pod: daemon-set-rl5rp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov  4 18:41:09.948: INFO: Pod daemon-set-rl5rp is not available
Nov  4 18:41:10.958: INFO: Wrong image for pod: daemon-set-rl5rp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov  4 18:41:10.958: INFO: Pod daemon-set-rl5rp is not available
Nov  4 18:41:11.957: INFO: Wrong image for pod: daemon-set-rl5rp. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov  4 18:41:11.958: INFO: Pod daemon-set-rl5rp is not available
Nov  4 18:41:12.958: INFO: Pod daemon-set-mz2lh is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8105, will wait for the garbage collector to delete the pods
Nov  4 18:41:13.029: INFO: Deleting DaemonSet.extensions daemon-set took: 7.406644ms
Nov  4 18:41:13.329: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.15927ms
Nov  4 18:41:19.532: INFO: Number of nodes with available pods: 0
Nov  4 18:41:19.532: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 18:41:19.534: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8105/daemonsets","resourceVersion":"26084"},"items":null}

Nov  4 18:41:19.536: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8105/pods","resourceVersion":"26084"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:41:19.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8105" for this suite.
Nov  4 18:41:25.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:41:25.655: INFO: namespace daemonsets-8105 deletion completed in 6.106024477s

â€¢ [SLOW TEST:23.913 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:41:25.656: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6180
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  4 18:41:25.799: INFO: Waiting up to 5m0s for pod "pod-50de9987-0b18-45ab-9afe-5e2d27605b10" in namespace "emptydir-6180" to be "success or failure"
Nov  4 18:41:25.809: INFO: Pod "pod-50de9987-0b18-45ab-9afe-5e2d27605b10": Phase="Pending", Reason="", readiness=false. Elapsed: 9.895796ms
Nov  4 18:41:27.812: INFO: Pod "pod-50de9987-0b18-45ab-9afe-5e2d27605b10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012804216s
STEP: Saw pod success
Nov  4 18:41:27.812: INFO: Pod "pod-50de9987-0b18-45ab-9afe-5e2d27605b10" satisfied condition "success or failure"
Nov  4 18:41:27.815: INFO: Trying to get logs from node k8s-1 pod pod-50de9987-0b18-45ab-9afe-5e2d27605b10 container test-container: <nil>
STEP: delete the pod
Nov  4 18:41:27.839: INFO: Waiting for pod pod-50de9987-0b18-45ab-9afe-5e2d27605b10 to disappear
Nov  4 18:41:27.842: INFO: Pod pod-50de9987-0b18-45ab-9afe-5e2d27605b10 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:41:27.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6180" for this suite.
Nov  4 18:41:33.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:41:33.937: INFO: namespace emptydir-6180 deletion completed in 6.091948909s

â€¢ [SLOW TEST:8.281 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:41:33.939: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2620
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:41:50.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2620" for this suite.
Nov  4 18:41:56.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:41:56.267: INFO: namespace resourcequota-2620 deletion completed in 6.09199992s

â€¢ [SLOW TEST:22.328 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:41:56.267: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7578
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:41:57.079: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 18:41:59.087: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489717, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489717, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489717, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489717, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:42:02.102: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
Nov  4 18:42:02.124: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:42:02.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7578" for this suite.
Nov  4 18:42:08.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:42:08.472: INFO: namespace webhook-7578 deletion completed in 6.085047079s
STEP: Destroying namespace "webhook-7578-markers" for this suite.
Nov  4 18:42:14.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:42:14.566: INFO: namespace webhook-7578-markers deletion completed in 6.093518934s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:18.313 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:42:14.581: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6275
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Nov  4 18:42:14.716: INFO: namespace kubectl-6275
Nov  4 18:42:14.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 create -f - --namespace=kubectl-6275'
Nov  4 18:42:14.914: INFO: stderr: ""
Nov  4 18:42:14.914: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  4 18:42:15.918: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:42:15.918: INFO: Found 0 / 1
Nov  4 18:42:16.918: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:42:16.918: INFO: Found 1 / 1
Nov  4 18:42:16.918: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  4 18:42:16.921: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:42:16.921: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  4 18:42:16.921: INFO: wait on redis-master startup in kubectl-6275 
Nov  4 18:42:16.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 logs redis-master-fhskx redis-master --namespace=kubectl-6275'
Nov  4 18:42:17.016: INFO: stderr: ""
Nov  4 18:42:17.016: INFO: stdout: "1:C 04 Nov 2019 18:42:15.498 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 04 Nov 2019 18:42:15.498 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 04 Nov 2019 18:42:15.498 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 04 Nov 2019 18:42:15.499 * Running mode=standalone, port=6379.\n1:M 04 Nov 2019 18:42:15.499 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Nov 2019 18:42:15.499 # Server initialized\n1:M 04 Nov 2019 18:42:15.499 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Nov 2019 18:42:15.499 * Ready to accept connections\n"
STEP: exposing RC
Nov  4 18:42:17.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6275'
Nov  4 18:42:17.114: INFO: stderr: ""
Nov  4 18:42:17.114: INFO: stdout: "service/rm2 exposed\n"
Nov  4 18:42:17.121: INFO: Service rm2 in namespace kubectl-6275 found.
STEP: exposing service
Nov  4 18:42:19.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6275'
Nov  4 18:42:20.256: INFO: stderr: ""
Nov  4 18:42:20.256: INFO: stdout: "service/rm3 exposed\n"
Nov  4 18:42:20.263: INFO: Service rm3 in namespace kubectl-6275 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:42:22.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6275" for this suite.
Nov  4 18:42:50.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:42:50.371: INFO: namespace kubectl-6275 deletion completed in 28.099637513s

â€¢ [SLOW TEST:35.790 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:42:50.372: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9443
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:42:50.514: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84d505b0-da7c-4cad-ba15-92845f52461d" in namespace "downward-api-9443" to be "success or failure"
Nov  4 18:42:50.518: INFO: Pod "downwardapi-volume-84d505b0-da7c-4cad-ba15-92845f52461d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.646234ms
Nov  4 18:42:52.520: INFO: Pod "downwardapi-volume-84d505b0-da7c-4cad-ba15-92845f52461d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006536007s
STEP: Saw pod success
Nov  4 18:42:52.521: INFO: Pod "downwardapi-volume-84d505b0-da7c-4cad-ba15-92845f52461d" satisfied condition "success or failure"
Nov  4 18:42:52.523: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-84d505b0-da7c-4cad-ba15-92845f52461d container client-container: <nil>
STEP: delete the pod
Nov  4 18:42:52.542: INFO: Waiting for pod downwardapi-volume-84d505b0-da7c-4cad-ba15-92845f52461d to disappear
Nov  4 18:42:52.551: INFO: Pod downwardapi-volume-84d505b0-da7c-4cad-ba15-92845f52461d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:42:52.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9443" for this suite.
Nov  4 18:42:58.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:42:58.640: INFO: namespace downward-api-9443 deletion completed in 6.08496339s

â€¢ [SLOW TEST:8.268 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:42:58.640: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-7195
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:42:58.775: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:43:04.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7195" for this suite.
Nov  4 18:43:11.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:43:11.135: INFO: namespace custom-resource-definition-7195 deletion completed in 6.352196235s

â€¢ [SLOW TEST:12.494 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:43:11.136: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9183
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-2xsk
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 18:43:11.290: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2xsk" in namespace "subpath-9183" to be "success or failure"
Nov  4 18:43:11.294: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Pending", Reason="", readiness=false. Elapsed: 4.595783ms
Nov  4 18:43:13.297: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Running", Reason="", readiness=true. Elapsed: 2.007660552s
Nov  4 18:43:15.300: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Running", Reason="", readiness=true. Elapsed: 4.010743658s
Nov  4 18:43:17.304: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Running", Reason="", readiness=true. Elapsed: 6.013871823s
Nov  4 18:43:19.307: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Running", Reason="", readiness=true. Elapsed: 8.016962128s
Nov  4 18:43:21.310: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Running", Reason="", readiness=true. Elapsed: 10.019877343s
Nov  4 18:43:23.312: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Running", Reason="", readiness=true. Elapsed: 12.022420403s
Nov  4 18:43:25.315: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Running", Reason="", readiness=true. Elapsed: 14.025170068s
Nov  4 18:43:27.318: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Running", Reason="", readiness=true. Elapsed: 16.028589613s
Nov  4 18:43:29.321: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Running", Reason="", readiness=true. Elapsed: 18.031521076s
Nov  4 18:43:31.324: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Running", Reason="", readiness=true. Elapsed: 20.03447487s
Nov  4 18:43:33.327: INFO: Pod "pod-subpath-test-configmap-2xsk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.037346699s
STEP: Saw pod success
Nov  4 18:43:33.327: INFO: Pod "pod-subpath-test-configmap-2xsk" satisfied condition "success or failure"
Nov  4 18:43:33.330: INFO: Trying to get logs from node k8s-1 pod pod-subpath-test-configmap-2xsk container test-container-subpath-configmap-2xsk: <nil>
STEP: delete the pod
Nov  4 18:43:33.349: INFO: Waiting for pod pod-subpath-test-configmap-2xsk to disappear
Nov  4 18:43:33.352: INFO: Pod pod-subpath-test-configmap-2xsk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2xsk
Nov  4 18:43:33.352: INFO: Deleting pod "pod-subpath-test-configmap-2xsk" in namespace "subpath-9183"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:43:33.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9183" for this suite.
Nov  4 18:43:39.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:43:39.459: INFO: namespace subpath-9183 deletion completed in 6.097630537s

â€¢ [SLOW TEST:28.323 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:43:39.459: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8446
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 18:43:40.608: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:43:40.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8446" for this suite.
Nov  4 18:43:46.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:43:46.726: INFO: namespace container-runtime-8446 deletion completed in 6.09074331s

â€¢ [SLOW TEST:7.267 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:43:46.726: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9592
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-fd83b3a2-014b-4e72-97e5-10738e8bb33c
STEP: Creating a pod to test consume configMaps
Nov  4 18:43:46.875: INFO: Waiting up to 5m0s for pod "pod-configmaps-31b551c0-5b62-402e-8a5f-8971507f0b05" in namespace "configmap-9592" to be "success or failure"
Nov  4 18:43:46.877: INFO: Pod "pod-configmaps-31b551c0-5b62-402e-8a5f-8971507f0b05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073884ms
Nov  4 18:43:48.880: INFO: Pod "pod-configmaps-31b551c0-5b62-402e-8a5f-8971507f0b05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004929887s
STEP: Saw pod success
Nov  4 18:43:48.880: INFO: Pod "pod-configmaps-31b551c0-5b62-402e-8a5f-8971507f0b05" satisfied condition "success or failure"
Nov  4 18:43:48.883: INFO: Trying to get logs from node k8s-1 pod pod-configmaps-31b551c0-5b62-402e-8a5f-8971507f0b05 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:43:48.902: INFO: Waiting for pod pod-configmaps-31b551c0-5b62-402e-8a5f-8971507f0b05 to disappear
Nov  4 18:43:48.908: INFO: Pod pod-configmaps-31b551c0-5b62-402e-8a5f-8971507f0b05 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:43:48.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9592" for this suite.
Nov  4 18:43:54.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:43:54.996: INFO: namespace configmap-9592 deletion completed in 6.084400239s

â€¢ [SLOW TEST:8.270 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:43:54.997: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 18:43:55.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-6493'
Nov  4 18:43:55.213: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 18:43:55.213: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Nov  4 18:43:57.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-430892974 delete deployment e2e-test-httpd-deployment --namespace=kubectl-6493'
Nov  4 18:43:57.303: INFO: stderr: ""
Nov  4 18:43:57.303: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:43:57.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6493" for this suite.
Nov  4 18:44:25.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:44:25.397: INFO: namespace kubectl-6493 deletion completed in 28.09043624s

â€¢ [SLOW TEST:30.400 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:44:25.398: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4938
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-ef6e2713-79f5-4496-815a-a3e950920e61
STEP: Creating a pod to test consume secrets
Nov  4 18:44:25.546: INFO: Waiting up to 5m0s for pod "pod-secrets-ef65e28c-c4d8-4390-919c-ba0e2c402e3a" in namespace "secrets-4938" to be "success or failure"
Nov  4 18:44:25.548: INFO: Pod "pod-secrets-ef65e28c-c4d8-4390-919c-ba0e2c402e3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.799614ms
Nov  4 18:44:27.552: INFO: Pod "pod-secrets-ef65e28c-c4d8-4390-919c-ba0e2c402e3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005879146s
STEP: Saw pod success
Nov  4 18:44:27.552: INFO: Pod "pod-secrets-ef65e28c-c4d8-4390-919c-ba0e2c402e3a" satisfied condition "success or failure"
Nov  4 18:44:27.554: INFO: Trying to get logs from node k8s-1 pod pod-secrets-ef65e28c-c4d8-4390-919c-ba0e2c402e3a container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:44:27.574: INFO: Waiting for pod pod-secrets-ef65e28c-c4d8-4390-919c-ba0e2c402e3a to disappear
Nov  4 18:44:27.577: INFO: Pod pod-secrets-ef65e28c-c4d8-4390-919c-ba0e2c402e3a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:44:27.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4938" for this suite.
Nov  4 18:44:33.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:44:33.665: INFO: namespace secrets-4938 deletion completed in 6.084170468s

â€¢ [SLOW TEST:8.268 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:44:33.666: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:44:33.811: INFO: (0) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.757889ms)
Nov  4 18:44:33.814: INFO: (1) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.023168ms)
Nov  4 18:44:33.817: INFO: (2) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.25972ms)
Nov  4 18:44:33.820: INFO: (3) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.824046ms)
Nov  4 18:44:33.823: INFO: (4) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.971645ms)
Nov  4 18:44:33.826: INFO: (5) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.078463ms)
Nov  4 18:44:33.829: INFO: (6) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.902246ms)
Nov  4 18:44:33.832: INFO: (7) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.00994ms)
Nov  4 18:44:33.836: INFO: (8) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.396614ms)
Nov  4 18:44:33.838: INFO: (9) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.544554ms)
Nov  4 18:44:33.842: INFO: (10) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.404804ms)
Nov  4 18:44:33.845: INFO: (11) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.298627ms)
Nov  4 18:44:33.848: INFO: (12) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.742221ms)
Nov  4 18:44:33.851: INFO: (13) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.180814ms)
Nov  4 18:44:33.854: INFO: (14) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.318585ms)
Nov  4 18:44:33.857: INFO: (15) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.534583ms)
Nov  4 18:44:33.860: INFO: (16) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.87298ms)
Nov  4 18:44:33.863: INFO: (17) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.14149ms)
Nov  4 18:44:33.866: INFO: (18) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.82838ms)
Nov  4 18:44:33.869: INFO: (19) /api/v1/nodes/k8s-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.978298ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:44:33.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6547" for this suite.
Nov  4 18:44:39.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:44:39.960: INFO: namespace proxy-6547 deletion completed in 6.087112964s

â€¢ [SLOW TEST:6.294 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:44:39.960: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9440
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:44:40.531: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:44:43.547: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:44:43.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9440" for this suite.
Nov  4 18:44:49.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:44:49.652: INFO: namespace webhook-9440 deletion completed in 6.095325509s
STEP: Destroying namespace "webhook-9440-markers" for this suite.
Nov  4 18:44:55.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:44:55.760: INFO: namespace webhook-9440-markers deletion completed in 6.107785355s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:15.813 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:44:55.774: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4913
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:44:56.470: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:44:59.487: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:44:59.490: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8640-crds.webhook.example.com via the AdmissionRegistration API
Nov  4 18:45:04.579: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:45:06.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4913" for this suite.
Nov  4 18:45:12.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:45:12.123: INFO: namespace webhook-4913 deletion completed in 6.080979409s
STEP: Destroying namespace "webhook-4913-markers" for this suite.
Nov  4 18:45:18.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:45:18.221: INFO: namespace webhook-4913-markers deletion completed in 6.098719519s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:22.461 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:45:18.236: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-546
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  4 18:45:24.414: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 18:45:24.417: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  4 18:45:26.417: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 18:45:26.420: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  4 18:45:28.417: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 18:45:28.422: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  4 18:45:30.417: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 18:45:30.421: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:45:30.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-546" for this suite.
Nov  4 18:45:42.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:45:42.508: INFO: namespace container-lifecycle-hook-546 deletion completed in 12.084243126s

â€¢ [SLOW TEST:24.273 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:45:42.509: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2546
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 18:45:42.647: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:45:45.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2546" for this suite.
Nov  4 18:46:13.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:46:13.720: INFO: namespace init-container-2546 deletion completed in 28.09290766s

â€¢ [SLOW TEST:31.212 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:46:13.721: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7007
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-b8d23a77-2a61-457e-9db9-7175a6e00c18 in namespace container-probe-7007
Nov  4 18:46:15.869: INFO: Started pod test-webserver-b8d23a77-2a61-457e-9db9-7175a6e00c18 in namespace container-probe-7007
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 18:46:15.872: INFO: Initial restart count of pod test-webserver-b8d23a77-2a61-457e-9db9-7175a6e00c18 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:50:16.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7007" for this suite.
Nov  4 18:50:22.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:50:22.370: INFO: namespace container-probe-7007 deletion completed in 6.097971414s

â€¢ [SLOW TEST:248.649 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:50:22.371: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7347
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:50:24.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7347" for this suite.
Nov  4 18:51:10.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:51:10.631: INFO: namespace kubelet-test-7347 deletion completed in 46.086670353s

â€¢ [SLOW TEST:48.261 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:51:10.633: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4786
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-k9t9
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 18:51:10.786: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-k9t9" in namespace "subpath-4786" to be "success or failure"
Nov  4 18:51:10.790: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.873277ms
Nov  4 18:51:12.792: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Running", Reason="", readiness=true. Elapsed: 2.006491973s
Nov  4 18:51:14.795: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Running", Reason="", readiness=true. Elapsed: 4.009640984s
Nov  4 18:51:16.799: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Running", Reason="", readiness=true. Elapsed: 6.012875524s
Nov  4 18:51:18.802: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Running", Reason="", readiness=true. Elapsed: 8.015850035s
Nov  4 18:51:20.805: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Running", Reason="", readiness=true. Elapsed: 10.018838571s
Nov  4 18:51:22.808: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Running", Reason="", readiness=true. Elapsed: 12.021765144s
Nov  4 18:51:24.811: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Running", Reason="", readiness=true. Elapsed: 14.024943785s
Nov  4 18:51:26.813: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Running", Reason="", readiness=true. Elapsed: 16.027639537s
Nov  4 18:51:28.817: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Running", Reason="", readiness=true. Elapsed: 18.030939223s
Nov  4 18:51:30.820: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Running", Reason="", readiness=true. Elapsed: 20.034106684s
Nov  4 18:51:32.823: INFO: Pod "pod-subpath-test-projected-k9t9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.037369655s
STEP: Saw pod success
Nov  4 18:51:32.823: INFO: Pod "pod-subpath-test-projected-k9t9" satisfied condition "success or failure"
Nov  4 18:51:32.826: INFO: Trying to get logs from node k8s-1 pod pod-subpath-test-projected-k9t9 container test-container-subpath-projected-k9t9: <nil>
STEP: delete the pod
Nov  4 18:51:32.846: INFO: Waiting for pod pod-subpath-test-projected-k9t9 to disappear
Nov  4 18:51:32.852: INFO: Pod pod-subpath-test-projected-k9t9 no longer exists
STEP: Deleting pod pod-subpath-test-projected-k9t9
Nov  4 18:51:32.852: INFO: Deleting pod "pod-subpath-test-projected-k9t9" in namespace "subpath-4786"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:51:32.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4786" for this suite.
Nov  4 18:51:38.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:51:38.947: INFO: namespace subpath-4786 deletion completed in 6.087939143s

â€¢ [SLOW TEST:28.314 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:51:38.947: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2616
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-9b882b73-2328-438d-8805-a94f140a8a73
STEP: Creating secret with name s-test-opt-upd-b0fb812a-4d5a-4060-8e4c-14368a0f8af6
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9b882b73-2328-438d-8805-a94f140a8a73
STEP: Updating secret s-test-opt-upd-b0fb812a-4d5a-4060-8e4c-14368a0f8af6
STEP: Creating secret with name s-test-opt-create-b6a9f10d-6c4c-4d65-8da6-c1638a119476
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:51:43.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2616" for this suite.
Nov  4 18:51:55.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:51:55.256: INFO: namespace projected-2616 deletion completed in 12.087603401s

â€¢ [SLOW TEST:16.309 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:51:55.257: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9327
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:51:55.402: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd842e14-88e0-4786-8d20-b1d35b14007a" in namespace "downward-api-9327" to be "success or failure"
Nov  4 18:51:55.412: INFO: Pod "downwardapi-volume-bd842e14-88e0-4786-8d20-b1d35b14007a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.051534ms
Nov  4 18:51:57.415: INFO: Pod "downwardapi-volume-bd842e14-88e0-4786-8d20-b1d35b14007a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013016547s
STEP: Saw pod success
Nov  4 18:51:57.415: INFO: Pod "downwardapi-volume-bd842e14-88e0-4786-8d20-b1d35b14007a" satisfied condition "success or failure"
Nov  4 18:51:57.418: INFO: Trying to get logs from node k8s-1 pod downwardapi-volume-bd842e14-88e0-4786-8d20-b1d35b14007a container client-container: <nil>
STEP: delete the pod
Nov  4 18:51:57.436: INFO: Waiting for pod downwardapi-volume-bd842e14-88e0-4786-8d20-b1d35b14007a to disappear
Nov  4 18:51:57.439: INFO: Pod downwardapi-volume-bd842e14-88e0-4786-8d20-b1d35b14007a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:51:57.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9327" for this suite.
Nov  4 18:52:03.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:52:03.531: INFO: namespace downward-api-9327 deletion completed in 6.089624045s

â€¢ [SLOW TEST:8.275 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:52:03.532: INFO: >>> kubeConfig: /tmp/kubeconfig-430892974
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5540
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:52:20.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5540" for this suite.
Nov  4 18:52:26.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:52:26.799: INFO: namespace resourcequota-5540 deletion completed in 6.092521262s

â€¢ [SLOW TEST:23.267 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSNov  4 18:52:26.799: INFO: Running AfterSuite actions on all nodes
Nov  4 18:52:26.799: INFO: Running AfterSuite actions on node 1
Nov  4 18:52:26.799: INFO: Skipping dumping logs from cluster

Ran 276 of 4897 Specs in 6717.427 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4621 Skipped
PASS

Ginkgo ran 1 suite in 1h51m59.023682469s
Test Suite Passed
