I0224 08:38:37.881414      21 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-533328996
I0224 08:38:37.881525      21 e2e.go:92] Starting e2e run "2daddc70-04b7-4f43-afab-fae069a8d13b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1582533516 - Will randomize all specs
Will run 276 of 4731 specs

Feb 24 08:38:37.897: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 08:38:37.899: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 24 08:38:37.908: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 24 08:38:37.929: INFO: The status of Pod minio-setup-j6w9s is Succeeded, skipping waiting
Feb 24 08:38:37.929: INFO: 17 / 18 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 24 08:38:37.929: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Feb 24 08:38:37.929: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 24 08:38:37.934: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 24 08:38:37.934: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 24 08:38:37.934: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'velero-restic' (0 seconds elapsed)
Feb 24 08:38:37.935: INFO: e2e test version: v1.16.7
Feb 24 08:38:37.935: INFO: kube-apiserver version: v1.16.7
Feb 24 08:38:37.935: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 08:38:37.939: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:38:37.939: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename job
Feb 24 08:38:37.961: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Feb 24 08:38:44.478: INFO: Successfully updated pod "adopt-release-bnns5"
STEP: Checking that the Job readopts the Pod
Feb 24 08:38:44.478: INFO: Waiting up to 15m0s for pod "adopt-release-bnns5" in namespace "job-6285" to be "adopted"
Feb 24 08:38:44.490: INFO: Pod "adopt-release-bnns5": Phase="Running", Reason="", readiness=true. Elapsed: 11.555692ms
Feb 24 08:38:44.490: INFO: Pod "adopt-release-bnns5" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Feb 24 08:38:45.000: INFO: Successfully updated pod "adopt-release-bnns5"
STEP: Checking that the Job releases the Pod
Feb 24 08:38:45.000: INFO: Waiting up to 15m0s for pod "adopt-release-bnns5" in namespace "job-6285" to be "released"
Feb 24 08:38:45.007: INFO: Pod "adopt-release-bnns5": Phase="Running", Reason="", readiness=true. Elapsed: 7.103277ms
Feb 24 08:38:45.007: INFO: Pod "adopt-release-bnns5" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:38:45.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6285" for this suite.
Feb 24 08:39:35.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:39:35.098: INFO: namespace job-6285 deletion completed in 50.079529459s

• [SLOW TEST:57.159 seconds]
[sig-apps] Job
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:39:35.098: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 08:39:35.143: INFO: Waiting up to 5m0s for pod "busybox-user-65534-f0740d98-1c52-4225-850b-3159b99f39d9" in namespace "security-context-test-1058" to be "success or failure"
Feb 24 08:39:35.156: INFO: Pod "busybox-user-65534-f0740d98-1c52-4225-850b-3159b99f39d9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.780757ms
Feb 24 08:39:37.158: INFO: Pod "busybox-user-65534-f0740d98-1c52-4225-850b-3159b99f39d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014848383s
Feb 24 08:39:37.158: INFO: Pod "busybox-user-65534-f0740d98-1c52-4225-850b-3159b99f39d9" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:39:37.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1058" for this suite.
Feb 24 08:39:43.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:39:43.252: INFO: namespace security-context-test-1058 deletion completed in 6.090902555s

• [SLOW TEST:8.154 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:39:43.252: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Feb 24 08:39:43.323: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 24 08:40:43.337: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 08:40:43.339: INFO: Starting informer...
STEP: Starting pod...
Feb 24 08:40:43.548: INFO: Pod is running on ip-10-100-10-76.eu-west-1.compute.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Feb 24 08:40:43.573: INFO: Pod wasn't evicted. Proceeding
Feb 24 08:40:43.573: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Feb 24 08:41:58.658: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:41:58.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-3566" for this suite.
Feb 24 08:42:10.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:42:10.745: INFO: namespace taint-single-pod-3566 deletion completed in 12.084561615s

• [SLOW TEST:147.493 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:42:10.745: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 08:42:10.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-7442'
Feb 24 08:42:11.025: INFO: stderr: ""
Feb 24 08:42:11.025: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Feb 24 08:42:21.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pod e2e-test-httpd-pod --namespace=kubectl-7442 -o json'
Feb 24 08:42:21.134: INFO: stderr: ""
Feb 24 08:42:21.134: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"172.16.14.209/32\"\n        },\n        \"creationTimestamp\": \"2020-02-24T08:42:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-7442\",\n        \"resourceVersion\": \"4294\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7442/pods/e2e-test-httpd-pod\",\n        \"uid\": \"bee77409-1d76-4936-8497-4fc5bf001b46\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-mfhmp\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-100-10-76.eu-west-1.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-mfhmp\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-mfhmp\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-24T08:42:11Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-24T08:42:17Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-24T08:42:17Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-24T08:42:11Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://7310554db4185927fe1db2cbf45bbe6a754c91a80cdc07c5d5d2969b7f48df2b\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-02-24T08:42:17Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.100.10.76\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.14.209\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.16.14.209\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-02-24T08:42:11Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 24 08:42:21.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 replace -f - --namespace=kubectl-7442'
Feb 24 08:42:21.320: INFO: stderr: ""
Feb 24 08:42:21.320: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Feb 24 08:42:21.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete pods e2e-test-httpd-pod --namespace=kubectl-7442'
Feb 24 08:42:33.334: INFO: stderr: ""
Feb 24 08:42:33.334: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:42:33.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7442" for this suite.
Feb 24 08:42:39.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:42:39.430: INFO: namespace kubectl-7442 deletion completed in 6.088537826s

• [SLOW TEST:28.684 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:42:39.430: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-8ztj
STEP: Creating a pod to test atomic-volume-subpath
Feb 24 08:42:39.510: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-8ztj" in namespace "subpath-357" to be "success or failure"
Feb 24 08:42:39.515: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Pending", Reason="", readiness=false. Elapsed: 5.517865ms
Feb 24 08:42:41.518: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007660952s
Feb 24 08:42:43.520: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Running", Reason="", readiness=true. Elapsed: 4.0098334s
Feb 24 08:42:45.522: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Running", Reason="", readiness=true. Elapsed: 6.011961259s
Feb 24 08:42:47.524: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Running", Reason="", readiness=true. Elapsed: 8.013986869s
Feb 24 08:42:49.526: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Running", Reason="", readiness=true. Elapsed: 10.01613095s
Feb 24 08:42:51.528: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Running", Reason="", readiness=true. Elapsed: 12.018099683s
Feb 24 08:42:53.530: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Running", Reason="", readiness=true. Elapsed: 14.020081793s
Feb 24 08:42:55.532: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Running", Reason="", readiness=true. Elapsed: 16.022091674s
Feb 24 08:42:57.534: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Running", Reason="", readiness=true. Elapsed: 18.024265963s
Feb 24 08:42:59.536: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Running", Reason="", readiness=true. Elapsed: 20.026402313s
Feb 24 08:43:01.538: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Running", Reason="", readiness=true. Elapsed: 22.028599852s
Feb 24 08:43:03.541: INFO: Pod "pod-subpath-test-projected-8ztj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.030609954s
STEP: Saw pod success
Feb 24 08:43:03.541: INFO: Pod "pod-subpath-test-projected-8ztj" satisfied condition "success or failure"
Feb 24 08:43:03.542: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-subpath-test-projected-8ztj container test-container-subpath-projected-8ztj: <nil>
STEP: delete the pod
Feb 24 08:43:03.573: INFO: Waiting for pod pod-subpath-test-projected-8ztj to disappear
Feb 24 08:43:03.575: INFO: Pod pod-subpath-test-projected-8ztj no longer exists
STEP: Deleting pod pod-subpath-test-projected-8ztj
Feb 24 08:43:03.576: INFO: Deleting pod "pod-subpath-test-projected-8ztj" in namespace "subpath-357"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:43:03.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-357" for this suite.
Feb 24 08:43:09.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:43:09.658: INFO: namespace subpath-357 deletion completed in 6.078064152s

• [SLOW TEST:30.228 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:43:09.659: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 08:43:09.677: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:43:13.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8360" for this suite.
Feb 24 08:43:57.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:43:57.775: INFO: namespace pods-8360 deletion completed in 44.074797223s

• [SLOW TEST:48.116 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:43:57.775: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1642.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1642.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1642.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1642.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1642.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1642.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1642.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1642.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1642.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1642.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1642.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 98.109.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.109.98_udp@PTR;check="$$(dig +tcp +noall +answer +search 98.109.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.109.98_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1642.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1642.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1642.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1642.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1642.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1642.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1642.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1642.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1642.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1642.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1642.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 98.109.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.109.98_udp@PTR;check="$$(dig +tcp +noall +answer +search 98.109.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.109.98_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 08:44:11.844: INFO: Unable to read wheezy_udp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:11.846: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:11.848: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:11.850: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:11.862: INFO: Unable to read jessie_udp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:11.864: INFO: Unable to read jessie_tcp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:11.866: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:11.868: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:11.878: INFO: Lookups using dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0 failed for: [wheezy_udp@dns-test-service.dns-1642.svc.cluster.local wheezy_tcp@dns-test-service.dns-1642.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local jessie_udp@dns-test-service.dns-1642.svc.cluster.local jessie_tcp@dns-test-service.dns-1642.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local]

Feb 24 08:44:16.880: INFO: Unable to read wheezy_udp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:16.882: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:16.884: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:16.886: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:16.903: INFO: Unable to read jessie_udp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:16.904: INFO: Unable to read jessie_tcp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:16.906: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:16.908: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:16.919: INFO: Lookups using dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0 failed for: [wheezy_udp@dns-test-service.dns-1642.svc.cluster.local wheezy_tcp@dns-test-service.dns-1642.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local jessie_udp@dns-test-service.dns-1642.svc.cluster.local jessie_tcp@dns-test-service.dns-1642.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local]

Feb 24 08:44:21.880: INFO: Unable to read wheezy_udp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:21.883: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:21.885: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:21.886: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:21.905: INFO: Unable to read jessie_udp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:21.908: INFO: Unable to read jessie_tcp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:21.914: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:21.917: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:21.934: INFO: Lookups using dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0 failed for: [wheezy_udp@dns-test-service.dns-1642.svc.cluster.local wheezy_tcp@dns-test-service.dns-1642.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local jessie_udp@dns-test-service.dns-1642.svc.cluster.local jessie_tcp@dns-test-service.dns-1642.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local]

Feb 24 08:44:26.880: INFO: Unable to read wheezy_udp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:26.882: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:26.884: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:26.886: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:26.897: INFO: Unable to read jessie_udp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:26.899: INFO: Unable to read jessie_tcp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:26.901: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:26.903: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:26.921: INFO: Lookups using dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0 failed for: [wheezy_udp@dns-test-service.dns-1642.svc.cluster.local wheezy_tcp@dns-test-service.dns-1642.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local jessie_udp@dns-test-service.dns-1642.svc.cluster.local jessie_tcp@dns-test-service.dns-1642.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local]

Feb 24 08:44:31.880: INFO: Unable to read wheezy_udp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:31.882: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:31.884: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:31.886: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:31.910: INFO: Unable to read jessie_udp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:31.912: INFO: Unable to read jessie_tcp@dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:31.914: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:31.915: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local from pod dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0: the server could not find the requested resource (get pods dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0)
Feb 24 08:44:31.926: INFO: Lookups using dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0 failed for: [wheezy_udp@dns-test-service.dns-1642.svc.cluster.local wheezy_tcp@dns-test-service.dns-1642.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local jessie_udp@dns-test-service.dns-1642.svc.cluster.local jessie_tcp@dns-test-service.dns-1642.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1642.svc.cluster.local]

Feb 24 08:44:37.009: INFO: DNS probes using dns-1642/dns-test-cae206eb-22b8-492b-8b4f-d393ab408ee0 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:44:37.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1642" for this suite.
Feb 24 08:44:43.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:44:43.191: INFO: namespace dns-1642 deletion completed in 6.076879998s

• [SLOW TEST:45.416 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:44:43.192: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 08:44:43.218: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1f3184f5-cc73-41f4-915f-7a20e30aa4c5" in namespace "projected-9044" to be "success or failure"
Feb 24 08:44:43.220: INFO: Pod "downwardapi-volume-1f3184f5-cc73-41f4-915f-7a20e30aa4c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.150356ms
Feb 24 08:44:45.225: INFO: Pod "downwardapi-volume-1f3184f5-cc73-41f4-915f-7a20e30aa4c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006781685s
Feb 24 08:44:47.227: INFO: Pod "downwardapi-volume-1f3184f5-cc73-41f4-915f-7a20e30aa4c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00897994s
STEP: Saw pod success
Feb 24 08:44:47.227: INFO: Pod "downwardapi-volume-1f3184f5-cc73-41f4-915f-7a20e30aa4c5" satisfied condition "success or failure"
Feb 24 08:44:47.229: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-1f3184f5-cc73-41f4-915f-7a20e30aa4c5 container client-container: <nil>
STEP: delete the pod
Feb 24 08:44:47.258: INFO: Waiting for pod downwardapi-volume-1f3184f5-cc73-41f4-915f-7a20e30aa4c5 to disappear
Feb 24 08:44:47.260: INFO: Pod downwardapi-volume-1f3184f5-cc73-41f4-915f-7a20e30aa4c5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:44:47.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9044" for this suite.
Feb 24 08:44:53.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:44:53.336: INFO: namespace projected-9044 deletion completed in 6.073889271s

• [SLOW TEST:10.145 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:44:53.337: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 24 08:45:03.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 24 08:45:03.409: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 24 08:45:05.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 24 08:45:05.411: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 24 08:45:07.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 24 08:45:07.411: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:45:07.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9440" for this suite.
Feb 24 08:45:35.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:45:35.490: INFO: namespace container-lifecycle-hook-9440 deletion completed in 28.072207216s

• [SLOW TEST:42.154 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:45:35.491: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-2442609a-d9ab-441f-8e6e-d8cb87af855b
STEP: Creating a pod to test consume secrets
Feb 24 08:45:35.518: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6b09fbfc-6c03-4d1b-ae5c-2be0e6771032" in namespace "projected-1468" to be "success or failure"
Feb 24 08:45:35.525: INFO: Pod "pod-projected-secrets-6b09fbfc-6c03-4d1b-ae5c-2be0e6771032": Phase="Pending", Reason="", readiness=false. Elapsed: 6.312743ms
Feb 24 08:45:37.527: INFO: Pod "pod-projected-secrets-6b09fbfc-6c03-4d1b-ae5c-2be0e6771032": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008288617s
Feb 24 08:45:39.529: INFO: Pod "pod-projected-secrets-6b09fbfc-6c03-4d1b-ae5c-2be0e6771032": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01027238s
STEP: Saw pod success
Feb 24 08:45:39.529: INFO: Pod "pod-projected-secrets-6b09fbfc-6c03-4d1b-ae5c-2be0e6771032" satisfied condition "success or failure"
Feb 24 08:45:39.530: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-secrets-6b09fbfc-6c03-4d1b-ae5c-2be0e6771032 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 24 08:45:39.551: INFO: Waiting for pod pod-projected-secrets-6b09fbfc-6c03-4d1b-ae5c-2be0e6771032 to disappear
Feb 24 08:45:39.558: INFO: Pod pod-projected-secrets-6b09fbfc-6c03-4d1b-ae5c-2be0e6771032 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:45:39.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1468" for this suite.
Feb 24 08:45:45.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:45:45.804: INFO: namespace projected-1468 deletion completed in 6.244158769s

• [SLOW TEST:10.314 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:45:45.804: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6656.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6656.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 08:45:49.854: INFO: DNS probes using dns-test-3acfdd9e-f52f-47fd-995a-c783661cafb0 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6656.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6656.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 08:45:53.912: INFO: File wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local from pod  dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 24 08:45:53.914: INFO: File jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local from pod  dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 24 08:45:53.914: INFO: Lookups using dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef failed for: [wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local]

Feb 24 08:45:58.917: INFO: File wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local from pod  dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 24 08:45:58.919: INFO: File jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local from pod  dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 24 08:45:58.919: INFO: Lookups using dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef failed for: [wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local]

Feb 24 08:46:03.917: INFO: File wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local from pod  dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 24 08:46:03.919: INFO: File jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local from pod  dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 24 08:46:03.919: INFO: Lookups using dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef failed for: [wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local]

Feb 24 08:46:08.917: INFO: File wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local from pod  dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 24 08:46:08.919: INFO: File jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local from pod  dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 24 08:46:08.919: INFO: Lookups using dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef failed for: [wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local]

Feb 24 08:46:13.917: INFO: File wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local from pod  dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 24 08:46:13.919: INFO: File jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local from pod  dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 24 08:46:13.919: INFO: Lookups using dns-6656/dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef failed for: [wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local]

Feb 24 08:46:18.919: INFO: DNS probes using dns-test-595fd08d-9d28-4869-ad79-9c4c88c955ef succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6656.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6656.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6656.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6656.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 08:46:22.983: INFO: DNS probes using dns-test-5a31ca60-8238-453b-ad52-97c8db798d7e succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:46:23.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6656" for this suite.
Feb 24 08:46:29.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:46:29.100: INFO: namespace dns-6656 deletion completed in 6.08191042s

• [SLOW TEST:43.296 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:46:29.100: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Feb 24 08:46:39.176: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0224 08:46:39.176235      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:46:39.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9149" for this suite.
Feb 24 08:46:45.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:46:45.300: INFO: namespace gc-9149 deletion completed in 6.121435048s

• [SLOW TEST:16.200 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:46:45.300: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 08:46:45.333: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 24 08:46:48.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-8781 create -f -'
Feb 24 08:46:48.683: INFO: stderr: ""
Feb 24 08:46:48.683: INFO: stdout: "e2e-test-crd-publish-openapi-6075-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 24 08:46:48.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-8781 delete e2e-test-crd-publish-openapi-6075-crds test-cr'
Feb 24 08:46:48.743: INFO: stderr: ""
Feb 24 08:46:48.743: INFO: stdout: "e2e-test-crd-publish-openapi-6075-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Feb 24 08:46:48.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-8781 apply -f -'
Feb 24 08:46:48.883: INFO: stderr: ""
Feb 24 08:46:48.883: INFO: stdout: "e2e-test-crd-publish-openapi-6075-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 24 08:46:48.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-8781 delete e2e-test-crd-publish-openapi-6075-crds test-cr'
Feb 24 08:46:48.945: INFO: stderr: ""
Feb 24 08:46:48.945: INFO: stdout: "e2e-test-crd-publish-openapi-6075-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb 24 08:46:48.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 explain e2e-test-crd-publish-openapi-6075-crds'
Feb 24 08:46:49.083: INFO: stderr: ""
Feb 24 08:46:49.083: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6075-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:46:52.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8781" for this suite.
Feb 24 08:46:58.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:46:58.575: INFO: namespace crd-publish-openapi-8781 deletion completed in 6.072419859s

• [SLOW TEST:13.276 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:46:58.575: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-69feb748-f5e8-4e7f-a9f5-7b792c94017c
STEP: Creating a pod to test consume secrets
Feb 24 08:46:58.653: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-08927d9a-c88c-4db9-9eec-373f1729d252" in namespace "projected-2189" to be "success or failure"
Feb 24 08:46:58.662: INFO: Pod "pod-projected-secrets-08927d9a-c88c-4db9-9eec-373f1729d252": Phase="Pending", Reason="", readiness=false. Elapsed: 8.708491ms
Feb 24 08:47:00.664: INFO: Pod "pod-projected-secrets-08927d9a-c88c-4db9-9eec-373f1729d252": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010860244s
Feb 24 08:47:02.667: INFO: Pod "pod-projected-secrets-08927d9a-c88c-4db9-9eec-373f1729d252": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013113677s
STEP: Saw pod success
Feb 24 08:47:02.667: INFO: Pod "pod-projected-secrets-08927d9a-c88c-4db9-9eec-373f1729d252" satisfied condition "success or failure"
Feb 24 08:47:02.669: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-secrets-08927d9a-c88c-4db9-9eec-373f1729d252 container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 08:47:02.686: INFO: Waiting for pod pod-projected-secrets-08927d9a-c88c-4db9-9eec-373f1729d252 to disappear
Feb 24 08:47:02.687: INFO: Pod pod-projected-secrets-08927d9a-c88c-4db9-9eec-373f1729d252 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:47:02.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2189" for this suite.
Feb 24 08:47:08.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:47:08.765: INFO: namespace projected-2189 deletion completed in 6.074889723s

• [SLOW TEST:10.189 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:47:08.765: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1735
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 24 08:47:08.789: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 24 08:47:34.872: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.14.229:8080/dial?request=hostName&protocol=udp&host=172.16.145.155&port=8081&tries=1'] Namespace:pod-network-test-1735 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 08:47:34.872: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 08:47:35.011: INFO: Waiting for endpoints: map[]
Feb 24 08:47:35.014: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.14.229:8080/dial?request=hostName&protocol=udp&host=172.16.14.228&port=8081&tries=1'] Namespace:pod-network-test-1735 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 08:47:35.014: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 08:47:35.165: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:47:35.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1735" for this suite.
Feb 24 08:47:47.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:47:47.254: INFO: namespace pod-network-test-1735 deletion completed in 12.085037484s

• [SLOW TEST:38.489 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:47:47.255: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-775/configmap-test-4747c4b4-b312-4652-b6c7-61963888b458
STEP: Creating a pod to test consume configMaps
Feb 24 08:47:47.283: INFO: Waiting up to 5m0s for pod "pod-configmaps-e929c1f5-a4fd-426f-a338-2b2e3a746d4b" in namespace "configmap-775" to be "success or failure"
Feb 24 08:47:47.287: INFO: Pod "pod-configmaps-e929c1f5-a4fd-426f-a338-2b2e3a746d4b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.213711ms
Feb 24 08:47:49.289: INFO: Pod "pod-configmaps-e929c1f5-a4fd-426f-a338-2b2e3a746d4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006050189s
STEP: Saw pod success
Feb 24 08:47:49.289: INFO: Pod "pod-configmaps-e929c1f5-a4fd-426f-a338-2b2e3a746d4b" satisfied condition "success or failure"
Feb 24 08:47:49.291: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-configmaps-e929c1f5-a4fd-426f-a338-2b2e3a746d4b container env-test: <nil>
STEP: delete the pod
Feb 24 08:47:49.305: INFO: Waiting for pod pod-configmaps-e929c1f5-a4fd-426f-a338-2b2e3a746d4b to disappear
Feb 24 08:47:49.306: INFO: Pod pod-configmaps-e929c1f5-a4fd-426f-a338-2b2e3a746d4b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:47:49.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-775" for this suite.
Feb 24 08:47:55.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:47:55.379: INFO: namespace configmap-775 deletion completed in 6.070587455s

• [SLOW TEST:8.124 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:47:55.379: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Feb 24 08:47:55.450: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 08:47:58.375: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:48:09.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2599" for this suite.
Feb 24 08:48:15.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:48:16.054: INFO: namespace crd-publish-openapi-2599 deletion completed in 6.074270927s

• [SLOW TEST:20.675 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:48:16.054: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8b040ff3-da3f-465a-9405-499162819ba6
STEP: Creating a pod to test consume configMaps
Feb 24 08:48:16.080: INFO: Waiting up to 5m0s for pod "pod-configmaps-e45607bf-7e58-47be-817b-7ef492c83563" in namespace "configmap-3451" to be "success or failure"
Feb 24 08:48:16.083: INFO: Pod "pod-configmaps-e45607bf-7e58-47be-817b-7ef492c83563": Phase="Pending", Reason="", readiness=false. Elapsed: 2.635406ms
Feb 24 08:48:18.084: INFO: Pod "pod-configmaps-e45607bf-7e58-47be-817b-7ef492c83563": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004556437s
STEP: Saw pod success
Feb 24 08:48:18.084: INFO: Pod "pod-configmaps-e45607bf-7e58-47be-817b-7ef492c83563" satisfied condition "success or failure"
Feb 24 08:48:18.086: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-configmaps-e45607bf-7e58-47be-817b-7ef492c83563 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 08:48:18.104: INFO: Waiting for pod pod-configmaps-e45607bf-7e58-47be-817b-7ef492c83563 to disappear
Feb 24 08:48:18.106: INFO: Pod pod-configmaps-e45607bf-7e58-47be-817b-7ef492c83563 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:48:18.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3451" for this suite.
Feb 24 08:48:24.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:48:24.181: INFO: namespace configmap-3451 deletion completed in 6.072990975s

• [SLOW TEST:8.127 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:48:24.181: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 08:48:24.203: INFO: Waiting up to 5m0s for pod "downwardapi-volume-300673c3-8dc7-46cd-ab1a-5ec2a55fdf0b" in namespace "downward-api-4991" to be "success or failure"
Feb 24 08:48:24.207: INFO: Pod "downwardapi-volume-300673c3-8dc7-46cd-ab1a-5ec2a55fdf0b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.805343ms
Feb 24 08:48:26.209: INFO: Pod "downwardapi-volume-300673c3-8dc7-46cd-ab1a-5ec2a55fdf0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005512544s
STEP: Saw pod success
Feb 24 08:48:26.209: INFO: Pod "downwardapi-volume-300673c3-8dc7-46cd-ab1a-5ec2a55fdf0b" satisfied condition "success or failure"
Feb 24 08:48:26.210: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-300673c3-8dc7-46cd-ab1a-5ec2a55fdf0b container client-container: <nil>
STEP: delete the pod
Feb 24 08:48:26.233: INFO: Waiting for pod downwardapi-volume-300673c3-8dc7-46cd-ab1a-5ec2a55fdf0b to disappear
Feb 24 08:48:26.238: INFO: Pod downwardapi-volume-300673c3-8dc7-46cd-ab1a-5ec2a55fdf0b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:48:26.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4991" for this suite.
Feb 24 08:48:32.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:48:32.319: INFO: namespace downward-api-4991 deletion completed in 6.07835919s

• [SLOW TEST:8.138 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:48:32.319: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-9fa10749-4443-4eb4-afe0-e42fcd43b23d
STEP: Creating secret with name secret-projected-all-test-volume-32e58f6b-f128-48d1-ab46-23b56e716bca
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 24 08:48:32.358: INFO: Waiting up to 5m0s for pod "projected-volume-71e81c5c-1129-49cb-84b9-1e3531d3d6c9" in namespace "projected-2012" to be "success or failure"
Feb 24 08:48:32.360: INFO: Pod "projected-volume-71e81c5c-1129-49cb-84b9-1e3531d3d6c9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.797266ms
Feb 24 08:48:34.363: INFO: Pod "projected-volume-71e81c5c-1129-49cb-84b9-1e3531d3d6c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004972264s
STEP: Saw pod success
Feb 24 08:48:34.363: INFO: Pod "projected-volume-71e81c5c-1129-49cb-84b9-1e3531d3d6c9" satisfied condition "success or failure"
Feb 24 08:48:34.365: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod projected-volume-71e81c5c-1129-49cb-84b9-1e3531d3d6c9 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 24 08:48:34.377: INFO: Waiting for pod projected-volume-71e81c5c-1129-49cb-84b9-1e3531d3d6c9 to disappear
Feb 24 08:48:34.381: INFO: Pod projected-volume-71e81c5c-1129-49cb-84b9-1e3531d3d6c9 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:48:34.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2012" for this suite.
Feb 24 08:48:40.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:48:40.455: INFO: namespace projected-2012 deletion completed in 6.071844296s

• [SLOW TEST:8.137 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:48:40.456: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-81
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-81
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-81
Feb 24 08:48:40.537: INFO: Found 0 stateful pods, waiting for 1
Feb 24 08:48:50.539: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 24 08:48:50.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-81 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 08:48:50.753: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 08:48:50.753: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 08:48:50.753: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 08:48:50.756: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 24 08:49:00.758: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 08:49:00.758: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 08:49:00.766: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999725s
Feb 24 08:49:01.769: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997074163s
Feb 24 08:49:02.771: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994706478s
Feb 24 08:49:03.774: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.992330861s
Feb 24 08:49:04.776: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.989895304s
Feb 24 08:49:05.778: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.98769093s
Feb 24 08:49:06.781: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.985157083s
Feb 24 08:49:07.783: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.982681471s
Feb 24 08:49:08.786: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.980446356s
Feb 24 08:49:09.788: INFO: Verifying statefulset ss doesn't scale past 1 for another 978.065659ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-81
Feb 24 08:49:10.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-81 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:49:10.964: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 08:49:10.964: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 08:49:10.964: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 08:49:10.970: INFO: Found 1 stateful pods, waiting for 3
Feb 24 08:49:20.973: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 08:49:20.973: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 08:49:20.973: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=false
Feb 24 08:49:30.973: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 08:49:30.973: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 08:49:30.973: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 24 08:49:30.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-81 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 08:49:31.155: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 08:49:31.155: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 08:49:31.155: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 08:49:31.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-81 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 08:49:31.409: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 08:49:31.409: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 08:49:31.409: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 08:49:31.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-81 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 08:49:31.584: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 08:49:31.584: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 08:49:31.584: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 08:49:31.584: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 08:49:31.587: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 24 08:49:41.590: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 08:49:41.590: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 08:49:41.590: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 08:49:41.598: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999792s
Feb 24 08:49:42.600: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996748938s
Feb 24 08:49:43.603: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994495346s
Feb 24 08:49:44.605: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991986987s
Feb 24 08:49:45.607: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.989618845s
Feb 24 08:49:46.610: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98729643s
Feb 24 08:49:47.613: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.984544031s
Feb 24 08:49:48.615: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.982082857s
Feb 24 08:49:49.618: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.979687156s
Feb 24 08:49:50.620: INFO: Verifying statefulset ss doesn't scale past 3 for another 977.09377ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-81
Feb 24 08:49:51.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-81 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:49:51.798: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 08:49:51.798: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 08:49:51.798: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 08:49:51.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-81 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:49:52.004: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 08:49:52.004: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 08:49:52.004: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 08:49:52.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-81 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:49:52.188: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 08:49:52.188: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 08:49:52.188: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 08:49:52.188: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 08:50:22.198: INFO: Deleting all statefulset in ns statefulset-81
Feb 24 08:50:22.199: INFO: Scaling statefulset ss to 0
Feb 24 08:50:22.204: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 08:50:22.205: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:50:22.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-81" for this suite.
Feb 24 08:50:28.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:50:28.291: INFO: namespace statefulset-81 deletion completed in 6.074861589s

• [SLOW TEST:107.835 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:50:28.291: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:50:32.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5498" for this suite.
Feb 24 08:50:38.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:50:38.649: INFO: namespace watch-5498 deletion completed in 6.204260251s

• [SLOW TEST:10.358 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:50:38.649: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6758
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-6758
I0224 08:50:38.686879      21 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6758, replica count: 2
Feb 24 08:50:41.737: INFO: Creating new exec pod
I0224 08:50:41.737202      21 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 24 08:50:46.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-6758 execpodcdkqp -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 24 08:50:46.950: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 24 08:50:46.950: INFO: stdout: ""
Feb 24 08:50:46.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-6758 execpodcdkqp -- /bin/sh -x -c nc -zv -t -w 2 10.110.68.52 80'
Feb 24 08:50:47.146: INFO: stderr: "+ nc -zv -t -w 2 10.110.68.52 80\nConnection to 10.110.68.52 80 port [tcp/http] succeeded!\n"
Feb 24 08:50:47.146: INFO: stdout: ""
Feb 24 08:50:47.146: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:50:47.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6758" for this suite.
Feb 24 08:50:53.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:50:53.247: INFO: namespace services-6758 deletion completed in 6.077518847s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:14.598 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:50:53.247: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3626
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 24 08:50:53.267: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 24 08:51:13.328: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.14.238:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3626 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 08:51:13.328: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 08:51:13.467: INFO: Found all expected endpoints: [netserver-0]
Feb 24 08:51:13.470: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.145.158:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3626 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 08:51:13.470: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 08:51:13.617: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:51:13.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3626" for this suite.
Feb 24 08:51:25.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:51:25.692: INFO: namespace pod-network-test-3626 deletion completed in 12.071913714s

• [SLOW TEST:32.444 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:51:25.692: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 08:51:25.721: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ef376970-2355-46c6-b7e4-6cc96f91e782" in namespace "projected-8315" to be "success or failure"
Feb 24 08:51:25.728: INFO: Pod "downwardapi-volume-ef376970-2355-46c6-b7e4-6cc96f91e782": Phase="Pending", Reason="", readiness=false. Elapsed: 6.580131ms
Feb 24 08:51:27.730: INFO: Pod "downwardapi-volume-ef376970-2355-46c6-b7e4-6cc96f91e782": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008759428s
Feb 24 08:51:29.732: INFO: Pod "downwardapi-volume-ef376970-2355-46c6-b7e4-6cc96f91e782": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011054963s
STEP: Saw pod success
Feb 24 08:51:29.733: INFO: Pod "downwardapi-volume-ef376970-2355-46c6-b7e4-6cc96f91e782" satisfied condition "success or failure"
Feb 24 08:51:29.734: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-ef376970-2355-46c6-b7e4-6cc96f91e782 container client-container: <nil>
STEP: delete the pod
Feb 24 08:51:29.756: INFO: Waiting for pod downwardapi-volume-ef376970-2355-46c6-b7e4-6cc96f91e782 to disappear
Feb 24 08:51:29.759: INFO: Pod downwardapi-volume-ef376970-2355-46c6-b7e4-6cc96f91e782 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:51:29.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8315" for this suite.
Feb 24 08:51:35.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:51:35.839: INFO: namespace projected-8315 deletion completed in 6.076498659s

• [SLOW TEST:10.147 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:51:35.839: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0224 08:51:36.880981      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 24 08:51:36.881: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:51:36.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9338" for this suite.
Feb 24 08:51:42.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:51:42.959: INFO: namespace gc-9338 deletion completed in 6.074071217s

• [SLOW TEST:7.119 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:51:42.959: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 24 08:51:42.978: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 24 08:51:42.986: INFO: Waiting for terminating namespaces to be deleted...
Feb 24 08:51:42.988: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-135.eu-west-1.compute.internal before test
Feb 24 08:51:43.001: INFO: kube-state-metrics-58f8cfc86c-cn6fm from monitoring started at 2020-02-24 08:33:09 +0000 UTC (2 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 24 08:51:43.001: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 24 08:51:43.001: INFO: node-exporter-hn87r from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container node-exporter ready: true, restart count 0
Feb 24 08:51:43.001: INFO: grafana-864bdcc8d4-qrbtv from monitoring started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container grafana ready: true, restart count 0
Feb 24 08:51:43.001: INFO: local-path-provisioner-58b55cb6b6-vnzz8 from local-path-storage started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container local-path-provisioner ready: true, restart count 0
Feb 24 08:51:43.001: INFO: forecastle-744778954f-xqj69 from ingress-nginx started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container forecastle ready: true, restart count 0
Feb 24 08:51:43.001: INFO: cert-manager-cainjector-898cb7556-ff586 from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container cainjector ready: true, restart count 0
Feb 24 08:51:43.001: INFO: coredns-5644d7b6d9-n6pvc from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container coredns ready: true, restart count 0
Feb 24 08:51:43.001: INFO: cert-manager-webhook-b65959699-5bd7k from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container webhook ready: true, restart count 0
Feb 24 08:51:43.001: INFO: goldpinger-kmzxp from monitoring started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container goldpinger ready: true, restart count 0
Feb 24 08:51:43.001: INFO: calico-node-phn96 from kube-system started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container calico-node ready: true, restart count 0
Feb 24 08:51:43.001: INFO: minio-0 from kube-system started at 2020-02-24 08:34:46 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container minio ready: true, restart count 0
Feb 24 08:51:43.001: INFO: elasticsearch-0 from logging started at 2020-02-24 08:34:47 +0000 UTC (2 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container elasticsearch ready: true, restart count 0
Feb 24 08:51:43.001: INFO: 	Container exporter ready: true, restart count 0
Feb 24 08:51:43.001: INFO: sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-rzsmv from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 08:51:43.001: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 08:51:43.001: INFO: kube-proxy-wpbzf from kube-system started at 2020-02-24 08:25:43 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 08:51:43.001: INFO: velero-restic-rx97v from kube-system started at 2020-02-24 08:33:05 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container restic ready: true, restart count 0
Feb 24 08:51:43.001: INFO: prometheus-operator-748c7fffd8-68gvp from monitoring started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb 24 08:51:43.001: INFO: minio-setup-j6w9s from kube-system started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.001: INFO: 	Container mc ready: false, restart count 2
Feb 24 08:51:43.001: INFO: cert-manager-54bb694dc-hhltb from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.002: INFO: 	Container cert-manager ready: true, restart count 0
Feb 24 08:51:43.002: INFO: fluentd-64hh4 from logging started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.002: INFO: 	Container fluentd ready: true, restart count 0
Feb 24 08:51:43.002: INFO: nginx-ingress-controller-wgp6c from ingress-nginx started at 2020-02-24 08:33:05 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.002: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 24 08:51:43.002: INFO: kibana-756b6ddfcd-4s9ml from logging started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.002: INFO: 	Container kibana ready: true, restart count 0
Feb 24 08:51:43.002: INFO: velero-79446c99cd-b99nf from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.002: INFO: 	Container velero ready: true, restart count 0
Feb 24 08:51:43.002: INFO: cerebro-d67c8c48-xs4h6 from logging started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.002: INFO: 	Container cerebro ready: true, restart count 0
Feb 24 08:51:43.002: INFO: coredns-5644d7b6d9-p22w4 from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.002: INFO: 	Container coredns ready: true, restart count 0
Feb 24 08:51:43.002: INFO: calico-kube-controllers-655bb9f786-gx8ws from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.002: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 24 08:51:43.002: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-76.eu-west-1.compute.internal before test
Feb 24 08:51:43.015: INFO: calico-node-66z5c from kube-system started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.015: INFO: 	Container calico-node ready: true, restart count 0
Feb 24 08:51:43.015: INFO: goldpinger-c9h65 from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.015: INFO: 	Container goldpinger ready: true, restart count 0
Feb 24 08:51:43.015: INFO: sonobuoy from sonobuoy started at 2020-02-24 08:38:00 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.015: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 24 08:51:43.015: INFO: velero-restic-6hpr9 from kube-system started at 2020-02-24 08:40:53 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.015: INFO: 	Container restic ready: true, restart count 0
Feb 24 08:51:43.015: INFO: sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-7vc7s from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 08:51:43.015: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 08:51:43.015: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 08:51:43.015: INFO: fluentd-47t8s from logging started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.015: INFO: 	Container fluentd ready: true, restart count 0
Feb 24 08:51:43.015: INFO: nginx-ingress-controller-lg9pz from ingress-nginx started at 2020-02-24 08:41:03 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.015: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 24 08:51:43.015: INFO: sonobuoy-e2e-job-e55756929f3b41bc from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 08:51:43.015: INFO: 	Container e2e ready: true, restart count 0
Feb 24 08:51:43.015: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 08:51:43.015: INFO: kube-proxy-59p45 from kube-system started at 2020-02-24 08:25:43 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.015: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 08:51:43.015: INFO: node-exporter-cbcbp from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 08:51:43.015: INFO: 	Container node-exporter ready: true, restart count 0
Feb 24 08:51:43.015: INFO: prometheus-k8s-0 from monitoring started at 2020-02-24 08:40:53 +0000 UTC (3 container statuses recorded)
Feb 24 08:51:43.015: INFO: 	Container prometheus ready: true, restart count 0
Feb 24 08:51:43.015: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb 24 08:51:43.015: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node ip-10-100-10-135.eu-west-1.compute.internal
STEP: verifying the node has the label node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod cert-manager-54bb694dc-hhltb requesting resource cpu=50m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod cert-manager-cainjector-898cb7556-ff586 requesting resource cpu=50m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod cert-manager-webhook-b65959699-5bd7k requesting resource cpu=50m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod forecastle-744778954f-xqj69 requesting resource cpu=50m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod nginx-ingress-controller-lg9pz requesting resource cpu=0m on Node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod nginx-ingress-controller-wgp6c requesting resource cpu=0m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod calico-kube-controllers-655bb9f786-gx8ws requesting resource cpu=0m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod calico-node-66z5c requesting resource cpu=250m on Node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod calico-node-phn96 requesting resource cpu=250m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod coredns-5644d7b6d9-n6pvc requesting resource cpu=100m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod coredns-5644d7b6d9-p22w4 requesting resource cpu=100m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod kube-proxy-59p45 requesting resource cpu=0m on Node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod kube-proxy-wpbzf requesting resource cpu=0m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod minio-0 requesting resource cpu=0m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod velero-79446c99cd-b99nf requesting resource cpu=100m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod velero-restic-6hpr9 requesting resource cpu=100m on Node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod velero-restic-rx97v requesting resource cpu=100m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod local-path-provisioner-58b55cb6b6-vnzz8 requesting resource cpu=0m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod cerebro-d67c8c48-xs4h6 requesting resource cpu=500m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod elasticsearch-0 requesting resource cpu=1600m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod fluentd-47t8s requesting resource cpu=300m on Node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod fluentd-64hh4 requesting resource cpu=300m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod kibana-756b6ddfcd-4s9ml requesting resource cpu=100m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod goldpinger-c9h65 requesting resource cpu=1m on Node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod goldpinger-kmzxp requesting resource cpu=1m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod grafana-864bdcc8d4-qrbtv requesting resource cpu=100m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod kube-state-metrics-58f8cfc86c-cn6fm requesting resource cpu=110m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod node-exporter-cbcbp requesting resource cpu=102m on Node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod node-exporter-hn87r requesting resource cpu=102m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod prometheus-k8s-0 requesting resource cpu=700m on Node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod prometheus-operator-748c7fffd8-68gvp requesting resource cpu=100m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod sonobuoy-e2e-job-e55756929f3b41bc requesting resource cpu=0m on Node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-7vc7s requesting resource cpu=0m on Node ip-10-100-10-76.eu-west-1.compute.internal
Feb 24 08:51:43.050: INFO: Pod sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-rzsmv requesting resource cpu=0m on Node ip-10-100-10-135.eu-west-1.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
Feb 24 08:51:43.050: INFO: Creating a pod which consumes cpu=165m on Node ip-10-100-10-135.eu-west-1.compute.internal
Feb 24 08:51:43.059: INFO: Creating a pod which consumes cpu=1782m on Node ip-10-100-10-76.eu-west-1.compute.internal
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1475c90c-88bd-4c38-9248-ec3fcf23deab.15f64a9061ec2d4a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-25/filler-pod-1475c90c-88bd-4c38-9248-ec3fcf23deab to ip-10-100-10-135.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1475c90c-88bd-4c38-9248-ec3fcf23deab.15f64a90ac005df9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1475c90c-88bd-4c38-9248-ec3fcf23deab.15f64a90b11545e6], Reason = [Created], Message = [Created container filler-pod-1475c90c-88bd-4c38-9248-ec3fcf23deab]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1475c90c-88bd-4c38-9248-ec3fcf23deab.15f64a90bd86cdae], Reason = [Started], Message = [Started container filler-pod-1475c90c-88bd-4c38-9248-ec3fcf23deab]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98fd0c2d-e2bd-4a36-81a1-8c1751cb2778.15f64a9062df0549], Reason = [Scheduled], Message = [Successfully assigned sched-pred-25/filler-pod-98fd0c2d-e2bd-4a36-81a1-8c1751cb2778 to ip-10-100-10-76.eu-west-1.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98fd0c2d-e2bd-4a36-81a1-8c1751cb2778.15f64a90a50a6264], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98fd0c2d-e2bd-4a36-81a1-8c1751cb2778.15f64a90aa411f6e], Reason = [Created], Message = [Created container filler-pod-98fd0c2d-e2bd-4a36-81a1-8c1751cb2778]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98fd0c2d-e2bd-4a36-81a1-8c1751cb2778.15f64a90b5cad21f], Reason = [Started], Message = [Started container filler-pod-98fd0c2d-e2bd-4a36-81a1-8c1751cb2778]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f64a915268f20c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node ip-10-100-10-135.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-100-10-76.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:51:48.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-25" for this suite.
Feb 24 08:51:54.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:51:54.209: INFO: namespace sched-pred-25 deletion completed in 6.07289245s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:11.251 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:51:54.210: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 24 08:51:56.761: INFO: Successfully updated pod "annotationupdated74e57df-a73b-4727-967c-7e754c1ecd56"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:51:58.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5436" for this suite.
Feb 24 08:52:26.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:52:26.846: INFO: namespace downward-api-5436 deletion completed in 28.073329242s

• [SLOW TEST:32.636 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:52:26.846: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 08:52:26.875: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46032000-62db-4c2e-8ab1-8507c6a08a26" in namespace "downward-api-7265" to be "success or failure"
Feb 24 08:52:26.881: INFO: Pod "downwardapi-volume-46032000-62db-4c2e-8ab1-8507c6a08a26": Phase="Pending", Reason="", readiness=false. Elapsed: 6.23004ms
Feb 24 08:52:28.883: INFO: Pod "downwardapi-volume-46032000-62db-4c2e-8ab1-8507c6a08a26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008305882s
Feb 24 08:52:30.886: INFO: Pod "downwardapi-volume-46032000-62db-4c2e-8ab1-8507c6a08a26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01047268s
STEP: Saw pod success
Feb 24 08:52:30.886: INFO: Pod "downwardapi-volume-46032000-62db-4c2e-8ab1-8507c6a08a26" satisfied condition "success or failure"
Feb 24 08:52:30.888: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-46032000-62db-4c2e-8ab1-8507c6a08a26 container client-container: <nil>
STEP: delete the pod
Feb 24 08:52:30.903: INFO: Waiting for pod downwardapi-volume-46032000-62db-4c2e-8ab1-8507c6a08a26 to disappear
Feb 24 08:52:30.905: INFO: Pod downwardapi-volume-46032000-62db-4c2e-8ab1-8507c6a08a26 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:52:30.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7265" for this suite.
Feb 24 08:52:36.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:52:36.991: INFO: namespace downward-api-7265 deletion completed in 6.083124502s

• [SLOW TEST:10.145 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:52:36.991: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-29120d5d-04d5-4697-8fee-3624df91db0e
STEP: Creating a pod to test consume configMaps
Feb 24 08:52:37.042: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-242164c8-f548-4c7d-9272-3d57ae2ca701" in namespace "projected-425" to be "success or failure"
Feb 24 08:52:37.044: INFO: Pod "pod-projected-configmaps-242164c8-f548-4c7d-9272-3d57ae2ca701": Phase="Pending", Reason="", readiness=false. Elapsed: 1.92894ms
Feb 24 08:52:39.046: INFO: Pod "pod-projected-configmaps-242164c8-f548-4c7d-9272-3d57ae2ca701": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004048395s
Feb 24 08:52:41.048: INFO: Pod "pod-projected-configmaps-242164c8-f548-4c7d-9272-3d57ae2ca701": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006157173s
STEP: Saw pod success
Feb 24 08:52:41.048: INFO: Pod "pod-projected-configmaps-242164c8-f548-4c7d-9272-3d57ae2ca701" satisfied condition "success or failure"
Feb 24 08:52:41.050: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-configmaps-242164c8-f548-4c7d-9272-3d57ae2ca701 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 08:52:41.065: INFO: Waiting for pod pod-projected-configmaps-242164c8-f548-4c7d-9272-3d57ae2ca701 to disappear
Feb 24 08:52:41.068: INFO: Pod pod-projected-configmaps-242164c8-f548-4c7d-9272-3d57ae2ca701 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:52:41.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-425" for this suite.
Feb 24 08:52:47.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:52:47.147: INFO: namespace projected-425 deletion completed in 6.072864883s

• [SLOW TEST:10.156 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:52:47.147: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 08:52:47.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131167, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131167, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131167, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131167, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 08:52:49.713: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131167, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131167, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131167, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131167, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 08:52:52.721: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 08:52:52.723: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:52:53.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2158" for this suite.
Feb 24 08:52:59.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:52:59.950: INFO: namespace webhook-2158 deletion completed in 6.097375691s
STEP: Destroying namespace "webhook-2158-markers" for this suite.
Feb 24 08:53:05.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:53:06.028: INFO: namespace webhook-2158-markers deletion completed in 6.078084891s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.889 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:53:06.036: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb 24 08:53:06.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-1509'
Feb 24 08:53:06.249: INFO: stderr: ""
Feb 24 08:53:06.249: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 08:53:06.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1509'
Feb 24 08:53:06.320: INFO: stderr: ""
Feb 24 08:53:06.320: INFO: stdout: "update-demo-nautilus-rc6wj update-demo-nautilus-rqc8m "
Feb 24 08:53:06.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-rc6wj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:06.378: INFO: stderr: ""
Feb 24 08:53:06.378: INFO: stdout: ""
Feb 24 08:53:06.378: INFO: update-demo-nautilus-rc6wj is created but not running
Feb 24 08:53:11.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1509'
Feb 24 08:53:11.440: INFO: stderr: ""
Feb 24 08:53:11.440: INFO: stdout: "update-demo-nautilus-rc6wj update-demo-nautilus-rqc8m "
Feb 24 08:53:11.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-rc6wj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:11.497: INFO: stderr: ""
Feb 24 08:53:11.497: INFO: stdout: "true"
Feb 24 08:53:11.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-rc6wj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:11.554: INFO: stderr: ""
Feb 24 08:53:11.554: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 08:53:11.554: INFO: validating pod update-demo-nautilus-rc6wj
Feb 24 08:53:11.557: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 08:53:11.557: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 08:53:11.557: INFO: update-demo-nautilus-rc6wj is verified up and running
Feb 24 08:53:11.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-rqc8m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:11.614: INFO: stderr: ""
Feb 24 08:53:11.614: INFO: stdout: "true"
Feb 24 08:53:11.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-rqc8m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:11.671: INFO: stderr: ""
Feb 24 08:53:11.671: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 08:53:11.671: INFO: validating pod update-demo-nautilus-rqc8m
Feb 24 08:53:11.674: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 08:53:11.674: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 08:53:11.674: INFO: update-demo-nautilus-rqc8m is verified up and running
STEP: scaling down the replication controller
Feb 24 08:53:11.676: INFO: scanned /root for discovery docs: <nil>
Feb 24 08:53:11.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1509'
Feb 24 08:53:12.749: INFO: stderr: ""
Feb 24 08:53:12.749: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 08:53:12.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1509'
Feb 24 08:53:12.809: INFO: stderr: ""
Feb 24 08:53:12.809: INFO: stdout: "update-demo-nautilus-rc6wj update-demo-nautilus-rqc8m "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 24 08:53:17.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1509'
Feb 24 08:53:17.869: INFO: stderr: ""
Feb 24 08:53:17.869: INFO: stdout: "update-demo-nautilus-rc6wj update-demo-nautilus-rqc8m "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 24 08:53:22.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1509'
Feb 24 08:53:22.929: INFO: stderr: ""
Feb 24 08:53:22.929: INFO: stdout: "update-demo-nautilus-rc6wj update-demo-nautilus-rqc8m "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 24 08:53:27.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1509'
Feb 24 08:53:27.987: INFO: stderr: ""
Feb 24 08:53:27.987: INFO: stdout: "update-demo-nautilus-rqc8m "
Feb 24 08:53:27.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-rqc8m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:28.043: INFO: stderr: ""
Feb 24 08:53:28.043: INFO: stdout: "true"
Feb 24 08:53:28.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-rqc8m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:28.100: INFO: stderr: ""
Feb 24 08:53:28.100: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 08:53:28.100: INFO: validating pod update-demo-nautilus-rqc8m
Feb 24 08:53:28.103: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 08:53:28.103: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 08:53:28.103: INFO: update-demo-nautilus-rqc8m is verified up and running
STEP: scaling up the replication controller
Feb 24 08:53:28.104: INFO: scanned /root for discovery docs: <nil>
Feb 24 08:53:28.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1509'
Feb 24 08:53:29.182: INFO: stderr: ""
Feb 24 08:53:29.182: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 08:53:29.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1509'
Feb 24 08:53:29.241: INFO: stderr: ""
Feb 24 08:53:29.241: INFO: stdout: "update-demo-nautilus-ckqgx update-demo-nautilus-rqc8m "
Feb 24 08:53:29.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-ckqgx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:29.297: INFO: stderr: ""
Feb 24 08:53:29.297: INFO: stdout: ""
Feb 24 08:53:29.297: INFO: update-demo-nautilus-ckqgx is created but not running
Feb 24 08:53:34.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1509'
Feb 24 08:53:34.357: INFO: stderr: ""
Feb 24 08:53:34.357: INFO: stdout: "update-demo-nautilus-ckqgx update-demo-nautilus-rqc8m "
Feb 24 08:53:34.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-ckqgx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:34.416: INFO: stderr: ""
Feb 24 08:53:34.416: INFO: stdout: "true"
Feb 24 08:53:34.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-ckqgx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:34.479: INFO: stderr: ""
Feb 24 08:53:34.479: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 08:53:34.479: INFO: validating pod update-demo-nautilus-ckqgx
Feb 24 08:53:34.483: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 08:53:34.483: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 08:53:34.483: INFO: update-demo-nautilus-ckqgx is verified up and running
Feb 24 08:53:34.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-rqc8m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:34.546: INFO: stderr: ""
Feb 24 08:53:34.546: INFO: stdout: "true"
Feb 24 08:53:34.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-rqc8m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1509'
Feb 24 08:53:34.609: INFO: stderr: ""
Feb 24 08:53:34.609: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 08:53:34.609: INFO: validating pod update-demo-nautilus-rqc8m
Feb 24 08:53:34.612: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 08:53:34.612: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 08:53:34.612: INFO: update-demo-nautilus-rqc8m is verified up and running
STEP: using delete to clean up resources
Feb 24 08:53:34.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete --grace-period=0 --force -f - --namespace=kubectl-1509'
Feb 24 08:53:34.678: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 08:53:34.678: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 24 08:53:34.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1509'
Feb 24 08:53:34.740: INFO: stderr: "No resources found in kubectl-1509 namespace.\n"
Feb 24 08:53:34.740: INFO: stdout: ""
Feb 24 08:53:34.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -l name=update-demo --namespace=kubectl-1509 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 24 08:53:34.810: INFO: stderr: ""
Feb 24 08:53:34.810: INFO: stdout: "update-demo-nautilus-ckqgx\nupdate-demo-nautilus-rqc8m\n"
Feb 24 08:53:35.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1509'
Feb 24 08:53:35.398: INFO: stderr: "No resources found in kubectl-1509 namespace.\n"
Feb 24 08:53:35.398: INFO: stdout: ""
Feb 24 08:53:35.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -l name=update-demo --namespace=kubectl-1509 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 24 08:53:35.473: INFO: stderr: ""
Feb 24 08:53:35.473: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:53:35.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1509" for this suite.
Feb 24 08:53:41.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:53:41.552: INFO: namespace kubectl-1509 deletion completed in 6.076294254s

• [SLOW TEST:35.515 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:53:41.553: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3869
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-3869
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3869
Feb 24 08:53:41.634: INFO: Found 0 stateful pods, waiting for 1
Feb 24 08:53:51.637: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 24 08:53:51.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 08:53:51.816: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 08:53:51.816: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 08:53:51.816: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 08:53:51.821: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 24 08:54:01.823: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 08:54:01.823: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 08:54:01.839: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Feb 24 08:54:01.839: INFO: ss-0  ip-10-100-10-76.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:53:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:53:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:53:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:53:41 +0000 UTC  }]
Feb 24 08:54:01.839: INFO: 
Feb 24 08:54:01.839: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 24 08:54:02.842: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989556422s
Feb 24 08:54:03.844: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987164452s
Feb 24 08:54:04.847: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984856996s
Feb 24 08:54:05.849: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982193296s
Feb 24 08:54:06.852: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.97969918s
Feb 24 08:54:07.854: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977415279s
Feb 24 08:54:08.856: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.974984363s
Feb 24 08:54:09.859: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.972548331s
Feb 24 08:54:10.861: INFO: Verifying statefulset ss doesn't scale past 3 for another 969.910909ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3869
Feb 24 08:54:11.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:54:12.060: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 08:54:12.060: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 08:54:12.060: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 08:54:12.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:54:12.259: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 24 08:54:12.259: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 08:54:12.259: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 08:54:12.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:54:12.439: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 24 08:54:12.439: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 08:54:12.439: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 08:54:12.442: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 08:54:12.442: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 08:54:12.442: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 24 08:54:12.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 08:54:12.626: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 08:54:12.627: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 08:54:12.627: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 08:54:12.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 08:54:12.828: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 08:54:12.828: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 08:54:12.828: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 08:54:12.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 08:54:13.025: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 08:54:13.025: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 08:54:13.025: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 08:54:13.025: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 08:54:13.027: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 24 08:54:23.031: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 08:54:23.031: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 08:54:23.031: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 24 08:54:23.038: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 24 08:54:23.038: INFO: ss-0  ip-10-100-10-76.eu-west-1.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:53:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:53:41 +0000 UTC  }]
Feb 24 08:54:23.038: INFO: ss-1  ip-10-100-10-135.eu-west-1.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:23.038: INFO: ss-2  ip-10-100-10-76.eu-west-1.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:23.038: INFO: 
Feb 24 08:54:23.038: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 24 08:54:24.040: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 24 08:54:24.040: INFO: ss-0  ip-10-100-10-76.eu-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:53:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:53:41 +0000 UTC  }]
Feb 24 08:54:24.040: INFO: ss-1  ip-10-100-10-135.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:24.040: INFO: ss-2  ip-10-100-10-76.eu-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:24.040: INFO: 
Feb 24 08:54:24.040: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 24 08:54:25.043: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 24 08:54:25.043: INFO: ss-0  ip-10-100-10-76.eu-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:53:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:53:41 +0000 UTC  }]
Feb 24 08:54:25.043: INFO: ss-1  ip-10-100-10-135.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:25.043: INFO: ss-2  ip-10-100-10-76.eu-west-1.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:25.043: INFO: 
Feb 24 08:54:25.043: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 24 08:54:26.045: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 24 08:54:26.045: INFO: ss-1  ip-10-100-10-135.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:26.045: INFO: ss-2  ip-10-100-10-76.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:26.045: INFO: 
Feb 24 08:54:26.045: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 24 08:54:27.048: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 24 08:54:27.048: INFO: ss-1  ip-10-100-10-135.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:27.048: INFO: ss-2  ip-10-100-10-76.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:27.048: INFO: 
Feb 24 08:54:27.048: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 24 08:54:28.050: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 24 08:54:28.050: INFO: ss-1  ip-10-100-10-135.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:28.050: INFO: ss-2  ip-10-100-10-76.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:28.050: INFO: 
Feb 24 08:54:28.050: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 24 08:54:29.053: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 24 08:54:29.053: INFO: ss-1  ip-10-100-10-135.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:29.053: INFO: ss-2  ip-10-100-10-76.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:29.053: INFO: 
Feb 24 08:54:29.053: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 24 08:54:30.056: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 24 08:54:30.056: INFO: ss-1  ip-10-100-10-135.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:30.056: INFO: ss-2  ip-10-100-10-76.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:30.056: INFO: 
Feb 24 08:54:30.056: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 24 08:54:31.059: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 24 08:54:31.059: INFO: ss-1  ip-10-100-10-135.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:31.059: INFO: ss-2  ip-10-100-10-76.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:31.059: INFO: 
Feb 24 08:54:31.059: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 24 08:54:32.061: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Feb 24 08:54:32.061: INFO: ss-1  ip-10-100-10-135.eu-west-1.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:32.061: INFO: ss-2  ip-10-100-10-76.eu-west-1.compute.internal   Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:13 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-24 08:54:01 +0000 UTC  }]
Feb 24 08:54:32.061: INFO: 
Feb 24 08:54:32.061: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3869
Feb 24 08:54:33.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:54:33.155: INFO: rc: 1
Feb 24 08:54:33.155: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Feb 24 08:54:43.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:54:43.215: INFO: rc: 1
Feb 24 08:54:43.215: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:54:53.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:54:53.275: INFO: rc: 1
Feb 24 08:54:53.275: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:55:03.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:55:03.338: INFO: rc: 1
Feb 24 08:55:03.338: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:55:13.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:55:13.398: INFO: rc: 1
Feb 24 08:55:13.398: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:55:23.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:55:23.456: INFO: rc: 1
Feb 24 08:55:23.456: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:55:33.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:55:33.514: INFO: rc: 1
Feb 24 08:55:33.514: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:55:43.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:55:43.574: INFO: rc: 1
Feb 24 08:55:43.574: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:55:53.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:55:53.634: INFO: rc: 1
Feb 24 08:55:53.634: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:56:03.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:56:03.691: INFO: rc: 1
Feb 24 08:56:03.691: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:56:13.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:56:13.749: INFO: rc: 1
Feb 24 08:56:13.749: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:56:23.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:56:23.809: INFO: rc: 1
Feb 24 08:56:23.809: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:56:33.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:56:33.868: INFO: rc: 1
Feb 24 08:56:33.868: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:56:43.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:56:43.926: INFO: rc: 1
Feb 24 08:56:43.926: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:56:53.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:56:54.134: INFO: rc: 1
Feb 24 08:56:54.134: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:57:04.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:57:04.192: INFO: rc: 1
Feb 24 08:57:04.192: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:57:14.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:57:14.250: INFO: rc: 1
Feb 24 08:57:14.250: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:57:24.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:57:24.309: INFO: rc: 1
Feb 24 08:57:24.309: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:57:34.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:57:34.370: INFO: rc: 1
Feb 24 08:57:34.370: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:57:44.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:57:44.430: INFO: rc: 1
Feb 24 08:57:44.430: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:57:54.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:57:54.488: INFO: rc: 1
Feb 24 08:57:54.488: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:58:04.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:58:04.551: INFO: rc: 1
Feb 24 08:58:04.551: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:58:14.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:58:14.608: INFO: rc: 1
Feb 24 08:58:14.608: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:58:24.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:58:24.666: INFO: rc: 1
Feb 24 08:58:24.666: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:58:34.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:58:34.736: INFO: rc: 1
Feb 24 08:58:34.736: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:58:44.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:58:44.798: INFO: rc: 1
Feb 24 08:58:44.798: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:58:54.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:58:54.857: INFO: rc: 1
Feb 24 08:58:54.857: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:59:04.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:59:04.916: INFO: rc: 1
Feb 24 08:59:04.916: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:59:14.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:59:14.974: INFO: rc: 1
Feb 24 08:59:14.974: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:59:24.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:59:25.033: INFO: rc: 1
Feb 24 08:59:25.033: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Feb 24 08:59:35.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-3869 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 08:59:35.092: INFO: rc: 1
Feb 24 08:59:35.092: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: 
Feb 24 08:59:35.092: INFO: Scaling statefulset ss to 0
Feb 24 08:59:35.098: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 08:59:35.101: INFO: Deleting all statefulset in ns statefulset-3869
Feb 24 08:59:35.103: INFO: Scaling statefulset ss to 0
Feb 24 08:59:35.109: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 08:59:35.110: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:59:35.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3869" for this suite.
Feb 24 08:59:41.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:59:41.217: INFO: namespace statefulset-3869 deletion completed in 6.074725254s

• [SLOW TEST:359.665 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:59:41.218: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:59:49.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6422" for this suite.
Feb 24 08:59:55.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 08:59:55.348: INFO: namespace job-6422 deletion completed in 6.103125917s

• [SLOW TEST:14.131 seconds]
[sig-apps] Job
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 08:59:55.349: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Feb 24 08:59:55.367: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-533328996 proxy --unix-socket=/tmp/kubectl-proxy-unix481006935/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 08:59:55.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1596" for this suite.
Feb 24 09:00:01.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:00:01.494: INFO: namespace kubectl-1596 deletion completed in 6.077412416s

• [SLOW TEST:6.145 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:00:01.494: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb 24 09:00:01.515: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:00:18.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-175" for this suite.
Feb 24 09:00:24.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:00:24.909: INFO: namespace crd-publish-openapi-175 deletion completed in 6.075200232s

• [SLOW TEST:23.415 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:00:24.909: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Feb 24 09:00:24.933: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 24 09:00:33.965: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:00:33.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2357" for this suite.
Feb 24 09:00:39.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:00:40.051: INFO: namespace pods-2357 deletion completed in 6.081908836s

• [SLOW TEST:15.142 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:00:40.051: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 24 09:00:44.597: INFO: Successfully updated pod "labelsupdatebc9f7252-ddab-4d7f-9fc1-30cbc0721ec8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:00:46.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1655" for this suite.
Feb 24 09:01:04.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:01:04.692: INFO: namespace projected-1655 deletion completed in 18.081993232s

• [SLOW TEST:24.641 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:01:04.692: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:01:04.715: INFO: Waiting up to 5m0s for pod "downwardapi-volume-16e60e8e-0920-4030-8472-6fa1c306599c" in namespace "downward-api-7069" to be "success or failure"
Feb 24 09:01:04.723: INFO: Pod "downwardapi-volume-16e60e8e-0920-4030-8472-6fa1c306599c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.303188ms
Feb 24 09:01:06.725: INFO: Pod "downwardapi-volume-16e60e8e-0920-4030-8472-6fa1c306599c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010320374s
STEP: Saw pod success
Feb 24 09:01:06.725: INFO: Pod "downwardapi-volume-16e60e8e-0920-4030-8472-6fa1c306599c" satisfied condition "success or failure"
Feb 24 09:01:06.727: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-16e60e8e-0920-4030-8472-6fa1c306599c container client-container: <nil>
STEP: delete the pod
Feb 24 09:01:06.739: INFO: Waiting for pod downwardapi-volume-16e60e8e-0920-4030-8472-6fa1c306599c to disappear
Feb 24 09:01:06.743: INFO: Pod downwardapi-volume-16e60e8e-0920-4030-8472-6fa1c306599c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:01:06.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7069" for this suite.
Feb 24 09:01:12.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:01:12.820: INFO: namespace downward-api-7069 deletion completed in 6.073676636s

• [SLOW TEST:8.128 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:01:12.820: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:01:13.320: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:01:15.325: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131673, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131673, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131673, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131673, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:01:18.335: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:01:28.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5564" for this suite.
Feb 24 09:01:34.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:01:34.522: INFO: namespace webhook-5564 deletion completed in 6.08421679s
STEP: Destroying namespace "webhook-5564-markers" for this suite.
Feb 24 09:01:40.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:01:40.598: INFO: namespace webhook-5564-markers deletion completed in 6.075131991s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:27.786 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:01:40.605: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:01:56.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4092" for this suite.
Feb 24 09:02:02.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:02:02.765: INFO: namespace resourcequota-4092 deletion completed in 6.0763736s

• [SLOW TEST:22.160 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:02:02.765: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:02:03.511: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:02:05.517: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131723, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131723, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131723, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131723, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:02:08.531: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:02:08.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4495" for this suite.
Feb 24 09:02:14.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:02:14.686: INFO: namespace webhook-4495 deletion completed in 6.073529653s
STEP: Destroying namespace "webhook-4495-markers" for this suite.
Feb 24 09:02:20.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:02:20.772: INFO: namespace webhook-4495-markers deletion completed in 6.085830907s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.014 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:02:20.779: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-6842
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6842
STEP: Deleting pre-stop pod
Feb 24 09:02:31.837: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:02:31.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6842" for this suite.
Feb 24 09:03:15.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:03:15.935: INFO: namespace prestop-6842 deletion completed in 44.088952282s

• [SLOW TEST:55.156 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:03:15.935: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:03:15.961: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9db710cb-fea2-4659-9daa-9b3711d3695e" in namespace "downward-api-7566" to be "success or failure"
Feb 24 09:03:15.964: INFO: Pod "downwardapi-volume-9db710cb-fea2-4659-9daa-9b3711d3695e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.61821ms
Feb 24 09:03:17.966: INFO: Pod "downwardapi-volume-9db710cb-fea2-4659-9daa-9b3711d3695e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004740663s
Feb 24 09:03:19.968: INFO: Pod "downwardapi-volume-9db710cb-fea2-4659-9daa-9b3711d3695e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006962973s
STEP: Saw pod success
Feb 24 09:03:19.968: INFO: Pod "downwardapi-volume-9db710cb-fea2-4659-9daa-9b3711d3695e" satisfied condition "success or failure"
Feb 24 09:03:19.970: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-9db710cb-fea2-4659-9daa-9b3711d3695e container client-container: <nil>
STEP: delete the pod
Feb 24 09:03:19.990: INFO: Waiting for pod downwardapi-volume-9db710cb-fea2-4659-9daa-9b3711d3695e to disappear
Feb 24 09:03:19.992: INFO: Pod downwardapi-volume-9db710cb-fea2-4659-9daa-9b3711d3695e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:03:19.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7566" for this suite.
Feb 24 09:03:26.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:03:26.070: INFO: namespace downward-api-7566 deletion completed in 6.075935586s

• [SLOW TEST:10.135 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:03:26.070: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 24 09:03:26.108: INFO: Waiting up to 5m0s for pod "downward-api-c6adea30-bff1-4488-854b-eb500c65e278" in namespace "downward-api-8111" to be "success or failure"
Feb 24 09:03:26.140: INFO: Pod "downward-api-c6adea30-bff1-4488-854b-eb500c65e278": Phase="Pending", Reason="", readiness=false. Elapsed: 1.953737ms
Feb 24 09:03:28.143: INFO: Pod "downward-api-c6adea30-bff1-4488-854b-eb500c65e278": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004175752s
Feb 24 09:03:30.145: INFO: Pod "downward-api-c6adea30-bff1-4488-854b-eb500c65e278": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006126491s
STEP: Saw pod success
Feb 24 09:03:30.145: INFO: Pod "downward-api-c6adea30-bff1-4488-854b-eb500c65e278" satisfied condition "success or failure"
Feb 24 09:03:30.147: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downward-api-c6adea30-bff1-4488-854b-eb500c65e278 container dapi-container: <nil>
STEP: delete the pod
Feb 24 09:03:30.162: INFO: Waiting for pod downward-api-c6adea30-bff1-4488-854b-eb500c65e278 to disappear
Feb 24 09:03:30.165: INFO: Pod downward-api-c6adea30-bff1-4488-854b-eb500c65e278 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:03:30.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8111" for this suite.
Feb 24 09:03:36.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:03:36.245: INFO: namespace downward-api-8111 deletion completed in 6.077190694s

• [SLOW TEST:10.175 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:03:36.245: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 24 09:03:36.280: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7304 /api/v1/namespaces/watch-7304/configmaps/e2e-watch-test-resource-version ecf45ac9-3b72-4619-a2e8-ee222deedb4a 10432 0 2020-02-24 09:03:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 24 09:03:36.280: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7304 /api/v1/namespaces/watch-7304/configmaps/e2e-watch-test-resource-version ecf45ac9-3b72-4619-a2e8-ee222deedb4a 10433 0 2020-02-24 09:03:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:03:36.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7304" for this suite.
Feb 24 09:03:42.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:03:42.356: INFO: namespace watch-7304 deletion completed in 6.073404399s

• [SLOW TEST:6.112 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:03:42.356: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:03:46.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-666" for this suite.
Feb 24 09:04:36.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:04:36.471: INFO: namespace kubelet-test-666 deletion completed in 50.076076199s

• [SLOW TEST:54.114 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:04:36.471: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Feb 24 09:04:36.496: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-533328996 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:04:36.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7550" for this suite.
Feb 24 09:04:42.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:04:42.621: INFO: namespace kubectl-7550 deletion completed in 6.07003825s

• [SLOW TEST:6.150 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:04:42.621: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Feb 24 09:04:42.703: INFO: Waiting up to 5m0s for pod "client-containers-09ef0505-c782-4b65-b965-cef5bc26c970" in namespace "containers-7909" to be "success or failure"
Feb 24 09:04:42.707: INFO: Pod "client-containers-09ef0505-c782-4b65-b965-cef5bc26c970": Phase="Pending", Reason="", readiness=false. Elapsed: 3.890244ms
Feb 24 09:04:44.709: INFO: Pod "client-containers-09ef0505-c782-4b65-b965-cef5bc26c970": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005545149s
STEP: Saw pod success
Feb 24 09:04:44.709: INFO: Pod "client-containers-09ef0505-c782-4b65-b965-cef5bc26c970" satisfied condition "success or failure"
Feb 24 09:04:44.710: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod client-containers-09ef0505-c782-4b65-b965-cef5bc26c970 container test-container: <nil>
STEP: delete the pod
Feb 24 09:04:44.724: INFO: Waiting for pod client-containers-09ef0505-c782-4b65-b965-cef5bc26c970 to disappear
Feb 24 09:04:44.726: INFO: Pod client-containers-09ef0505-c782-4b65-b965-cef5bc26c970 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:04:44.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7909" for this suite.
Feb 24 09:04:50.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:04:50.818: INFO: namespace containers-7909 deletion completed in 6.089272897s

• [SLOW TEST:8.197 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:04:50.818: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:04:51.090: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:04:53.096: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131891, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131891, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131891, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718131891, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:04:56.130: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:04:56.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8889" for this suite.
Feb 24 09:05:02.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:05:02.292: INFO: namespace webhook-8889 deletion completed in 6.075672445s
STEP: Destroying namespace "webhook-8889-markers" for this suite.
Feb 24 09:05:08.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:05:08.367: INFO: namespace webhook-8889-markers deletion completed in 6.074998969s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.555 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:05:08.373: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 24 09:05:08.641: INFO: Pod name wrapped-volume-race-f789887e-b7dc-40ad-9fa5-dba330e3235d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f789887e-b7dc-40ad-9fa5-dba330e3235d in namespace emptydir-wrapper-1182, will wait for the garbage collector to delete the pods
Feb 24 09:05:30.761: INFO: Deleting ReplicationController wrapped-volume-race-f789887e-b7dc-40ad-9fa5-dba330e3235d took: 4.357755ms
Feb 24 09:05:31.365: INFO: Terminating ReplicationController wrapped-volume-race-f789887e-b7dc-40ad-9fa5-dba330e3235d pods took: 603.690391ms
STEP: Creating RC which spawns configmap-volume pods
Feb 24 09:06:08.075: INFO: Pod name wrapped-volume-race-c0f3eafa-e55b-41ec-ab1d-cacc6cc8d9f2: Found 0 pods out of 5
Feb 24 09:06:13.078: INFO: Pod name wrapped-volume-race-c0f3eafa-e55b-41ec-ab1d-cacc6cc8d9f2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c0f3eafa-e55b-41ec-ab1d-cacc6cc8d9f2 in namespace emptydir-wrapper-1182, will wait for the garbage collector to delete the pods
Feb 24 09:06:25.151: INFO: Deleting ReplicationController wrapped-volume-race-c0f3eafa-e55b-41ec-ab1d-cacc6cc8d9f2 took: 7.7765ms
Feb 24 09:06:25.754: INFO: Terminating ReplicationController wrapped-volume-race-c0f3eafa-e55b-41ec-ab1d-cacc6cc8d9f2 pods took: 603.235886ms
STEP: Creating RC which spawns configmap-volume pods
Feb 24 09:07:13.864: INFO: Pod name wrapped-volume-race-d7bde55e-113b-4480-a04f-63c4c6addea2: Found 0 pods out of 5
Feb 24 09:07:18.868: INFO: Pod name wrapped-volume-race-d7bde55e-113b-4480-a04f-63c4c6addea2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d7bde55e-113b-4480-a04f-63c4c6addea2 in namespace emptydir-wrapper-1182, will wait for the garbage collector to delete the pods
Feb 24 09:07:30.934: INFO: Deleting ReplicationController wrapped-volume-race-d7bde55e-113b-4480-a04f-63c4c6addea2 took: 4.732707ms
Feb 24 09:07:31.534: INFO: Terminating ReplicationController wrapped-volume-race-d7bde55e-113b-4480-a04f-63c4c6addea2 pods took: 600.169497ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:08:08.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1182" for this suite.
Feb 24 09:08:14.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:08:14.557: INFO: namespace emptydir-wrapper-1182 deletion completed in 6.073097933s

• [SLOW TEST:186.184 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:08:14.558: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Feb 24 09:08:14.583: INFO: Waiting up to 5m0s for pod "client-containers-e9133d12-96ac-4235-adae-b39579b65a06" in namespace "containers-3762" to be "success or failure"
Feb 24 09:08:14.588: INFO: Pod "client-containers-e9133d12-96ac-4235-adae-b39579b65a06": Phase="Pending", Reason="", readiness=false. Elapsed: 5.231881ms
Feb 24 09:08:16.591: INFO: Pod "client-containers-e9133d12-96ac-4235-adae-b39579b65a06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007339402s
Feb 24 09:08:18.593: INFO: Pod "client-containers-e9133d12-96ac-4235-adae-b39579b65a06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009455489s
STEP: Saw pod success
Feb 24 09:08:18.593: INFO: Pod "client-containers-e9133d12-96ac-4235-adae-b39579b65a06" satisfied condition "success or failure"
Feb 24 09:08:18.594: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod client-containers-e9133d12-96ac-4235-adae-b39579b65a06 container test-container: <nil>
STEP: delete the pod
Feb 24 09:08:18.614: INFO: Waiting for pod client-containers-e9133d12-96ac-4235-adae-b39579b65a06 to disappear
Feb 24 09:08:18.616: INFO: Pod client-containers-e9133d12-96ac-4235-adae-b39579b65a06 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:08:18.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3762" for this suite.
Feb 24 09:08:24.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:08:24.691: INFO: namespace containers-3762 deletion completed in 6.072276634s

• [SLOW TEST:10.133 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:08:24.691: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Feb 24 09:08:24.717: INFO: Waiting up to 5m0s for pod "var-expansion-ed390c13-a876-4dea-9938-574f66d930c4" in namespace "var-expansion-7435" to be "success or failure"
Feb 24 09:08:24.721: INFO: Pod "var-expansion-ed390c13-a876-4dea-9938-574f66d930c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.714589ms
Feb 24 09:08:26.723: INFO: Pod "var-expansion-ed390c13-a876-4dea-9938-574f66d930c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006950542s
Feb 24 09:08:28.726: INFO: Pod "var-expansion-ed390c13-a876-4dea-9938-574f66d930c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008981009s
STEP: Saw pod success
Feb 24 09:08:28.726: INFO: Pod "var-expansion-ed390c13-a876-4dea-9938-574f66d930c4" satisfied condition "success or failure"
Feb 24 09:08:28.727: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod var-expansion-ed390c13-a876-4dea-9938-574f66d930c4 container dapi-container: <nil>
STEP: delete the pod
Feb 24 09:08:28.742: INFO: Waiting for pod var-expansion-ed390c13-a876-4dea-9938-574f66d930c4 to disappear
Feb 24 09:08:28.743: INFO: Pod var-expansion-ed390c13-a876-4dea-9938-574f66d930c4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:08:28.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7435" for this suite.
Feb 24 09:08:34.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:08:34.869: INFO: namespace var-expansion-7435 deletion completed in 6.123224514s

• [SLOW TEST:10.178 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:08:34.869: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:08:34.894: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 24 09:08:39.897: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 24 09:08:39.897: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 24 09:08:39.922: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-6848 /apis/apps/v1/namespaces/deployment-6848/deployments/test-cleanup-deployment fa9d2183-d93d-434c-b341-9e9c7dd7b72c 12420 1 2020-02-24 09:08:39 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001834fc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Feb 24 09:08:39.930: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-6848 /apis/apps/v1/namespaces/deployment-6848/replicasets/test-cleanup-deployment-65db99849b ac7395d2-5b28-4634-bf90-f0e8fad2393f 12422 1 2020-02-24 09:08:39 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment fa9d2183-d93d-434c-b341-9e9c7dd7b72c 0xc0018355f7 0xc0018355f8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0018356e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 09:08:39.930: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb 24 09:08:39.930: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-6848 /apis/apps/v1/namespaces/deployment-6848/replicasets/test-cleanup-controller 78ba43bf-2835-4f9f-bd4b-cd3f8c8a8739 12421 1 2020-02-24 09:08:34 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment fa9d2183-d93d-434c-b341-9e9c7dd7b72c 0xc001835517 0xc001835518}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001835588 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 24 09:08:39.939: INFO: Pod "test-cleanup-controller-smq6x" is available:
&Pod{ObjectMeta:{test-cleanup-controller-smq6x test-cleanup-controller- deployment-6848 /api/v1/namespaces/deployment-6848/pods/test-cleanup-controller-smq6x 4ec5a5e6-684c-4157-8f47-76f4938346e2 12409 0 2020-02-24 09:08:34 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:172.16.14.213/32] [{apps/v1 ReplicaSet test-cleanup-controller 78ba43bf-2835-4f9f-bd4b-cd3f8c8a8739 0xc001835f77 0xc001835f78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kx2k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kx2k,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kx2k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:08:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:08:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:08:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:08:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:172.16.14.213,StartTime:2020-02-24 09:08:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 09:08:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://90f137c1aa93488cd697cc8fc940d51599903c043a085aa7c68d029d07775909,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.14.213,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:08:39.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6848" for this suite.
Feb 24 09:08:45.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:08:46.062: INFO: namespace deployment-6848 deletion completed in 6.0969893s

• [SLOW TEST:11.193 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:08:46.062: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0224 09:09:16.125243      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 24 09:09:16.125: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:09:16.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3951" for this suite.
Feb 24 09:09:22.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:09:22.202: INFO: namespace gc-3951 deletion completed in 6.074240315s

• [SLOW TEST:36.140 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:09:22.203: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:09:22.231: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d9baf7b-9f06-4b88-b11f-e2b8041438fb" in namespace "projected-4978" to be "success or failure"
Feb 24 09:09:22.236: INFO: Pod "downwardapi-volume-9d9baf7b-9f06-4b88-b11f-e2b8041438fb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.153635ms
Feb 24 09:09:24.238: INFO: Pod "downwardapi-volume-9d9baf7b-9f06-4b88-b11f-e2b8041438fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007479854s
STEP: Saw pod success
Feb 24 09:09:24.238: INFO: Pod "downwardapi-volume-9d9baf7b-9f06-4b88-b11f-e2b8041438fb" satisfied condition "success or failure"
Feb 24 09:09:24.240: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-9d9baf7b-9f06-4b88-b11f-e2b8041438fb container client-container: <nil>
STEP: delete the pod
Feb 24 09:09:24.259: INFO: Waiting for pod downwardapi-volume-9d9baf7b-9f06-4b88-b11f-e2b8041438fb to disappear
Feb 24 09:09:24.260: INFO: Pod downwardapi-volume-9d9baf7b-9f06-4b88-b11f-e2b8041438fb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:09:24.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4978" for this suite.
Feb 24 09:09:30.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:09:30.335: INFO: namespace projected-4978 deletion completed in 6.073220245s

• [SLOW TEST:8.133 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:09:30.335: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-942e2cd1-8ee7-4c78-8d27-7451d23b354b
STEP: Creating a pod to test consume secrets
Feb 24 09:09:30.364: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b989bf2e-acce-46a0-9848-a1ef29edae3f" in namespace "projected-426" to be "success or failure"
Feb 24 09:09:30.372: INFO: Pod "pod-projected-secrets-b989bf2e-acce-46a0-9848-a1ef29edae3f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.85997ms
Feb 24 09:09:32.375: INFO: Pod "pod-projected-secrets-b989bf2e-acce-46a0-9848-a1ef29edae3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010376427s
STEP: Saw pod success
Feb 24 09:09:32.375: INFO: Pod "pod-projected-secrets-b989bf2e-acce-46a0-9848-a1ef29edae3f" satisfied condition "success or failure"
Feb 24 09:09:32.381: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-secrets-b989bf2e-acce-46a0-9848-a1ef29edae3f container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 24 09:09:32.393: INFO: Waiting for pod pod-projected-secrets-b989bf2e-acce-46a0-9848-a1ef29edae3f to disappear
Feb 24 09:09:32.399: INFO: Pod pod-projected-secrets-b989bf2e-acce-46a0-9848-a1ef29edae3f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:09:32.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-426" for this suite.
Feb 24 09:09:38.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:09:38.479: INFO: namespace projected-426 deletion completed in 6.076250086s

• [SLOW TEST:8.144 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:09:38.479: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 24 09:09:38.510: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed 77f39cd6-231d-4131-89e5-025955af1d96 12757 0 2020-02-24 09:09:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 24 09:09:38.510: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed 77f39cd6-231d-4131-89e5-025955af1d96 12758 0 2020-02-24 09:09:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 24 09:09:38.510: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed 77f39cd6-231d-4131-89e5-025955af1d96 12759 0 2020-02-24 09:09:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 24 09:09:48.525: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed 77f39cd6-231d-4131-89e5-025955af1d96 12786 0 2020-02-24 09:09:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 24 09:09:48.525: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed 77f39cd6-231d-4131-89e5-025955af1d96 12787 0 2020-02-24 09:09:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 24 09:09:48.525: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7171 /api/v1/namespaces/watch-7171/configmaps/e2e-watch-test-label-changed 77f39cd6-231d-4131-89e5-025955af1d96 12788 0 2020-02-24 09:09:38 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:09:48.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7171" for this suite.
Feb 24 09:09:54.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:09:54.602: INFO: namespace watch-7171 deletion completed in 6.075130193s

• [SLOW TEST:16.123 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:09:54.603: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:10:05.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5714" for this suite.
Feb 24 09:10:11.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:10:11.752: INFO: namespace resourcequota-5714 deletion completed in 6.072599244s

• [SLOW TEST:17.149 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:10:11.752: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 24 09:10:14.301: INFO: Successfully updated pod "labelsupdatef19d050e-68b1-4651-9e0f-c96add71f082"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:10:16.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5978" for this suite.
Feb 24 09:10:28.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:10:28.394: INFO: namespace downward-api-5978 deletion completed in 12.08025464s

• [SLOW TEST:16.642 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:10:28.394: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:10:28.509: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"5b16344c-3d09-4077-bb84-b095279399d1", Controller:(*bool)(0xc004db1f26), BlockOwnerDeletion:(*bool)(0xc004db1f27)}}
Feb 24 09:10:28.515: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"eec0e966-6d18-474b-9057-1fbe21363b54", Controller:(*bool)(0xc003af20fa), BlockOwnerDeletion:(*bool)(0xc003af20fb)}}
Feb 24 09:10:28.527: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b839744e-f551-4f73-b2e1-f1650a3a7350", Controller:(*bool)(0xc003946236), BlockOwnerDeletion:(*bool)(0xc003946237)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:10:33.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3881" for this suite.
Feb 24 09:10:39.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:10:39.615: INFO: namespace gc-3881 deletion completed in 6.073605685s

• [SLOW TEST:11.220 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:10:39.615: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 09:10:39.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9264'
Feb 24 09:10:39.845: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 24 09:10:39.845: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Feb 24 09:10:41.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete deployment e2e-test-httpd-deployment --namespace=kubectl-9264'
Feb 24 09:10:41.933: INFO: stderr: ""
Feb 24 09:10:41.933: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:10:41.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9264" for this suite.
Feb 24 09:10:47.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:10:48.022: INFO: namespace kubectl-9264 deletion completed in 6.083771402s

• [SLOW TEST:8.407 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:10:48.022: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:10:48.090: INFO: Creating ReplicaSet my-hostname-basic-08c8438b-6467-4d0d-9bc0-27b3d07322e5
Feb 24 09:10:48.095: INFO: Pod name my-hostname-basic-08c8438b-6467-4d0d-9bc0-27b3d07322e5: Found 0 pods out of 1
Feb 24 09:10:53.098: INFO: Pod name my-hostname-basic-08c8438b-6467-4d0d-9bc0-27b3d07322e5: Found 1 pods out of 1
Feb 24 09:10:53.098: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-08c8438b-6467-4d0d-9bc0-27b3d07322e5" is running
Feb 24 09:10:53.099: INFO: Pod "my-hostname-basic-08c8438b-6467-4d0d-9bc0-27b3d07322e5-r9wzr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 09:10:48 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 09:10:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 09:10:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 09:10:48 +0000 UTC Reason: Message:}])
Feb 24 09:10:53.099: INFO: Trying to dial the pod
Feb 24 09:10:58.105: INFO: Controller my-hostname-basic-08c8438b-6467-4d0d-9bc0-27b3d07322e5: Got expected result from replica 1 [my-hostname-basic-08c8438b-6467-4d0d-9bc0-27b3d07322e5-r9wzr]: "my-hostname-basic-08c8438b-6467-4d0d-9bc0-27b3d07322e5-r9wzr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:10:58.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7778" for this suite.
Feb 24 09:11:04.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:11:04.185: INFO: namespace replicaset-7778 deletion completed in 6.077546459s

• [SLOW TEST:16.162 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:11:04.185: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:11:04.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3913" for this suite.
Feb 24 09:11:10.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:11:10.311: INFO: namespace resourcequota-3913 deletion completed in 6.079968088s

• [SLOW TEST:6.127 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:11:10.312: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:11:10.332: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:11:16.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9887" for this suite.
Feb 24 09:11:22.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:11:22.784: INFO: namespace custom-resource-definition-9887 deletion completed in 6.075361343s

• [SLOW TEST:12.472 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:11:22.784: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7535
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 24 09:11:22.855: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 24 09:11:48.929: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.145.179 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7535 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 09:11:48.929: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 09:11:50.040: INFO: Found all expected endpoints: [netserver-0]
Feb 24 09:11:50.042: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.14.226 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7535 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 09:11:50.042: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 09:11:51.188: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:11:51.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7535" for this suite.
Feb 24 09:12:03.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:12:03.273: INFO: namespace pod-network-test-7535 deletion completed in 12.077529236s

• [SLOW TEST:40.489 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:12:03.273: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:12:03.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8359" for this suite.
Feb 24 09:12:09.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:12:09.420: INFO: namespace services-8359 deletion completed in 6.071047487s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.148 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:12:09.420: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:12:20.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6492" for this suite.
Feb 24 09:12:26.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:12:26.534: INFO: namespace resourcequota-6492 deletion completed in 6.075297035s

• [SLOW TEST:17.114 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:12:26.535: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:12:26.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 version'
Feb 24 09:12:26.610: INFO: stderr: ""
Feb 24 09:12:26.610: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.7\", GitCommit:\"be3d344ed06bff7a4fc60656200a93c74f31f9a4\", GitTreeState:\"clean\", BuildDate:\"2020-02-11T19:34:02Z\", GoVersion:\"go1.13.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.7\", GitCommit:\"be3d344ed06bff7a4fc60656200a93c74f31f9a4\", GitTreeState:\"clean\", BuildDate:\"2020-02-11T19:24:46Z\", GoVersion:\"go1.13.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:12:26.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5259" for this suite.
Feb 24 09:12:32.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:12:32.685: INFO: namespace kubectl-5259 deletion completed in 6.072153933s

• [SLOW TEST:6.150 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:12:32.685: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 24 09:12:32.761: INFO: Waiting up to 5m0s for pod "downward-api-9fa8938b-0d36-49b5-a554-ffd527193692" in namespace "downward-api-9056" to be "success or failure"
Feb 24 09:12:32.766: INFO: Pod "downward-api-9fa8938b-0d36-49b5-a554-ffd527193692": Phase="Pending", Reason="", readiness=false. Elapsed: 4.315705ms
Feb 24 09:12:34.768: INFO: Pod "downward-api-9fa8938b-0d36-49b5-a554-ffd527193692": Phase="Running", Reason="", readiness=true. Elapsed: 2.006519889s
Feb 24 09:12:36.770: INFO: Pod "downward-api-9fa8938b-0d36-49b5-a554-ffd527193692": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008668945s
STEP: Saw pod success
Feb 24 09:12:36.770: INFO: Pod "downward-api-9fa8938b-0d36-49b5-a554-ffd527193692" satisfied condition "success or failure"
Feb 24 09:12:36.772: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downward-api-9fa8938b-0d36-49b5-a554-ffd527193692 container dapi-container: <nil>
STEP: delete the pod
Feb 24 09:12:36.795: INFO: Waiting for pod downward-api-9fa8938b-0d36-49b5-a554-ffd527193692 to disappear
Feb 24 09:12:36.796: INFO: Pod downward-api-9fa8938b-0d36-49b5-a554-ffd527193692 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:12:36.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9056" for this suite.
Feb 24 09:12:42.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:12:42.871: INFO: namespace downward-api-9056 deletion completed in 6.073293503s

• [SLOW TEST:10.187 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:12:42.872: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:12:42.948: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aee2152a-8248-42e1-bb1a-70556f084f8c" in namespace "projected-2665" to be "success or failure"
Feb 24 09:12:42.951: INFO: Pod "downwardapi-volume-aee2152a-8248-42e1-bb1a-70556f084f8c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.341919ms
Feb 24 09:12:44.953: INFO: Pod "downwardapi-volume-aee2152a-8248-42e1-bb1a-70556f084f8c": Phase="Running", Reason="", readiness=true. Elapsed: 2.004444028s
Feb 24 09:12:46.955: INFO: Pod "downwardapi-volume-aee2152a-8248-42e1-bb1a-70556f084f8c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00645851s
STEP: Saw pod success
Feb 24 09:12:46.955: INFO: Pod "downwardapi-volume-aee2152a-8248-42e1-bb1a-70556f084f8c" satisfied condition "success or failure"
Feb 24 09:12:46.956: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-aee2152a-8248-42e1-bb1a-70556f084f8c container client-container: <nil>
STEP: delete the pod
Feb 24 09:12:46.974: INFO: Waiting for pod downwardapi-volume-aee2152a-8248-42e1-bb1a-70556f084f8c to disappear
Feb 24 09:12:46.975: INFO: Pod downwardapi-volume-aee2152a-8248-42e1-bb1a-70556f084f8c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:12:46.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2665" for this suite.
Feb 24 09:12:52.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:12:53.051: INFO: namespace projected-2665 deletion completed in 6.073805877s

• [SLOW TEST:10.179 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:12:53.051: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Feb 24 09:12:53.071: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 09:12:56.007: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:13:07.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4885" for this suite.
Feb 24 09:13:13.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:13:13.749: INFO: namespace crd-publish-openapi-4885 deletion completed in 6.072128594s

• [SLOW TEST:20.698 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:13:13.749: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:13:17.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9490" for this suite.
Feb 24 09:13:23.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:13:23.862: INFO: namespace kubelet-test-9490 deletion completed in 6.079943813s

• [SLOW TEST:10.113 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:13:23.862: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 09:13:23.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2631'
Feb 24 09:13:23.952: INFO: stderr: ""
Feb 24 09:13:23.952: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Feb 24 09:13:23.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete pods e2e-test-httpd-pod --namespace=kubectl-2631'
Feb 24 09:13:33.339: INFO: stderr: ""
Feb 24 09:13:33.340: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:13:33.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2631" for this suite.
Feb 24 09:13:39.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:13:39.427: INFO: namespace kubectl-2631 deletion completed in 6.084538844s

• [SLOW TEST:15.565 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:13:39.428: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Feb 24 09:13:39.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-6811'
Feb 24 09:13:39.683: INFO: stderr: ""
Feb 24 09:13:39.683: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 09:13:39.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6811'
Feb 24 09:13:39.747: INFO: stderr: ""
Feb 24 09:13:39.747: INFO: stdout: "update-demo-nautilus-49znm update-demo-nautilus-vhb4b "
Feb 24 09:13:39.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-49znm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6811'
Feb 24 09:13:39.809: INFO: stderr: ""
Feb 24 09:13:39.809: INFO: stdout: ""
Feb 24 09:13:39.809: INFO: update-demo-nautilus-49znm is created but not running
Feb 24 09:13:44.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6811'
Feb 24 09:13:44.869: INFO: stderr: ""
Feb 24 09:13:44.869: INFO: stdout: "update-demo-nautilus-49znm update-demo-nautilus-vhb4b "
Feb 24 09:13:44.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-49znm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6811'
Feb 24 09:13:44.927: INFO: stderr: ""
Feb 24 09:13:44.927: INFO: stdout: "true"
Feb 24 09:13:44.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-49znm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6811'
Feb 24 09:13:44.989: INFO: stderr: ""
Feb 24 09:13:44.989: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 09:13:44.989: INFO: validating pod update-demo-nautilus-49znm
Feb 24 09:13:44.991: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 09:13:44.991: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 09:13:44.991: INFO: update-demo-nautilus-49znm is verified up and running
Feb 24 09:13:44.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-vhb4b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6811'
Feb 24 09:13:45.049: INFO: stderr: ""
Feb 24 09:13:45.049: INFO: stdout: "true"
Feb 24 09:13:45.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-vhb4b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6811'
Feb 24 09:13:45.108: INFO: stderr: ""
Feb 24 09:13:45.108: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 09:13:45.108: INFO: validating pod update-demo-nautilus-vhb4b
Feb 24 09:13:45.111: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 09:13:45.111: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 09:13:45.111: INFO: update-demo-nautilus-vhb4b is verified up and running
STEP: rolling-update to new replication controller
Feb 24 09:13:45.113: INFO: scanned /root for discovery docs: <nil>
Feb 24 09:13:45.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6811'
Feb 24 09:14:07.399: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 24 09:14:07.399: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 09:14:07.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6811'
Feb 24 09:14:07.471: INFO: stderr: ""
Feb 24 09:14:07.471: INFO: stdout: "update-demo-kitten-59fzb update-demo-kitten-qd965 "
Feb 24 09:14:07.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-kitten-59fzb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6811'
Feb 24 09:14:07.528: INFO: stderr: ""
Feb 24 09:14:07.528: INFO: stdout: "true"
Feb 24 09:14:07.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-kitten-59fzb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6811'
Feb 24 09:14:07.586: INFO: stderr: ""
Feb 24 09:14:07.586: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 24 09:14:07.586: INFO: validating pod update-demo-kitten-59fzb
Feb 24 09:14:07.589: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 24 09:14:07.589: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 24 09:14:07.589: INFO: update-demo-kitten-59fzb is verified up and running
Feb 24 09:14:07.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-kitten-qd965 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6811'
Feb 24 09:14:07.645: INFO: stderr: ""
Feb 24 09:14:07.645: INFO: stdout: "true"
Feb 24 09:14:07.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-kitten-qd965 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6811'
Feb 24 09:14:07.703: INFO: stderr: ""
Feb 24 09:14:07.703: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 24 09:14:07.703: INFO: validating pod update-demo-kitten-qd965
Feb 24 09:14:07.706: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 24 09:14:07.706: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 24 09:14:07.706: INFO: update-demo-kitten-qd965 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:14:07.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6811" for this suite.
Feb 24 09:14:35.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:14:35.793: INFO: namespace kubectl-6811 deletion completed in 28.084129226s

• [SLOW TEST:56.365 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:14:35.793: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:14:37.845: INFO: Waiting up to 5m0s for pod "client-envvars-d029dc1e-e8eb-4f22-ae5b-3b380e914345" in namespace "pods-4255" to be "success or failure"
Feb 24 09:14:37.853: INFO: Pod "client-envvars-d029dc1e-e8eb-4f22-ae5b-3b380e914345": Phase="Pending", Reason="", readiness=false. Elapsed: 8.16826ms
Feb 24 09:14:39.856: INFO: Pod "client-envvars-d029dc1e-e8eb-4f22-ae5b-3b380e914345": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010299737s
STEP: Saw pod success
Feb 24 09:14:39.856: INFO: Pod "client-envvars-d029dc1e-e8eb-4f22-ae5b-3b380e914345" satisfied condition "success or failure"
Feb 24 09:14:39.860: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod client-envvars-d029dc1e-e8eb-4f22-ae5b-3b380e914345 container env3cont: <nil>
STEP: delete the pod
Feb 24 09:14:39.882: INFO: Waiting for pod client-envvars-d029dc1e-e8eb-4f22-ae5b-3b380e914345 to disappear
Feb 24 09:14:39.884: INFO: Pod client-envvars-d029dc1e-e8eb-4f22-ae5b-3b380e914345 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:14:39.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4255" for this suite.
Feb 24 09:15:07.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:15:07.975: INFO: namespace pods-4255 deletion completed in 28.088165454s

• [SLOW TEST:32.182 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:15:07.975: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-e5255c05-33f7-4315-869a-7ea8ab070d7a
STEP: Creating a pod to test consume configMaps
Feb 24 09:15:08.003: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-23257fdf-b32b-44b4-abf7-a8509435e6cb" in namespace "projected-454" to be "success or failure"
Feb 24 09:15:08.012: INFO: Pod "pod-projected-configmaps-23257fdf-b32b-44b4-abf7-a8509435e6cb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.686807ms
Feb 24 09:15:10.015: INFO: Pod "pod-projected-configmaps-23257fdf-b32b-44b4-abf7-a8509435e6cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011932882s
Feb 24 09:15:12.017: INFO: Pod "pod-projected-configmaps-23257fdf-b32b-44b4-abf7-a8509435e6cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013969431s
STEP: Saw pod success
Feb 24 09:15:12.017: INFO: Pod "pod-projected-configmaps-23257fdf-b32b-44b4-abf7-a8509435e6cb" satisfied condition "success or failure"
Feb 24 09:15:12.018: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-configmaps-23257fdf-b32b-44b4-abf7-a8509435e6cb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 09:15:12.037: INFO: Waiting for pod pod-projected-configmaps-23257fdf-b32b-44b4-abf7-a8509435e6cb to disappear
Feb 24 09:15:12.039: INFO: Pod pod-projected-configmaps-23257fdf-b32b-44b4-abf7-a8509435e6cb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:15:12.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-454" for this suite.
Feb 24 09:15:18.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:15:18.117: INFO: namespace projected-454 deletion completed in 6.073272968s

• [SLOW TEST:10.142 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:15:18.117: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:15:18.144: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79616c1e-d405-49d7-a8b2-5e4da8013baa" in namespace "projected-8337" to be "success or failure"
Feb 24 09:15:18.149: INFO: Pod "downwardapi-volume-79616c1e-d405-49d7-a8b2-5e4da8013baa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.511964ms
Feb 24 09:15:20.151: INFO: Pod "downwardapi-volume-79616c1e-d405-49d7-a8b2-5e4da8013baa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006777144s
Feb 24 09:15:22.153: INFO: Pod "downwardapi-volume-79616c1e-d405-49d7-a8b2-5e4da8013baa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009095502s
STEP: Saw pod success
Feb 24 09:15:22.153: INFO: Pod "downwardapi-volume-79616c1e-d405-49d7-a8b2-5e4da8013baa" satisfied condition "success or failure"
Feb 24 09:15:22.155: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-79616c1e-d405-49d7-a8b2-5e4da8013baa container client-container: <nil>
STEP: delete the pod
Feb 24 09:15:22.172: INFO: Waiting for pod downwardapi-volume-79616c1e-d405-49d7-a8b2-5e4da8013baa to disappear
Feb 24 09:15:22.174: INFO: Pod downwardapi-volume-79616c1e-d405-49d7-a8b2-5e4da8013baa no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:15:22.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8337" for this suite.
Feb 24 09:15:28.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:15:28.252: INFO: namespace projected-8337 deletion completed in 6.075292496s

• [SLOW TEST:10.135 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:15:28.252: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-173/secret-test-6589cea2-d139-442b-bab3-a694d280654c
STEP: Creating a pod to test consume secrets
Feb 24 09:15:28.282: INFO: Waiting up to 5m0s for pod "pod-configmaps-0445c30f-5a52-4c91-a008-3ac038bca42d" in namespace "secrets-173" to be "success or failure"
Feb 24 09:15:28.290: INFO: Pod "pod-configmaps-0445c30f-5a52-4c91-a008-3ac038bca42d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.594558ms
Feb 24 09:15:30.292: INFO: Pod "pod-configmaps-0445c30f-5a52-4c91-a008-3ac038bca42d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008215351s
Feb 24 09:15:32.294: INFO: Pod "pod-configmaps-0445c30f-5a52-4c91-a008-3ac038bca42d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010247754s
STEP: Saw pod success
Feb 24 09:15:32.294: INFO: Pod "pod-configmaps-0445c30f-5a52-4c91-a008-3ac038bca42d" satisfied condition "success or failure"
Feb 24 09:15:32.296: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-configmaps-0445c30f-5a52-4c91-a008-3ac038bca42d container env-test: <nil>
STEP: delete the pod
Feb 24 09:15:32.323: INFO: Waiting for pod pod-configmaps-0445c30f-5a52-4c91-a008-3ac038bca42d to disappear
Feb 24 09:15:32.324: INFO: Pod pod-configmaps-0445c30f-5a52-4c91-a008-3ac038bca42d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:15:32.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-173" for this suite.
Feb 24 09:15:38.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:15:38.399: INFO: namespace secrets-173 deletion completed in 6.0726921s

• [SLOW TEST:10.148 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:15:38.400: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2872.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2872.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2872.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2872.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2872.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2872.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 09:15:40.449: INFO: DNS probes using dns-2872/dns-test-67af2228-f79b-45ab-969d-1b1a10d88728 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:15:40.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2872" for this suite.
Feb 24 09:15:46.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:15:46.537: INFO: namespace dns-2872 deletion completed in 6.072485562s

• [SLOW TEST:8.137 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:15:46.537: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 24 09:15:46.606: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:15:50.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9611" for this suite.
Feb 24 09:16:18.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:16:18.719: INFO: namespace init-container-9611 deletion completed in 28.085459393s

• [SLOW TEST:32.182 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:16:18.720: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:16:18.750: INFO: (0) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 9.791618ms)
Feb 24 09:16:18.752: INFO: (1) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.315115ms)
Feb 24 09:16:18.755: INFO: (2) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.141012ms)
Feb 24 09:16:18.757: INFO: (3) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.355169ms)
Feb 24 09:16:18.759: INFO: (4) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.027493ms)
Feb 24 09:16:18.762: INFO: (5) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.317824ms)
Feb 24 09:16:18.764: INFO: (6) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.269755ms)
Feb 24 09:16:18.766: INFO: (7) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.004072ms)
Feb 24 09:16:18.768: INFO: (8) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.92932ms)
Feb 24 09:16:18.770: INFO: (9) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.412153ms)
Feb 24 09:16:18.773: INFO: (10) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.351525ms)
Feb 24 09:16:18.775: INFO: (11) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.268931ms)
Feb 24 09:16:18.777: INFO: (12) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.270777ms)
Feb 24 09:16:18.780: INFO: (13) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.365676ms)
Feb 24 09:16:18.782: INFO: (14) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.03362ms)
Feb 24 09:16:18.784: INFO: (15) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.430975ms)
Feb 24 09:16:18.789: INFO: (16) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 5.117945ms)
Feb 24 09:16:18.792: INFO: (17) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.326096ms)
Feb 24 09:16:18.794: INFO: (18) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.964584ms)
Feb 24 09:16:18.796: INFO: (19) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.939852ms)
[AfterEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:16:18.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7665" for this suite.
Feb 24 09:16:24.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:16:24.871: INFO: namespace proxy-7665 deletion completed in 6.073183737s

• [SLOW TEST:6.151 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:16:24.871: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Feb 24 09:16:28.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec pod-sharedvolume-d7ad3fdd-50e2-425e-9913-949e17f1bcea -c busybox-main-container --namespace=emptydir-3007 -- cat /usr/share/volumeshare/shareddata.txt'
Feb 24 09:16:29.120: INFO: stderr: ""
Feb 24 09:16:29.120: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:16:29.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3007" for this suite.
Feb 24 09:16:35.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:16:35.270: INFO: namespace emptydir-3007 deletion completed in 6.147434289s

• [SLOW TEST:10.399 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:16:35.270: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:16:35.296: INFO: Creating deployment "test-recreate-deployment"
Feb 24 09:16:35.301: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 24 09:16:35.336: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb 24 09:16:37.340: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 24 09:16:37.341: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132595, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132595, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132595, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132595, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 09:16:39.343: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 24 09:16:39.347: INFO: Updating deployment test-recreate-deployment
Feb 24 09:16:39.347: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 24 09:16:39.409: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-4458 /apis/apps/v1/namespaces/deployment-4458/deployments/test-recreate-deployment 40fd1e75-f34b-419f-829f-60962a756db7 14902 2 2020-02-24 09:16:35 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0032a1f48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-02-24 09:16:39 +0000 UTC,LastTransitionTime:2020-02-24 09:16:39 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-02-24 09:16:39 +0000 UTC,LastTransitionTime:2020-02-24 09:16:35 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Feb 24 09:16:39.411: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-4458 /apis/apps/v1/namespaces/deployment-4458/replicasets/test-recreate-deployment-5f94c574ff 37bdb868-669c-4f10-8747-03add54a7cc7 14901 1 2020-02-24 09:16:39 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 40fd1e75-f34b-419f-829f-60962a756db7 0xc004bcf197 0xc004bcf198}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004bcf1f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 09:16:39.411: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 24 09:16:39.411: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-4458 /apis/apps/v1/namespaces/deployment-4458/replicasets/test-recreate-deployment-68fc85c7bb 4465d35b-d364-4b7a-be94-533f6a867d40 14888 2 2020-02-24 09:16:35 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 40fd1e75-f34b-419f-829f-60962a756db7 0xc004bcf267 0xc004bcf268}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004bcf2c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 09:16:39.414: INFO: Pod "test-recreate-deployment-5f94c574ff-dgdn6" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-dgdn6 test-recreate-deployment-5f94c574ff- deployment-4458 /api/v1/namespaces/deployment-4458/pods/test-recreate-deployment-5f94c574ff-dgdn6 50f96983-e31f-4ee6-9796-754906a52f26 14900 0 2020-02-24 09:16:39 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 37bdb868-669c-4f10-8747-03add54a7cc7 0xc004bcf737 0xc004bcf738}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-f7r4v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-f7r4v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-f7r4v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:16:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:16:39 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:16:39 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:16:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 09:16:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:16:39.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4458" for this suite.
Feb 24 09:16:45.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:16:45.494: INFO: namespace deployment-4458 deletion completed in 6.076664062s

• [SLOW TEST:10.223 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:16:45.494: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-e4c90fbc-5105-4460-b026-cfee6af82e76 in namespace container-probe-2178
Feb 24 09:16:47.525: INFO: Started pod liveness-e4c90fbc-5105-4460-b026-cfee6af82e76 in namespace container-probe-2178
STEP: checking the pod's current state and verifying that restartCount is present
Feb 24 09:16:47.527: INFO: Initial restart count of pod liveness-e4c90fbc-5105-4460-b026-cfee6af82e76 is 0
Feb 24 09:17:07.549: INFO: Restart count of pod container-probe-2178/liveness-e4c90fbc-5105-4460-b026-cfee6af82e76 is now 1 (20.022020973s elapsed)
Feb 24 09:17:27.570: INFO: Restart count of pod container-probe-2178/liveness-e4c90fbc-5105-4460-b026-cfee6af82e76 is now 2 (40.042914601s elapsed)
Feb 24 09:17:47.591: INFO: Restart count of pod container-probe-2178/liveness-e4c90fbc-5105-4460-b026-cfee6af82e76 is now 3 (1m0.064603907s elapsed)
Feb 24 09:18:07.614: INFO: Restart count of pod container-probe-2178/liveness-e4c90fbc-5105-4460-b026-cfee6af82e76 is now 4 (1m20.086924981s elapsed)
Feb 24 09:18:27.634: INFO: Restart count of pod container-probe-2178/liveness-e4c90fbc-5105-4460-b026-cfee6af82e76 is now 5 (1m40.107284897s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:18:27.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2178" for this suite.
Feb 24 09:18:33.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:18:33.727: INFO: namespace container-probe-2178 deletion completed in 6.080561928s

• [SLOW TEST:108.233 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:18:33.727: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:18:34.028: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:18:36.034: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132713, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132713, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132714, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132713, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:18:39.044: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:18:39.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1646" for this suite.
Feb 24 09:18:45.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:18:45.180: INFO: namespace webhook-1646 deletion completed in 6.094426918s
STEP: Destroying namespace "webhook-1646-markers" for this suite.
Feb 24 09:18:51.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:18:51.260: INFO: namespace webhook-1646-markers deletion completed in 6.080205935s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.540 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:18:51.267: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Feb 24 09:18:51.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 cluster-info'
Feb 24 09:18:51.351: INFO: stderr: ""
Feb 24 09:18:51.351: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:18:51.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2108" for this suite.
Feb 24 09:18:57.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:18:57.433: INFO: namespace kubectl-2108 deletion completed in 6.073782656s

• [SLOW TEST:6.166 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:18:57.433: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-6259/configmap-test-3ae7a1ca-792d-4d77-8337-3694d43eca62
STEP: Creating a pod to test consume configMaps
Feb 24 09:18:57.460: INFO: Waiting up to 5m0s for pod "pod-configmaps-b1365ca0-86ea-419e-beae-cd3ab79ea8de" in namespace "configmap-6259" to be "success or failure"
Feb 24 09:18:57.463: INFO: Pod "pod-configmaps-b1365ca0-86ea-419e-beae-cd3ab79ea8de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.5342ms
Feb 24 09:18:59.465: INFO: Pod "pod-configmaps-b1365ca0-86ea-419e-beae-cd3ab79ea8de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004474205s
Feb 24 09:19:01.467: INFO: Pod "pod-configmaps-b1365ca0-86ea-419e-beae-cd3ab79ea8de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006559302s
STEP: Saw pod success
Feb 24 09:19:01.467: INFO: Pod "pod-configmaps-b1365ca0-86ea-419e-beae-cd3ab79ea8de" satisfied condition "success or failure"
Feb 24 09:19:01.468: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-configmaps-b1365ca0-86ea-419e-beae-cd3ab79ea8de container env-test: <nil>
STEP: delete the pod
Feb 24 09:19:01.491: INFO: Waiting for pod pod-configmaps-b1365ca0-86ea-419e-beae-cd3ab79ea8de to disappear
Feb 24 09:19:01.492: INFO: Pod pod-configmaps-b1365ca0-86ea-419e-beae-cd3ab79ea8de no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:19:01.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6259" for this suite.
Feb 24 09:19:07.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:19:07.567: INFO: namespace configmap-6259 deletion completed in 6.072708935s

• [SLOW TEST:10.133 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:19:07.567: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:19:07.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-5082" for this suite.
Feb 24 09:19:13.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:19:13.676: INFO: namespace tables-5082 deletion completed in 6.071607792s

• [SLOW TEST:6.109 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:19:13.676: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:19:13.700: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9cd3a040-8d7e-499b-9ee8-a2e7aa736b53" in namespace "projected-9632" to be "success or failure"
Feb 24 09:19:13.706: INFO: Pod "downwardapi-volume-9cd3a040-8d7e-499b-9ee8-a2e7aa736b53": Phase="Pending", Reason="", readiness=false. Elapsed: 6.258407ms
Feb 24 09:19:15.708: INFO: Pod "downwardapi-volume-9cd3a040-8d7e-499b-9ee8-a2e7aa736b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008190869s
STEP: Saw pod success
Feb 24 09:19:15.708: INFO: Pod "downwardapi-volume-9cd3a040-8d7e-499b-9ee8-a2e7aa736b53" satisfied condition "success or failure"
Feb 24 09:19:15.710: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-9cd3a040-8d7e-499b-9ee8-a2e7aa736b53 container client-container: <nil>
STEP: delete the pod
Feb 24 09:19:15.727: INFO: Waiting for pod downwardapi-volume-9cd3a040-8d7e-499b-9ee8-a2e7aa736b53 to disappear
Feb 24 09:19:15.732: INFO: Pod downwardapi-volume-9cd3a040-8d7e-499b-9ee8-a2e7aa736b53 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:19:15.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9632" for this suite.
Feb 24 09:19:21.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:19:21.813: INFO: namespace projected-9632 deletion completed in 6.079011294s

• [SLOW TEST:8.137 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:19:21.813: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-7055190d-8078-4021-9bbf-8183651002c2
STEP: Creating configMap with name cm-test-opt-upd-365a07c5-d8c9-4353-8e34-64a787a5571c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-7055190d-8078-4021-9bbf-8183651002c2
STEP: Updating configmap cm-test-opt-upd-365a07c5-d8c9-4353-8e34-64a787a5571c
STEP: Creating configMap with name cm-test-opt-create-56598971-3fa0-4122-8df8-49a6f897a8dd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:19:25.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-913" for this suite.
Feb 24 09:19:49.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:19:49.991: INFO: namespace projected-913 deletion completed in 24.088501457s

• [SLOW TEST:28.178 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:19:49.991: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-ed26715b-4f3d-4e61-bad8-bb79428ca5c7
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:19:50.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3931" for this suite.
Feb 24 09:19:56.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:19:56.137: INFO: namespace configmap-3931 deletion completed in 6.073366366s

• [SLOW TEST:6.146 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:19:56.138: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-8b2d3905-caa0-445a-9eb4-9f1a026bc231
STEP: Creating a pod to test consume configMaps
Feb 24 09:19:56.165: INFO: Waiting up to 5m0s for pod "pod-configmaps-ed6159fc-fb25-4a43-82c1-5d430dd44d9f" in namespace "configmap-4516" to be "success or failure"
Feb 24 09:19:56.178: INFO: Pod "pod-configmaps-ed6159fc-fb25-4a43-82c1-5d430dd44d9f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.782073ms
Feb 24 09:19:58.181: INFO: Pod "pod-configmaps-ed6159fc-fb25-4a43-82c1-5d430dd44d9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015075613s
STEP: Saw pod success
Feb 24 09:19:58.181: INFO: Pod "pod-configmaps-ed6159fc-fb25-4a43-82c1-5d430dd44d9f" satisfied condition "success or failure"
Feb 24 09:19:58.183: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-configmaps-ed6159fc-fb25-4a43-82c1-5d430dd44d9f container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 09:19:58.203: INFO: Waiting for pod pod-configmaps-ed6159fc-fb25-4a43-82c1-5d430dd44d9f to disappear
Feb 24 09:19:58.207: INFO: Pod pod-configmaps-ed6159fc-fb25-4a43-82c1-5d430dd44d9f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:19:58.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4516" for this suite.
Feb 24 09:20:04.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:20:04.285: INFO: namespace configmap-4516 deletion completed in 6.073508553s

• [SLOW TEST:8.147 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:20:04.285: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:20:04.980: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:20:06.986: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132804, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132804, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132804, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132804, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:20:09.995: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:20:09.998: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7023-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:20:11.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3271" for this suite.
Feb 24 09:20:17.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:20:17.172: INFO: namespace webhook-3271 deletion completed in 6.078249356s
STEP: Destroying namespace "webhook-3271-markers" for this suite.
Feb 24 09:20:23.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:20:23.247: INFO: namespace webhook-3271-markers deletion completed in 6.074990999s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.969 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:20:23.254: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:20:23.645: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:20:25.651: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132823, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132823, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132823, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132823, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:20:28.661: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:20:28.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6445" for this suite.
Feb 24 09:20:34.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:20:34.775: INFO: namespace webhook-6445 deletion completed in 6.078777676s
STEP: Destroying namespace "webhook-6445-markers" for this suite.
Feb 24 09:20:40.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:20:40.851: INFO: namespace webhook-6445-markers deletion completed in 6.075670507s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.604 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:20:40.859: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 24 09:20:40.880: INFO: PodSpec: initContainers in spec.initContainers
Feb 24 09:21:25.261: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-4a62279e-b199-46b2-9bd1-c17c0217e1ba", GenerateName:"", Namespace:"init-container-4767", SelfLink:"/api/v1/namespaces/init-container-4767/pods/pod-init-4a62279e-b199-46b2-9bd1-c17c0217e1ba", UID:"2ccb479b-340e-4baa-9a34-08c202dbadda", ResourceVersion:"16200", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63718132840, loc:(*time.Location)(0x788c6e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"880299820"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"172.16.14.247/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-6sttb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00505f940), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6sttb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6sttb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6sttb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003192ba8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-100-10-76.eu-west-1.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002c5d200), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003192c20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003192d20)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003192d28), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003192d2c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132840, loc:(*time.Location)(0x788c6e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132840, loc:(*time.Location)(0x788c6e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132840, loc:(*time.Location)(0x788c6e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718132840, loc:(*time.Location)(0x788c6e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.100.10.76", PodIP:"172.16.14.247", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.16.14.247"}}, StartTime:(*v1.Time)(0xc003819d00), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002c11810)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002c11880)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://fbba578499abc7e7bbfce8af46e214ed9e1f2238fac28d55ccd2b5fa56166140", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003819d40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003819d20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc003192dcf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:21:25.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4767" for this suite.
Feb 24 09:21:53.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:21:53.351: INFO: namespace init-container-4767 deletion completed in 28.080918138s

• [SLOW TEST:72.493 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:21:53.351: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-n4949 in namespace proxy-6010
I0224 09:21:53.388646      21 runners.go:184] Created replication controller with name: proxy-service-n4949, namespace: proxy-6010, replica count: 1
I0224 09:21:54.438932      21 runners.go:184] proxy-service-n4949 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0224 09:21:55.439081      21 runners.go:184] proxy-service-n4949 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0224 09:21:56.439235      21 runners.go:184] proxy-service-n4949 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0224 09:21:57.439390      21 runners.go:184] proxy-service-n4949 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 24 09:21:57.441: INFO: setup took 4.068058054s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 24 09:21:57.451: INFO: (0) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 8.975738ms)
Feb 24 09:21:57.451: INFO: (0) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 10.169749ms)
Feb 24 09:21:57.452: INFO: (0) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 10.027414ms)
Feb 24 09:21:57.453: INFO: (0) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 11.232385ms)
Feb 24 09:21:57.453: INFO: (0) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 11.424267ms)
Feb 24 09:21:57.454: INFO: (0) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 12.752069ms)
Feb 24 09:21:57.454: INFO: (0) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 12.962027ms)
Feb 24 09:21:57.456: INFO: (0) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 14.77855ms)
Feb 24 09:21:57.456: INFO: (0) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 14.80671ms)
Feb 24 09:21:57.457: INFO: (0) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 15.14377ms)
Feb 24 09:21:57.457: INFO: (0) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 15.074619ms)
Feb 24 09:21:57.457: INFO: (0) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 15.894792ms)
Feb 24 09:21:57.457: INFO: (0) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 15.596901ms)
Feb 24 09:21:57.457: INFO: (0) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 15.968857ms)
Feb 24 09:21:57.460: INFO: (0) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 18.616868ms)
Feb 24 09:21:57.460: INFO: (0) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 18.365045ms)
Feb 24 09:21:57.467: INFO: (1) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 6.194882ms)
Feb 24 09:21:57.468: INFO: (1) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 8.249006ms)
Feb 24 09:21:57.469: INFO: (1) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 8.366166ms)
Feb 24 09:21:57.469: INFO: (1) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 8.360252ms)
Feb 24 09:21:57.469: INFO: (1) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 8.642665ms)
Feb 24 09:21:57.469: INFO: (1) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 8.579641ms)
Feb 24 09:21:57.469: INFO: (1) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 8.525505ms)
Feb 24 09:21:57.469: INFO: (1) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 9.017522ms)
Feb 24 09:21:57.470: INFO: (1) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 9.359054ms)
Feb 24 09:21:57.470: INFO: (1) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 10.029496ms)
Feb 24 09:21:57.470: INFO: (1) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 10.174631ms)
Feb 24 09:21:57.471: INFO: (1) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 10.54711ms)
Feb 24 09:21:57.471: INFO: (1) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 10.740547ms)
Feb 24 09:21:57.471: INFO: (1) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 10.601253ms)
Feb 24 09:21:57.471: INFO: (1) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 10.644223ms)
Feb 24 09:21:57.471: INFO: (1) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 10.719951ms)
Feb 24 09:21:57.478: INFO: (2) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 6.675545ms)
Feb 24 09:21:57.479: INFO: (2) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 7.666258ms)
Feb 24 09:21:57.479: INFO: (2) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 7.605498ms)
Feb 24 09:21:57.481: INFO: (2) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 9.570055ms)
Feb 24 09:21:57.481: INFO: (2) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 10.008928ms)
Feb 24 09:21:57.481: INFO: (2) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 9.668121ms)
Feb 24 09:21:57.482: INFO: (2) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 10.334193ms)
Feb 24 09:21:57.482: INFO: (2) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 10.089578ms)
Feb 24 09:21:57.482: INFO: (2) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 10.467087ms)
Feb 24 09:21:57.482: INFO: (2) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 10.334468ms)
Feb 24 09:21:57.482: INFO: (2) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 10.516449ms)
Feb 24 09:21:57.482: INFO: (2) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 10.976076ms)
Feb 24 09:21:57.482: INFO: (2) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 10.733449ms)
Feb 24 09:21:57.487: INFO: (2) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 15.421926ms)
Feb 24 09:21:57.487: INFO: (2) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 15.264232ms)
Feb 24 09:21:57.487: INFO: (2) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 15.613275ms)
Feb 24 09:21:57.493: INFO: (3) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 6.214273ms)
Feb 24 09:21:57.501: INFO: (3) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 13.198534ms)
Feb 24 09:21:57.501: INFO: (3) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 12.913764ms)
Feb 24 09:21:57.501: INFO: (3) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 13.344333ms)
Feb 24 09:21:57.501: INFO: (3) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 13.72346ms)
Feb 24 09:21:57.501: INFO: (3) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 13.599313ms)
Feb 24 09:21:57.501: INFO: (3) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 13.03274ms)
Feb 24 09:21:57.501: INFO: (3) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 13.831882ms)
Feb 24 09:21:57.501: INFO: (3) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 12.95567ms)
Feb 24 09:21:57.501: INFO: (3) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 13.745381ms)
Feb 24 09:21:57.508: INFO: (3) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 20.489362ms)
Feb 24 09:21:57.508: INFO: (3) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 20.676241ms)
Feb 24 09:21:57.510: INFO: (3) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 22.904932ms)
Feb 24 09:21:57.512: INFO: (3) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 24.668274ms)
Feb 24 09:21:57.512: INFO: (3) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 24.722749ms)
Feb 24 09:21:57.512: INFO: (3) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 24.401226ms)
Feb 24 09:21:57.519: INFO: (4) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 6.614369ms)
Feb 24 09:21:57.519: INFO: (4) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 6.577106ms)
Feb 24 09:21:57.519: INFO: (4) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 6.904815ms)
Feb 24 09:21:57.519: INFO: (4) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 6.97799ms)
Feb 24 09:21:57.521: INFO: (4) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 8.351467ms)
Feb 24 09:21:57.521: INFO: (4) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 8.437716ms)
Feb 24 09:21:57.521: INFO: (4) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 8.468566ms)
Feb 24 09:21:57.521: INFO: (4) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 8.685188ms)
Feb 24 09:21:57.522: INFO: (4) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 8.985005ms)
Feb 24 09:21:57.522: INFO: (4) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 9.078847ms)
Feb 24 09:21:57.523: INFO: (4) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 10.026124ms)
Feb 24 09:21:57.523: INFO: (4) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 10.277992ms)
Feb 24 09:21:57.526: INFO: (4) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 13.876944ms)
Feb 24 09:21:57.526: INFO: (4) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 14.135147ms)
Feb 24 09:21:57.527: INFO: (4) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 14.119912ms)
Feb 24 09:21:57.527: INFO: (4) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 13.904023ms)
Feb 24 09:21:57.535: INFO: (5) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 7.962285ms)
Feb 24 09:21:57.535: INFO: (5) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 8.361948ms)
Feb 24 09:21:57.535: INFO: (5) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 8.416193ms)
Feb 24 09:21:57.535: INFO: (5) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 8.407347ms)
Feb 24 09:21:57.536: INFO: (5) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 8.760362ms)
Feb 24 09:21:57.536: INFO: (5) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 8.889963ms)
Feb 24 09:21:57.536: INFO: (5) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 9.417206ms)
Feb 24 09:21:57.536: INFO: (5) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 9.521179ms)
Feb 24 09:21:57.538: INFO: (5) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 11.417417ms)
Feb 24 09:21:57.538: INFO: (5) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 11.576193ms)
Feb 24 09:21:57.538: INFO: (5) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 11.750106ms)
Feb 24 09:21:57.538: INFO: (5) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 11.688568ms)
Feb 24 09:21:57.539: INFO: (5) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 11.794754ms)
Feb 24 09:21:57.539: INFO: (5) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 11.960162ms)
Feb 24 09:21:57.539: INFO: (5) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 12.141637ms)
Feb 24 09:21:57.540: INFO: (5) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 13.158752ms)
Feb 24 09:21:57.546: INFO: (6) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 5.18448ms)
Feb 24 09:21:57.546: INFO: (6) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 6.175308ms)
Feb 24 09:21:57.547: INFO: (6) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 6.629843ms)
Feb 24 09:21:57.547: INFO: (6) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 6.36001ms)
Feb 24 09:21:57.548: INFO: (6) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 7.590871ms)
Feb 24 09:21:57.548: INFO: (6) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 8.032966ms)
Feb 24 09:21:57.548: INFO: (6) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 8.143609ms)
Feb 24 09:21:57.549: INFO: (6) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 8.412465ms)
Feb 24 09:21:57.549: INFO: (6) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 8.582514ms)
Feb 24 09:21:57.549: INFO: (6) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 8.833584ms)
Feb 24 09:21:57.549: INFO: (6) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 9.278117ms)
Feb 24 09:21:57.550: INFO: (6) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 9.359713ms)
Feb 24 09:21:57.551: INFO: (6) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 10.192383ms)
Feb 24 09:21:57.551: INFO: (6) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 10.662332ms)
Feb 24 09:21:57.551: INFO: (6) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 10.930259ms)
Feb 24 09:21:57.551: INFO: (6) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 10.958075ms)
Feb 24 09:21:57.565: INFO: (7) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 13.933419ms)
Feb 24 09:21:57.566: INFO: (7) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 13.919096ms)
Feb 24 09:21:57.567: INFO: (7) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 14.52399ms)
Feb 24 09:21:57.568: INFO: (7) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 16.602168ms)
Feb 24 09:21:57.569: INFO: (7) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 16.839131ms)
Feb 24 09:21:57.569: INFO: (7) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 17.044631ms)
Feb 24 09:21:57.569: INFO: (7) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 17.19161ms)
Feb 24 09:21:57.569: INFO: (7) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 17.52486ms)
Feb 24 09:21:57.569: INFO: (7) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 17.770784ms)
Feb 24 09:21:57.570: INFO: (7) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 18.489784ms)
Feb 24 09:21:57.570: INFO: (7) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 18.785738ms)
Feb 24 09:21:57.571: INFO: (7) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 19.467288ms)
Feb 24 09:21:57.571: INFO: (7) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 19.066453ms)
Feb 24 09:21:57.571: INFO: (7) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 18.945235ms)
Feb 24 09:21:57.571: INFO: (7) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 19.209269ms)
Feb 24 09:21:57.571: INFO: (7) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 19.470638ms)
Feb 24 09:21:57.592: INFO: (8) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 20.251703ms)
Feb 24 09:21:57.592: INFO: (8) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 20.709418ms)
Feb 24 09:21:57.592: INFO: (8) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 20.777031ms)
Feb 24 09:21:57.592: INFO: (8) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 20.84336ms)
Feb 24 09:21:57.592: INFO: (8) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 20.637145ms)
Feb 24 09:21:57.593: INFO: (8) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 21.856372ms)
Feb 24 09:21:57.593: INFO: (8) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 22.040904ms)
Feb 24 09:21:57.593: INFO: (8) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 21.966856ms)
Feb 24 09:21:57.594: INFO: (8) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 22.568065ms)
Feb 24 09:21:57.594: INFO: (8) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 22.496904ms)
Feb 24 09:21:57.594: INFO: (8) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 22.550274ms)
Feb 24 09:21:57.594: INFO: (8) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 23.050784ms)
Feb 24 09:21:57.595: INFO: (8) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 23.01045ms)
Feb 24 09:21:57.595: INFO: (8) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 23.118232ms)
Feb 24 09:21:57.599: INFO: (8) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 26.988779ms)
Feb 24 09:21:57.599: INFO: (8) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 27.593624ms)
Feb 24 09:21:57.608: INFO: (9) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 8.389936ms)
Feb 24 09:21:57.610: INFO: (9) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 10.122692ms)
Feb 24 09:21:57.610: INFO: (9) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 10.669304ms)
Feb 24 09:21:57.610: INFO: (9) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 11.08519ms)
Feb 24 09:21:57.611: INFO: (9) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 10.711295ms)
Feb 24 09:21:57.611: INFO: (9) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 10.782012ms)
Feb 24 09:21:57.611: INFO: (9) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 10.774219ms)
Feb 24 09:21:57.611: INFO: (9) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 10.912528ms)
Feb 24 09:21:57.611: INFO: (9) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 11.581105ms)
Feb 24 09:21:57.611: INFO: (9) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 11.226073ms)
Feb 24 09:21:57.611: INFO: (9) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 11.438529ms)
Feb 24 09:21:57.613: INFO: (9) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 13.173275ms)
Feb 24 09:21:57.613: INFO: (9) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 13.760181ms)
Feb 24 09:21:57.613: INFO: (9) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 14.011915ms)
Feb 24 09:21:57.613: INFO: (9) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 13.773916ms)
Feb 24 09:21:57.614: INFO: (9) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 14.140762ms)
Feb 24 09:21:57.621: INFO: (10) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 6.891337ms)
Feb 24 09:21:57.621: INFO: (10) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 6.886302ms)
Feb 24 09:21:57.621: INFO: (10) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 6.851584ms)
Feb 24 09:21:57.621: INFO: (10) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 7.116025ms)
Feb 24 09:21:57.621: INFO: (10) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 7.195451ms)
Feb 24 09:21:57.621: INFO: (10) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 7.069588ms)
Feb 24 09:21:57.621: INFO: (10) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 7.016338ms)
Feb 24 09:21:57.621: INFO: (10) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 6.711187ms)
Feb 24 09:21:57.622: INFO: (10) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 7.434498ms)
Feb 24 09:21:57.622: INFO: (10) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 8.050025ms)
Feb 24 09:21:57.625: INFO: (10) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 9.958388ms)
Feb 24 09:21:57.625: INFO: (10) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 9.84922ms)
Feb 24 09:21:57.625: INFO: (10) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 10.164946ms)
Feb 24 09:21:57.625: INFO: (10) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 10.539606ms)
Feb 24 09:21:57.625: INFO: (10) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 10.730135ms)
Feb 24 09:21:57.626: INFO: (10) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 11.28959ms)
Feb 24 09:21:57.634: INFO: (11) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 8.393369ms)
Feb 24 09:21:57.635: INFO: (11) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 8.751313ms)
Feb 24 09:21:57.637: INFO: (11) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 10.890417ms)
Feb 24 09:21:57.637: INFO: (11) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 10.7817ms)
Feb 24 09:21:57.637: INFO: (11) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 10.697356ms)
Feb 24 09:21:57.637: INFO: (11) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 10.889393ms)
Feb 24 09:21:57.637: INFO: (11) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 10.854524ms)
Feb 24 09:21:57.637: INFO: (11) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 10.776102ms)
Feb 24 09:21:57.637: INFO: (11) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 10.89311ms)
Feb 24 09:21:57.637: INFO: (11) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 11.163801ms)
Feb 24 09:21:57.638: INFO: (11) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 11.580264ms)
Feb 24 09:21:57.638: INFO: (11) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 11.416367ms)
Feb 24 09:21:57.638: INFO: (11) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 11.92902ms)
Feb 24 09:21:57.638: INFO: (11) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 11.913628ms)
Feb 24 09:21:57.638: INFO: (11) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 12.260067ms)
Feb 24 09:21:57.638: INFO: (11) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 12.205571ms)
Feb 24 09:21:57.644: INFO: (12) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 5.973555ms)
Feb 24 09:21:57.645: INFO: (12) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 7.01401ms)
Feb 24 09:21:57.646: INFO: (12) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 7.493668ms)
Feb 24 09:21:57.646: INFO: (12) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 7.680034ms)
Feb 24 09:21:57.646: INFO: (12) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 7.674976ms)
Feb 24 09:21:57.646: INFO: (12) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 8.269035ms)
Feb 24 09:21:57.646: INFO: (12) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 8.075427ms)
Feb 24 09:21:57.647: INFO: (12) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 8.283065ms)
Feb 24 09:21:57.647: INFO: (12) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 8.309527ms)
Feb 24 09:21:57.647: INFO: (12) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 9.034297ms)
Feb 24 09:21:57.649: INFO: (12) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 11.181618ms)
Feb 24 09:21:57.650: INFO: (12) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 11.395322ms)
Feb 24 09:21:57.650: INFO: (12) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 12.00525ms)
Feb 24 09:21:57.651: INFO: (12) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 12.210899ms)
Feb 24 09:21:57.651: INFO: (12) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 12.284802ms)
Feb 24 09:21:57.651: INFO: (12) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 12.46284ms)
Feb 24 09:21:57.658: INFO: (13) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 7.181578ms)
Feb 24 09:21:57.659: INFO: (13) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 7.988675ms)
Feb 24 09:21:57.659: INFO: (13) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 7.96061ms)
Feb 24 09:21:57.660: INFO: (13) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 8.965757ms)
Feb 24 09:21:57.662: INFO: (13) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 11.231361ms)
Feb 24 09:21:57.662: INFO: (13) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 11.384031ms)
Feb 24 09:21:57.662: INFO: (13) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 11.382915ms)
Feb 24 09:21:57.662: INFO: (13) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 11.387626ms)
Feb 24 09:21:57.662: INFO: (13) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 11.52946ms)
Feb 24 09:21:57.662: INFO: (13) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 11.615446ms)
Feb 24 09:21:57.663: INFO: (13) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 11.632039ms)
Feb 24 09:21:57.663: INFO: (13) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 11.958339ms)
Feb 24 09:21:57.663: INFO: (13) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 11.961495ms)
Feb 24 09:21:57.663: INFO: (13) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 12.164456ms)
Feb 24 09:21:57.663: INFO: (13) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 12.664647ms)
Feb 24 09:21:57.664: INFO: (13) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 13.156999ms)
Feb 24 09:21:57.669: INFO: (14) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 5.101929ms)
Feb 24 09:21:57.675: INFO: (14) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 10.852937ms)
Feb 24 09:21:57.675: INFO: (14) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 10.809932ms)
Feb 24 09:21:57.675: INFO: (14) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 11.025444ms)
Feb 24 09:21:57.675: INFO: (14) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 11.359556ms)
Feb 24 09:21:57.676: INFO: (14) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 11.459557ms)
Feb 24 09:21:57.676: INFO: (14) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 12.069901ms)
Feb 24 09:21:57.676: INFO: (14) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 11.68477ms)
Feb 24 09:21:57.676: INFO: (14) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 11.70698ms)
Feb 24 09:21:57.677: INFO: (14) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 12.219655ms)
Feb 24 09:21:57.677: INFO: (14) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 12.672074ms)
Feb 24 09:21:57.677: INFO: (14) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 12.405569ms)
Feb 24 09:21:57.677: INFO: (14) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 13.260824ms)
Feb 24 09:21:57.677: INFO: (14) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 13.076755ms)
Feb 24 09:21:57.677: INFO: (14) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 13.058902ms)
Feb 24 09:21:57.677: INFO: (14) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 13.13432ms)
Feb 24 09:21:57.685: INFO: (15) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 7.390832ms)
Feb 24 09:21:57.685: INFO: (15) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 7.56669ms)
Feb 24 09:21:57.686: INFO: (15) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 8.158847ms)
Feb 24 09:21:57.686: INFO: (15) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 8.542135ms)
Feb 24 09:21:57.686: INFO: (15) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 8.939838ms)
Feb 24 09:21:57.687: INFO: (15) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 8.976998ms)
Feb 24 09:21:57.687: INFO: (15) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 8.866123ms)
Feb 24 09:21:57.687: INFO: (15) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 9.278455ms)
Feb 24 09:21:57.688: INFO: (15) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 9.858782ms)
Feb 24 09:21:57.688: INFO: (15) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 10.330915ms)
Feb 24 09:21:57.689: INFO: (15) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 11.596574ms)
Feb 24 09:21:57.690: INFO: (15) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 12.504298ms)
Feb 24 09:21:57.690: INFO: (15) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 12.515625ms)
Feb 24 09:21:57.690: INFO: (15) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 12.832629ms)
Feb 24 09:21:57.691: INFO: (15) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 13.244085ms)
Feb 24 09:21:57.691: INFO: (15) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 12.843186ms)
Feb 24 09:21:57.697: INFO: (16) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 5.598028ms)
Feb 24 09:21:57.697: INFO: (16) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 5.79899ms)
Feb 24 09:21:57.697: INFO: (16) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 5.767283ms)
Feb 24 09:21:57.697: INFO: (16) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 6.031397ms)
Feb 24 09:21:57.701: INFO: (16) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 10.070498ms)
Feb 24 09:21:57.701: INFO: (16) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 10.37094ms)
Feb 24 09:21:57.702: INFO: (16) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 10.760996ms)
Feb 24 09:21:57.702: INFO: (16) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 10.70124ms)
Feb 24 09:21:57.702: INFO: (16) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 10.806473ms)
Feb 24 09:21:57.703: INFO: (16) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 11.838363ms)
Feb 24 09:21:57.703: INFO: (16) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 11.814134ms)
Feb 24 09:21:57.703: INFO: (16) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 11.817476ms)
Feb 24 09:21:57.703: INFO: (16) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 12.214642ms)
Feb 24 09:21:57.703: INFO: (16) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 12.278173ms)
Feb 24 09:21:57.703: INFO: (16) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 12.198764ms)
Feb 24 09:21:57.703: INFO: (16) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 12.212663ms)
Feb 24 09:21:57.715: INFO: (17) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 11.380359ms)
Feb 24 09:21:57.715: INFO: (17) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 11.506685ms)
Feb 24 09:21:57.715: INFO: (17) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 11.650118ms)
Feb 24 09:21:57.716: INFO: (17) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 12.048603ms)
Feb 24 09:21:57.716: INFO: (17) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 12.322011ms)
Feb 24 09:21:57.716: INFO: (17) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 11.971239ms)
Feb 24 09:21:57.716: INFO: (17) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 12.193489ms)
Feb 24 09:21:57.716: INFO: (17) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 12.172495ms)
Feb 24 09:21:57.716: INFO: (17) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 12.451182ms)
Feb 24 09:21:57.716: INFO: (17) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 12.245731ms)
Feb 24 09:21:57.716: INFO: (17) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 12.682835ms)
Feb 24 09:21:57.716: INFO: (17) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 12.944771ms)
Feb 24 09:21:57.716: INFO: (17) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 12.756711ms)
Feb 24 09:21:57.717: INFO: (17) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 13.02244ms)
Feb 24 09:21:57.717: INFO: (17) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 13.347117ms)
Feb 24 09:21:57.717: INFO: (17) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 13.194265ms)
Feb 24 09:21:57.725: INFO: (18) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 7.690145ms)
Feb 24 09:21:57.726: INFO: (18) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 8.150673ms)
Feb 24 09:21:57.727: INFO: (18) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 10.178949ms)
Feb 24 09:21:57.727: INFO: (18) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 9.469855ms)
Feb 24 09:21:57.728: INFO: (18) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 10.888865ms)
Feb 24 09:21:57.729: INFO: (18) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 11.427809ms)
Feb 24 09:21:57.729: INFO: (18) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 11.469703ms)
Feb 24 09:21:57.729: INFO: (18) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 11.62945ms)
Feb 24 09:21:57.729: INFO: (18) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 11.670136ms)
Feb 24 09:21:57.729: INFO: (18) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 11.473736ms)
Feb 24 09:21:57.729: INFO: (18) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 12.15821ms)
Feb 24 09:21:57.729: INFO: (18) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 11.478658ms)
Feb 24 09:21:57.729: INFO: (18) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 11.71642ms)
Feb 24 09:21:57.729: INFO: (18) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 11.991651ms)
Feb 24 09:21:57.731: INFO: (18) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 13.973463ms)
Feb 24 09:21:57.732: INFO: (18) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 14.396787ms)
Feb 24 09:21:57.738: INFO: (19) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:160/proxy/: foo (200; 5.97222ms)
Feb 24 09:21:57.739: INFO: (19) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:1080/proxy/rewriteme">test<... (200; 7.403261ms)
Feb 24 09:21:57.740: INFO: (19) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:162/proxy/: bar (200; 7.37042ms)
Feb 24 09:21:57.740: INFO: (19) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname2/proxy/: tls qux (200; 7.829127ms)
Feb 24 09:21:57.741: INFO: (19) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m/proxy/rewriteme">test</a> (200; 8.872667ms)
Feb 24 09:21:57.741: INFO: (19) /api/v1/namespaces/proxy-6010/pods/proxy-service-n4949-fv55m:162/proxy/: bar (200; 8.889186ms)
Feb 24 09:21:57.742: INFO: (19) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:462/proxy/: tls qux (200; 9.694294ms)
Feb 24 09:21:57.742: INFO: (19) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:1080/proxy/rewriteme">... (200; 10.272739ms)
Feb 24 09:21:57.743: INFO: (19) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname1/proxy/: foo (200; 10.734524ms)
Feb 24 09:21:57.743: INFO: (19) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/: <a href="/api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:443/proxy/tlsrewritem... (200; 10.773339ms)
Feb 24 09:21:57.744: INFO: (19) /api/v1/namespaces/proxy-6010/pods/http:proxy-service-n4949-fv55m:160/proxy/: foo (200; 11.484123ms)
Feb 24 09:21:57.744: INFO: (19) /api/v1/namespaces/proxy-6010/pods/https:proxy-service-n4949-fv55m:460/proxy/: tls baz (200; 11.456549ms)
Feb 24 09:21:57.745: INFO: (19) /api/v1/namespaces/proxy-6010/services/https:proxy-service-n4949:tlsportname1/proxy/: tls baz (200; 12.481658ms)
Feb 24 09:21:57.745: INFO: (19) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname1/proxy/: foo (200; 12.607572ms)
Feb 24 09:21:57.745: INFO: (19) /api/v1/namespaces/proxy-6010/services/http:proxy-service-n4949:portname2/proxy/: bar (200; 12.983252ms)
Feb 24 09:21:57.746: INFO: (19) /api/v1/namespaces/proxy-6010/services/proxy-service-n4949:portname2/proxy/: bar (200; 13.876459ms)
STEP: deleting ReplicationController proxy-service-n4949 in namespace proxy-6010, will wait for the garbage collector to delete the pods
Feb 24 09:21:57.802: INFO: Deleting ReplicationController proxy-service-n4949 took: 4.127893ms
Feb 24 09:21:58.302: INFO: Terminating ReplicationController proxy-service-n4949 pods took: 500.184706ms
[AfterEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:22:03.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6010" for this suite.
Feb 24 09:22:09.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:22:09.481: INFO: namespace proxy-6010 deletion completed in 6.076069021s

• [SLOW TEST:16.130 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:22:09.481: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:22:15.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6806" for this suite.
Feb 24 09:22:21.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:22:21.652: INFO: namespace namespaces-6806 deletion completed in 6.080350441s
STEP: Destroying namespace "nsdeletetest-9336" for this suite.
Feb 24 09:22:21.654: INFO: Namespace nsdeletetest-9336 was already deleted
STEP: Destroying namespace "nsdeletetest-9821" for this suite.
Feb 24 09:22:27.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:22:27.740: INFO: namespace nsdeletetest-9821 deletion completed in 6.086331637s

• [SLOW TEST:18.259 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:22:27.742: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 24 09:22:30.778: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:22:30.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5057" for this suite.
Feb 24 09:22:36.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:22:36.869: INFO: namespace container-runtime-5057 deletion completed in 6.076534861s

• [SLOW TEST:9.127 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:22:36.869: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 24 09:22:36.944: INFO: Waiting up to 5m0s for pod "downward-api-40de7455-7378-43d3-aa6d-aa4d8e090737" in namespace "downward-api-9305" to be "success or failure"
Feb 24 09:22:36.946: INFO: Pod "downward-api-40de7455-7378-43d3-aa6d-aa4d8e090737": Phase="Pending", Reason="", readiness=false. Elapsed: 2.337951ms
Feb 24 09:22:38.948: INFO: Pod "downward-api-40de7455-7378-43d3-aa6d-aa4d8e090737": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004619s
Feb 24 09:22:40.950: INFO: Pod "downward-api-40de7455-7378-43d3-aa6d-aa4d8e090737": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006918495s
STEP: Saw pod success
Feb 24 09:22:40.951: INFO: Pod "downward-api-40de7455-7378-43d3-aa6d-aa4d8e090737" satisfied condition "success or failure"
Feb 24 09:22:40.952: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downward-api-40de7455-7378-43d3-aa6d-aa4d8e090737 container dapi-container: <nil>
STEP: delete the pod
Feb 24 09:22:40.972: INFO: Waiting for pod downward-api-40de7455-7378-43d3-aa6d-aa4d8e090737 to disappear
Feb 24 09:22:40.974: INFO: Pod downward-api-40de7455-7378-43d3-aa6d-aa4d8e090737 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:22:40.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9305" for this suite.
Feb 24 09:22:46.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:22:47.049: INFO: namespace downward-api-9305 deletion completed in 6.072176781s

• [SLOW TEST:10.180 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:22:47.049: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-f1408863-a738-4b5d-be19-6d516c4b26bd
STEP: Creating configMap with name cm-test-opt-upd-223282aa-292d-4e3b-8905-489c9b0e8f8c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f1408863-a738-4b5d-be19-6d516c4b26bd
STEP: Updating configmap cm-test-opt-upd-223282aa-292d-4e3b-8905-489c9b0e8f8c
STEP: Creating configMap with name cm-test-opt-create-41eaf684-5fb2-40ea-94e6-a3a806dbfd9e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:24:11.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9735" for this suite.
Feb 24 09:24:39.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:24:39.450: INFO: namespace configmap-9735 deletion completed in 28.07203631s

• [SLOW TEST:112.401 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:24:39.450: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:24:39.470: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:24:40.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1482" for this suite.
Feb 24 09:24:46.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:24:46.569: INFO: namespace custom-resource-definition-1482 deletion completed in 6.076825458s

• [SLOW TEST:7.119 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:24:46.570: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 24 09:24:48.604: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:24:48.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3831" for this suite.
Feb 24 09:24:54.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:24:54.692: INFO: namespace container-runtime-3831 deletion completed in 6.073780073s

• [SLOW TEST:8.123 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:24:54.693: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 24 09:24:54.768: INFO: Waiting up to 5m0s for pod "pod-9b557195-be20-4ed5-82d3-361147bedca8" in namespace "emptydir-6578" to be "success or failure"
Feb 24 09:24:54.772: INFO: Pod "pod-9b557195-be20-4ed5-82d3-361147bedca8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.502354ms
Feb 24 09:24:56.775: INFO: Pod "pod-9b557195-be20-4ed5-82d3-361147bedca8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006216767s
Feb 24 09:24:58.777: INFO: Pod "pod-9b557195-be20-4ed5-82d3-361147bedca8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00829425s
STEP: Saw pod success
Feb 24 09:24:58.777: INFO: Pod "pod-9b557195-be20-4ed5-82d3-361147bedca8" satisfied condition "success or failure"
Feb 24 09:24:58.779: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-9b557195-be20-4ed5-82d3-361147bedca8 container test-container: <nil>
STEP: delete the pod
Feb 24 09:24:58.795: INFO: Waiting for pod pod-9b557195-be20-4ed5-82d3-361147bedca8 to disappear
Feb 24 09:24:58.798: INFO: Pod pod-9b557195-be20-4ed5-82d3-361147bedca8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:24:58.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6578" for this suite.
Feb 24 09:25:04.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:25:04.920: INFO: namespace emptydir-6578 deletion completed in 6.120319615s

• [SLOW TEST:10.228 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:25:04.920: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8360.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8360.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8360.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8360.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8360.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8360.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 09:25:06.967: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:06.969: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:06.971: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:06.973: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:06.978: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:06.980: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:06.982: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:06.983: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:06.987: INFO: Lookups using dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local]

Feb 24 09:25:11.989: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:11.991: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:11.993: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:12.002: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:12.008: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:12.010: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:12.012: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:12.014: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:12.018: INFO: Lookups using dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local]

Feb 24 09:25:16.989: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:16.992: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:16.994: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:16.995: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:17.001: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:17.003: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:17.004: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:17.006: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:17.010: INFO: Lookups using dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local]

Feb 24 09:25:21.989: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:21.992: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:21.994: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:21.996: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:22.001: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:22.003: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:22.005: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:22.006: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:22.010: INFO: Lookups using dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local]

Feb 24 09:25:26.990: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:26.992: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:26.994: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:26.997: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:27.002: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:27.004: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:27.006: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:27.008: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:27.011: INFO: Lookups using dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local]

Feb 24 09:25:31.990: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:31.995: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:31.997: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:32.002: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:32.019: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:32.022: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:32.024: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:32.026: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:32.030: INFO: Lookups using dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8360.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local]

Feb 24 09:25:37.006: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:37.008: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:37.009: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:37.011: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local from pod dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197: the server could not find the requested resource (get pods dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197)
Feb 24 09:25:37.014: INFO: Lookups using dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197 failed for: [jessie_udp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8360.svc.cluster.local jessie_udp@dns-test-service-2.dns-8360.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8360.svc.cluster.local]

Feb 24 09:25:42.008: INFO: DNS probes using dns-8360/dns-test-6364fa44-8ce2-4145-8a5b-80bb17624197 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:25:42.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8360" for this suite.
Feb 24 09:25:48.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:25:48.136: INFO: namespace dns-8360 deletion completed in 6.083116851s

• [SLOW TEST:43.216 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:25:48.136: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 24 09:25:50.678: INFO: Successfully updated pod "pod-update-activedeadlineseconds-72f02937-c267-4153-b8ad-ead591194a6f"
Feb 24 09:25:50.678: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-72f02937-c267-4153-b8ad-ead591194a6f" in namespace "pods-1435" to be "terminated due to deadline exceeded"
Feb 24 09:25:50.680: INFO: Pod "pod-update-activedeadlineseconds-72f02937-c267-4153-b8ad-ead591194a6f": Phase="Running", Reason="", readiness=true. Elapsed: 1.659513ms
Feb 24 09:25:52.682: INFO: Pod "pod-update-activedeadlineseconds-72f02937-c267-4153-b8ad-ead591194a6f": Phase="Running", Reason="", readiness=true. Elapsed: 2.003935254s
Feb 24 09:25:54.684: INFO: Pod "pod-update-activedeadlineseconds-72f02937-c267-4153-b8ad-ead591194a6f": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.00604755s
Feb 24 09:25:54.684: INFO: Pod "pod-update-activedeadlineseconds-72f02937-c267-4153-b8ad-ead591194a6f" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:25:54.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1435" for this suite.
Feb 24 09:26:00.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:26:00.771: INFO: namespace pods-1435 deletion completed in 6.08394772s

• [SLOW TEST:12.634 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:26:00.771: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Feb 24 09:26:00.795: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 24 09:26:00.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-8202'
Feb 24 09:26:01.146: INFO: stderr: ""
Feb 24 09:26:01.146: INFO: stdout: "service/redis-slave created\n"
Feb 24 09:26:01.146: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 24 09:26:01.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-8202'
Feb 24 09:26:01.305: INFO: stderr: ""
Feb 24 09:26:01.306: INFO: stdout: "service/redis-master created\n"
Feb 24 09:26:01.306: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 24 09:26:01.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-8202'
Feb 24 09:26:01.473: INFO: stderr: ""
Feb 24 09:26:01.473: INFO: stdout: "service/frontend created\n"
Feb 24 09:26:01.473: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 24 09:26:01.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-8202'
Feb 24 09:26:01.629: INFO: stderr: ""
Feb 24 09:26:01.629: INFO: stdout: "deployment.apps/frontend created\n"
Feb 24 09:26:01.629: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 24 09:26:01.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-8202'
Feb 24 09:26:01.773: INFO: stderr: ""
Feb 24 09:26:01.773: INFO: stdout: "deployment.apps/redis-master created\n"
Feb 24 09:26:01.773: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 24 09:26:01.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-8202'
Feb 24 09:26:01.915: INFO: stderr: ""
Feb 24 09:26:01.915: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Feb 24 09:26:01.915: INFO: Waiting for all frontend pods to be Running.
Feb 24 09:26:16.966: INFO: Waiting for frontend to serve content.
Feb 24 09:26:16.975: INFO: Trying to add a new entry to the guestbook.
Feb 24 09:26:16.984: INFO: Verifying that added entry can be retrieved.
Feb 24 09:26:16.991: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Feb 24 09:26:22.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete --grace-period=0 --force -f - --namespace=kubectl-8202'
Feb 24 09:26:22.076: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 09:26:22.076: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 24 09:26:22.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete --grace-period=0 --force -f - --namespace=kubectl-8202'
Feb 24 09:26:22.168: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 09:26:22.168: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 24 09:26:22.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete --grace-period=0 --force -f - --namespace=kubectl-8202'
Feb 24 09:26:22.274: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 09:26:22.274: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 24 09:26:22.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete --grace-period=0 --force -f - --namespace=kubectl-8202'
Feb 24 09:26:22.343: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 09:26:22.343: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 24 09:26:22.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete --grace-period=0 --force -f - --namespace=kubectl-8202'
Feb 24 09:26:22.404: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 09:26:22.404: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 24 09:26:22.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete --grace-period=0 --force -f - --namespace=kubectl-8202'
Feb 24 09:26:22.463: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 09:26:22.463: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:26:22.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8202" for this suite.
Feb 24 09:26:50.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:26:50.554: INFO: namespace kubectl-8202 deletion completed in 28.08837947s

• [SLOW TEST:49.784 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:26:50.555: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:26:50.843: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:26:52.850: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718133210, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718133210, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718133210, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718133210, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:26:55.861: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:26:55.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3915" for this suite.
Feb 24 09:27:01.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:27:02.064: INFO: namespace webhook-3915 deletion completed in 6.077059707s
STEP: Destroying namespace "webhook-3915-markers" for this suite.
Feb 24 09:27:08.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:27:08.140: INFO: namespace webhook-3915-markers deletion completed in 6.075843851s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.593 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:27:08.148: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:27:08.169: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:27:08.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3219" for this suite.
Feb 24 09:27:14.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:27:14.299: INFO: namespace custom-resource-definition-3219 deletion completed in 6.093458354s

• [SLOW TEST:6.152 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:27:14.299: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-6410, will wait for the garbage collector to delete the pods
Feb 24 09:27:18.378: INFO: Deleting Job.batch foo took: 3.597947ms
Feb 24 09:27:18.478: INFO: Terminating Job.batch foo pods took: 100.157151ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:28:03.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6410" for this suite.
Feb 24 09:28:09.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:28:09.470: INFO: namespace job-6410 deletion completed in 6.086814996s

• [SLOW TEST:55.170 seconds]
[sig-apps] Job
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:28:09.470: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:28:09.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-8073'
Feb 24 09:28:09.643: INFO: stderr: ""
Feb 24 09:28:09.643: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 24 09:28:09.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-8073'
Feb 24 09:28:09.789: INFO: stderr: ""
Feb 24 09:28:09.789: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 24 09:28:10.791: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 09:28:10.791: INFO: Found 0 / 1
Feb 24 09:28:11.791: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 09:28:11.791: INFO: Found 1 / 1
Feb 24 09:28:11.791: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 24 09:28:11.793: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 09:28:11.793: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 24 09:28:11.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 describe pod redis-master-gfwck --namespace=kubectl-8073'
Feb 24 09:28:11.864: INFO: stderr: ""
Feb 24 09:28:11.864: INFO: stdout: "Name:         redis-master-gfwck\nNamespace:    kubectl-8073\nPriority:     0\nNode:         ip-10-100-10-76.eu-west-1.compute.internal/10.100.10.76\nStart Time:   Mon, 24 Feb 2020 09:28:09 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 172.16.14.195/32\nStatus:       Running\nIP:           172.16.14.195\nIPs:\n  IP:           172.16.14.195\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://e292196da097a8fbf69931964d41db743d431cda1145b857477ae07790916a8f\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 24 Feb 2020 09:28:11 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-npq7j (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-npq7j:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-npq7j\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                 Message\n  ----    ------     ----  ----                                                 -------\n  Normal  Scheduled  2s    default-scheduler                                    Successfully assigned kubectl-8073/redis-master-gfwck to ip-10-100-10-76.eu-west-1.compute.internal\n  Normal  Pulled     1s    kubelet, ip-10-100-10-76.eu-west-1.compute.internal  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s    kubelet, ip-10-100-10-76.eu-west-1.compute.internal  Created container redis-master\n  Normal  Started    0s    kubelet, ip-10-100-10-76.eu-west-1.compute.internal  Started container redis-master\n"
Feb 24 09:28:11.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 describe rc redis-master --namespace=kubectl-8073'
Feb 24 09:28:11.938: INFO: stderr: ""
Feb 24 09:28:11.938: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8073\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-gfwck\n"
Feb 24 09:28:11.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 describe service redis-master --namespace=kubectl-8073'
Feb 24 09:28:12.003: INFO: stderr: ""
Feb 24 09:28:12.003: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8073\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.111.71.97\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.16.14.195:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 24 09:28:12.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 describe node ip-10-100-0-248.eu-west-1.compute.internal'
Feb 24 09:28:12.086: INFO: stderr: ""
Feb 24 09:28:12.086: INFO: stdout: "Name:               ip-10-100-0-248.eu-west-1.compute.internal\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-100-0-248.eu-west-1.compute.internal\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.100.0.248/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.16.252.128\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 24 Feb 2020 08:25:22 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 24 Feb 2020 08:33:05 +0000   Mon, 24 Feb 2020 08:33:05 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Mon, 24 Feb 2020 09:27:57 +0000   Mon, 24 Feb 2020 08:25:18 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 24 Feb 2020 09:27:57 +0000   Mon, 24 Feb 2020 08:25:18 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 24 Feb 2020 09:27:57 +0000   Mon, 24 Feb 2020 08:25:18 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 24 Feb 2020 09:27:57 +0000   Mon, 24 Feb 2020 08:33:14 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.100.0.248\n  Hostname:    ip-10-100-0-248.eu-west-1.compute.internal\nCapacity:\n cpu:                2\n ephemeral-storage:  101583780Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7865432Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  93619611493\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7763032Ki\n pods:               110\nSystem Info:\n Machine ID:                 ec219a3a03b3760f7fc07df5885c0d9d\n System UUID:                EC219A3A-03B3-760F-7FC0-7DF5885C0D9D\n Boot ID:                    b0a16170-8897-4375-82af-756879ed6b23\n Kernel Version:             4.15.0-1058-aws\n OS Image:                   Ubuntu 18.04.4 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://19.3.6\n Kubelet Version:            v1.16.2\n Kube-Proxy Version:         v1.16.2\nPodCIDR:                     172.16.0.0/24\nPodCIDRs:                    172.16.0.0/24\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                                  CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                                  ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-c4k79                                                     250m (12%)    0 (0%)      0 (0%)           0 (0%)         55m\n  kube-system                etcd-ip-10-100-0-248.eu-west-1.compute.internal                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         61m\n  kube-system                kube-apiserver-ip-10-100-0-248.eu-west-1.compute.internal             250m (12%)    0 (0%)      0 (0%)           0 (0%)         61m\n  kube-system                kube-controller-manager-ip-10-100-0-248.eu-west-1.compute.internal    200m (10%)    0 (0%)      0 (0%)           0 (0%)         61m\n  kube-system                kube-proxy-hq2z6                                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         62m\n  kube-system                kube-scheduler-ip-10-100-0-248.eu-west-1.compute.internal             100m (5%)     0 (0%)      0 (0%)           0 (0%)         61m\n  logging                    fluentd-7k2gk                                                         300m (15%)    1 (50%)     400Mi (5%)       400Mi (5%)     55m\n  monitoring                 goldpinger-8hmbg                                                      1m (0%)       0 (0%)      40Mi (0%)        80Mi (1%)      55m\n  monitoring                 node-exporter-99wk6                                                   102m (5%)     102m (5%)   180Mi (2%)       180Mi (2%)     55m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-s5r96               0 (0%)        0 (0%)      0 (0%)           0 (0%)         50m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                1203m (60%)  1102m (55%)\n  memory             620Mi (8%)   660Mi (8%)\n  ephemeral-storage  0 (0%)       0 (0%)\nEvents:\n  Type    Reason     Age   From                                                 Message\n  ----    ------     ----  ----                                                 -------\n  Normal  NodeReady  54m   kubelet, ip-10-100-0-248.eu-west-1.compute.internal  Node ip-10-100-0-248.eu-west-1.compute.internal status is now: NodeReady\n"
Feb 24 09:28:12.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 describe namespace kubectl-8073'
Feb 24 09:28:12.150: INFO: stderr: ""
Feb 24 09:28:12.150: INFO: stdout: "Name:         kubectl-8073\nLabels:       e2e-framework=kubectl\n              e2e-run=2daddc70-04b7-4f43-afab-fae069a8d13b\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:28:12.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8073" for this suite.
Feb 24 09:28:24.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:28:24.226: INFO: namespace kubectl-8073 deletion completed in 12.073824276s

• [SLOW TEST:14.757 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:28:24.226: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:28:24.251: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba8502bf-9eaa-43ef-b3dc-f5857cd919b0" in namespace "downward-api-9656" to be "success or failure"
Feb 24 09:28:24.259: INFO: Pod "downwardapi-volume-ba8502bf-9eaa-43ef-b3dc-f5857cd919b0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.003051ms
Feb 24 09:28:26.261: INFO: Pod "downwardapi-volume-ba8502bf-9eaa-43ef-b3dc-f5857cd919b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010386446s
STEP: Saw pod success
Feb 24 09:28:26.261: INFO: Pod "downwardapi-volume-ba8502bf-9eaa-43ef-b3dc-f5857cd919b0" satisfied condition "success or failure"
Feb 24 09:28:26.263: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-ba8502bf-9eaa-43ef-b3dc-f5857cd919b0 container client-container: <nil>
STEP: delete the pod
Feb 24 09:28:26.291: INFO: Waiting for pod downwardapi-volume-ba8502bf-9eaa-43ef-b3dc-f5857cd919b0 to disappear
Feb 24 09:28:26.293: INFO: Pod downwardapi-volume-ba8502bf-9eaa-43ef-b3dc-f5857cd919b0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:28:26.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9656" for this suite.
Feb 24 09:28:32.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:28:32.371: INFO: namespace downward-api-9656 deletion completed in 6.07517189s

• [SLOW TEST:8.144 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:28:32.371: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:28:35.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-899" for this suite.
Feb 24 09:29:03.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:29:03.486: INFO: namespace replication-controller-899 deletion completed in 28.072314412s

• [SLOW TEST:31.115 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:29:03.486: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:29:07.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1749" for this suite.
Feb 24 09:29:13.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:29:13.628: INFO: namespace emptydir-wrapper-1749 deletion completed in 6.078926877s

• [SLOW TEST:10.143 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:29:13.629: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 24 09:29:18.184: INFO: Successfully updated pod "annotationupdate10a19d42-450f-4a49-a3c4-db4a5c05bf75"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:29:20.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6762" for this suite.
Feb 24 09:29:36.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:29:36.281: INFO: namespace projected-6762 deletion completed in 16.078349135s

• [SLOW TEST:22.653 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:29:36.281: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-780
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-780 to expose endpoints map[]
Feb 24 09:29:36.315: INFO: Get endpoints failed (6.231874ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 24 09:29:37.317: INFO: successfully validated that service endpoint-test2 in namespace services-780 exposes endpoints map[] (1.008242554s elapsed)
STEP: Creating pod pod1 in namespace services-780
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-780 to expose endpoints map[pod1:[80]]
Feb 24 09:29:39.336: INFO: successfully validated that service endpoint-test2 in namespace services-780 exposes endpoints map[pod1:[80]] (2.014074081s elapsed)
STEP: Creating pod pod2 in namespace services-780
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-780 to expose endpoints map[pod1:[80] pod2:[80]]
Feb 24 09:29:42.366: INFO: successfully validated that service endpoint-test2 in namespace services-780 exposes endpoints map[pod1:[80] pod2:[80]] (3.025057385s elapsed)
STEP: Deleting pod pod1 in namespace services-780
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-780 to expose endpoints map[pod2:[80]]
Feb 24 09:29:42.382: INFO: successfully validated that service endpoint-test2 in namespace services-780 exposes endpoints map[pod2:[80]] (11.337534ms elapsed)
STEP: Deleting pod pod2 in namespace services-780
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-780 to expose endpoints map[]
Feb 24 09:29:43.395: INFO: successfully validated that service endpoint-test2 in namespace services-780 exposes endpoints map[] (1.004968027s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:29:43.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-780" for this suite.
Feb 24 09:29:55.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:29:55.489: INFO: namespace services-780 deletion completed in 12.074757012s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.207 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:29:55.489: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:29:55.822: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:29:57.827: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718133395, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718133395, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718133395, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718133395, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:30:00.837: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Feb 24 09:30:00.849: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:30:00.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2754" for this suite.
Feb 24 09:30:06.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:30:06.939: INFO: namespace webhook-2754 deletion completed in 6.078879578s
STEP: Destroying namespace "webhook-2754-markers" for this suite.
Feb 24 09:30:12.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:30:13.015: INFO: namespace webhook-2754-markers deletion completed in 6.075618166s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.533 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:30:13.022: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:30:13.091: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 24 09:30:16.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-8423 create -f -'
Feb 24 09:30:16.410: INFO: stderr: ""
Feb 24 09:30:16.410: INFO: stdout: "e2e-test-crd-publish-openapi-7325-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 24 09:30:16.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-8423 delete e2e-test-crd-publish-openapi-7325-crds test-cr'
Feb 24 09:30:16.471: INFO: stderr: ""
Feb 24 09:30:16.471: INFO: stdout: "e2e-test-crd-publish-openapi-7325-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Feb 24 09:30:16.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-8423 apply -f -'
Feb 24 09:30:16.611: INFO: stderr: ""
Feb 24 09:30:16.611: INFO: stdout: "e2e-test-crd-publish-openapi-7325-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 24 09:30:16.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-8423 delete e2e-test-crd-publish-openapi-7325-crds test-cr'
Feb 24 09:30:16.671: INFO: stderr: ""
Feb 24 09:30:16.671: INFO: stdout: "e2e-test-crd-publish-openapi-7325-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Feb 24 09:30:16.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 explain e2e-test-crd-publish-openapi-7325-crds'
Feb 24 09:30:16.806: INFO: stderr: ""
Feb 24 09:30:16.806: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7325-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:30:19.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8423" for this suite.
Feb 24 09:30:25.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:30:25.797: INFO: namespace crd-publish-openapi-8423 deletion completed in 6.077881862s

• [SLOW TEST:12.775 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:30:25.797: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-e7c1bc67-46da-4b35-974f-ab38f27654e3
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-e7c1bc67-46da-4b35-974f-ab38f27654e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:31:38.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7071" for this suite.
Feb 24 09:31:56.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:31:56.163: INFO: namespace projected-7071 deletion completed in 18.096913108s

• [SLOW TEST:90.366 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:31:56.164: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 24 09:31:56.187: INFO: Waiting up to 5m0s for pod "pod-1abc072d-027c-49d9-bbe2-22e99e018654" in namespace "emptydir-4958" to be "success or failure"
Feb 24 09:31:56.191: INFO: Pod "pod-1abc072d-027c-49d9-bbe2-22e99e018654": Phase="Pending", Reason="", readiness=false. Elapsed: 3.96958ms
Feb 24 09:31:58.194: INFO: Pod "pod-1abc072d-027c-49d9-bbe2-22e99e018654": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006106207s
Feb 24 09:32:00.196: INFO: Pod "pod-1abc072d-027c-49d9-bbe2-22e99e018654": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008207244s
STEP: Saw pod success
Feb 24 09:32:00.196: INFO: Pod "pod-1abc072d-027c-49d9-bbe2-22e99e018654" satisfied condition "success or failure"
Feb 24 09:32:00.197: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-1abc072d-027c-49d9-bbe2-22e99e018654 container test-container: <nil>
STEP: delete the pod
Feb 24 09:32:00.210: INFO: Waiting for pod pod-1abc072d-027c-49d9-bbe2-22e99e018654 to disappear
Feb 24 09:32:00.213: INFO: Pod pod-1abc072d-027c-49d9-bbe2-22e99e018654 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:32:00.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4958" for this suite.
Feb 24 09:32:06.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:32:06.307: INFO: namespace emptydir-4958 deletion completed in 6.091988486s

• [SLOW TEST:10.143 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:32:06.308: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 09:32:06.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-1260'
Feb 24 09:32:06.392: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 24 09:32:06.392: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Feb 24 09:32:08.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete deployment e2e-test-httpd-deployment --namespace=kubectl-1260'
Feb 24 09:32:08.481: INFO: stderr: ""
Feb 24 09:32:08.481: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:32:08.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1260" for this suite.
Feb 24 09:32:36.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:32:36.556: INFO: namespace kubectl-1260 deletion completed in 28.072121997s

• [SLOW TEST:30.248 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:32:36.556: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:33:03.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5592" for this suite.
Feb 24 09:33:09.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:33:09.846: INFO: namespace container-runtime-5592 deletion completed in 6.079946331s

• [SLOW TEST:33.290 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:33:09.846: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5370
I0224 09:33:09.868354      21 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5370, replica count: 1
I0224 09:33:10.918736      21 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0224 09:33:11.918934      21 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0224 09:33:12.919099      21 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 24 09:33:13.029: INFO: Created: latency-svc-xzgf2
Feb 24 09:33:13.031: INFO: Got endpoints: latency-svc-xzgf2 [11.754763ms]
Feb 24 09:33:13.052: INFO: Created: latency-svc-fndfg
Feb 24 09:33:13.059: INFO: Got endpoints: latency-svc-fndfg [27.704717ms]
Feb 24 09:33:13.066: INFO: Created: latency-svc-67ls8
Feb 24 09:33:13.074: INFO: Created: latency-svc-cspl2
Feb 24 09:33:13.077: INFO: Got endpoints: latency-svc-67ls8 [46.070143ms]
Feb 24 09:33:13.086: INFO: Got endpoints: latency-svc-cspl2 [55.100884ms]
Feb 24 09:33:13.086: INFO: Created: latency-svc-q7zg7
Feb 24 09:33:13.091: INFO: Got endpoints: latency-svc-q7zg7 [59.575317ms]
Feb 24 09:33:13.097: INFO: Created: latency-svc-j24bj
Feb 24 09:33:13.105: INFO: Got endpoints: latency-svc-j24bj [73.681075ms]
Feb 24 09:33:13.111: INFO: Created: latency-svc-rbd4n
Feb 24 09:33:13.115: INFO: Got endpoints: latency-svc-rbd4n [83.840959ms]
Feb 24 09:33:13.129: INFO: Created: latency-svc-z97jm
Feb 24 09:33:13.130: INFO: Got endpoints: latency-svc-z97jm [25.072745ms]
Feb 24 09:33:13.142: INFO: Created: latency-svc-7gg42
Feb 24 09:33:13.143: INFO: Got endpoints: latency-svc-7gg42 [112.277724ms]
Feb 24 09:33:13.160: INFO: Created: latency-svc-rgbjk
Feb 24 09:33:13.165: INFO: Got endpoints: latency-svc-rgbjk [134.037525ms]
Feb 24 09:33:13.169: INFO: Created: latency-svc-5879k
Feb 24 09:33:13.171: INFO: Got endpoints: latency-svc-5879k [140.098379ms]
Feb 24 09:33:13.186: INFO: Created: latency-svc-gzhtv
Feb 24 09:33:13.191: INFO: Got endpoints: latency-svc-gzhtv [159.204826ms]
Feb 24 09:33:13.208: INFO: Created: latency-svc-6xr95
Feb 24 09:33:13.208: INFO: Got endpoints: latency-svc-6xr95 [176.756955ms]
Feb 24 09:33:13.241: INFO: Created: latency-svc-rdcmt
Feb 24 09:33:13.246: INFO: Got endpoints: latency-svc-rdcmt [214.894485ms]
Feb 24 09:33:13.269: INFO: Created: latency-svc-mz59c
Feb 24 09:33:13.278: INFO: Got endpoints: latency-svc-mz59c [246.661444ms]
Feb 24 09:33:13.280: INFO: Created: latency-svc-dmjkl
Feb 24 09:33:13.289: INFO: Got endpoints: latency-svc-dmjkl [257.452898ms]
Feb 24 09:33:13.297: INFO: Created: latency-svc-vl9lq
Feb 24 09:33:13.299: INFO: Got endpoints: latency-svc-vl9lq [267.510169ms]
Feb 24 09:33:13.311: INFO: Created: latency-svc-jsm4m
Feb 24 09:33:13.315: INFO: Got endpoints: latency-svc-jsm4m [255.501425ms]
Feb 24 09:33:13.327: INFO: Created: latency-svc-s2vrj
Feb 24 09:33:13.335: INFO: Got endpoints: latency-svc-s2vrj [257.540901ms]
Feb 24 09:33:13.336: INFO: Created: latency-svc-bf4dk
Feb 24 09:33:13.343: INFO: Got endpoints: latency-svc-bf4dk [256.508951ms]
Feb 24 09:33:13.355: INFO: Created: latency-svc-kjht4
Feb 24 09:33:13.361: INFO: Got endpoints: latency-svc-kjht4 [270.311158ms]
Feb 24 09:33:13.365: INFO: Created: latency-svc-skcpx
Feb 24 09:33:13.368: INFO: Got endpoints: latency-svc-skcpx [252.28087ms]
Feb 24 09:33:13.378: INFO: Created: latency-svc-t8bnr
Feb 24 09:33:13.384: INFO: Got endpoints: latency-svc-t8bnr [254.115455ms]
Feb 24 09:33:13.402: INFO: Created: latency-svc-5jmhn
Feb 24 09:33:13.406: INFO: Got endpoints: latency-svc-5jmhn [262.702633ms]
Feb 24 09:33:13.414: INFO: Created: latency-svc-mstwt
Feb 24 09:33:13.416: INFO: Got endpoints: latency-svc-mstwt [250.154382ms]
Feb 24 09:33:13.429: INFO: Created: latency-svc-v7tc2
Feb 24 09:33:13.433: INFO: Got endpoints: latency-svc-v7tc2 [262.0239ms]
Feb 24 09:33:13.438: INFO: Created: latency-svc-54m2q
Feb 24 09:33:13.440: INFO: Got endpoints: latency-svc-54m2q [249.825133ms]
Feb 24 09:33:13.457: INFO: Created: latency-svc-mwwk4
Feb 24 09:33:13.460: INFO: Got endpoints: latency-svc-mwwk4 [252.355519ms]
Feb 24 09:33:13.470: INFO: Created: latency-svc-bjbtt
Feb 24 09:33:13.475: INFO: Got endpoints: latency-svc-bjbtt [228.399389ms]
Feb 24 09:33:13.482: INFO: Created: latency-svc-lctnl
Feb 24 09:33:13.484: INFO: Got endpoints: latency-svc-lctnl [206.192805ms]
Feb 24 09:33:13.518: INFO: Created: latency-svc-4mdkv
Feb 24 09:33:13.519: INFO: Created: latency-svc-zmzns
Feb 24 09:33:13.542: INFO: Got endpoints: latency-svc-4mdkv [252.751163ms]
Feb 24 09:33:13.549: INFO: Got endpoints: latency-svc-zmzns [250.541458ms]
Feb 24 09:33:13.552: INFO: Created: latency-svc-lmqjg
Feb 24 09:33:13.560: INFO: Got endpoints: latency-svc-lmqjg [245.474313ms]
Feb 24 09:33:13.566: INFO: Created: latency-svc-lqrpq
Feb 24 09:33:13.566: INFO: Got endpoints: latency-svc-lqrpq [230.805722ms]
Feb 24 09:33:13.585: INFO: Created: latency-svc-8tv7v
Feb 24 09:33:13.585: INFO: Got endpoints: latency-svc-8tv7v [242.198564ms]
Feb 24 09:33:13.607: INFO: Created: latency-svc-tkxc8
Feb 24 09:33:13.608: INFO: Created: latency-svc-nwkhg
Feb 24 09:33:13.614: INFO: Got endpoints: latency-svc-tkxc8 [252.364178ms]
Feb 24 09:33:13.618: INFO: Got endpoints: latency-svc-nwkhg [250.476619ms]
Feb 24 09:33:13.626: INFO: Created: latency-svc-5zpf9
Feb 24 09:33:13.630: INFO: Got endpoints: latency-svc-5zpf9 [245.139689ms]
Feb 24 09:33:13.677: INFO: Created: latency-svc-75bbw
Feb 24 09:33:13.686: INFO: Got endpoints: latency-svc-75bbw [279.983292ms]
Feb 24 09:33:13.691: INFO: Created: latency-svc-f6n6g
Feb 24 09:33:13.691: INFO: Got endpoints: latency-svc-f6n6g [275.665086ms]
Feb 24 09:33:13.707: INFO: Created: latency-svc-mc595
Feb 24 09:33:13.707: INFO: Got endpoints: latency-svc-mc595 [273.375623ms]
Feb 24 09:33:13.719: INFO: Created: latency-svc-qsmc8
Feb 24 09:33:13.719: INFO: Got endpoints: latency-svc-qsmc8 [278.216072ms]
Feb 24 09:33:13.723: INFO: Created: latency-svc-q5pjz
Feb 24 09:33:13.725: INFO: Got endpoints: latency-svc-q5pjz [265.19398ms]
Feb 24 09:33:13.738: INFO: Created: latency-svc-6vtnq
Feb 24 09:33:13.738: INFO: Got endpoints: latency-svc-6vtnq [263.785876ms]
Feb 24 09:33:13.748: INFO: Created: latency-svc-gzrkm
Feb 24 09:33:13.761: INFO: Created: latency-svc-wqcnd
Feb 24 09:33:13.764: INFO: Created: latency-svc-w2ls6
Feb 24 09:33:13.773: INFO: Created: latency-svc-dgnfw
Feb 24 09:33:13.784: INFO: Got endpoints: latency-svc-gzrkm [299.887727ms]
Feb 24 09:33:13.789: INFO: Created: latency-svc-s4bhx
Feb 24 09:33:13.807: INFO: Created: latency-svc-5kp6n
Feb 24 09:33:13.843: INFO: Created: latency-svc-m7s59
Feb 24 09:33:13.852: INFO: Got endpoints: latency-svc-wqcnd [310.219468ms]
Feb 24 09:33:13.870: INFO: Created: latency-svc-h2bpk
Feb 24 09:33:13.881: INFO: Got endpoints: latency-svc-w2ls6 [331.81664ms]
Feb 24 09:33:13.904: INFO: Created: latency-svc-dzh4x
Feb 24 09:33:13.918: INFO: Created: latency-svc-pnxrp
Feb 24 09:33:13.931: INFO: Created: latency-svc-nx7s4
Feb 24 09:33:13.934: INFO: Got endpoints: latency-svc-dgnfw [374.05427ms]
Feb 24 09:33:13.945: INFO: Created: latency-svc-dmfm6
Feb 24 09:33:13.955: INFO: Created: latency-svc-8bxjl
Feb 24 09:33:13.968: INFO: Created: latency-svc-xqp8p
Feb 24 09:33:13.982: INFO: Got endpoints: latency-svc-s4bhx [416.28524ms]
Feb 24 09:33:13.984: INFO: Created: latency-svc-pp6zh
Feb 24 09:33:13.995: INFO: Created: latency-svc-pzwck
Feb 24 09:33:14.042: INFO: Created: latency-svc-8p77z
Feb 24 09:33:14.047: INFO: Got endpoints: latency-svc-5kp6n [461.749425ms]
Feb 24 09:33:14.085: INFO: Created: latency-svc-t7pkh
Feb 24 09:33:14.087: INFO: Got endpoints: latency-svc-m7s59 [473.119166ms]
Feb 24 09:33:14.100: INFO: Created: latency-svc-sqnxg
Feb 24 09:33:14.111: INFO: Created: latency-svc-zznd2
Feb 24 09:33:14.121: INFO: Created: latency-svc-5s2j6
Feb 24 09:33:14.132: INFO: Got endpoints: latency-svc-h2bpk [513.480883ms]
Feb 24 09:33:14.137: INFO: Created: latency-svc-zw22h
Feb 24 09:33:14.152: INFO: Created: latency-svc-kx48p
Feb 24 09:33:14.181: INFO: Got endpoints: latency-svc-dzh4x [551.731759ms]
Feb 24 09:33:14.192: INFO: Created: latency-svc-bbk95
Feb 24 09:33:14.231: INFO: Got endpoints: latency-svc-pnxrp [544.673367ms]
Feb 24 09:33:14.243: INFO: Created: latency-svc-7ns8t
Feb 24 09:33:14.281: INFO: Got endpoints: latency-svc-nx7s4 [589.18324ms]
Feb 24 09:33:14.297: INFO: Created: latency-svc-l6bh4
Feb 24 09:33:14.331: INFO: Got endpoints: latency-svc-dmfm6 [623.874313ms]
Feb 24 09:33:14.346: INFO: Created: latency-svc-vdnth
Feb 24 09:33:14.380: INFO: Got endpoints: latency-svc-8bxjl [661.427234ms]
Feb 24 09:33:14.431: INFO: Created: latency-svc-hqbc6
Feb 24 09:33:14.437: INFO: Got endpoints: latency-svc-xqp8p [711.307127ms]
Feb 24 09:33:14.451: INFO: Created: latency-svc-n6prz
Feb 24 09:33:14.480: INFO: Got endpoints: latency-svc-pp6zh [741.53805ms]
Feb 24 09:33:14.556: INFO: Got endpoints: latency-svc-pzwck [771.750508ms]
Feb 24 09:33:14.591: INFO: Created: latency-svc-kdmrn
Feb 24 09:33:14.638: INFO: Got endpoints: latency-svc-8p77z [785.720592ms]
Feb 24 09:33:14.694: INFO: Got endpoints: latency-svc-t7pkh [812.516315ms]
Feb 24 09:33:14.699: INFO: Got endpoints: latency-svc-sqnxg [764.433189ms]
Feb 24 09:33:14.719: INFO: Created: latency-svc-kc98g
Feb 24 09:33:14.731: INFO: Created: latency-svc-pnfch
Feb 24 09:33:14.732: INFO: Got endpoints: latency-svc-zznd2 [749.837916ms]
Feb 24 09:33:14.745: INFO: Created: latency-svc-h5wgx
Feb 24 09:33:14.752: INFO: Created: latency-svc-r2tc7
Feb 24 09:33:14.765: INFO: Created: latency-svc-skzb7
Feb 24 09:33:14.781: INFO: Got endpoints: latency-svc-5s2j6 [733.359184ms]
Feb 24 09:33:14.798: INFO: Created: latency-svc-sd6lq
Feb 24 09:33:14.830: INFO: Got endpoints: latency-svc-zw22h [743.357455ms]
Feb 24 09:33:14.847: INFO: Created: latency-svc-xp2pb
Feb 24 09:33:14.881: INFO: Got endpoints: latency-svc-kx48p [749.071523ms]
Feb 24 09:33:14.902: INFO: Created: latency-svc-z6p2g
Feb 24 09:33:14.930: INFO: Got endpoints: latency-svc-bbk95 [748.950613ms]
Feb 24 09:33:14.946: INFO: Created: latency-svc-hk5gs
Feb 24 09:33:14.980: INFO: Got endpoints: latency-svc-7ns8t [749.055798ms]
Feb 24 09:33:14.993: INFO: Created: latency-svc-9pmgp
Feb 24 09:33:15.036: INFO: Got endpoints: latency-svc-l6bh4 [755.247085ms]
Feb 24 09:33:15.062: INFO: Created: latency-svc-nf9cj
Feb 24 09:33:15.082: INFO: Got endpoints: latency-svc-vdnth [751.569329ms]
Feb 24 09:33:15.103: INFO: Created: latency-svc-4hv74
Feb 24 09:33:15.131: INFO: Got endpoints: latency-svc-hqbc6 [750.153018ms]
Feb 24 09:33:15.146: INFO: Created: latency-svc-gnwb4
Feb 24 09:33:15.180: INFO: Got endpoints: latency-svc-n6prz [742.962981ms]
Feb 24 09:33:15.196: INFO: Created: latency-svc-f522w
Feb 24 09:33:15.230: INFO: Got endpoints: latency-svc-kdmrn [749.970564ms]
Feb 24 09:33:15.270: INFO: Created: latency-svc-j8h9j
Feb 24 09:33:15.283: INFO: Got endpoints: latency-svc-kc98g [726.52469ms]
Feb 24 09:33:15.310: INFO: Created: latency-svc-bhzpl
Feb 24 09:33:15.329: INFO: Got endpoints: latency-svc-pnfch [691.53337ms]
Feb 24 09:33:15.343: INFO: Created: latency-svc-z4dwb
Feb 24 09:33:15.381: INFO: Got endpoints: latency-svc-h5wgx [686.761497ms]
Feb 24 09:33:15.400: INFO: Created: latency-svc-cr2zl
Feb 24 09:33:15.430: INFO: Got endpoints: latency-svc-r2tc7 [731.063156ms]
Feb 24 09:33:15.454: INFO: Created: latency-svc-pdt5g
Feb 24 09:33:15.479: INFO: Got endpoints: latency-svc-skzb7 [747.227994ms]
Feb 24 09:33:15.493: INFO: Created: latency-svc-ttl2h
Feb 24 09:33:15.532: INFO: Got endpoints: latency-svc-sd6lq [750.969688ms]
Feb 24 09:33:15.545: INFO: Created: latency-svc-s2qdr
Feb 24 09:33:15.586: INFO: Got endpoints: latency-svc-xp2pb [755.398453ms]
Feb 24 09:33:15.601: INFO: Created: latency-svc-ndddn
Feb 24 09:33:15.630: INFO: Got endpoints: latency-svc-z6p2g [749.398203ms]
Feb 24 09:33:15.644: INFO: Created: latency-svc-trqv9
Feb 24 09:33:15.680: INFO: Got endpoints: latency-svc-hk5gs [749.944858ms]
Feb 24 09:33:15.696: INFO: Created: latency-svc-5kbbx
Feb 24 09:33:15.730: INFO: Got endpoints: latency-svc-9pmgp [750.015885ms]
Feb 24 09:33:15.744: INFO: Created: latency-svc-ffdwd
Feb 24 09:33:15.781: INFO: Got endpoints: latency-svc-nf9cj [745.299251ms]
Feb 24 09:33:15.800: INFO: Created: latency-svc-f2sld
Feb 24 09:33:15.830: INFO: Got endpoints: latency-svc-4hv74 [747.909618ms]
Feb 24 09:33:15.847: INFO: Created: latency-svc-9sd8t
Feb 24 09:33:15.880: INFO: Got endpoints: latency-svc-gnwb4 [749.473531ms]
Feb 24 09:33:15.895: INFO: Created: latency-svc-xz2pz
Feb 24 09:33:15.931: INFO: Got endpoints: latency-svc-f522w [750.640733ms]
Feb 24 09:33:15.946: INFO: Created: latency-svc-9d5mj
Feb 24 09:33:15.981: INFO: Got endpoints: latency-svc-j8h9j [750.903153ms]
Feb 24 09:33:15.996: INFO: Created: latency-svc-n8mrn
Feb 24 09:33:16.030: INFO: Got endpoints: latency-svc-bhzpl [747.724507ms]
Feb 24 09:33:16.052: INFO: Created: latency-svc-cq2nr
Feb 24 09:33:16.081: INFO: Got endpoints: latency-svc-z4dwb [751.657528ms]
Feb 24 09:33:16.097: INFO: Created: latency-svc-c28bs
Feb 24 09:33:16.144: INFO: Got endpoints: latency-svc-cr2zl [763.177369ms]
Feb 24 09:33:16.160: INFO: Created: latency-svc-drt6h
Feb 24 09:33:16.180: INFO: Got endpoints: latency-svc-pdt5g [750.160011ms]
Feb 24 09:33:16.195: INFO: Created: latency-svc-7clxv
Feb 24 09:33:16.230: INFO: Got endpoints: latency-svc-ttl2h [750.521719ms]
Feb 24 09:33:16.244: INFO: Created: latency-svc-v4lbt
Feb 24 09:33:16.284: INFO: Got endpoints: latency-svc-s2qdr [751.965324ms]
Feb 24 09:33:16.299: INFO: Created: latency-svc-th9jn
Feb 24 09:33:16.331: INFO: Got endpoints: latency-svc-ndddn [745.11776ms]
Feb 24 09:33:16.348: INFO: Created: latency-svc-x784d
Feb 24 09:33:16.380: INFO: Got endpoints: latency-svc-trqv9 [750.038722ms]
Feb 24 09:33:16.398: INFO: Created: latency-svc-bb2g6
Feb 24 09:33:16.433: INFO: Got endpoints: latency-svc-5kbbx [753.028249ms]
Feb 24 09:33:16.457: INFO: Created: latency-svc-tmr58
Feb 24 09:33:16.480: INFO: Got endpoints: latency-svc-ffdwd [750.296037ms]
Feb 24 09:33:16.517: INFO: Created: latency-svc-dm6s8
Feb 24 09:33:16.532: INFO: Got endpoints: latency-svc-f2sld [750.376506ms]
Feb 24 09:33:16.550: INFO: Created: latency-svc-852qf
Feb 24 09:33:16.580: INFO: Got endpoints: latency-svc-9sd8t [749.607468ms]
Feb 24 09:33:16.593: INFO: Created: latency-svc-xwl5v
Feb 24 09:33:16.631: INFO: Got endpoints: latency-svc-xz2pz [750.704139ms]
Feb 24 09:33:16.659: INFO: Created: latency-svc-4bhrh
Feb 24 09:33:16.682: INFO: Got endpoints: latency-svc-9d5mj [751.065316ms]
Feb 24 09:33:16.695: INFO: Created: latency-svc-zsvvb
Feb 24 09:33:16.738: INFO: Got endpoints: latency-svc-n8mrn [757.141326ms]
Feb 24 09:33:16.754: INFO: Created: latency-svc-dpw5j
Feb 24 09:33:16.780: INFO: Got endpoints: latency-svc-cq2nr [749.924588ms]
Feb 24 09:33:16.795: INFO: Created: latency-svc-qnzt2
Feb 24 09:33:16.832: INFO: Got endpoints: latency-svc-c28bs [750.643537ms]
Feb 24 09:33:16.847: INFO: Created: latency-svc-khg4n
Feb 24 09:33:16.880: INFO: Got endpoints: latency-svc-drt6h [736.133985ms]
Feb 24 09:33:16.895: INFO: Created: latency-svc-skkkb
Feb 24 09:33:16.931: INFO: Got endpoints: latency-svc-7clxv [750.546862ms]
Feb 24 09:33:16.945: INFO: Created: latency-svc-k45ll
Feb 24 09:33:16.981: INFO: Got endpoints: latency-svc-v4lbt [750.723143ms]
Feb 24 09:33:16.997: INFO: Created: latency-svc-4c7vv
Feb 24 09:33:17.030: INFO: Got endpoints: latency-svc-th9jn [746.229857ms]
Feb 24 09:33:17.045: INFO: Created: latency-svc-8jsrf
Feb 24 09:33:17.080: INFO: Got endpoints: latency-svc-x784d [749.157865ms]
Feb 24 09:33:17.098: INFO: Created: latency-svc-4h878
Feb 24 09:33:17.130: INFO: Got endpoints: latency-svc-bb2g6 [749.378925ms]
Feb 24 09:33:17.144: INFO: Created: latency-svc-n6d8t
Feb 24 09:33:17.186: INFO: Got endpoints: latency-svc-tmr58 [752.811708ms]
Feb 24 09:33:17.204: INFO: Created: latency-svc-hd4q9
Feb 24 09:33:17.232: INFO: Got endpoints: latency-svc-dm6s8 [751.582485ms]
Feb 24 09:33:17.246: INFO: Created: latency-svc-rdxtr
Feb 24 09:33:17.280: INFO: Got endpoints: latency-svc-852qf [748.356557ms]
Feb 24 09:33:17.301: INFO: Created: latency-svc-fbhxj
Feb 24 09:33:17.329: INFO: Got endpoints: latency-svc-xwl5v [749.605061ms]
Feb 24 09:33:17.341: INFO: Created: latency-svc-xvtrk
Feb 24 09:33:17.381: INFO: Got endpoints: latency-svc-4bhrh [749.906168ms]
Feb 24 09:33:17.403: INFO: Created: latency-svc-gbbpr
Feb 24 09:33:17.431: INFO: Got endpoints: latency-svc-zsvvb [748.858958ms]
Feb 24 09:33:17.446: INFO: Created: latency-svc-jpg7m
Feb 24 09:33:17.484: INFO: Got endpoints: latency-svc-dpw5j [745.445337ms]
Feb 24 09:33:17.510: INFO: Created: latency-svc-k26mg
Feb 24 09:33:17.531: INFO: Got endpoints: latency-svc-qnzt2 [750.278305ms]
Feb 24 09:33:17.546: INFO: Created: latency-svc-x2xm7
Feb 24 09:33:17.580: INFO: Got endpoints: latency-svc-khg4n [748.162713ms]
Feb 24 09:33:17.596: INFO: Created: latency-svc-rcd7d
Feb 24 09:33:17.630: INFO: Got endpoints: latency-svc-skkkb [749.953257ms]
Feb 24 09:33:17.665: INFO: Created: latency-svc-l9c4s
Feb 24 09:33:17.681: INFO: Got endpoints: latency-svc-k45ll [750.064751ms]
Feb 24 09:33:17.696: INFO: Created: latency-svc-ldgww
Feb 24 09:33:17.730: INFO: Got endpoints: latency-svc-4c7vv [749.210392ms]
Feb 24 09:33:17.746: INFO: Created: latency-svc-nmd5b
Feb 24 09:33:17.780: INFO: Got endpoints: latency-svc-8jsrf [750.185858ms]
Feb 24 09:33:17.792: INFO: Created: latency-svc-h957w
Feb 24 09:33:17.830: INFO: Got endpoints: latency-svc-4h878 [750.042427ms]
Feb 24 09:33:17.841: INFO: Created: latency-svc-9frcp
Feb 24 09:33:17.881: INFO: Got endpoints: latency-svc-n6d8t [751.159341ms]
Feb 24 09:33:17.896: INFO: Created: latency-svc-875v5
Feb 24 09:33:17.932: INFO: Got endpoints: latency-svc-hd4q9 [745.490297ms]
Feb 24 09:33:17.954: INFO: Created: latency-svc-hwnlr
Feb 24 09:33:17.980: INFO: Got endpoints: latency-svc-rdxtr [748.334157ms]
Feb 24 09:33:17.996: INFO: Created: latency-svc-vp2t8
Feb 24 09:33:18.031: INFO: Got endpoints: latency-svc-fbhxj [751.076509ms]
Feb 24 09:33:18.049: INFO: Created: latency-svc-dqht8
Feb 24 09:33:18.083: INFO: Got endpoints: latency-svc-xvtrk [753.070586ms]
Feb 24 09:33:18.101: INFO: Created: latency-svc-ptztt
Feb 24 09:33:18.130: INFO: Got endpoints: latency-svc-gbbpr [749.09734ms]
Feb 24 09:33:18.148: INFO: Created: latency-svc-6jwm7
Feb 24 09:33:18.179: INFO: Got endpoints: latency-svc-jpg7m [748.723024ms]
Feb 24 09:33:18.190: INFO: Created: latency-svc-599zn
Feb 24 09:33:18.231: INFO: Got endpoints: latency-svc-k26mg [747.327809ms]
Feb 24 09:33:18.248: INFO: Created: latency-svc-zwnnc
Feb 24 09:33:18.281: INFO: Got endpoints: latency-svc-x2xm7 [750.039735ms]
Feb 24 09:33:18.296: INFO: Created: latency-svc-c25zd
Feb 24 09:33:18.331: INFO: Got endpoints: latency-svc-rcd7d [750.685318ms]
Feb 24 09:33:18.345: INFO: Created: latency-svc-zhg5n
Feb 24 09:33:18.380: INFO: Got endpoints: latency-svc-l9c4s [750.12066ms]
Feb 24 09:33:18.404: INFO: Created: latency-svc-84zg5
Feb 24 09:33:18.430: INFO: Got endpoints: latency-svc-ldgww [749.140899ms]
Feb 24 09:33:18.440: INFO: Created: latency-svc-fgvd7
Feb 24 09:33:18.480: INFO: Got endpoints: latency-svc-nmd5b [749.784132ms]
Feb 24 09:33:18.499: INFO: Created: latency-svc-qbtxh
Feb 24 09:33:18.529: INFO: Got endpoints: latency-svc-h957w [749.366232ms]
Feb 24 09:33:18.543: INFO: Created: latency-svc-cc7lg
Feb 24 09:33:18.583: INFO: Got endpoints: latency-svc-9frcp [752.72724ms]
Feb 24 09:33:18.596: INFO: Created: latency-svc-695hv
Feb 24 09:33:18.631: INFO: Got endpoints: latency-svc-875v5 [750.068474ms]
Feb 24 09:33:18.648: INFO: Created: latency-svc-cd7fp
Feb 24 09:33:18.679: INFO: Got endpoints: latency-svc-hwnlr [747.444794ms]
Feb 24 09:33:18.695: INFO: Created: latency-svc-sch6g
Feb 24 09:33:18.729: INFO: Got endpoints: latency-svc-vp2t8 [749.143265ms]
Feb 24 09:33:18.743: INFO: Created: latency-svc-nsgdr
Feb 24 09:33:18.782: INFO: Got endpoints: latency-svc-dqht8 [750.79564ms]
Feb 24 09:33:18.797: INFO: Created: latency-svc-lm5xv
Feb 24 09:33:18.829: INFO: Got endpoints: latency-svc-ptztt [746.664007ms]
Feb 24 09:33:18.843: INFO: Created: latency-svc-5hv78
Feb 24 09:33:18.880: INFO: Got endpoints: latency-svc-6jwm7 [749.817692ms]
Feb 24 09:33:18.906: INFO: Created: latency-svc-78h7z
Feb 24 09:33:18.930: INFO: Got endpoints: latency-svc-599zn [750.235134ms]
Feb 24 09:33:18.955: INFO: Created: latency-svc-587qj
Feb 24 09:33:19.032: INFO: Got endpoints: latency-svc-zwnnc [801.13349ms]
Feb 24 09:33:19.034: INFO: Got endpoints: latency-svc-c25zd [753.337897ms]
Feb 24 09:33:19.046: INFO: Created: latency-svc-7dtqh
Feb 24 09:33:19.057: INFO: Created: latency-svc-npn9j
Feb 24 09:33:19.083: INFO: Got endpoints: latency-svc-zhg5n [752.106093ms]
Feb 24 09:33:19.099: INFO: Created: latency-svc-wh4xn
Feb 24 09:33:19.156: INFO: Got endpoints: latency-svc-84zg5 [775.514699ms]
Feb 24 09:33:19.192: INFO: Created: latency-svc-ql8xn
Feb 24 09:33:19.194: INFO: Got endpoints: latency-svc-fgvd7 [764.086569ms]
Feb 24 09:33:19.220: INFO: Created: latency-svc-4pcg9
Feb 24 09:33:19.230: INFO: Got endpoints: latency-svc-qbtxh [749.855902ms]
Feb 24 09:33:19.255: INFO: Created: latency-svc-cnhbn
Feb 24 09:33:19.284: INFO: Got endpoints: latency-svc-cc7lg [754.208995ms]
Feb 24 09:33:19.309: INFO: Created: latency-svc-n6hs7
Feb 24 09:33:19.330: INFO: Got endpoints: latency-svc-695hv [747.183057ms]
Feb 24 09:33:19.360: INFO: Created: latency-svc-pn7pl
Feb 24 09:33:19.380: INFO: Got endpoints: latency-svc-cd7fp [749.106867ms]
Feb 24 09:33:19.404: INFO: Created: latency-svc-wv2sj
Feb 24 09:33:19.431: INFO: Got endpoints: latency-svc-sch6g [751.519606ms]
Feb 24 09:33:19.445: INFO: Created: latency-svc-7tdx4
Feb 24 09:33:19.479: INFO: Got endpoints: latency-svc-nsgdr [749.814733ms]
Feb 24 09:33:19.507: INFO: Created: latency-svc-r54vh
Feb 24 09:33:19.530: INFO: Got endpoints: latency-svc-lm5xv [747.910914ms]
Feb 24 09:33:19.563: INFO: Created: latency-svc-2dd46
Feb 24 09:33:19.579: INFO: Got endpoints: latency-svc-5hv78 [750.047527ms]
Feb 24 09:33:19.593: INFO: Created: latency-svc-vblcn
Feb 24 09:33:19.630: INFO: Got endpoints: latency-svc-78h7z [749.68865ms]
Feb 24 09:33:19.644: INFO: Created: latency-svc-wgt52
Feb 24 09:33:19.680: INFO: Got endpoints: latency-svc-587qj [750.160314ms]
Feb 24 09:33:19.690: INFO: Created: latency-svc-j4hpm
Feb 24 09:33:19.729: INFO: Got endpoints: latency-svc-7dtqh [697.163742ms]
Feb 24 09:33:19.746: INFO: Created: latency-svc-6mqq5
Feb 24 09:33:19.780: INFO: Got endpoints: latency-svc-npn9j [745.637229ms]
Feb 24 09:33:19.796: INFO: Created: latency-svc-mjr62
Feb 24 09:33:19.830: INFO: Got endpoints: latency-svc-wh4xn [747.038696ms]
Feb 24 09:33:19.843: INFO: Created: latency-svc-b7q2x
Feb 24 09:33:19.882: INFO: Got endpoints: latency-svc-ql8xn [726.465371ms]
Feb 24 09:33:19.893: INFO: Created: latency-svc-bdr9z
Feb 24 09:33:19.934: INFO: Got endpoints: latency-svc-4pcg9 [739.463427ms]
Feb 24 09:33:19.949: INFO: Created: latency-svc-cbjwh
Feb 24 09:33:19.980: INFO: Got endpoints: latency-svc-cnhbn [749.83819ms]
Feb 24 09:33:19.993: INFO: Created: latency-svc-2fjl5
Feb 24 09:33:20.040: INFO: Got endpoints: latency-svc-n6hs7 [755.887632ms]
Feb 24 09:33:20.056: INFO: Created: latency-svc-7bdbv
Feb 24 09:33:20.080: INFO: Got endpoints: latency-svc-pn7pl [749.787287ms]
Feb 24 09:33:20.100: INFO: Created: latency-svc-k9bq2
Feb 24 09:33:20.130: INFO: Got endpoints: latency-svc-wv2sj [749.662126ms]
Feb 24 09:33:20.149: INFO: Created: latency-svc-mc8p6
Feb 24 09:33:20.182: INFO: Got endpoints: latency-svc-7tdx4 [751.125269ms]
Feb 24 09:33:20.201: INFO: Created: latency-svc-ss67d
Feb 24 09:33:20.231: INFO: Got endpoints: latency-svc-r54vh [751.459704ms]
Feb 24 09:33:20.286: INFO: Got endpoints: latency-svc-2dd46 [755.705187ms]
Feb 24 09:33:20.288: INFO: Created: latency-svc-2d298
Feb 24 09:33:20.307: INFO: Created: latency-svc-7ndlx
Feb 24 09:33:20.330: INFO: Got endpoints: latency-svc-vblcn [750.93708ms]
Feb 24 09:33:20.350: INFO: Created: latency-svc-sgvrg
Feb 24 09:33:20.389: INFO: Got endpoints: latency-svc-wgt52 [758.918016ms]
Feb 24 09:33:20.411: INFO: Created: latency-svc-jnbmt
Feb 24 09:33:20.430: INFO: Got endpoints: latency-svc-j4hpm [749.874616ms]
Feb 24 09:33:20.443: INFO: Created: latency-svc-w58lf
Feb 24 09:33:20.480: INFO: Got endpoints: latency-svc-6mqq5 [750.522304ms]
Feb 24 09:33:20.497: INFO: Created: latency-svc-mfjx8
Feb 24 09:33:20.531: INFO: Got endpoints: latency-svc-mjr62 [750.727856ms]
Feb 24 09:33:20.547: INFO: Created: latency-svc-sdspz
Feb 24 09:33:20.582: INFO: Got endpoints: latency-svc-b7q2x [751.784698ms]
Feb 24 09:33:20.609: INFO: Created: latency-svc-jk5nj
Feb 24 09:33:20.630: INFO: Got endpoints: latency-svc-bdr9z [747.762926ms]
Feb 24 09:33:20.647: INFO: Created: latency-svc-b58zp
Feb 24 09:33:20.680: INFO: Got endpoints: latency-svc-cbjwh [745.939723ms]
Feb 24 09:33:20.695: INFO: Created: latency-svc-4bgbg
Feb 24 09:33:20.730: INFO: Got endpoints: latency-svc-2fjl5 [750.092419ms]
Feb 24 09:33:20.750: INFO: Created: latency-svc-bp5nj
Feb 24 09:33:20.784: INFO: Got endpoints: latency-svc-7bdbv [743.835908ms]
Feb 24 09:33:20.803: INFO: Created: latency-svc-n56dm
Feb 24 09:33:20.829: INFO: Got endpoints: latency-svc-k9bq2 [749.189607ms]
Feb 24 09:33:20.842: INFO: Created: latency-svc-q6krj
Feb 24 09:33:20.882: INFO: Got endpoints: latency-svc-mc8p6 [752.684436ms]
Feb 24 09:33:20.930: INFO: Got endpoints: latency-svc-ss67d [747.73978ms]
Feb 24 09:33:20.981: INFO: Got endpoints: latency-svc-2d298 [749.918586ms]
Feb 24 09:33:21.040: INFO: Got endpoints: latency-svc-7ndlx [754.722833ms]
Feb 24 09:33:21.079: INFO: Got endpoints: latency-svc-sgvrg [749.032146ms]
Feb 24 09:33:21.129: INFO: Got endpoints: latency-svc-jnbmt [740.596254ms]
Feb 24 09:33:21.179: INFO: Got endpoints: latency-svc-w58lf [749.612169ms]
Feb 24 09:33:21.231: INFO: Got endpoints: latency-svc-mfjx8 [751.256461ms]
Feb 24 09:33:21.280: INFO: Got endpoints: latency-svc-sdspz [748.904707ms]
Feb 24 09:33:21.332: INFO: Got endpoints: latency-svc-jk5nj [750.024887ms]
Feb 24 09:33:21.380: INFO: Got endpoints: latency-svc-b58zp [746.134117ms]
Feb 24 09:33:21.429: INFO: Got endpoints: latency-svc-4bgbg [749.660375ms]
Feb 24 09:33:21.481: INFO: Got endpoints: latency-svc-bp5nj [751.2025ms]
Feb 24 09:33:21.531: INFO: Got endpoints: latency-svc-n56dm [747.805351ms]
Feb 24 09:33:21.580: INFO: Got endpoints: latency-svc-q6krj [751.229959ms]
Feb 24 09:33:21.581: INFO: Latencies: [25.072745ms 27.704717ms 46.070143ms 55.100884ms 59.575317ms 73.681075ms 83.840959ms 112.277724ms 134.037525ms 140.098379ms 159.204826ms 176.756955ms 206.192805ms 214.894485ms 228.399389ms 230.805722ms 242.198564ms 245.139689ms 245.474313ms 246.661444ms 249.825133ms 250.154382ms 250.476619ms 250.541458ms 252.28087ms 252.355519ms 252.364178ms 252.751163ms 254.115455ms 255.501425ms 256.508951ms 257.452898ms 257.540901ms 262.0239ms 262.702633ms 263.785876ms 265.19398ms 267.510169ms 270.311158ms 273.375623ms 275.665086ms 278.216072ms 279.983292ms 299.887727ms 310.219468ms 331.81664ms 374.05427ms 416.28524ms 461.749425ms 473.119166ms 513.480883ms 544.673367ms 551.731759ms 589.18324ms 623.874313ms 661.427234ms 686.761497ms 691.53337ms 697.163742ms 711.307127ms 726.465371ms 726.52469ms 731.063156ms 733.359184ms 736.133985ms 739.463427ms 740.596254ms 741.53805ms 742.962981ms 743.357455ms 743.835908ms 745.11776ms 745.299251ms 745.445337ms 745.490297ms 745.637229ms 745.939723ms 746.134117ms 746.229857ms 746.664007ms 747.038696ms 747.183057ms 747.227994ms 747.327809ms 747.444794ms 747.724507ms 747.73978ms 747.762926ms 747.805351ms 747.909618ms 747.910914ms 748.162713ms 748.334157ms 748.356557ms 748.723024ms 748.858958ms 748.904707ms 748.950613ms 749.032146ms 749.055798ms 749.071523ms 749.09734ms 749.106867ms 749.140899ms 749.143265ms 749.157865ms 749.189607ms 749.210392ms 749.366232ms 749.378925ms 749.398203ms 749.473531ms 749.605061ms 749.607468ms 749.612169ms 749.660375ms 749.662126ms 749.68865ms 749.784132ms 749.787287ms 749.814733ms 749.817692ms 749.837916ms 749.83819ms 749.855902ms 749.874616ms 749.906168ms 749.918586ms 749.924588ms 749.944858ms 749.953257ms 749.970564ms 750.015885ms 750.024887ms 750.038722ms 750.039735ms 750.042427ms 750.047527ms 750.064751ms 750.068474ms 750.092419ms 750.12066ms 750.153018ms 750.160011ms 750.160314ms 750.185858ms 750.235134ms 750.278305ms 750.296037ms 750.376506ms 750.521719ms 750.522304ms 750.546862ms 750.640733ms 750.643537ms 750.685318ms 750.704139ms 750.723143ms 750.727856ms 750.79564ms 750.903153ms 750.93708ms 750.969688ms 751.065316ms 751.076509ms 751.125269ms 751.159341ms 751.2025ms 751.229959ms 751.256461ms 751.459704ms 751.519606ms 751.569329ms 751.582485ms 751.657528ms 751.784698ms 751.965324ms 752.106093ms 752.684436ms 752.72724ms 752.811708ms 753.028249ms 753.070586ms 753.337897ms 754.208995ms 754.722833ms 755.247085ms 755.398453ms 755.705187ms 755.887632ms 757.141326ms 758.918016ms 763.177369ms 764.086569ms 764.433189ms 771.750508ms 775.514699ms 785.720592ms 801.13349ms 812.516315ms]
Feb 24 09:33:21.581: INFO: 50 %ile: 749.071523ms
Feb 24 09:33:21.581: INFO: 90 %ile: 752.811708ms
Feb 24 09:33:21.581: INFO: 99 %ile: 801.13349ms
Feb 24 09:33:21.581: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:33:21.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5370" for this suite.
Feb 24 09:33:33.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:33:33.670: INFO: namespace svc-latency-5370 deletion completed in 12.084139624s

• [SLOW TEST:23.824 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:33:33.670: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Feb 24 09:33:36.228: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1412 pod-service-account-24598246-09a5-4f0c-b7a2-6be0d89a3457 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Feb 24 09:33:36.409: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1412 pod-service-account-24598246-09a5-4f0c-b7a2-6be0d89a3457 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Feb 24 09:33:36.604: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1412 pod-service-account-24598246-09a5-4f0c-b7a2-6be0d89a3457 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:33:36.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1412" for this suite.
Feb 24 09:33:42.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:33:42.874: INFO: namespace svcaccounts-1412 deletion completed in 6.078329353s

• [SLOW TEST:9.204 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:33:42.875: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-7866
STEP: creating replication controller nodeport-test in namespace services-7866
I0224 09:33:42.959890      21 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-7866, replica count: 2
I0224 09:33:46.010187      21 runners.go:184] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 24 09:33:49.010: INFO: Creating new exec pod
I0224 09:33:49.010348      21 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 24 09:33:52.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-7866 execpodzfztd -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Feb 24 09:33:52.228: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Feb 24 09:33:52.228: INFO: stdout: ""
Feb 24 09:33:52.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-7866 execpodzfztd -- /bin/sh -x -c nc -zv -t -w 2 10.106.11.173 80'
Feb 24 09:33:52.429: INFO: stderr: "+ nc -zv -t -w 2 10.106.11.173 80\nConnection to 10.106.11.173 80 port [tcp/http] succeeded!\n"
Feb 24 09:33:52.429: INFO: stdout: ""
Feb 24 09:33:52.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-7866 execpodzfztd -- /bin/sh -x -c nc -zv -t -w 2 10.100.10.135 31524'
Feb 24 09:33:52.648: INFO: stderr: "+ nc -zv -t -w 2 10.100.10.135 31524\nConnection to 10.100.10.135 31524 port [tcp/31524] succeeded!\n"
Feb 24 09:33:52.648: INFO: stdout: ""
Feb 24 09:33:52.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-7866 execpodzfztd -- /bin/sh -x -c nc -zv -t -w 2 10.100.10.76 31524'
Feb 24 09:33:52.836: INFO: stderr: "+ nc -zv -t -w 2 10.100.10.76 31524\nConnection to 10.100.10.76 31524 port [tcp/31524] succeeded!\n"
Feb 24 09:33:52.836: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:33:52.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7866" for this suite.
Feb 24 09:33:58.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:33:58.913: INFO: namespace services-7866 deletion completed in 6.071469844s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.039 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:33:58.914: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7602.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7602.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7602.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7602.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7602.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7602.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 09:34:02.978: INFO: DNS probes using dns-7602/dns-test-a0622ed4-c829-4609-9ce1-2bc6fed112eb succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:34:03.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7602" for this suite.
Feb 24 09:34:09.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:34:09.081: INFO: namespace dns-7602 deletion completed in 6.07276625s

• [SLOW TEST:10.167 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:34:09.081: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 09:34:09.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-6465'
Feb 24 09:34:09.175: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 24 09:34:09.175: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Feb 24 09:34:09.192: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-8kvn9]
Feb 24 09:34:09.192: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-8kvn9" in namespace "kubectl-6465" to be "running and ready"
Feb 24 09:34:09.201: INFO: Pod "e2e-test-httpd-rc-8kvn9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.493401ms
Feb 24 09:34:11.203: INFO: Pod "e2e-test-httpd-rc-8kvn9": Phase="Running", Reason="", readiness=true. Elapsed: 2.011274153s
Feb 24 09:34:11.203: INFO: Pod "e2e-test-httpd-rc-8kvn9" satisfied condition "running and ready"
Feb 24 09:34:11.203: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-8kvn9]
Feb 24 09:34:11.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 logs rc/e2e-test-httpd-rc --namespace=kubectl-6465'
Feb 24 09:34:11.288: INFO: stderr: ""
Feb 24 09:34:11.288: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.16.14.225. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.16.14.225. Set the 'ServerName' directive globally to suppress this message\n[Mon Feb 24 09:34:10.552214 2020] [mpm_event:notice] [pid 1:tid 140212968299368] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Feb 24 09:34:10.552261 2020] [core:notice] [pid 1:tid 140212968299368] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Feb 24 09:34:11.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete rc e2e-test-httpd-rc --namespace=kubectl-6465'
Feb 24 09:34:11.360: INFO: stderr: ""
Feb 24 09:34:11.361: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:34:11.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6465" for this suite.
Feb 24 09:34:39.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:34:39.443: INFO: namespace kubectl-6465 deletion completed in 28.079382611s

• [SLOW TEST:30.361 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:34:39.443: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 24 09:34:39.487: INFO: Waiting up to 5m0s for pod "pod-b97c58a1-ea6c-4c95-b6f9-6e24f770985f" in namespace "emptydir-4614" to be "success or failure"
Feb 24 09:34:39.491: INFO: Pod "pod-b97c58a1-ea6c-4c95-b6f9-6e24f770985f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.17752ms
Feb 24 09:34:41.493: INFO: Pod "pod-b97c58a1-ea6c-4c95-b6f9-6e24f770985f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006205233s
Feb 24 09:34:43.495: INFO: Pod "pod-b97c58a1-ea6c-4c95-b6f9-6e24f770985f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008280838s
STEP: Saw pod success
Feb 24 09:34:43.495: INFO: Pod "pod-b97c58a1-ea6c-4c95-b6f9-6e24f770985f" satisfied condition "success or failure"
Feb 24 09:34:43.497: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-b97c58a1-ea6c-4c95-b6f9-6e24f770985f container test-container: <nil>
STEP: delete the pod
Feb 24 09:34:43.509: INFO: Waiting for pod pod-b97c58a1-ea6c-4c95-b6f9-6e24f770985f to disappear
Feb 24 09:34:43.511: INFO: Pod pod-b97c58a1-ea6c-4c95-b6f9-6e24f770985f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:34:43.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4614" for this suite.
Feb 24 09:34:49.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:34:49.591: INFO: namespace emptydir-4614 deletion completed in 6.078470961s

• [SLOW TEST:10.148 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:34:49.591: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:34:49.623: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b84c412-32ac-4d73-a065-ced5bccc28cc" in namespace "projected-2970" to be "success or failure"
Feb 24 09:34:49.632: INFO: Pod "downwardapi-volume-5b84c412-32ac-4d73-a065-ced5bccc28cc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.980747ms
Feb 24 09:34:51.634: INFO: Pod "downwardapi-volume-5b84c412-32ac-4d73-a065-ced5bccc28cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011048983s
STEP: Saw pod success
Feb 24 09:34:51.634: INFO: Pod "downwardapi-volume-5b84c412-32ac-4d73-a065-ced5bccc28cc" satisfied condition "success or failure"
Feb 24 09:34:51.637: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-5b84c412-32ac-4d73-a065-ced5bccc28cc container client-container: <nil>
STEP: delete the pod
Feb 24 09:34:51.654: INFO: Waiting for pod downwardapi-volume-5b84c412-32ac-4d73-a065-ced5bccc28cc to disappear
Feb 24 09:34:51.656: INFO: Pod downwardapi-volume-5b84c412-32ac-4d73-a065-ced5bccc28cc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:34:51.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2970" for this suite.
Feb 24 09:34:57.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:34:57.737: INFO: namespace projected-2970 deletion completed in 6.079701644s

• [SLOW TEST:8.146 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:34:57.738: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 24 09:34:57.763: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 24 09:35:02.765: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:35:03.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6491" for this suite.
Feb 24 09:35:09.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:35:09.855: INFO: namespace replication-controller-6491 deletion completed in 6.077786081s

• [SLOW TEST:12.117 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:35:09.855: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 09:35:09.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7216'
Feb 24 09:35:09.947: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 24 09:35:09.947: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Feb 24 09:35:09.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete jobs e2e-test-httpd-job --namespace=kubectl-7216'
Feb 24 09:35:10.016: INFO: stderr: ""
Feb 24 09:35:10.016: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:35:10.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7216" for this suite.
Feb 24 09:35:16.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:35:16.094: INFO: namespace kubectl-7216 deletion completed in 6.072475093s

• [SLOW TEST:6.239 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:35:16.094: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-be517fae-487c-4808-8b8a-92592f8aec31
STEP: Creating a pod to test consume secrets
Feb 24 09:35:16.139: INFO: Waiting up to 5m0s for pod "pod-secrets-4581de0c-9880-4dcf-912f-a43ea8ae065d" in namespace "secrets-2251" to be "success or failure"
Feb 24 09:35:16.144: INFO: Pod "pod-secrets-4581de0c-9880-4dcf-912f-a43ea8ae065d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.087749ms
Feb 24 09:35:18.146: INFO: Pod "pod-secrets-4581de0c-9880-4dcf-912f-a43ea8ae065d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007110371s
Feb 24 09:35:20.149: INFO: Pod "pod-secrets-4581de0c-9880-4dcf-912f-a43ea8ae065d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009306389s
STEP: Saw pod success
Feb 24 09:35:20.149: INFO: Pod "pod-secrets-4581de0c-9880-4dcf-912f-a43ea8ae065d" satisfied condition "success or failure"
Feb 24 09:35:20.150: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-secrets-4581de0c-9880-4dcf-912f-a43ea8ae065d container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 09:35:20.161: INFO: Waiting for pod pod-secrets-4581de0c-9880-4dcf-912f-a43ea8ae065d to disappear
Feb 24 09:35:20.163: INFO: Pod pod-secrets-4581de0c-9880-4dcf-912f-a43ea8ae065d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:35:20.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2251" for this suite.
Feb 24 09:35:26.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:35:26.241: INFO: namespace secrets-2251 deletion completed in 6.075772314s
STEP: Destroying namespace "secret-namespace-945" for this suite.
Feb 24 09:35:32.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:35:32.321: INFO: namespace secret-namespace-945 deletion completed in 6.080462616s

• [SLOW TEST:16.227 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:35:32.322: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:35:48.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5600" for this suite.
Feb 24 09:35:54.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:35:54.442: INFO: namespace resourcequota-5600 deletion completed in 6.076553011s

• [SLOW TEST:22.120 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:35:54.442: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 24 09:35:54.465: INFO: Waiting up to 5m0s for pod "pod-fa641b6f-363f-4074-9ccb-c65c4948a886" in namespace "emptydir-5903" to be "success or failure"
Feb 24 09:35:54.469: INFO: Pod "pod-fa641b6f-363f-4074-9ccb-c65c4948a886": Phase="Pending", Reason="", readiness=false. Elapsed: 4.577791ms
Feb 24 09:35:56.471: INFO: Pod "pod-fa641b6f-363f-4074-9ccb-c65c4948a886": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006665527s
STEP: Saw pod success
Feb 24 09:35:56.471: INFO: Pod "pod-fa641b6f-363f-4074-9ccb-c65c4948a886" satisfied condition "success or failure"
Feb 24 09:35:56.473: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-fa641b6f-363f-4074-9ccb-c65c4948a886 container test-container: <nil>
STEP: delete the pod
Feb 24 09:35:56.486: INFO: Waiting for pod pod-fa641b6f-363f-4074-9ccb-c65c4948a886 to disappear
Feb 24 09:35:56.488: INFO: Pod pod-fa641b6f-363f-4074-9ccb-c65c4948a886 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:35:56.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5903" for this suite.
Feb 24 09:36:02.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:36:02.574: INFO: namespace emptydir-5903 deletion completed in 6.07592725s

• [SLOW TEST:8.132 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:36:02.574: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:37:02.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1501" for this suite.
Feb 24 09:37:14.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:37:14.724: INFO: namespace container-probe-1501 deletion completed in 12.072648749s

• [SLOW TEST:72.149 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:37:14.724: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-fb124447-e087-4ade-b24f-bfc651462a73 in namespace container-probe-7083
Feb 24 09:37:16.752: INFO: Started pod busybox-fb124447-e087-4ade-b24f-bfc651462a73 in namespace container-probe-7083
STEP: checking the pod's current state and verifying that restartCount is present
Feb 24 09:37:16.754: INFO: Initial restart count of pod busybox-fb124447-e087-4ade-b24f-bfc651462a73 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:41:17.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7083" for this suite.
Feb 24 09:41:23.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:41:23.113: INFO: namespace container-probe-7083 deletion completed in 6.07691731s

• [SLOW TEST:248.390 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:41:23.114: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-285b
STEP: Creating a pod to test atomic-volume-subpath
Feb 24 09:41:23.143: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-285b" in namespace "subpath-8234" to be "success or failure"
Feb 24 09:41:23.145: INFO: Pod "pod-subpath-test-secret-285b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.544527ms
Feb 24 09:41:25.147: INFO: Pod "pod-subpath-test-secret-285b": Phase="Running", Reason="", readiness=true. Elapsed: 2.003813248s
Feb 24 09:41:27.150: INFO: Pod "pod-subpath-test-secret-285b": Phase="Running", Reason="", readiness=true. Elapsed: 4.006748771s
Feb 24 09:41:29.155: INFO: Pod "pod-subpath-test-secret-285b": Phase="Running", Reason="", readiness=true. Elapsed: 6.0115682s
Feb 24 09:41:31.158: INFO: Pod "pod-subpath-test-secret-285b": Phase="Running", Reason="", readiness=true. Elapsed: 8.014946716s
Feb 24 09:41:33.160: INFO: Pod "pod-subpath-test-secret-285b": Phase="Running", Reason="", readiness=true. Elapsed: 10.016825249s
Feb 24 09:41:35.163: INFO: Pod "pod-subpath-test-secret-285b": Phase="Running", Reason="", readiness=true. Elapsed: 12.019972588s
Feb 24 09:41:37.165: INFO: Pod "pod-subpath-test-secret-285b": Phase="Running", Reason="", readiness=true. Elapsed: 14.022224235s
Feb 24 09:41:39.168: INFO: Pod "pod-subpath-test-secret-285b": Phase="Running", Reason="", readiness=true. Elapsed: 16.025444705s
Feb 24 09:41:41.171: INFO: Pod "pod-subpath-test-secret-285b": Phase="Running", Reason="", readiness=true. Elapsed: 18.027553412s
Feb 24 09:41:43.173: INFO: Pod "pod-subpath-test-secret-285b": Phase="Running", Reason="", readiness=true. Elapsed: 20.02973171s
Feb 24 09:41:45.204: INFO: Pod "pod-subpath-test-secret-285b": Phase="Running", Reason="", readiness=true. Elapsed: 22.061231358s
Feb 24 09:41:47.206: INFO: Pod "pod-subpath-test-secret-285b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.063345753s
STEP: Saw pod success
Feb 24 09:41:47.206: INFO: Pod "pod-subpath-test-secret-285b" satisfied condition "success or failure"
Feb 24 09:41:47.208: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-subpath-test-secret-285b container test-container-subpath-secret-285b: <nil>
STEP: delete the pod
Feb 24 09:41:47.234: INFO: Waiting for pod pod-subpath-test-secret-285b to disappear
Feb 24 09:41:47.235: INFO: Pod pod-subpath-test-secret-285b no longer exists
STEP: Deleting pod pod-subpath-test-secret-285b
Feb 24 09:41:47.235: INFO: Deleting pod "pod-subpath-test-secret-285b" in namespace "subpath-8234"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:41:47.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8234" for this suite.
Feb 24 09:41:53.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:41:53.314: INFO: namespace subpath-8234 deletion completed in 6.075110876s

• [SLOW TEST:30.200 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:41:53.314: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Feb 24 09:41:53.335: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Feb 24 09:42:04.919: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 09:42:08.358: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:42:19.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2530" for this suite.
Feb 24 09:42:26.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:42:26.087: INFO: namespace crd-publish-openapi-2530 deletion completed in 6.087884861s

• [SLOW TEST:32.773 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:42:26.088: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 24 09:42:26.116: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1193 /api/v1/namespaces/watch-1193/configmaps/e2e-watch-test-watch-closed 15e4ab64-3de6-46a1-8da4-9b450877ea26 22863 0 2020-02-24 09:42:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 24 09:42:26.117: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1193 /api/v1/namespaces/watch-1193/configmaps/e2e-watch-test-watch-closed 15e4ab64-3de6-46a1-8da4-9b450877ea26 22864 0 2020-02-24 09:42:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 24 09:42:26.124: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1193 /api/v1/namespaces/watch-1193/configmaps/e2e-watch-test-watch-closed 15e4ab64-3de6-46a1-8da4-9b450877ea26 22865 0 2020-02-24 09:42:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 24 09:42:26.125: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1193 /api/v1/namespaces/watch-1193/configmaps/e2e-watch-test-watch-closed 15e4ab64-3de6-46a1-8da4-9b450877ea26 22866 0 2020-02-24 09:42:26 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:42:26.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1193" for this suite.
Feb 24 09:42:32.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:42:32.204: INFO: namespace watch-1193 deletion completed in 6.076526316s

• [SLOW TEST:6.116 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:42:32.204: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb 24 09:42:32.276: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:42:47.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1255" for this suite.
Feb 24 09:42:53.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:42:53.803: INFO: namespace crd-publish-openapi-1255 deletion completed in 6.076539614s

• [SLOW TEST:21.599 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:42:53.803: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:43:06.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5479" for this suite.
Feb 24 09:43:12.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:43:12.999: INFO: namespace resourcequota-5479 deletion completed in 6.08778112s

• [SLOW TEST:19.195 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:43:12.999: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:43:13.039: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 24 09:43:13.046: INFO: Number of nodes with available pods: 0
Feb 24 09:43:13.046: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 24 09:43:13.061: INFO: Number of nodes with available pods: 0
Feb 24 09:43:13.061: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 09:43:14.063: INFO: Number of nodes with available pods: 0
Feb 24 09:43:14.064: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 09:43:15.063: INFO: Number of nodes with available pods: 0
Feb 24 09:43:15.063: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 09:43:16.063: INFO: Number of nodes with available pods: 1
Feb 24 09:43:16.063: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 24 09:43:16.081: INFO: Number of nodes with available pods: 1
Feb 24 09:43:16.081: INFO: Number of running nodes: 0, number of available pods: 1
Feb 24 09:43:17.084: INFO: Number of nodes with available pods: 0
Feb 24 09:43:17.084: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 24 09:43:17.088: INFO: Number of nodes with available pods: 0
Feb 24 09:43:17.088: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 09:43:18.093: INFO: Number of nodes with available pods: 0
Feb 24 09:43:18.093: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 09:43:19.091: INFO: Number of nodes with available pods: 0
Feb 24 09:43:19.091: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 09:43:20.091: INFO: Number of nodes with available pods: 0
Feb 24 09:43:20.091: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 09:43:21.091: INFO: Number of nodes with available pods: 0
Feb 24 09:43:21.091: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 09:43:22.091: INFO: Number of nodes with available pods: 1
Feb 24 09:43:22.091: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-872, will wait for the garbage collector to delete the pods
Feb 24 09:43:22.150: INFO: Deleting DaemonSet.extensions daemon-set took: 3.945798ms
Feb 24 09:43:22.650: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.185328ms
Feb 24 09:43:25.952: INFO: Number of nodes with available pods: 0
Feb 24 09:43:25.952: INFO: Number of running nodes: 0, number of available pods: 0
Feb 24 09:43:25.955: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-872/daemonsets","resourceVersion":"23140"},"items":null}

Feb 24 09:43:25.957: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-872/pods","resourceVersion":"23140"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:43:25.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-872" for this suite.
Feb 24 09:43:31.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:43:32.046: INFO: namespace daemonsets-872 deletion completed in 6.07341021s

• [SLOW TEST:19.047 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:43:32.046: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-785dda1a-d370-4898-aca1-71d42d0c1e79
STEP: Creating a pod to test consume configMaps
Feb 24 09:43:32.123: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2d017a55-c8b4-4d88-8291-d819353021fc" in namespace "projected-5673" to be "success or failure"
Feb 24 09:43:32.127: INFO: Pod "pod-projected-configmaps-2d017a55-c8b4-4d88-8291-d819353021fc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.522621ms
Feb 24 09:43:34.129: INFO: Pod "pod-projected-configmaps-2d017a55-c8b4-4d88-8291-d819353021fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006633671s
Feb 24 09:43:36.132: INFO: Pod "pod-projected-configmaps-2d017a55-c8b4-4d88-8291-d819353021fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0088741s
STEP: Saw pod success
Feb 24 09:43:36.132: INFO: Pod "pod-projected-configmaps-2d017a55-c8b4-4d88-8291-d819353021fc" satisfied condition "success or failure"
Feb 24 09:43:36.134: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-configmaps-2d017a55-c8b4-4d88-8291-d819353021fc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 09:43:36.150: INFO: Waiting for pod pod-projected-configmaps-2d017a55-c8b4-4d88-8291-d819353021fc to disappear
Feb 24 09:43:36.154: INFO: Pod pod-projected-configmaps-2d017a55-c8b4-4d88-8291-d819353021fc no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:43:36.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5673" for this suite.
Feb 24 09:43:42.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:43:42.232: INFO: namespace projected-5673 deletion completed in 6.075373107s

• [SLOW TEST:10.186 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:43:42.232: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7650
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb 24 09:43:42.316: INFO: Found 0 stateful pods, waiting for 3
Feb 24 09:43:52.318: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 09:43:52.318: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 09:43:52.318: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 09:43:52.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-7650 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 09:43:52.714: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 09:43:52.714: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 09:43:52.714: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb 24 09:44:02.736: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 24 09:44:12.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-7650 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 09:44:12.965: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 09:44:12.965: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 09:44:12.965: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 09:44:22.976: INFO: Waiting for StatefulSet statefulset-7650/ss2 to complete update
Feb 24 09:44:22.976: INFO: Waiting for Pod statefulset-7650/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 24 09:44:22.976: INFO: Waiting for Pod statefulset-7650/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 24 09:44:32.980: INFO: Waiting for StatefulSet statefulset-7650/ss2 to complete update
Feb 24 09:44:32.980: INFO: Waiting for Pod statefulset-7650/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 24 09:44:32.980: INFO: Waiting for Pod statefulset-7650/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 24 09:44:42.980: INFO: Waiting for StatefulSet statefulset-7650/ss2 to complete update
Feb 24 09:44:42.980: INFO: Waiting for Pod statefulset-7650/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Feb 24 09:44:52.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-7650 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 24 09:44:53.191: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 24 09:44:53.191: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 24 09:44:53.191: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 24 09:44:53.216: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 24 09:45:03.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=statefulset-7650 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 24 09:45:03.464: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 24 09:45:03.464: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 24 09:45:03.464: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 24 09:45:13.475: INFO: Waiting for StatefulSet statefulset-7650/ss2 to complete update
Feb 24 09:45:13.475: INFO: Waiting for Pod statefulset-7650/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb 24 09:45:13.475: INFO: Waiting for Pod statefulset-7650/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb 24 09:45:23.479: INFO: Waiting for StatefulSet statefulset-7650/ss2 to complete update
Feb 24 09:45:23.479: INFO: Waiting for Pod statefulset-7650/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 09:45:33.479: INFO: Deleting all statefulset in ns statefulset-7650
Feb 24 09:45:33.482: INFO: Scaling statefulset ss2 to 0
Feb 24 09:45:43.501: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 09:45:43.503: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:45:43.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7650" for this suite.
Feb 24 09:45:49.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:45:49.593: INFO: namespace statefulset-7650 deletion completed in 6.076632666s

• [SLOW TEST:127.361 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:45:49.593: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 24 09:45:49.616: INFO: Waiting up to 5m0s for pod "pod-b93c2a01-8e9a-44d7-a8ae-4c749aa7fe8d" in namespace "emptydir-8844" to be "success or failure"
Feb 24 09:45:49.618: INFO: Pod "pod-b93c2a01-8e9a-44d7-a8ae-4c749aa7fe8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041158ms
Feb 24 09:45:51.621: INFO: Pod "pod-b93c2a01-8e9a-44d7-a8ae-4c749aa7fe8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004198874s
STEP: Saw pod success
Feb 24 09:45:51.621: INFO: Pod "pod-b93c2a01-8e9a-44d7-a8ae-4c749aa7fe8d" satisfied condition "success or failure"
Feb 24 09:45:51.627: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-b93c2a01-8e9a-44d7-a8ae-4c749aa7fe8d container test-container: <nil>
STEP: delete the pod
Feb 24 09:45:51.654: INFO: Waiting for pod pod-b93c2a01-8e9a-44d7-a8ae-4c749aa7fe8d to disappear
Feb 24 09:45:51.656: INFO: Pod pod-b93c2a01-8e9a-44d7-a8ae-4c749aa7fe8d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:45:51.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8844" for this suite.
Feb 24 09:45:57.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:45:57.735: INFO: namespace emptydir-8844 deletion completed in 6.077241312s

• [SLOW TEST:8.143 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:45:57.736: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb 24 09:45:57.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-9899'
Feb 24 09:45:57.945: INFO: stderr: ""
Feb 24 09:45:57.945: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 24 09:45:57.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9899'
Feb 24 09:45:58.010: INFO: stderr: ""
Feb 24 09:45:58.010: INFO: stdout: "update-demo-nautilus-m2xcc update-demo-nautilus-m49nc "
Feb 24 09:45:58.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-m2xcc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9899'
Feb 24 09:45:58.067: INFO: stderr: ""
Feb 24 09:45:58.067: INFO: stdout: ""
Feb 24 09:45:58.067: INFO: update-demo-nautilus-m2xcc is created but not running
Feb 24 09:46:03.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9899'
Feb 24 09:46:03.129: INFO: stderr: ""
Feb 24 09:46:03.129: INFO: stdout: "update-demo-nautilus-m2xcc update-demo-nautilus-m49nc "
Feb 24 09:46:03.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-m2xcc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9899'
Feb 24 09:46:03.185: INFO: stderr: ""
Feb 24 09:46:03.185: INFO: stdout: "true"
Feb 24 09:46:03.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-m2xcc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9899'
Feb 24 09:46:03.243: INFO: stderr: ""
Feb 24 09:46:03.243: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 09:46:03.243: INFO: validating pod update-demo-nautilus-m2xcc
Feb 24 09:46:03.246: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 09:46:03.246: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 09:46:03.246: INFO: update-demo-nautilus-m2xcc is verified up and running
Feb 24 09:46:03.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-m49nc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9899'
Feb 24 09:46:03.303: INFO: stderr: ""
Feb 24 09:46:03.303: INFO: stdout: "true"
Feb 24 09:46:03.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods update-demo-nautilus-m49nc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9899'
Feb 24 09:46:03.363: INFO: stderr: ""
Feb 24 09:46:03.363: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 24 09:46:03.363: INFO: validating pod update-demo-nautilus-m49nc
Feb 24 09:46:03.366: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 24 09:46:03.366: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 24 09:46:03.366: INFO: update-demo-nautilus-m49nc is verified up and running
STEP: using delete to clean up resources
Feb 24 09:46:03.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete --grace-period=0 --force -f - --namespace=kubectl-9899'
Feb 24 09:46:03.429: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 09:46:03.429: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 24 09:46:03.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9899'
Feb 24 09:46:03.490: INFO: stderr: "No resources found in kubectl-9899 namespace.\n"
Feb 24 09:46:03.490: INFO: stdout: ""
Feb 24 09:46:03.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -l name=update-demo --namespace=kubectl-9899 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 24 09:46:03.549: INFO: stderr: ""
Feb 24 09:46:03.549: INFO: stdout: "update-demo-nautilus-m2xcc\nupdate-demo-nautilus-m49nc\n"
Feb 24 09:46:04.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9899'
Feb 24 09:46:04.142: INFO: stderr: "No resources found in kubectl-9899 namespace.\n"
Feb 24 09:46:04.142: INFO: stdout: ""
Feb 24 09:46:04.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -l name=update-demo --namespace=kubectl-9899 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 24 09:46:04.210: INFO: stderr: ""
Feb 24 09:46:04.210: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:46:04.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9899" for this suite.
Feb 24 09:46:16.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:46:16.288: INFO: namespace kubectl-9899 deletion completed in 12.075112139s

• [SLOW TEST:18.552 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:46:16.288: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:46:17.293: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:46:19.298: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134377, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134377, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134377, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134377, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:46:22.311: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
Feb 24 09:46:22.321: INFO: Waiting for webhook configuration to be ready...
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:46:22.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3499" for this suite.
Feb 24 09:46:28.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:46:28.512: INFO: namespace webhook-3499 deletion completed in 6.07180775s
STEP: Destroying namespace "webhook-3499-markers" for this suite.
Feb 24 09:46:34.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:46:34.596: INFO: namespace webhook-3499-markers deletion completed in 6.08364115s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.317 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:46:34.605: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:46:34.941: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:46:36.946: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134394, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134394, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134394, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134394, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:46:39.957: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Feb 24 09:46:43.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 attach --namespace=webhook-9151 to-be-attached-pod -i -c=container1'
Feb 24 09:46:44.051: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:46:44.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9151" for this suite.
Feb 24 09:46:56.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:46:56.135: INFO: namespace webhook-9151 deletion completed in 12.07670803s
STEP: Destroying namespace "webhook-9151-markers" for this suite.
Feb 24 09:47:02.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:47:02.236: INFO: namespace webhook-9151-markers deletion completed in 6.101806802s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:27.640 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:47:02.245: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-ba6c39b1-745d-440c-af5c-e77ed5264c99
STEP: Creating a pod to test consume configMaps
Feb 24 09:47:02.272: INFO: Waiting up to 5m0s for pod "pod-configmaps-b44d96ff-45ba-4ed3-8d63-44421b339b31" in namespace "configmap-1740" to be "success or failure"
Feb 24 09:47:02.279: INFO: Pod "pod-configmaps-b44d96ff-45ba-4ed3-8d63-44421b339b31": Phase="Pending", Reason="", readiness=false. Elapsed: 7.042306ms
Feb 24 09:47:04.281: INFO: Pod "pod-configmaps-b44d96ff-45ba-4ed3-8d63-44421b339b31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009038975s
STEP: Saw pod success
Feb 24 09:47:04.281: INFO: Pod "pod-configmaps-b44d96ff-45ba-4ed3-8d63-44421b339b31" satisfied condition "success or failure"
Feb 24 09:47:04.282: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-configmaps-b44d96ff-45ba-4ed3-8d63-44421b339b31 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 09:47:04.294: INFO: Waiting for pod pod-configmaps-b44d96ff-45ba-4ed3-8d63-44421b339b31 to disappear
Feb 24 09:47:04.297: INFO: Pod pod-configmaps-b44d96ff-45ba-4ed3-8d63-44421b339b31 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:47:04.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1740" for this suite.
Feb 24 09:47:10.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:47:10.376: INFO: namespace configmap-1740 deletion completed in 6.076612993s

• [SLOW TEST:8.130 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:47:10.376: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Feb 24 09:47:10.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=kubectl-3666 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 24 09:47:12.682: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 24 09:47:12.682: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:47:14.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3666" for this suite.
Feb 24 09:47:24.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:47:24.760: INFO: namespace kubectl-3666 deletion completed in 10.072168996s

• [SLOW TEST:14.384 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:47:24.760: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-1fba56c6-fa97-407e-a087-b8010d9a1188
STEP: Creating a pod to test consume configMaps
Feb 24 09:47:24.806: INFO: Waiting up to 5m0s for pod "pod-configmaps-524116bf-75e8-43f6-a8f4-dc70b7269fef" in namespace "configmap-6687" to be "success or failure"
Feb 24 09:47:24.814: INFO: Pod "pod-configmaps-524116bf-75e8-43f6-a8f4-dc70b7269fef": Phase="Pending", Reason="", readiness=false. Elapsed: 7.456224ms
Feb 24 09:47:26.816: INFO: Pod "pod-configmaps-524116bf-75e8-43f6-a8f4-dc70b7269fef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009528458s
STEP: Saw pod success
Feb 24 09:47:26.816: INFO: Pod "pod-configmaps-524116bf-75e8-43f6-a8f4-dc70b7269fef" satisfied condition "success or failure"
Feb 24 09:47:26.818: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-configmaps-524116bf-75e8-43f6-a8f4-dc70b7269fef container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 09:47:26.829: INFO: Waiting for pod pod-configmaps-524116bf-75e8-43f6-a8f4-dc70b7269fef to disappear
Feb 24 09:47:26.832: INFO: Pod pod-configmaps-524116bf-75e8-43f6-a8f4-dc70b7269fef no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:47:26.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6687" for this suite.
Feb 24 09:47:32.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:47:32.913: INFO: namespace configmap-6687 deletion completed in 6.074429763s

• [SLOW TEST:8.153 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:47:32.914: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-79843033-d320-4820-b318-7dd9ac26faa4
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:47:36.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4359" for this suite.
Feb 24 09:47:48.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:47:49.060: INFO: namespace configmap-4359 deletion completed in 12.079394934s

• [SLOW TEST:16.146 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:47:49.060: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-34fcda35-8c09-43ec-95db-9506f5f120ca
STEP: Creating a pod to test consume secrets
Feb 24 09:47:49.087: INFO: Waiting up to 5m0s for pod "pod-secrets-c93a0a2d-21d9-47a2-b091-1c18dca9d337" in namespace "secrets-7975" to be "success or failure"
Feb 24 09:47:49.100: INFO: Pod "pod-secrets-c93a0a2d-21d9-47a2-b091-1c18dca9d337": Phase="Pending", Reason="", readiness=false. Elapsed: 12.708474ms
Feb 24 09:47:51.102: INFO: Pod "pod-secrets-c93a0a2d-21d9-47a2-b091-1c18dca9d337": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014817273s
Feb 24 09:47:53.104: INFO: Pod "pod-secrets-c93a0a2d-21d9-47a2-b091-1c18dca9d337": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016943103s
STEP: Saw pod success
Feb 24 09:47:53.104: INFO: Pod "pod-secrets-c93a0a2d-21d9-47a2-b091-1c18dca9d337" satisfied condition "success or failure"
Feb 24 09:47:53.106: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-secrets-c93a0a2d-21d9-47a2-b091-1c18dca9d337 container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 09:47:53.118: INFO: Waiting for pod pod-secrets-c93a0a2d-21d9-47a2-b091-1c18dca9d337 to disappear
Feb 24 09:47:53.127: INFO: Pod pod-secrets-c93a0a2d-21d9-47a2-b091-1c18dca9d337 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:47:53.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7975" for this suite.
Feb 24 09:47:59.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:47:59.204: INFO: namespace secrets-7975 deletion completed in 6.075299944s

• [SLOW TEST:10.144 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:47:59.205: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Feb 24 09:48:39.246: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0224 09:48:39.246642      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:48:39.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-439" for this suite.
Feb 24 09:48:45.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:48:45.359: INFO: namespace gc-439 deletion completed in 6.110227931s

• [SLOW TEST:46.154 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:48:45.359: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:48:45.384: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 24 09:48:50.387: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 24 09:48:50.387: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 24 09:48:52.389: INFO: Creating deployment "test-rollover-deployment"
Feb 24 09:48:52.394: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 24 09:48:54.400: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 24 09:48:54.403: INFO: Ensure that both replica sets have 1 created replica
Feb 24 09:48:54.406: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 24 09:48:54.412: INFO: Updating deployment test-rollover-deployment
Feb 24 09:48:54.412: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 24 09:48:56.419: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 24 09:48:56.423: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 24 09:48:56.425: INFO: all replica sets need to contain the pod-template-hash label
Feb 24 09:48:56.425: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134534, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 09:48:58.430: INFO: all replica sets need to contain the pod-template-hash label
Feb 24 09:48:58.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134536, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 09:49:00.429: INFO: all replica sets need to contain the pod-template-hash label
Feb 24 09:49:00.429: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134536, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 09:49:02.429: INFO: all replica sets need to contain the pod-template-hash label
Feb 24 09:49:02.429: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134536, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 09:49:04.430: INFO: all replica sets need to contain the pod-template-hash label
Feb 24 09:49:04.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134536, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 09:49:06.429: INFO: all replica sets need to contain the pod-template-hash label
Feb 24 09:49:06.429: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134536, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718134532, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 09:49:08.429: INFO: 
Feb 24 09:49:08.429: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 24 09:49:08.434: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-161 /apis/apps/v1/namespaces/deployment-161/deployments/test-rollover-deployment b6a003a6-ed94-4365-8008-17855db9970a 25298 2 2020-02-24 09:48:52 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000f26338 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-24 09:48:52 +0000 UTC,LastTransitionTime:2020-02-24 09:48:52 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-02-24 09:49:06 +0000 UTC,LastTransitionTime:2020-02-24 09:48:52 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 24 09:49:08.436: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-161 /apis/apps/v1/namespaces/deployment-161/replicasets/test-rollover-deployment-7d7dc6548c 88922faf-ea56-4cf5-9c17-8002987bcf4a 25287 2 2020-02-24 09:48:54 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment b6a003a6-ed94-4365-8008-17855db9970a 0xc000f272b7 0xc000f272b8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000f27378 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 24 09:49:08.436: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 24 09:49:08.436: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-161 /apis/apps/v1/namespaces/deployment-161/replicasets/test-rollover-controller cb8f2541-bd4c-4694-a47c-ae2be5142e1a 25297 2 2020-02-24 09:48:45 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment b6a003a6-ed94-4365-8008-17855db9970a 0xc000f271d7 0xc000f271d8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc000f27248 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 09:49:08.437: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-161 /apis/apps/v1/namespaces/deployment-161/replicasets/test-rollover-deployment-f6c94f66c 3b7e49f7-1990-496b-8528-38342847e343 25241 2 2020-02-24 09:48:52 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment b6a003a6-ed94-4365-8008-17855db9970a 0xc000f273e0 0xc000f273e1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000f27458 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 09:49:08.439: INFO: Pod "test-rollover-deployment-7d7dc6548c-p652w" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-p652w test-rollover-deployment-7d7dc6548c- deployment-161 /api/v1/namespaces/deployment-161/pods/test-rollover-deployment-7d7dc6548c-p652w 3227f003-1270-4e9f-a400-4484db5539f8 25257 0 2020-02-24 09:48:54 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[cni.projectcalico.org/podIP:172.16.14.196/32] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 88922faf-ea56-4cf5-9c17-8002987bcf4a 0xc000f279e7 0xc000f279e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4rhzt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4rhzt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4rhzt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:48:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:48:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:48:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:48:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:172.16.14.196,StartTime:2020-02-24 09:48:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 09:48:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://d926de23e3e8ce1aeec0681304cfaa70dd89439442e62479f6a996aa4d1a9807,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.14.196,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:49:08.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-161" for this suite.
Feb 24 09:49:14.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:49:14.519: INFO: namespace deployment-161 deletion completed in 6.078435339s

• [SLOW TEST:29.161 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:49:14.519: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:49:31.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2985" for this suite.
Feb 24 09:49:37.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:49:37.667: INFO: namespace resourcequota-2985 deletion completed in 6.080575394s

• [SLOW TEST:23.148 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:49:37.667: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb 24 09:49:37.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-6621'
Feb 24 09:49:37.828: INFO: stderr: ""
Feb 24 09:49:37.829: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 24 09:49:38.831: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 09:49:38.831: INFO: Found 0 / 1
Feb 24 09:49:39.831: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 09:49:39.831: INFO: Found 0 / 1
Feb 24 09:49:40.831: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 09:49:40.831: INFO: Found 1 / 1
Feb 24 09:49:40.831: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 24 09:49:40.833: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 09:49:40.833: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 24 09:49:40.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 patch pod redis-master-967b9 --namespace=kubectl-6621 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 24 09:49:40.897: INFO: stderr: ""
Feb 24 09:49:40.897: INFO: stdout: "pod/redis-master-967b9 patched\n"
STEP: checking annotations
Feb 24 09:49:40.900: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 09:49:40.900: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:49:40.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6621" for this suite.
Feb 24 09:49:52.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:49:52.999: INFO: namespace kubectl-6621 deletion completed in 12.096652492s

• [SLOW TEST:15.332 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:49:52.999: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 24 09:49:53.019: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:49:57.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2558" for this suite.
Feb 24 09:50:03.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:50:03.137: INFO: namespace init-container-2558 deletion completed in 6.077490327s

• [SLOW TEST:10.138 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:50:03.138: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:50:14.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2479" for this suite.
Feb 24 09:50:20.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:50:20.337: INFO: namespace resourcequota-2479 deletion completed in 6.156685425s

• [SLOW TEST:17.199 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:50:20.337: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8433.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8433.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 24 09:50:24.436: INFO: DNS probes using dns-8433/dns-test-f4f3b115-044d-44ea-913b-e1996182aa7b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:50:24.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8433" for this suite.
Feb 24 09:50:30.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:50:30.527: INFO: namespace dns-8433 deletion completed in 6.079092418s

• [SLOW TEST:10.190 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:50:30.527: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 24 09:50:38.576: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 24 09:50:38.579: INFO: Pod pod-with-prestop-http-hook still exists
Feb 24 09:50:40.579: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 24 09:50:40.582: INFO: Pod pod-with-prestop-http-hook still exists
Feb 24 09:50:42.579: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 24 09:50:42.582: INFO: Pod pod-with-prestop-http-hook still exists
Feb 24 09:50:44.579: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 24 09:50:44.582: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:50:44.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8154" for this suite.
Feb 24 09:50:56.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:50:56.677: INFO: namespace container-lifecycle-hook-8154 deletion completed in 12.082929436s

• [SLOW TEST:26.150 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:50:56.677: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 24 09:51:01.716: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:51:01.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8129" for this suite.
Feb 24 09:51:29.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:51:29.830: INFO: namespace replicaset-8129 deletion completed in 28.0865803s

• [SLOW TEST:33.152 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:51:29.830: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-165
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-165
STEP: Creating statefulset with conflicting port in namespace statefulset-165
STEP: Waiting until pod test-pod will start running in namespace statefulset-165
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-165
Feb 24 09:51:33.874: INFO: Observed stateful pod in namespace: statefulset-165, name: ss-0, uid: f0201750-3ce2-48e3-8d62-eaa62c1613ec, status phase: Pending. Waiting for statefulset controller to delete.
Feb 24 09:51:34.267: INFO: Observed stateful pod in namespace: statefulset-165, name: ss-0, uid: f0201750-3ce2-48e3-8d62-eaa62c1613ec, status phase: Failed. Waiting for statefulset controller to delete.
Feb 24 09:51:34.271: INFO: Observed stateful pod in namespace: statefulset-165, name: ss-0, uid: f0201750-3ce2-48e3-8d62-eaa62c1613ec, status phase: Failed. Waiting for statefulset controller to delete.
Feb 24 09:51:34.276: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-165
STEP: Removing pod with conflicting port in namespace statefulset-165
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-165 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 09:51:38.297: INFO: Deleting all statefulset in ns statefulset-165
Feb 24 09:51:38.300: INFO: Scaling statefulset ss to 0
Feb 24 09:51:48.316: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 09:51:48.318: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:51:48.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-165" for this suite.
Feb 24 09:51:54.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:51:54.411: INFO: namespace statefulset-165 deletion completed in 6.083204134s

• [SLOW TEST:24.581 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:51:54.411: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Feb 24 09:51:54.431: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 24 09:52:54.444: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:52:54.446: INFO: Starting informer...
STEP: Starting pods...
Feb 24 09:52:54.656: INFO: Pod1 is running on ip-10-100-10-76.eu-west-1.compute.internal. Tainting Node
Feb 24 09:52:56.867: INFO: Pod2 is running on ip-10-100-10-76.eu-west-1.compute.internal. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Feb 24 09:53:03.884: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Feb 24 09:53:24.037: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:53:24.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-7791" for this suite.
Feb 24 09:53:30.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:53:30.174: INFO: namespace taint-multiple-pods-7791 deletion completed in 6.106760337s

• [SLOW TEST:95.763 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:53:30.174: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-1113
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1113 to expose endpoints map[]
Feb 24 09:53:30.209: INFO: successfully validated that service multi-endpoint-test in namespace services-1113 exposes endpoints map[] (3.741622ms elapsed)
STEP: Creating pod pod1 in namespace services-1113
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1113 to expose endpoints map[pod1:[100]]
Feb 24 09:53:32.234: INFO: successfully validated that service multi-endpoint-test in namespace services-1113 exposes endpoints map[pod1:[100]] (2.016020506s elapsed)
STEP: Creating pod pod2 in namespace services-1113
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1113 to expose endpoints map[pod1:[100] pod2:[101]]
Feb 24 09:53:35.267: INFO: successfully validated that service multi-endpoint-test in namespace services-1113 exposes endpoints map[pod1:[100] pod2:[101]] (3.031217103s elapsed)
STEP: Deleting pod pod1 in namespace services-1113
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1113 to expose endpoints map[pod2:[101]]
Feb 24 09:53:36.296: INFO: successfully validated that service multi-endpoint-test in namespace services-1113 exposes endpoints map[pod2:[101]] (1.022775026s elapsed)
STEP: Deleting pod pod2 in namespace services-1113
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1113 to expose endpoints map[]
Feb 24 09:53:36.305: INFO: successfully validated that service multi-endpoint-test in namespace services-1113 exposes endpoints map[] (1.927541ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:53:36.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1113" for this suite.
Feb 24 09:53:48.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:53:48.400: INFO: namespace services-1113 deletion completed in 12.074401299s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.225 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:53:48.400: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-69f32e4c-6507-4aeb-a9a2-e31b119ba04c
STEP: Creating a pod to test consume configMaps
Feb 24 09:53:48.476: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f26fcc0d-51cf-4e51-bc1e-cfc61965187e" in namespace "projected-7408" to be "success or failure"
Feb 24 09:53:48.485: INFO: Pod "pod-projected-configmaps-f26fcc0d-51cf-4e51-bc1e-cfc61965187e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.379191ms
Feb 24 09:53:50.488: INFO: Pod "pod-projected-configmaps-f26fcc0d-51cf-4e51-bc1e-cfc61965187e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011700272s
STEP: Saw pod success
Feb 24 09:53:50.488: INFO: Pod "pod-projected-configmaps-f26fcc0d-51cf-4e51-bc1e-cfc61965187e" satisfied condition "success or failure"
Feb 24 09:53:50.490: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-configmaps-f26fcc0d-51cf-4e51-bc1e-cfc61965187e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 09:53:50.509: INFO: Waiting for pod pod-projected-configmaps-f26fcc0d-51cf-4e51-bc1e-cfc61965187e to disappear
Feb 24 09:53:50.511: INFO: Pod pod-projected-configmaps-f26fcc0d-51cf-4e51-bc1e-cfc61965187e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:53:50.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7408" for this suite.
Feb 24 09:53:56.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:53:56.588: INFO: namespace projected-7408 deletion completed in 6.075474269s

• [SLOW TEST:8.189 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:53:56.589: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 24 09:53:56.613: INFO: Waiting up to 5m0s for pod "pod-1686ba7d-47eb-4a03-aa1e-507904cd2af2" in namespace "emptydir-3173" to be "success or failure"
Feb 24 09:53:56.616: INFO: Pod "pod-1686ba7d-47eb-4a03-aa1e-507904cd2af2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.645174ms
Feb 24 09:53:58.618: INFO: Pod "pod-1686ba7d-47eb-4a03-aa1e-507904cd2af2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004868987s
Feb 24 09:54:00.620: INFO: Pod "pod-1686ba7d-47eb-4a03-aa1e-507904cd2af2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007115448s
STEP: Saw pod success
Feb 24 09:54:00.621: INFO: Pod "pod-1686ba7d-47eb-4a03-aa1e-507904cd2af2" satisfied condition "success or failure"
Feb 24 09:54:00.622: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-1686ba7d-47eb-4a03-aa1e-507904cd2af2 container test-container: <nil>
STEP: delete the pod
Feb 24 09:54:00.635: INFO: Waiting for pod pod-1686ba7d-47eb-4a03-aa1e-507904cd2af2 to disappear
Feb 24 09:54:00.636: INFO: Pod pod-1686ba7d-47eb-4a03-aa1e-507904cd2af2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:54:00.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3173" for this suite.
Feb 24 09:54:06.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:54:06.713: INFO: namespace emptydir-3173 deletion completed in 6.075491282s

• [SLOW TEST:10.124 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:54:06.714: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 24 09:54:06.739: INFO: Waiting up to 5m0s for pod "pod-e6e8dad6-5a40-4c7a-8c26-daf7fcbed2ce" in namespace "emptydir-7654" to be "success or failure"
Feb 24 09:54:06.745: INFO: Pod "pod-e6e8dad6-5a40-4c7a-8c26-daf7fcbed2ce": Phase="Pending", Reason="", readiness=false. Elapsed: 5.802489ms
Feb 24 09:54:08.747: INFO: Pod "pod-e6e8dad6-5a40-4c7a-8c26-daf7fcbed2ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00795769s
STEP: Saw pod success
Feb 24 09:54:08.747: INFO: Pod "pod-e6e8dad6-5a40-4c7a-8c26-daf7fcbed2ce" satisfied condition "success or failure"
Feb 24 09:54:08.755: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-e6e8dad6-5a40-4c7a-8c26-daf7fcbed2ce container test-container: <nil>
STEP: delete the pod
Feb 24 09:54:08.768: INFO: Waiting for pod pod-e6e8dad6-5a40-4c7a-8c26-daf7fcbed2ce to disappear
Feb 24 09:54:08.769: INFO: Pod pod-e6e8dad6-5a40-4c7a-8c26-daf7fcbed2ce no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:54:08.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7654" for this suite.
Feb 24 09:54:14.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:54:14.845: INFO: namespace emptydir-7654 deletion completed in 6.073350729s

• [SLOW TEST:8.131 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:54:14.845: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:54:36.876: INFO: Container started at 2020-02-24 09:54:16 +0000 UTC, pod became ready at 2020-02-24 09:54:35 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:54:36.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8615" for this suite.
Feb 24 09:54:48.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:54:48.957: INFO: namespace container-probe-8615 deletion completed in 12.077897398s

• [SLOW TEST:34.111 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:54:48.957: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7098
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 24 09:54:48.976: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 24 09:55:13.029: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.14.222:8080/dial?request=hostName&protocol=http&host=172.16.145.154&port=8080&tries=1'] Namespace:pod-network-test-7098 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 09:55:13.029: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 09:55:13.168: INFO: Waiting for endpoints: map[]
Feb 24 09:55:13.170: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.14.222:8080/dial?request=hostName&protocol=http&host=172.16.14.225&port=8080&tries=1'] Namespace:pod-network-test-7098 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 09:55:13.170: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 09:55:13.320: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:55:13.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7098" for this suite.
Feb 24 09:55:25.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:55:25.400: INFO: namespace pod-network-test-7098 deletion completed in 12.07686085s

• [SLOW TEST:36.443 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:55:25.400: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8111
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8111
STEP: creating replication controller externalsvc in namespace services-8111
I0224 09:55:25.456390      21 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8111, replica count: 2
I0224 09:55:28.506683      21 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Feb 24 09:55:28.518: INFO: Creating new exec pod
Feb 24 09:55:32.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-8111 execpod2z6mt -- /bin/sh -x -c nslookup clusterip-service'
Feb 24 09:55:32.907: INFO: stderr: "+ nslookup clusterip-service\n"
Feb 24 09:55:32.907: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-8111.svc.cluster.local\tcanonical name = externalsvc.services-8111.svc.cluster.local.\nName:\texternalsvc.services-8111.svc.cluster.local\nAddress: 10.99.224.23\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8111, will wait for the garbage collector to delete the pods
Feb 24 09:55:32.980: INFO: Deleting ReplicationController externalsvc took: 4.077274ms
Feb 24 09:55:33.480: INFO: Terminating ReplicationController externalsvc pods took: 500.155884ms
Feb 24 09:55:43.400: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:55:43.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8111" for this suite.
Feb 24 09:55:49.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:55:49.504: INFO: namespace services-8111 deletion completed in 6.080896988s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:24.103 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:55:49.504: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Feb 24 09:55:49.531: INFO: Waiting up to 5m0s for pod "var-expansion-cde55eb2-5fe1-44f3-a664-5c03ae6e8713" in namespace "var-expansion-7094" to be "success or failure"
Feb 24 09:55:49.534: INFO: Pod "var-expansion-cde55eb2-5fe1-44f3-a664-5c03ae6e8713": Phase="Pending", Reason="", readiness=false. Elapsed: 2.974798ms
Feb 24 09:55:51.536: INFO: Pod "var-expansion-cde55eb2-5fe1-44f3-a664-5c03ae6e8713": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00506677s
Feb 24 09:55:53.539: INFO: Pod "var-expansion-cde55eb2-5fe1-44f3-a664-5c03ae6e8713": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007388167s
STEP: Saw pod success
Feb 24 09:55:53.539: INFO: Pod "var-expansion-cde55eb2-5fe1-44f3-a664-5c03ae6e8713" satisfied condition "success or failure"
Feb 24 09:55:53.541: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod var-expansion-cde55eb2-5fe1-44f3-a664-5c03ae6e8713 container dapi-container: <nil>
STEP: delete the pod
Feb 24 09:55:53.560: INFO: Waiting for pod var-expansion-cde55eb2-5fe1-44f3-a664-5c03ae6e8713 to disappear
Feb 24 09:55:53.562: INFO: Pod var-expansion-cde55eb2-5fe1-44f3-a664-5c03ae6e8713 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:55:53.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7094" for this suite.
Feb 24 09:55:59.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:55:59.641: INFO: namespace var-expansion-7094 deletion completed in 6.077005627s

• [SLOW TEST:10.137 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:55:59.641: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:55:59.667: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d8a14a0f-90b2-4066-81cc-a94942040c6f" in namespace "downward-api-6502" to be "success or failure"
Feb 24 09:55:59.677: INFO: Pod "downwardapi-volume-d8a14a0f-90b2-4066-81cc-a94942040c6f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.308543ms
Feb 24 09:56:01.679: INFO: Pod "downwardapi-volume-d8a14a0f-90b2-4066-81cc-a94942040c6f": Phase="Running", Reason="", readiness=true. Elapsed: 2.012210683s
Feb 24 09:56:03.681: INFO: Pod "downwardapi-volume-d8a14a0f-90b2-4066-81cc-a94942040c6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014241753s
STEP: Saw pod success
Feb 24 09:56:03.681: INFO: Pod "downwardapi-volume-d8a14a0f-90b2-4066-81cc-a94942040c6f" satisfied condition "success or failure"
Feb 24 09:56:03.683: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-d8a14a0f-90b2-4066-81cc-a94942040c6f container client-container: <nil>
STEP: delete the pod
Feb 24 09:56:03.697: INFO: Waiting for pod downwardapi-volume-d8a14a0f-90b2-4066-81cc-a94942040c6f to disappear
Feb 24 09:56:03.701: INFO: Pod downwardapi-volume-d8a14a0f-90b2-4066-81cc-a94942040c6f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:56:03.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6502" for this suite.
Feb 24 09:56:09.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:56:09.785: INFO: namespace downward-api-6502 deletion completed in 6.08227169s

• [SLOW TEST:10.145 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:56:09.786: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:56:09.805: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Feb 24 09:56:13.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-4764 create -f -'
Feb 24 09:56:13.579: INFO: stderr: ""
Feb 24 09:56:13.579: INFO: stdout: "e2e-test-crd-publish-openapi-2826-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 24 09:56:13.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-4764 delete e2e-test-crd-publish-openapi-2826-crds test-foo'
Feb 24 09:56:13.643: INFO: stderr: ""
Feb 24 09:56:13.643: INFO: stdout: "e2e-test-crd-publish-openapi-2826-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Feb 24 09:56:13.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-4764 apply -f -'
Feb 24 09:56:13.793: INFO: stderr: ""
Feb 24 09:56:13.793: INFO: stdout: "e2e-test-crd-publish-openapi-2826-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 24 09:56:13.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-4764 delete e2e-test-crd-publish-openapi-2826-crds test-foo'
Feb 24 09:56:13.854: INFO: stderr: ""
Feb 24 09:56:13.854: INFO: stdout: "e2e-test-crd-publish-openapi-2826-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Feb 24 09:56:13.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-4764 create -f -'
Feb 24 09:56:13.979: INFO: rc: 1
Feb 24 09:56:13.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-4764 apply -f -'
Feb 24 09:56:14.123: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Feb 24 09:56:14.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-4764 create -f -'
Feb 24 09:56:14.258: INFO: rc: 1
Feb 24 09:56:14.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-4764 apply -f -'
Feb 24 09:56:14.392: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Feb 24 09:56:14.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 explain e2e-test-crd-publish-openapi-2826-crds'
Feb 24 09:56:14.528: INFO: stderr: ""
Feb 24 09:56:14.528: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2826-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Feb 24 09:56:14.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 explain e2e-test-crd-publish-openapi-2826-crds.metadata'
Feb 24 09:56:14.664: INFO: stderr: ""
Feb 24 09:56:14.664: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2826-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Feb 24 09:56:14.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 explain e2e-test-crd-publish-openapi-2826-crds.spec'
Feb 24 09:56:14.798: INFO: stderr: ""
Feb 24 09:56:14.798: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2826-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Feb 24 09:56:14.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 explain e2e-test-crd-publish-openapi-2826-crds.spec.bars'
Feb 24 09:56:14.931: INFO: stderr: ""
Feb 24 09:56:14.931: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2826-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Feb 24 09:56:14.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 explain e2e-test-crd-publish-openapi-2826-crds.spec.bars2'
Feb 24 09:56:15.067: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:56:17.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4764" for this suite.
Feb 24 09:56:23.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:56:24.055: INFO: namespace crd-publish-openapi-4764 deletion completed in 6.073833597s

• [SLOW TEST:14.269 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:56:24.055: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Feb 24 09:56:28.104: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-533328996 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 24 09:56:38.164: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:56:38.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9918" for this suite.
Feb 24 09:56:44.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:56:44.245: INFO: namespace pods-9918 deletion completed in 6.076015982s

• [SLOW TEST:20.190 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:56:44.245: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:56:44.682: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:56:46.689: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135004, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135004, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135004, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135004, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:56:49.699: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:56:49.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3403" for this suite.
Feb 24 09:56:55.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:56:55.813: INFO: namespace webhook-3403 deletion completed in 6.07480338s
STEP: Destroying namespace "webhook-3403-markers" for this suite.
Feb 24 09:57:01.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:57:01.902: INFO: namespace webhook-3403-markers deletion completed in 6.089025516s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.664 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:57:01.909: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Feb 24 09:57:01.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 api-versions'
Feb 24 09:57:01.993: INFO: stderr: ""
Feb 24 09:57:01.993: INFO: stdout: "admission.certmanager.k8s.io/v1beta1\nadmissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncertmanager.k8s.io/v1alpha1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmonitoring.coreos.com/v1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\nvelero.io/v1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:57:01.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9707" for this suite.
Feb 24 09:57:08.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:57:08.070: INFO: namespace kubectl-9707 deletion completed in 6.07482103s

• [SLOW TEST:6.161 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:57:08.071: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-p4pn
STEP: Creating a pod to test atomic-volume-subpath
Feb 24 09:57:08.103: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-p4pn" in namespace "subpath-1691" to be "success or failure"
Feb 24 09:57:08.106: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Pending", Reason="", readiness=false. Elapsed: 3.418871ms
Feb 24 09:57:10.108: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Running", Reason="", readiness=true. Elapsed: 2.005615055s
Feb 24 09:57:12.111: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Running", Reason="", readiness=true. Elapsed: 4.008205234s
Feb 24 09:57:14.113: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Running", Reason="", readiness=true. Elapsed: 6.010337106s
Feb 24 09:57:16.115: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Running", Reason="", readiness=true. Elapsed: 8.01233308s
Feb 24 09:57:18.117: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Running", Reason="", readiness=true. Elapsed: 10.014404864s
Feb 24 09:57:20.119: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Running", Reason="", readiness=true. Elapsed: 12.016434678s
Feb 24 09:57:22.121: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Running", Reason="", readiness=true. Elapsed: 14.018607019s
Feb 24 09:57:24.123: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Running", Reason="", readiness=true. Elapsed: 16.020639975s
Feb 24 09:57:26.125: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Running", Reason="", readiness=true. Elapsed: 18.02285941s
Feb 24 09:57:28.128: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Running", Reason="", readiness=true. Elapsed: 20.024982706s
Feb 24 09:57:30.130: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Running", Reason="", readiness=true. Elapsed: 22.027037035s
Feb 24 09:57:32.132: INFO: Pod "pod-subpath-test-configmap-p4pn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.029048779s
STEP: Saw pod success
Feb 24 09:57:32.132: INFO: Pod "pod-subpath-test-configmap-p4pn" satisfied condition "success or failure"
Feb 24 09:57:32.133: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-subpath-test-configmap-p4pn container test-container-subpath-configmap-p4pn: <nil>
STEP: delete the pod
Feb 24 09:57:32.146: INFO: Waiting for pod pod-subpath-test-configmap-p4pn to disappear
Feb 24 09:57:32.147: INFO: Pod pod-subpath-test-configmap-p4pn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-p4pn
Feb 24 09:57:32.147: INFO: Deleting pod "pod-subpath-test-configmap-p4pn" in namespace "subpath-1691"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:57:32.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1691" for this suite.
Feb 24 09:57:38.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:57:38.225: INFO: namespace subpath-1691 deletion completed in 6.074655541s

• [SLOW TEST:30.154 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:57:38.226: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3681
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-3681
I0224 09:57:38.275363      21 runners.go:184] Created replication controller with name: externalname-service, namespace: services-3681, replica count: 2
Feb 24 09:57:41.325: INFO: Creating new exec pod
I0224 09:57:41.325680      21 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 24 09:57:46.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-3681 execpodnt76v -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 24 09:57:46.533: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 24 09:57:46.533: INFO: stdout: ""
Feb 24 09:57:46.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-3681 execpodnt76v -- /bin/sh -x -c nc -zv -t -w 2 10.110.186.225 80'
Feb 24 09:57:46.727: INFO: stderr: "+ nc -zv -t -w 2 10.110.186.225 80\nConnection to 10.110.186.225 80 port [tcp/http] succeeded!\n"
Feb 24 09:57:46.727: INFO: stdout: ""
Feb 24 09:57:46.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-3681 execpodnt76v -- /bin/sh -x -c nc -zv -t -w 2 10.100.10.135 32160'
Feb 24 09:57:46.925: INFO: stderr: "+ nc -zv -t -w 2 10.100.10.135 32160\nConnection to 10.100.10.135 32160 port [tcp/32160] succeeded!\n"
Feb 24 09:57:46.925: INFO: stdout: ""
Feb 24 09:57:46.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-3681 execpodnt76v -- /bin/sh -x -c nc -zv -t -w 2 10.100.10.76 32160'
Feb 24 09:57:47.120: INFO: stderr: "+ nc -zv -t -w 2 10.100.10.76 32160\nConnection to 10.100.10.76 32160 port [tcp/32160] succeeded!\n"
Feb 24 09:57:47.120: INFO: stdout: ""
Feb 24 09:57:47.120: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:57:47.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3681" for this suite.
Feb 24 09:57:53.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:57:53.244: INFO: namespace services-3681 deletion completed in 6.095700073s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.018 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:57:53.244: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:57:53.270: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2316f003-0238-4fc2-84dd-449bef531d63" in namespace "projected-771" to be "success or failure"
Feb 24 09:57:53.274: INFO: Pod "downwardapi-volume-2316f003-0238-4fc2-84dd-449bef531d63": Phase="Pending", Reason="", readiness=false. Elapsed: 3.450932ms
Feb 24 09:57:55.278: INFO: Pod "downwardapi-volume-2316f003-0238-4fc2-84dd-449bef531d63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007385722s
STEP: Saw pod success
Feb 24 09:57:55.278: INFO: Pod "downwardapi-volume-2316f003-0238-4fc2-84dd-449bef531d63" satisfied condition "success or failure"
Feb 24 09:57:55.281: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-2316f003-0238-4fc2-84dd-449bef531d63 container client-container: <nil>
STEP: delete the pod
Feb 24 09:57:55.296: INFO: Waiting for pod downwardapi-volume-2316f003-0238-4fc2-84dd-449bef531d63 to disappear
Feb 24 09:57:55.298: INFO: Pod downwardapi-volume-2316f003-0238-4fc2-84dd-449bef531d63 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:57:55.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-771" for this suite.
Feb 24 09:58:01.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:58:01.380: INFO: namespace projected-771 deletion completed in 6.079299478s

• [SLOW TEST:8.136 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:58:01.380: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:58:01.823: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Feb 24 09:58:03.828: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135081, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135081, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135081, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135081, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:58:06.839: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:58:06.841: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:58:07.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2431" for this suite.
Feb 24 09:58:13.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:58:14.060: INFO: namespace crd-webhook-2431 deletion completed in 6.08007686s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:12.688 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:58:14.069: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-5308f2c2-7661-4f55-a6d4-698e3d080f28
STEP: Creating a pod to test consume secrets
Feb 24 09:58:14.101: INFO: Waiting up to 5m0s for pod "pod-secrets-5dfcd8c3-3718-466b-b462-1c2be85be11a" in namespace "secrets-5101" to be "success or failure"
Feb 24 09:58:14.113: INFO: Pod "pod-secrets-5dfcd8c3-3718-466b-b462-1c2be85be11a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.82728ms
Feb 24 09:58:16.115: INFO: Pod "pod-secrets-5dfcd8c3-3718-466b-b462-1c2be85be11a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013850162s
STEP: Saw pod success
Feb 24 09:58:16.115: INFO: Pod "pod-secrets-5dfcd8c3-3718-466b-b462-1c2be85be11a" satisfied condition "success or failure"
Feb 24 09:58:16.117: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-secrets-5dfcd8c3-3718-466b-b462-1c2be85be11a container secret-env-test: <nil>
STEP: delete the pod
Feb 24 09:58:16.131: INFO: Waiting for pod pod-secrets-5dfcd8c3-3718-466b-b462-1c2be85be11a to disappear
Feb 24 09:58:16.132: INFO: Pod pod-secrets-5dfcd8c3-3718-466b-b462-1c2be85be11a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:58:16.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5101" for this suite.
Feb 24 09:58:22.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:58:22.211: INFO: namespace secrets-5101 deletion completed in 6.076462796s

• [SLOW TEST:8.143 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:58:22.211: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:58:22.236: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f082db8f-43dd-4479-8f27-c3d8223d3514" in namespace "projected-2540" to be "success or failure"
Feb 24 09:58:22.242: INFO: Pod "downwardapi-volume-f082db8f-43dd-4479-8f27-c3d8223d3514": Phase="Pending", Reason="", readiness=false. Elapsed: 6.588019ms
Feb 24 09:58:24.246: INFO: Pod "downwardapi-volume-f082db8f-43dd-4479-8f27-c3d8223d3514": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010504276s
STEP: Saw pod success
Feb 24 09:58:24.246: INFO: Pod "downwardapi-volume-f082db8f-43dd-4479-8f27-c3d8223d3514" satisfied condition "success or failure"
Feb 24 09:58:24.248: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-f082db8f-43dd-4479-8f27-c3d8223d3514 container client-container: <nil>
STEP: delete the pod
Feb 24 09:58:24.263: INFO: Waiting for pod downwardapi-volume-f082db8f-43dd-4479-8f27-c3d8223d3514 to disappear
Feb 24 09:58:24.265: INFO: Pod downwardapi-volume-f082db8f-43dd-4479-8f27-c3d8223d3514 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:58:24.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2540" for this suite.
Feb 24 09:58:30.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:58:30.342: INFO: namespace projected-2540 deletion completed in 6.074981611s

• [SLOW TEST:8.131 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:58:30.342: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Feb 24 09:58:30.366: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-7151" to be "success or failure"
Feb 24 09:58:30.369: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.557228ms
Feb 24 09:58:32.371: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004584561s
STEP: Saw pod success
Feb 24 09:58:32.371: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 24 09:58:32.372: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 24 09:58:32.385: INFO: Waiting for pod pod-host-path-test to disappear
Feb 24 09:58:32.387: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:58:32.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-7151" for this suite.
Feb 24 09:58:38.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:58:38.470: INFO: namespace hostpath-7151 deletion completed in 6.080823661s

• [SLOW TEST:8.128 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:58:38.471: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 09:58:38.908: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 09:58:40.914: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135118, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135118, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135118, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135118, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 09:58:43.924: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:58:43.926: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7727-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:58:45.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5077" for this suite.
Feb 24 09:58:51.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:58:51.110: INFO: namespace webhook-5077 deletion completed in 6.077869452s
STEP: Destroying namespace "webhook-5077-markers" for this suite.
Feb 24 09:58:57.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:58:57.182: INFO: namespace webhook-5077-markers deletion completed in 6.072757572s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.719 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:58:57.190: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 09:58:57.219: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54303424-4573-4c9f-8447-cf1bb3bf4ea1" in namespace "downward-api-2538" to be "success or failure"
Feb 24 09:58:57.236: INFO: Pod "downwardapi-volume-54303424-4573-4c9f-8447-cf1bb3bf4ea1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.358518ms
Feb 24 09:58:59.239: INFO: Pod "downwardapi-volume-54303424-4573-4c9f-8447-cf1bb3bf4ea1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019863703s
STEP: Saw pod success
Feb 24 09:58:59.239: INFO: Pod "downwardapi-volume-54303424-4573-4c9f-8447-cf1bb3bf4ea1" satisfied condition "success or failure"
Feb 24 09:58:59.241: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-54303424-4573-4c9f-8447-cf1bb3bf4ea1 container client-container: <nil>
STEP: delete the pod
Feb 24 09:58:59.256: INFO: Waiting for pod downwardapi-volume-54303424-4573-4c9f-8447-cf1bb3bf4ea1 to disappear
Feb 24 09:58:59.258: INFO: Pod downwardapi-volume-54303424-4573-4c9f-8447-cf1bb3bf4ea1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:58:59.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2538" for this suite.
Feb 24 09:59:05.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:59:05.349: INFO: namespace downward-api-2538 deletion completed in 6.089289662s

• [SLOW TEST:8.159 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:59:05.349: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-98137374-804e-42de-9f2a-f46d4e250bb1 in namespace container-probe-3679
Feb 24 09:59:09.389: INFO: Started pod liveness-98137374-804e-42de-9f2a-f46d4e250bb1 in namespace container-probe-3679
STEP: checking the pod's current state and verifying that restartCount is present
Feb 24 09:59:09.391: INFO: Initial restart count of pod liveness-98137374-804e-42de-9f2a-f46d4e250bb1 is 0
Feb 24 09:59:27.412: INFO: Restart count of pod container-probe-3679/liveness-98137374-804e-42de-9f2a-f46d4e250bb1 is now 1 (18.020999028s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:59:27.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3679" for this suite.
Feb 24 09:59:33.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:59:33.670: INFO: namespace container-probe-3679 deletion completed in 6.24537233s

• [SLOW TEST:28.322 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:59:33.671: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 24 09:59:33.698: INFO: Waiting up to 5m0s for pod "downward-api-0a2f52b1-bb88-4466-a0e2-2b18d9a273f8" in namespace "downward-api-3613" to be "success or failure"
Feb 24 09:59:33.700: INFO: Pod "downward-api-0a2f52b1-bb88-4466-a0e2-2b18d9a273f8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.710317ms
Feb 24 09:59:35.702: INFO: Pod "downward-api-0a2f52b1-bb88-4466-a0e2-2b18d9a273f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003989034s
STEP: Saw pod success
Feb 24 09:59:35.702: INFO: Pod "downward-api-0a2f52b1-bb88-4466-a0e2-2b18d9a273f8" satisfied condition "success or failure"
Feb 24 09:59:35.704: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downward-api-0a2f52b1-bb88-4466-a0e2-2b18d9a273f8 container dapi-container: <nil>
STEP: delete the pod
Feb 24 09:59:35.717: INFO: Waiting for pod downward-api-0a2f52b1-bb88-4466-a0e2-2b18d9a273f8 to disappear
Feb 24 09:59:35.719: INFO: Pod downward-api-0a2f52b1-bb88-4466-a0e2-2b18d9a273f8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:59:35.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3613" for this suite.
Feb 24 09:59:41.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:59:41.794: INFO: namespace downward-api-3613 deletion completed in 6.073001184s

• [SLOW TEST:8.124 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:59:41.795: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 09:59:41.814: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 24 09:59:41.820: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 24 09:59:46.823: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 24 09:59:46.823: INFO: Creating deployment "test-rolling-update-deployment"
Feb 24 09:59:46.825: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 24 09:59:46.830: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 24 09:59:48.837: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 24 09:59:48.842: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135186, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135186, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135186, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135186, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 09:59:50.844: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 24 09:59:50.849: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2257 /apis/apps/v1/namespaces/deployment-2257/deployments/test-rolling-update-deployment 27ff30fe-4023-483d-b8c1-2033e0532fdd 28795 1 2020-02-24 09:59:46 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0069b17e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-24 09:59:46 +0000 UTC,LastTransitionTime:2020-02-24 09:59:46 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-02-24 09:59:48 +0000 UTC,LastTransitionTime:2020-02-24 09:59:46 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 24 09:59:50.851: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-2257 /apis/apps/v1/namespaces/deployment-2257/replicasets/test-rolling-update-deployment-55d946486 3b20e26e-df26-4d86-a7f5-ec060daf9ef8 28785 1 2020-02-24 09:59:46 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 27ff30fe-4023-483d-b8c1-2033e0532fdd 0xc0069b1cc0 0xc0069b1cc1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0069b1d28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 24 09:59:50.851: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 24 09:59:50.851: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2257 /apis/apps/v1/namespaces/deployment-2257/replicasets/test-rolling-update-controller 9d8818ea-1dd6-43a8-b432-3d84bb3e5b9f 28794 2 2020-02-24 09:59:41 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 27ff30fe-4023-483d-b8c1-2033e0532fdd 0xc0069b1bf7 0xc0069b1bf8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0069b1c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 09:59:50.853: INFO: Pod "test-rolling-update-deployment-55d946486-kqb25" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-kqb25 test-rolling-update-deployment-55d946486- deployment-2257 /api/v1/namespaces/deployment-2257/pods/test-rolling-update-deployment-55d946486-kqb25 f2606de0-a589-4a2a-a5b8-cfe98ea4918e 28784 0 2020-02-24 09:59:46 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[cni.projectcalico.org/podIP:172.16.14.246/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 3b20e26e-df26-4d86-a7f5-ec060daf9ef8 0xc00379ab80 0xc00379ab81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mqqcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mqqcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mqqcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:59:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:59:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:59:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 09:59:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:172.16.14.246,StartTime:2020-02-24 09:59:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 09:59:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://63e169a1ce3a28eca6b22d7d2d59b69f538372b81ba13ae9ddf7cc806c8f0c86,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.14.246,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 09:59:50.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2257" for this suite.
Feb 24 09:59:56.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 09:59:56.928: INFO: namespace deployment-2257 deletion completed in 6.073102304s

• [SLOW TEST:15.134 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 09:59:56.929: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-949b6a4e-fa8a-48d7-b500-e8e9a95f6e86
Feb 24 09:59:56.953: INFO: Pod name my-hostname-basic-949b6a4e-fa8a-48d7-b500-e8e9a95f6e86: Found 0 pods out of 1
Feb 24 10:00:01.955: INFO: Pod name my-hostname-basic-949b6a4e-fa8a-48d7-b500-e8e9a95f6e86: Found 1 pods out of 1
Feb 24 10:00:01.955: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-949b6a4e-fa8a-48d7-b500-e8e9a95f6e86" are running
Feb 24 10:00:01.957: INFO: Pod "my-hostname-basic-949b6a4e-fa8a-48d7-b500-e8e9a95f6e86-fmcv4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 09:59:56 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 09:59:58 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 09:59:58 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-24 09:59:56 +0000 UTC Reason: Message:}])
Feb 24 10:00:01.957: INFO: Trying to dial the pod
Feb 24 10:00:06.962: INFO: Controller my-hostname-basic-949b6a4e-fa8a-48d7-b500-e8e9a95f6e86: Got expected result from replica 1 [my-hostname-basic-949b6a4e-fa8a-48d7-b500-e8e9a95f6e86-fmcv4]: "my-hostname-basic-949b6a4e-fa8a-48d7-b500-e8e9a95f6e86-fmcv4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:00:06.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7294" for this suite.
Feb 24 10:00:12.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:00:13.039: INFO: namespace replication-controller-7294 deletion completed in 6.074622624s

• [SLOW TEST:16.111 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:00:13.040: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-b07190f3-e67b-4091-a9a2-cf0be5fb4841
STEP: Creating a pod to test consume secrets
Feb 24 10:00:13.068: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-83c3dc0b-f52c-44d9-821f-e658ab7985ff" in namespace "projected-6459" to be "success or failure"
Feb 24 10:00:13.077: INFO: Pod "pod-projected-secrets-83c3dc0b-f52c-44d9-821f-e658ab7985ff": Phase="Pending", Reason="", readiness=false. Elapsed: 8.292692ms
Feb 24 10:00:15.079: INFO: Pod "pod-projected-secrets-83c3dc0b-f52c-44d9-821f-e658ab7985ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01058174s
Feb 24 10:00:17.081: INFO: Pod "pod-projected-secrets-83c3dc0b-f52c-44d9-821f-e658ab7985ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012715844s
STEP: Saw pod success
Feb 24 10:00:17.081: INFO: Pod "pod-projected-secrets-83c3dc0b-f52c-44d9-821f-e658ab7985ff" satisfied condition "success or failure"
Feb 24 10:00:17.083: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-secrets-83c3dc0b-f52c-44d9-821f-e658ab7985ff container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 24 10:00:17.094: INFO: Waiting for pod pod-projected-secrets-83c3dc0b-f52c-44d9-821f-e658ab7985ff to disappear
Feb 24 10:00:17.096: INFO: Pod pod-projected-secrets-83c3dc0b-f52c-44d9-821f-e658ab7985ff no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:00:17.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6459" for this suite.
Feb 24 10:00:23.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:00:23.175: INFO: namespace projected-6459 deletion completed in 6.075882924s

• [SLOW TEST:10.135 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:00:23.175: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2354
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb 24 10:00:23.207: INFO: Found 0 stateful pods, waiting for 3
Feb 24 10:00:33.209: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 10:00:33.210: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 10:00:33.210: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb 24 10:00:33.229: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 24 10:00:43.258: INFO: Updating stateful set ss2
Feb 24 10:00:43.270: INFO: Waiting for Pod statefulset-2354/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Feb 24 10:00:53.319: INFO: Found 2 stateful pods, waiting for 3
Feb 24 10:01:03.322: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 10:01:03.322: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 24 10:01:03.322: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 24 10:01:03.340: INFO: Updating stateful set ss2
Feb 24 10:01:03.356: INFO: Waiting for Pod statefulset-2354/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 24 10:01:13.375: INFO: Updating stateful set ss2
Feb 24 10:01:13.381: INFO: Waiting for StatefulSet statefulset-2354/ss2 to complete update
Feb 24 10:01:13.381: INFO: Waiting for Pod statefulset-2354/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 10:01:23.385: INFO: Deleting all statefulset in ns statefulset-2354
Feb 24 10:01:23.387: INFO: Scaling statefulset ss2 to 0
Feb 24 10:01:33.398: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 10:01:33.400: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:01:33.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2354" for this suite.
Feb 24 10:01:39.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:01:39.496: INFO: namespace statefulset-2354 deletion completed in 6.084209045s

• [SLOW TEST:76.322 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:01:39.497: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Feb 24 10:01:45.536: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:01:45.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0224 10:01:45.536369      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-4850" for this suite.
Feb 24 10:01:51.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:01:51.627: INFO: namespace gc-4850 deletion completed in 6.087560131s

• [SLOW TEST:12.130 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:01:51.628: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 24 10:01:51.657: INFO: Waiting up to 5m0s for pod "pod-d25560fc-625e-4e1f-9f6e-b991deef544c" in namespace "emptydir-2575" to be "success or failure"
Feb 24 10:01:51.665: INFO: Pod "pod-d25560fc-625e-4e1f-9f6e-b991deef544c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.503642ms
Feb 24 10:01:53.667: INFO: Pod "pod-d25560fc-625e-4e1f-9f6e-b991deef544c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010515002s
Feb 24 10:01:55.669: INFO: Pod "pod-d25560fc-625e-4e1f-9f6e-b991deef544c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012514327s
STEP: Saw pod success
Feb 24 10:01:55.669: INFO: Pod "pod-d25560fc-625e-4e1f-9f6e-b991deef544c" satisfied condition "success or failure"
Feb 24 10:01:55.671: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-d25560fc-625e-4e1f-9f6e-b991deef544c container test-container: <nil>
STEP: delete the pod
Feb 24 10:01:55.690: INFO: Waiting for pod pod-d25560fc-625e-4e1f-9f6e-b991deef544c to disappear
Feb 24 10:01:55.691: INFO: Pod pod-d25560fc-625e-4e1f-9f6e-b991deef544c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:01:55.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2575" for this suite.
Feb 24 10:02:01.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:02:01.773: INFO: namespace emptydir-2575 deletion completed in 6.077721816s

• [SLOW TEST:10.145 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:02:01.773: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 24 10:02:01.794: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 24 10:02:01.801: INFO: Waiting for terminating namespaces to be deleted...
Feb 24 10:02:01.804: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-135.eu-west-1.compute.internal before test
Feb 24 10:02:01.818: INFO: calico-node-phn96 from kube-system started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container calico-node ready: true, restart count 0
Feb 24 10:02:01.819: INFO: minio-0 from kube-system started at 2020-02-24 08:34:46 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container minio ready: true, restart count 0
Feb 24 10:02:01.819: INFO: minio-setup-j6w9s from kube-system started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container mc ready: false, restart count 2
Feb 24 10:02:01.819: INFO: cert-manager-54bb694dc-hhltb from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container cert-manager ready: true, restart count 0
Feb 24 10:02:01.819: INFO: elasticsearch-0 from logging started at 2020-02-24 08:34:47 +0000 UTC (2 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container elasticsearch ready: true, restart count 0
Feb 24 10:02:01.819: INFO: 	Container exporter ready: true, restart count 0
Feb 24 10:02:01.819: INFO: sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-rzsmv from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 24 10:02:01.819: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 10:02:01.819: INFO: kube-proxy-wpbzf from kube-system started at 2020-02-24 08:25:43 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 10:02:01.819: INFO: velero-restic-rx97v from kube-system started at 2020-02-24 08:33:05 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container restic ready: true, restart count 0
Feb 24 10:02:01.819: INFO: prometheus-operator-748c7fffd8-68gvp from monitoring started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb 24 10:02:01.819: INFO: velero-79446c99cd-b99nf from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container velero ready: true, restart count 0
Feb 24 10:02:01.819: INFO: fluentd-64hh4 from logging started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container fluentd ready: true, restart count 0
Feb 24 10:02:01.819: INFO: nginx-ingress-controller-wgp6c from ingress-nginx started at 2020-02-24 08:33:05 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 24 10:02:01.819: INFO: kibana-756b6ddfcd-4s9ml from logging started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container kibana ready: true, restart count 0
Feb 24 10:02:01.819: INFO: cerebro-d67c8c48-xs4h6 from logging started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container cerebro ready: true, restart count 0
Feb 24 10:02:01.819: INFO: coredns-5644d7b6d9-p22w4 from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container coredns ready: true, restart count 0
Feb 24 10:02:01.819: INFO: calico-kube-controllers-655bb9f786-gx8ws from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 24 10:02:01.819: INFO: forecastle-744778954f-xqj69 from ingress-nginx started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container forecastle ready: true, restart count 0
Feb 24 10:02:01.819: INFO: cert-manager-cainjector-898cb7556-ff586 from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container cainjector ready: true, restart count 0
Feb 24 10:02:01.819: INFO: kube-state-metrics-58f8cfc86c-cn6fm from monitoring started at 2020-02-24 08:33:09 +0000 UTC (2 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 24 10:02:01.819: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 24 10:02:01.819: INFO: node-exporter-hn87r from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container node-exporter ready: true, restart count 0
Feb 24 10:02:01.819: INFO: grafana-864bdcc8d4-qrbtv from monitoring started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container grafana ready: true, restart count 0
Feb 24 10:02:01.819: INFO: local-path-provisioner-58b55cb6b6-vnzz8 from local-path-storage started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container local-path-provisioner ready: true, restart count 0
Feb 24 10:02:01.819: INFO: coredns-5644d7b6d9-n6pvc from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container coredns ready: true, restart count 0
Feb 24 10:02:01.819: INFO: cert-manager-webhook-b65959699-5bd7k from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container webhook ready: true, restart count 0
Feb 24 10:02:01.819: INFO: goldpinger-kmzxp from monitoring started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.819: INFO: 	Container goldpinger ready: true, restart count 0
Feb 24 10:02:01.819: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-76.eu-west-1.compute.internal before test
Feb 24 10:02:01.826: INFO: kube-proxy-59p45 from kube-system started at 2020-02-24 08:25:43 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.826: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 10:02:01.826: INFO: node-exporter-cbcbp from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.826: INFO: 	Container node-exporter ready: true, restart count 0
Feb 24 10:02:01.826: INFO: velero-restic-v74rb from kube-system started at 2020-02-24 09:53:24 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.826: INFO: 	Container restic ready: true, restart count 0
Feb 24 10:02:01.826: INFO: calico-node-66z5c from kube-system started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.826: INFO: 	Container calico-node ready: true, restart count 0
Feb 24 10:02:01.826: INFO: goldpinger-c9h65 from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.826: INFO: 	Container goldpinger ready: true, restart count 0
Feb 24 10:02:01.826: INFO: sonobuoy from sonobuoy started at 2020-02-24 08:38:00 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.826: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 24 10:02:01.826: INFO: nginx-ingress-controller-mz97z from ingress-nginx started at 2020-02-24 09:53:24 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.826: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 24 10:02:01.826: INFO: prometheus-k8s-0 from monitoring started at 2020-02-24 09:53:32 +0000 UTC (3 container statuses recorded)
Feb 24 10:02:01.826: INFO: 	Container prometheus ready: true, restart count 0
Feb 24 10:02:01.826: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb 24 10:02:01.826: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Feb 24 10:02:01.826: INFO: sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-7vc7s from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:02:01.826: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 24 10:02:01.827: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 10:02:01.827: INFO: fluentd-47t8s from logging started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:02:01.827: INFO: 	Container fluentd ready: true, restart count 0
Feb 24 10:02:01.827: INFO: sonobuoy-e2e-job-e55756929f3b41bc from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:02:01.827: INFO: 	Container e2e ready: true, restart count 0
Feb 24 10:02:01.827: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f64e66a5e3d9f7], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:02:02.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9153" for this suite.
Feb 24 10:02:08.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:02:08.942: INFO: namespace sched-pred-9153 deletion completed in 6.085981221s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.169 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:02:08.942: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 24 10:02:09.134: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-a 5f573b5b-1285-4346-a01f-9c6b9b6c0c50 29921 0 2020-02-24 10:02:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 24 10:02:09.134: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-a 5f573b5b-1285-4346-a01f-9c6b9b6c0c50 29921 0 2020-02-24 10:02:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 24 10:02:19.140: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-a 5f573b5b-1285-4346-a01f-9c6b9b6c0c50 29947 0 2020-02-24 10:02:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 24 10:02:19.140: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-a 5f573b5b-1285-4346-a01f-9c6b9b6c0c50 29947 0 2020-02-24 10:02:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 24 10:02:29.144: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-a 5f573b5b-1285-4346-a01f-9c6b9b6c0c50 29974 0 2020-02-24 10:02:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 24 10:02:29.145: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-a 5f573b5b-1285-4346-a01f-9c6b9b6c0c50 29974 0 2020-02-24 10:02:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 24 10:02:39.149: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-a 5f573b5b-1285-4346-a01f-9c6b9b6c0c50 30003 0 2020-02-24 10:02:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 24 10:02:39.149: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-a 5f573b5b-1285-4346-a01f-9c6b9b6c0c50 30003 0 2020-02-24 10:02:09 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 24 10:02:49.154: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-b 51f5abc6-4410-4963-9fd0-d132ab8b87d4 30029 0 2020-02-24 10:02:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 24 10:02:49.154: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-b 51f5abc6-4410-4963-9fd0-d132ab8b87d4 30029 0 2020-02-24 10:02:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 24 10:02:59.158: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-b 51f5abc6-4410-4963-9fd0-d132ab8b87d4 30058 0 2020-02-24 10:02:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 24 10:02:59.158: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-922 /api/v1/namespaces/watch-922/configmaps/e2e-watch-test-configmap-b 51f5abc6-4410-4963-9fd0-d132ab8b87d4 30058 0 2020-02-24 10:02:49 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:03:09.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-922" for this suite.
Feb 24 10:03:15.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:03:15.291: INFO: namespace watch-922 deletion completed in 6.12961885s

• [SLOW TEST:66.349 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:03:15.291: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 24 10:03:15.328: INFO: Waiting up to 5m0s for pod "downward-api-4d76f8c2-77b4-4b96-9039-0d61c10ed61c" in namespace "downward-api-7574" to be "success or failure"
Feb 24 10:03:15.338: INFO: Pod "downward-api-4d76f8c2-77b4-4b96-9039-0d61c10ed61c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.402257ms
Feb 24 10:03:17.340: INFO: Pod "downward-api-4d76f8c2-77b4-4b96-9039-0d61c10ed61c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012380251s
Feb 24 10:03:19.342: INFO: Pod "downward-api-4d76f8c2-77b4-4b96-9039-0d61c10ed61c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014598691s
STEP: Saw pod success
Feb 24 10:03:19.342: INFO: Pod "downward-api-4d76f8c2-77b4-4b96-9039-0d61c10ed61c" satisfied condition "success or failure"
Feb 24 10:03:19.344: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downward-api-4d76f8c2-77b4-4b96-9039-0d61c10ed61c container dapi-container: <nil>
STEP: delete the pod
Feb 24 10:03:19.362: INFO: Waiting for pod downward-api-4d76f8c2-77b4-4b96-9039-0d61c10ed61c to disappear
Feb 24 10:03:19.364: INFO: Pod downward-api-4d76f8c2-77b4-4b96-9039-0d61c10ed61c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:03:19.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7574" for this suite.
Feb 24 10:03:25.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:03:25.440: INFO: namespace downward-api-7574 deletion completed in 6.073712026s

• [SLOW TEST:10.149 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:03:25.440: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-7931c9eb-bb92-43b0-afe3-2efe7ccc6d9f
STEP: Creating a pod to test consume configMaps
Feb 24 10:03:25.475: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9c24bd40-3c7a-4f9d-9d16-40ab7d2b0821" in namespace "projected-4196" to be "success or failure"
Feb 24 10:03:25.482: INFO: Pod "pod-projected-configmaps-9c24bd40-3c7a-4f9d-9d16-40ab7d2b0821": Phase="Pending", Reason="", readiness=false. Elapsed: 6.557965ms
Feb 24 10:03:27.484: INFO: Pod "pod-projected-configmaps-9c24bd40-3c7a-4f9d-9d16-40ab7d2b0821": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008534038s
Feb 24 10:03:29.486: INFO: Pod "pod-projected-configmaps-9c24bd40-3c7a-4f9d-9d16-40ab7d2b0821": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010713546s
STEP: Saw pod success
Feb 24 10:03:29.486: INFO: Pod "pod-projected-configmaps-9c24bd40-3c7a-4f9d-9d16-40ab7d2b0821" satisfied condition "success or failure"
Feb 24 10:03:29.488: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-configmaps-9c24bd40-3c7a-4f9d-9d16-40ab7d2b0821 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 10:03:29.500: INFO: Waiting for pod pod-projected-configmaps-9c24bd40-3c7a-4f9d-9d16-40ab7d2b0821 to disappear
Feb 24 10:03:29.501: INFO: Pod pod-projected-configmaps-9c24bd40-3c7a-4f9d-9d16-40ab7d2b0821 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:03:29.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4196" for this suite.
Feb 24 10:03:35.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:03:35.584: INFO: namespace projected-4196 deletion completed in 6.080947302s

• [SLOW TEST:10.144 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:03:35.584: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 24 10:03:43.627: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5221 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 10:03:43.627: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 10:03:43.771: INFO: Exec stderr: ""
Feb 24 10:03:43.771: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5221 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 10:03:43.771: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 10:03:43.923: INFO: Exec stderr: ""
Feb 24 10:03:43.923: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5221 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 10:03:43.923: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 10:03:44.072: INFO: Exec stderr: ""
Feb 24 10:03:44.072: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5221 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 10:03:44.072: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 10:03:44.223: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 24 10:03:44.223: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5221 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 10:03:44.223: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 10:03:44.355: INFO: Exec stderr: ""
Feb 24 10:03:44.355: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5221 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 10:03:44.355: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 10:03:44.494: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 24 10:03:44.494: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5221 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 10:03:44.494: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 10:03:44.615: INFO: Exec stderr: ""
Feb 24 10:03:44.615: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5221 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 10:03:44.615: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 10:03:44.751: INFO: Exec stderr: ""
Feb 24 10:03:44.751: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5221 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 10:03:44.751: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 10:03:44.873: INFO: Exec stderr: ""
Feb 24 10:03:44.873: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5221 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 24 10:03:44.873: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
Feb 24 10:03:45.010: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:03:45.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5221" for this suite.
Feb 24 10:04:35.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:04:35.124: INFO: namespace e2e-kubelet-etc-hosts-5221 deletion completed in 50.1110616s

• [SLOW TEST:59.539 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:04:35.124: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 24 10:04:35.216: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 24 10:04:35.227: INFO: Waiting for terminating namespaces to be deleted...
Feb 24 10:04:35.229: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-135.eu-west-1.compute.internal before test
Feb 24 10:04:35.250: INFO: velero-79446c99cd-b99nf from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container velero ready: true, restart count 0
Feb 24 10:04:35.250: INFO: fluentd-64hh4 from logging started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container fluentd ready: true, restart count 0
Feb 24 10:04:35.250: INFO: nginx-ingress-controller-wgp6c from ingress-nginx started at 2020-02-24 08:33:05 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 24 10:04:35.250: INFO: kibana-756b6ddfcd-4s9ml from logging started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container kibana ready: true, restart count 0
Feb 24 10:04:35.250: INFO: cerebro-d67c8c48-xs4h6 from logging started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container cerebro ready: true, restart count 0
Feb 24 10:04:35.250: INFO: coredns-5644d7b6d9-p22w4 from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container coredns ready: true, restart count 0
Feb 24 10:04:35.250: INFO: calico-kube-controllers-655bb9f786-gx8ws from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 24 10:04:35.250: INFO: forecastle-744778954f-xqj69 from ingress-nginx started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container forecastle ready: true, restart count 0
Feb 24 10:04:35.250: INFO: cert-manager-cainjector-898cb7556-ff586 from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container cainjector ready: true, restart count 0
Feb 24 10:04:35.250: INFO: kube-state-metrics-58f8cfc86c-cn6fm from monitoring started at 2020-02-24 08:33:09 +0000 UTC (2 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 24 10:04:35.250: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 24 10:04:35.250: INFO: node-exporter-hn87r from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container node-exporter ready: true, restart count 0
Feb 24 10:04:35.250: INFO: grafana-864bdcc8d4-qrbtv from monitoring started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container grafana ready: true, restart count 0
Feb 24 10:04:35.250: INFO: local-path-provisioner-58b55cb6b6-vnzz8 from local-path-storage started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container local-path-provisioner ready: true, restart count 0
Feb 24 10:04:35.250: INFO: coredns-5644d7b6d9-n6pvc from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container coredns ready: true, restart count 0
Feb 24 10:04:35.250: INFO: cert-manager-webhook-b65959699-5bd7k from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container webhook ready: true, restart count 0
Feb 24 10:04:35.250: INFO: goldpinger-kmzxp from monitoring started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container goldpinger ready: true, restart count 0
Feb 24 10:04:35.250: INFO: calico-node-phn96 from kube-system started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container calico-node ready: true, restart count 0
Feb 24 10:04:35.250: INFO: minio-0 from kube-system started at 2020-02-24 08:34:46 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container minio ready: true, restart count 0
Feb 24 10:04:35.250: INFO: minio-setup-j6w9s from kube-system started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container mc ready: false, restart count 2
Feb 24 10:04:35.250: INFO: cert-manager-54bb694dc-hhltb from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container cert-manager ready: true, restart count 0
Feb 24 10:04:35.250: INFO: elasticsearch-0 from logging started at 2020-02-24 08:34:47 +0000 UTC (2 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container elasticsearch ready: true, restart count 0
Feb 24 10:04:35.250: INFO: 	Container exporter ready: true, restart count 0
Feb 24 10:04:35.250: INFO: sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-rzsmv from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 24 10:04:35.250: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 10:04:35.250: INFO: kube-proxy-wpbzf from kube-system started at 2020-02-24 08:25:43 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 10:04:35.250: INFO: velero-restic-rx97v from kube-system started at 2020-02-24 08:33:05 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container restic ready: true, restart count 0
Feb 24 10:04:35.250: INFO: prometheus-operator-748c7fffd8-68gvp from monitoring started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.250: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb 24 10:04:35.250: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-76.eu-west-1.compute.internal before test
Feb 24 10:04:35.262: INFO: kube-proxy-59p45 from kube-system started at 2020-02-24 08:25:43 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.262: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 10:04:35.262: INFO: node-exporter-cbcbp from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.262: INFO: 	Container node-exporter ready: true, restart count 0
Feb 24 10:04:35.262: INFO: velero-restic-v74rb from kube-system started at 2020-02-24 09:53:24 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.262: INFO: 	Container restic ready: true, restart count 0
Feb 24 10:04:35.262: INFO: calico-node-66z5c from kube-system started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.262: INFO: 	Container calico-node ready: true, restart count 0
Feb 24 10:04:35.262: INFO: goldpinger-c9h65 from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.262: INFO: 	Container goldpinger ready: true, restart count 0
Feb 24 10:04:35.262: INFO: sonobuoy from sonobuoy started at 2020-02-24 08:38:00 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.262: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 24 10:04:35.262: INFO: nginx-ingress-controller-mz97z from ingress-nginx started at 2020-02-24 09:53:24 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.262: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 24 10:04:35.262: INFO: prometheus-k8s-0 from monitoring started at 2020-02-24 09:53:32 +0000 UTC (3 container statuses recorded)
Feb 24 10:04:35.262: INFO: 	Container prometheus ready: true, restart count 0
Feb 24 10:04:35.262: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb 24 10:04:35.262: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Feb 24 10:04:35.262: INFO: sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-7vc7s from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:04:35.262: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 24 10:04:35.262: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 10:04:35.262: INFO: fluentd-47t8s from logging started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:04:35.262: INFO: 	Container fluentd ready: true, restart count 0
Feb 24 10:04:35.262: INFO: sonobuoy-e2e-job-e55756929f3b41bc from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:04:35.262: INFO: 	Container e2e ready: true, restart count 0
Feb 24 10:04:35.262: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-bbbf4150-f1d5-4ac5-8b36-4d370cea3622 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-bbbf4150-f1d5-4ac5-8b36-4d370cea3622 off the node ip-10-100-10-76.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-bbbf4150-f1d5-4ac5-8b36-4d370cea3622
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:04:51.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3943" for this suite.
Feb 24 10:05:09.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:05:09.437: INFO: namespace sched-pred-3943 deletion completed in 18.073277656s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:34.313 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:05:09.438: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 24 10:05:09.472: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:05:09.474: INFO: Number of nodes with available pods: 0
Feb 24 10:05:09.474: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:05:10.476: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:05:10.478: INFO: Number of nodes with available pods: 0
Feb 24 10:05:10.478: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:05:11.476: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:05:11.479: INFO: Number of nodes with available pods: 1
Feb 24 10:05:11.479: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:05:12.477: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:05:12.479: INFO: Number of nodes with available pods: 2
Feb 24 10:05:12.479: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 24 10:05:12.491: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:05:12.494: INFO: Number of nodes with available pods: 1
Feb 24 10:05:12.494: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:05:13.497: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:05:13.499: INFO: Number of nodes with available pods: 1
Feb 24 10:05:13.499: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:05:14.497: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:05:14.499: INFO: Number of nodes with available pods: 1
Feb 24 10:05:14.499: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:05:15.497: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:05:15.499: INFO: Number of nodes with available pods: 2
Feb 24 10:05:15.499: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3342, will wait for the garbage collector to delete the pods
Feb 24 10:05:15.558: INFO: Deleting DaemonSet.extensions daemon-set took: 3.627805ms
Feb 24 10:05:16.058: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.191251ms
Feb 24 10:05:23.460: INFO: Number of nodes with available pods: 0
Feb 24 10:05:23.460: INFO: Number of running nodes: 0, number of available pods: 0
Feb 24 10:05:23.462: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3342/daemonsets","resourceVersion":"30759"},"items":null}

Feb 24 10:05:23.463: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3342/pods","resourceVersion":"30759"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:05:23.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3342" for this suite.
Feb 24 10:05:29.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:05:29.544: INFO: namespace daemonsets-3342 deletion completed in 6.073526436s

• [SLOW TEST:20.106 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:05:29.544: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-6a0af22b-e645-4ff5-a254-8f27a9901507
STEP: Creating a pod to test consume secrets
Feb 24 10:05:29.619: INFO: Waiting up to 5m0s for pod "pod-secrets-02f1bedf-70d6-4e98-b8d4-c0efdbcc9c84" in namespace "secrets-5483" to be "success or failure"
Feb 24 10:05:29.625: INFO: Pod "pod-secrets-02f1bedf-70d6-4e98-b8d4-c0efdbcc9c84": Phase="Pending", Reason="", readiness=false. Elapsed: 6.581299ms
Feb 24 10:05:31.628: INFO: Pod "pod-secrets-02f1bedf-70d6-4e98-b8d4-c0efdbcc9c84": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008745576s
Feb 24 10:05:33.630: INFO: Pod "pod-secrets-02f1bedf-70d6-4e98-b8d4-c0efdbcc9c84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010848974s
STEP: Saw pod success
Feb 24 10:05:33.630: INFO: Pod "pod-secrets-02f1bedf-70d6-4e98-b8d4-c0efdbcc9c84" satisfied condition "success or failure"
Feb 24 10:05:33.631: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-secrets-02f1bedf-70d6-4e98-b8d4-c0efdbcc9c84 container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 10:05:33.643: INFO: Waiting for pod pod-secrets-02f1bedf-70d6-4e98-b8d4-c0efdbcc9c84 to disappear
Feb 24 10:05:33.645: INFO: Pod pod-secrets-02f1bedf-70d6-4e98-b8d4-c0efdbcc9c84 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:05:33.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5483" for this suite.
Feb 24 10:05:39.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:05:39.724: INFO: namespace secrets-5483 deletion completed in 6.077032158s

• [SLOW TEST:10.180 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:05:39.724: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-72587376-2c4b-4518-8380-b61893623be4
STEP: Creating a pod to test consume configMaps
Feb 24 10:05:39.758: INFO: Waiting up to 5m0s for pod "pod-configmaps-0ab48f87-355c-44c5-b622-c44f2fb488f9" in namespace "configmap-9312" to be "success or failure"
Feb 24 10:05:39.759: INFO: Pod "pod-configmaps-0ab48f87-355c-44c5-b622-c44f2fb488f9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.885162ms
Feb 24 10:05:41.762: INFO: Pod "pod-configmaps-0ab48f87-355c-44c5-b622-c44f2fb488f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003940576s
Feb 24 10:05:43.764: INFO: Pod "pod-configmaps-0ab48f87-355c-44c5-b622-c44f2fb488f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006151416s
STEP: Saw pod success
Feb 24 10:05:43.764: INFO: Pod "pod-configmaps-0ab48f87-355c-44c5-b622-c44f2fb488f9" satisfied condition "success or failure"
Feb 24 10:05:43.765: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-configmaps-0ab48f87-355c-44c5-b622-c44f2fb488f9 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 10:05:43.790: INFO: Waiting for pod pod-configmaps-0ab48f87-355c-44c5-b622-c44f2fb488f9 to disappear
Feb 24 10:05:43.794: INFO: Pod pod-configmaps-0ab48f87-355c-44c5-b622-c44f2fb488f9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:05:43.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9312" for this suite.
Feb 24 10:05:49.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:05:49.872: INFO: namespace configmap-9312 deletion completed in 6.075903656s

• [SLOW TEST:10.148 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:05:49.872: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6345
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-6345
Feb 24 10:05:49.963: INFO: Found 0 stateful pods, waiting for 1
Feb 24 10:05:59.965: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 24 10:05:59.976: INFO: Deleting all statefulset in ns statefulset-6345
Feb 24 10:05:59.989: INFO: Scaling statefulset ss to 0
Feb 24 10:06:20.006: INFO: Waiting for statefulset status.replicas updated to 0
Feb 24 10:06:20.012: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:06:20.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6345" for this suite.
Feb 24 10:06:26.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:06:26.219: INFO: namespace statefulset-6345 deletion completed in 6.196120378s

• [SLOW TEST:36.347 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:06:26.219: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-38e38ec3-f2ab-4062-b741-f7044e28544a
STEP: Creating a pod to test consume secrets
Feb 24 10:06:26.252: INFO: Waiting up to 5m0s for pod "pod-secrets-b124ea94-9801-4ca6-9d08-6348733315fb" in namespace "secrets-3023" to be "success or failure"
Feb 24 10:06:26.263: INFO: Pod "pod-secrets-b124ea94-9801-4ca6-9d08-6348733315fb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.937694ms
Feb 24 10:06:28.265: INFO: Pod "pod-secrets-b124ea94-9801-4ca6-9d08-6348733315fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010122421s
Feb 24 10:06:30.268: INFO: Pod "pod-secrets-b124ea94-9801-4ca6-9d08-6348733315fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012536761s
STEP: Saw pod success
Feb 24 10:06:30.268: INFO: Pod "pod-secrets-b124ea94-9801-4ca6-9d08-6348733315fb" satisfied condition "success or failure"
Feb 24 10:06:30.270: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-secrets-b124ea94-9801-4ca6-9d08-6348733315fb container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 10:06:30.286: INFO: Waiting for pod pod-secrets-b124ea94-9801-4ca6-9d08-6348733315fb to disappear
Feb 24 10:06:30.307: INFO: Pod pod-secrets-b124ea94-9801-4ca6-9d08-6348733315fb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:06:30.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3023" for this suite.
Feb 24 10:06:36.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:06:36.385: INFO: namespace secrets-3023 deletion completed in 6.075198127s

• [SLOW TEST:10.166 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:06:36.385: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:06:36.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8527" for this suite.
Feb 24 10:06:48.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:06:48.498: INFO: namespace pods-8527 deletion completed in 12.076730593s

• [SLOW TEST:12.113 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:06:48.498: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Feb 24 10:06:48.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-9238'
Feb 24 10:06:48.920: INFO: stderr: ""
Feb 24 10:06:48.920: INFO: stdout: "pod/pause created\n"
Feb 24 10:06:48.920: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 24 10:06:48.920: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9238" to be "running and ready"
Feb 24 10:06:48.926: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.287454ms
Feb 24 10:06:50.929: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009323s
Feb 24 10:06:50.929: INFO: Pod "pause" satisfied condition "running and ready"
Feb 24 10:06:50.929: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 24 10:06:50.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 label pods pause testing-label=testing-label-value --namespace=kubectl-9238'
Feb 24 10:06:50.996: INFO: stderr: ""
Feb 24 10:06:50.996: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 24 10:06:50.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pod pause -L testing-label --namespace=kubectl-9238'
Feb 24 10:06:51.061: INFO: stderr: ""
Feb 24 10:06:51.061: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 24 10:06:51.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 label pods pause testing-label- --namespace=kubectl-9238'
Feb 24 10:06:51.128: INFO: stderr: ""
Feb 24 10:06:51.128: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 24 10:06:51.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pod pause -L testing-label --namespace=kubectl-9238'
Feb 24 10:06:51.186: INFO: stderr: ""
Feb 24 10:06:51.186: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Feb 24 10:06:51.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete --grace-period=0 --force -f - --namespace=kubectl-9238'
Feb 24 10:06:51.253: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 24 10:06:51.253: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 24 10:06:51.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get rc,svc -l name=pause --no-headers --namespace=kubectl-9238'
Feb 24 10:06:51.324: INFO: stderr: "No resources found in kubectl-9238 namespace.\n"
Feb 24 10:06:51.324: INFO: stdout: ""
Feb 24 10:06:51.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -l name=pause --namespace=kubectl-9238 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 24 10:06:51.391: INFO: stderr: ""
Feb 24 10:06:51.391: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:06:51.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9238" for this suite.
Feb 24 10:06:57.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:06:57.474: INFO: namespace kubectl-9238 deletion completed in 6.080231083s

• [SLOW TEST:8.976 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:06:57.474: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 10:06:57.497: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4494500-0b9a-493e-ae4c-54af96b88051" in namespace "downward-api-9394" to be "success or failure"
Feb 24 10:06:57.502: INFO: Pod "downwardapi-volume-b4494500-0b9a-493e-ae4c-54af96b88051": Phase="Pending", Reason="", readiness=false. Elapsed: 5.505747ms
Feb 24 10:06:59.505: INFO: Pod "downwardapi-volume-b4494500-0b9a-493e-ae4c-54af96b88051": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008023712s
STEP: Saw pod success
Feb 24 10:06:59.505: INFO: Pod "downwardapi-volume-b4494500-0b9a-493e-ae4c-54af96b88051" satisfied condition "success or failure"
Feb 24 10:06:59.508: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-b4494500-0b9a-493e-ae4c-54af96b88051 container client-container: <nil>
STEP: delete the pod
Feb 24 10:06:59.520: INFO: Waiting for pod downwardapi-volume-b4494500-0b9a-493e-ae4c-54af96b88051 to disappear
Feb 24 10:06:59.522: INFO: Pod downwardapi-volume-b4494500-0b9a-493e-ae4c-54af96b88051 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:06:59.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9394" for this suite.
Feb 24 10:07:05.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:07:05.606: INFO: namespace downward-api-9394 deletion completed in 6.082490884s

• [SLOW TEST:8.132 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:07:05.607: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 24 10:07:07.647: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:07:07.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1425" for this suite.
Feb 24 10:07:13.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:07:13.732: INFO: namespace container-runtime-1425 deletion completed in 6.073007798s

• [SLOW TEST:8.125 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:07:13.732: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:07:20.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7610" for this suite.
Feb 24 10:07:26.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:07:26.888: INFO: namespace resourcequota-7610 deletion completed in 6.07528309s

• [SLOW TEST:13.156 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:07:26.888: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:07:26.909: INFO: Creating deployment "webserver-deployment"
Feb 24 10:07:26.911: INFO: Waiting for observed generation 1
Feb 24 10:07:28.917: INFO: Waiting for all required pods to come up
Feb 24 10:07:28.920: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 24 10:07:32.928: INFO: Waiting for deployment "webserver-deployment" to complete
Feb 24 10:07:32.931: INFO: Updating deployment "webserver-deployment" with a non-existent image
Feb 24 10:07:32.936: INFO: Updating deployment webserver-deployment
Feb 24 10:07:32.936: INFO: Waiting for observed generation 2
Feb 24 10:07:34.941: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 24 10:07:34.943: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 24 10:07:34.944: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 24 10:07:34.949: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 24 10:07:34.950: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 24 10:07:34.951: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 24 10:07:34.954: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Feb 24 10:07:34.954: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Feb 24 10:07:34.957: INFO: Updating deployment webserver-deployment
Feb 24 10:07:34.958: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Feb 24 10:07:34.967: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 24 10:07:36.978: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 24 10:07:36.983: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-7220 /apis/apps/v1/namespaces/deployment-7220/deployments/webserver-deployment 1e042462-0f75-41dc-884f-18a1e538f0c2 31759 3 2020-02-24 10:07:26 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002b42238 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-02-24 10:07:34 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-02-24 10:07:35 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Feb 24 10:07:36.985: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-7220 /apis/apps/v1/namespaces/deployment-7220/replicasets/webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 31746 3 2020-02-24 10:07:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 1e042462-0f75-41dc-884f-18a1e538f0c2 0xc0038f6c27 0xc0038f6c28}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0038f6c98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 24 10:07:36.985: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Feb 24 10:07:36.985: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-7220 /apis/apps/v1/namespaces/deployment-7220/replicasets/webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 31756 3 2020-02-24 10:07:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 1e042462-0f75-41dc-884f-18a1e538f0c2 0xc0038f6b67 0xc0038f6b68}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0038f6bc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Feb 24 10:07:36.988: INFO: Pod "webserver-deployment-595b5b9587-4zzw9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4zzw9 webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-4zzw9 56b1163b-a64a-4127-abc3-80c3bcdf42af 31786 0 2020-02-24 10:07:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b42677 0xc002b42678}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.135,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.989: INFO: Pod "webserver-deployment-595b5b9587-5j6ph" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5j6ph webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-5j6ph d273dc53-8106-40e6-8bfd-8c07eb333e92 31735 0 2020-02-24 10:07:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b427c7 0xc002b427c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.989: INFO: Pod "webserver-deployment-595b5b9587-6x656" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6x656 webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-6x656 86314e94-ef2b-4d10-9bbb-5218c6dd26d5 31546 0 2020-02-24 10:07:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.14.222/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b428e0 0xc002b428e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:172.16.14.222,StartTime:2020-02-24 10:07:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 10:07:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://57a3539189ac9bb4bf1e99a485d9c0509935c6ced2df90f3f64350d8e686c3fa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.14.222,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.989: INFO: Pod "webserver-deployment-595b5b9587-7bbfx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7bbfx webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-7bbfx 12d9a133-8183-4e2f-bb3a-ba79e8e806bd 31776 0 2020-02-24 10:07:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b42a47 0xc002b42a48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.989: INFO: Pod "webserver-deployment-595b5b9587-8j42d" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8j42d webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-8j42d 133f65a0-f500-49d1-aad5-113169f45214 31549 0 2020-02-24 10:07:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.145.167/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b42ba7 0xc002b42ba8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.135,PodIP:172.16.145.167,StartTime:2020-02-24 10:07:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 10:07:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://009de80e78b99d6ab86ae7b1598703d8c5f4e1b542efc54ae5acd3b03f602b7c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.145.167,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.990: INFO: Pod "webserver-deployment-595b5b9587-9gwkb" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9gwkb webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-9gwkb f900e23b-4e52-4974-89de-e110cc6f86ce 31567 0 2020-02-24 10:07:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.14.231/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b42d27 0xc002b42d28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:172.16.14.231,StartTime:2020-02-24 10:07:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 10:07:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://fee2d1fb5b2f32d8db9e95313b383b1a3012dc7eb9dba9f16f316fa696bbd3aa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.14.231,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.990: INFO: Pod "webserver-deployment-595b5b9587-b9nc7" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-b9nc7 webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-b9nc7 9eea0dcf-35c3-4f21-9fb0-4c0d47f77dd0 31802 0 2020-02-24 10:07:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b42e97 0xc002b42e98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.990: INFO: Pod "webserver-deployment-595b5b9587-cgnf4" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-cgnf4 webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-cgnf4 dab02d79-8fac-405b-91af-eeb3fa7efe13 31760 0 2020-02-24 10:07:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b42fe7 0xc002b42fe8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.135,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.990: INFO: Pod "webserver-deployment-595b5b9587-l69fx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-l69fx webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-l69fx 13f34993-ad97-483c-a9a6-4418c3a24d5f 31817 0 2020-02-24 10:07:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.14.236/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b43147 0xc002b43148}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.990: INFO: Pod "webserver-deployment-595b5b9587-l8j8b" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-l8j8b webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-l8j8b c1ffcd05-2eb8-48dc-a998-ddf1fe45e466 31734 0 2020-02-24 10:07:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b43297 0xc002b43298}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.991: INFO: Pod "webserver-deployment-595b5b9587-lgmth" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-lgmth webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-lgmth fbc8f96a-07a4-49b0-b9eb-a373517ad0fe 31572 0 2020-02-24 10:07:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.14.228/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b433b0 0xc002b433b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:172.16.14.228,StartTime:2020-02-24 10:07:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 10:07:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://0b25fec9a71f0bd3fbbfd01037fb5365cff83232e3e4e1b90a86fdd7b03cae6d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.14.228,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.991: INFO: Pod "webserver-deployment-595b5b9587-plndl" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-plndl webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-plndl 55099c99-7592-4370-be05-156adb694815 31793 0 2020-02-24 10:07:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.14.237/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b43527 0xc002b43528}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.991: INFO: Pod "webserver-deployment-595b5b9587-q75lc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-q75lc webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-q75lc 34dac838-caf7-4cf0-b7ed-1f6d48a170c5 31805 0 2020-02-24 10:07:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.14.238/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b43687 0xc002b43688}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.991: INFO: Pod "webserver-deployment-595b5b9587-r8nkv" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r8nkv webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-r8nkv 85c56b41-b147-4785-8e62-8271fa0c02a1 31535 0 2020-02-24 10:07:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.14.224/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b437e7 0xc002b437e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:172.16.14.224,StartTime:2020-02-24 10:07:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 10:07:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://d187580a5e0bcff59be7d429fadee701668afd3148ac1564a6afa4158f164a96,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.14.224,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.991: INFO: Pod "webserver-deployment-595b5b9587-rzrwz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rzrwz webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-rzrwz 6e0436b1-9c63-445c-b159-bc8395feff8b 31811 0 2020-02-24 10:07:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.145.164/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b43957 0xc002b43958}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.135,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.991: INFO: Pod "webserver-deployment-595b5b9587-s7x8r" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-s7x8r webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-s7x8r f7639089-b181-47a2-95de-74876852d7a9 31543 0 2020-02-24 10:07:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.145.166/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b43aa7 0xc002b43aa8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.135,PodIP:172.16.145.166,StartTime:2020-02-24 10:07:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 10:07:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6d84b183521c13910dbb10b432dfae8e27723fd5086ed5d06fd5b83861f7b844,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.145.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.992: INFO: Pod "webserver-deployment-595b5b9587-sx4sh" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sx4sh webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-sx4sh dcb98cf8-4a61-4e26-958e-74585c444442 31564 0 2020-02-24 10:07:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.14.227/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b43c37 0xc002b43c38}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:172.16.14.227,StartTime:2020-02-24 10:07:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 10:07:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://692dbedb4d79bb4ffdeff2b8132329ea6b62d7f6dcf3354b2d63345d8c0b3ee9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.14.227,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.992: INFO: Pod "webserver-deployment-595b5b9587-vdzbp" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vdzbp webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-vdzbp 584c88f3-4c00-41bb-8aa3-ec5ac9d9d3a7 31816 0 2020-02-24 10:07:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b43da7 0xc002b43da8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.135,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.992: INFO: Pod "webserver-deployment-595b5b9587-wmqs4" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wmqs4 webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-wmqs4 5e82f675-6785-4cbb-b287-86cca535ff2a 31524 0 2020-02-24 10:07:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.14.225/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc002b43f07 0xc002b43f08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:172.16.14.225,StartTime:2020-02-24 10:07:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 10:07:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6f6bad7c8ce50eca4dfa7911842fd8319f19c46f0e59aa4bdd09f65e9ec5bf8c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.14.225,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.992: INFO: Pod "webserver-deployment-595b5b9587-zttlj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zttlj webserver-deployment-595b5b9587- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-595b5b9587-zttlj 559d660a-d2e9-4dc2-ad9b-419d70795afe 31827 0 2020-02-24 10:07:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:172.16.145.169/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 505e0ddf-8d56-4945-b46f-6e869cbc26c8 0xc000468227 0xc000468228}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.135,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.992: INFO: Pod "webserver-deployment-c7997dcc8-29zzn" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-29zzn webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-29zzn 53b41335-1d1f-4d3f-8502-40abd6a0c29f 31799 0 2020-02-24 10:07:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.16.145.163/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc0004684f7 0xc0004684f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.135,PodIP:,StartTime:2020-02-24 10:07:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.992: INFO: Pod "webserver-deployment-c7997dcc8-52sdm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-52sdm webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-52sdm 590c6086-111b-4457-8220-63bfaf9fb4e4 31660 0 2020-02-24 10:07:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.16.14.235/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc000468807 0xc000468808}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.993: INFO: Pod "webserver-deployment-c7997dcc8-6pb2j" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-6pb2j webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-6pb2j 7f1f987b-5989-4c3d-990e-b37c85c31914 31755 0 2020-02-24 10:07:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.16.145.165/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc000468ce7 0xc000468ce8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.135,PodIP:172.16.145.165,StartTime:2020-02-24 10:07:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login': denied: requested access to the resource is denied,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.145.165,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.993: INFO: Pod "webserver-deployment-c7997dcc8-bmcj9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-bmcj9 webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-bmcj9 73394554-32b5-4391-9b2e-979ada99d94b 31669 0 2020-02-24 10:07:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.16.14.234/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc000469397 0xc000469398}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.993: INFO: Pod "webserver-deployment-c7997dcc8-dz4fr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-dz4fr webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-dz4fr ae39ddf1-0056-489a-8d24-ca04198a1ba9 31790 0 2020-02-24 10:07:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc000469757 0xc000469758}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.994: INFO: Pod "webserver-deployment-c7997dcc8-k5kbs" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-k5kbs webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-k5kbs 6396f4a2-7b39-4ab3-8d71-0d32300c15cf 31822 0 2020-02-24 10:07:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc000469d87 0xc000469d88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.994: INFO: Pod "webserver-deployment-c7997dcc8-kjsns" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kjsns webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-kjsns 57b44009-8873-4784-a9c4-9bc8eeb7eaff 31648 0 2020-02-24 10:07:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.16.14.232/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc003b7a037 0xc003b7a038}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.994: INFO: Pod "webserver-deployment-c7997dcc8-ksvcj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ksvcj webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-ksvcj c82dcbe3-80df-4de4-8dfa-3b642293ecfc 31736 0 2020-02-24 10:07:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc003b7a1a7 0xc003b7a1a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.994: INFO: Pod "webserver-deployment-c7997dcc8-m2g86" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-m2g86 webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-m2g86 e6e6ece6-7f74-46b5-b932-c6cef3a5b6b7 31657 0 2020-02-24 10:07:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.16.14.233/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc003b7a2d0 0xc003b7a2d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.994: INFO: Pod "webserver-deployment-c7997dcc8-q6kcj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-q6kcj webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-q6kcj 7cad98f8-8ef6-4ee4-b738-f9d4b867b126 31833 0 2020-02-24 10:07:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:172.16.14.239/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc003b7a447 0xc003b7a448}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.994: INFO: Pod "webserver-deployment-c7997dcc8-tl4l6" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tl4l6 webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-tl4l6 534be0f6-c239-44a5-9e27-f065204ea8e9 31772 0 2020-02-24 10:07:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc003b7a5b7 0xc003b7a5b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.135,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.994: INFO: Pod "webserver-deployment-c7997dcc8-x6gct" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-x6gct webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-x6gct e2bcf159-3e0f-4029-bc5a-28c4fdbaf6bf 31737 0 2020-02-24 10:07:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc003b7a727 0xc003b7a728}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 24 10:07:36.994: INFO: Pod "webserver-deployment-c7997dcc8-xd2ss" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xd2ss webserver-deployment-c7997dcc8- deployment-7220 /api/v1/namespaces/deployment-7220/pods/webserver-deployment-c7997dcc8-xd2ss 6b934494-804a-4aa9-92a2-7833ebf0bfc9 31797 0 2020-02-24 10:07:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 dd4368b9-b7ff-4ab3-99b3-66424eaebc07 0xc003b7a850 0xc003b7a851}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mmcd7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mmcd7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mmcd7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-135.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:07:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.135,PodIP:,StartTime:2020-02-24 10:07:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:07:36.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7220" for this suite.
Feb 24 10:07:43.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:07:43.167: INFO: namespace deployment-7220 deletion completed in 6.169317633s

• [SLOW TEST:16.279 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:07:43.167: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:07:43.200: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:07:49.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2877" for this suite.
Feb 24 10:08:35.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:08:35.422: INFO: namespace pods-2877 deletion completed in 46.077805932s

• [SLOW TEST:52.255 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:08:35.423: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 24 10:08:35.461: INFO: Waiting up to 5m0s for pod "pod-55bff8ba-84c6-4492-8344-9082baa0a045" in namespace "emptydir-4782" to be "success or failure"
Feb 24 10:08:35.465: INFO: Pod "pod-55bff8ba-84c6-4492-8344-9082baa0a045": Phase="Pending", Reason="", readiness=false. Elapsed: 3.501343ms
Feb 24 10:08:37.467: INFO: Pod "pod-55bff8ba-84c6-4492-8344-9082baa0a045": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00550508s
Feb 24 10:08:39.469: INFO: Pod "pod-55bff8ba-84c6-4492-8344-9082baa0a045": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008026582s
STEP: Saw pod success
Feb 24 10:08:39.469: INFO: Pod "pod-55bff8ba-84c6-4492-8344-9082baa0a045" satisfied condition "success or failure"
Feb 24 10:08:39.472: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-55bff8ba-84c6-4492-8344-9082baa0a045 container test-container: <nil>
STEP: delete the pod
Feb 24 10:08:39.492: INFO: Waiting for pod pod-55bff8ba-84c6-4492-8344-9082baa0a045 to disappear
Feb 24 10:08:39.493: INFO: Pod pod-55bff8ba-84c6-4492-8344-9082baa0a045 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:08:39.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4782" for this suite.
Feb 24 10:08:45.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:08:45.586: INFO: namespace emptydir-4782 deletion completed in 6.08722585s

• [SLOW TEST:10.163 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:08:45.586: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 24 10:08:45.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-4953'
Feb 24 10:08:45.681: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 24 10:08:45.681: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Feb 24 10:08:45.700: INFO: scanned /root for discovery docs: <nil>
Feb 24 10:08:45.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4953'
Feb 24 10:09:01.452: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 24 10:09:01.453: INFO: stdout: "Created e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a\nScaling up e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Feb 24 10:09:01.453: INFO: stdout: "Created e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a\nScaling up e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Feb 24 10:09:01.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-4953'
Feb 24 10:09:01.520: INFO: stderr: ""
Feb 24 10:09:01.520: INFO: stdout: "e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a-95x5g e2e-test-httpd-rc-n4hxd "
STEP: Replicas for run=e2e-test-httpd-rc: expected=1 actual=2
Feb 24 10:09:06.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-4953'
Feb 24 10:09:06.581: INFO: stderr: ""
Feb 24 10:09:06.581: INFO: stdout: "e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a-95x5g "
Feb 24 10:09:06.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a-95x5g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4953'
Feb 24 10:09:06.641: INFO: stderr: ""
Feb 24 10:09:06.641: INFO: stdout: "true"
Feb 24 10:09:06.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 get pods e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a-95x5g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4953'
Feb 24 10:09:06.697: INFO: stderr: ""
Feb 24 10:09:06.697: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Feb 24 10:09:06.697: INFO: e2e-test-httpd-rc-c93ae815fe9f20b9065a56b033ce6a5a-95x5g is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Feb 24 10:09:06.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete rc e2e-test-httpd-rc --namespace=kubectl-4953'
Feb 24 10:09:06.759: INFO: stderr: ""
Feb 24 10:09:06.759: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:09:06.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4953" for this suite.
Feb 24 10:09:18.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:09:18.851: INFO: namespace kubectl-4953 deletion completed in 12.084989377s

• [SLOW TEST:33.265 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:09:18.851: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-e8847c4f-ee50-448b-8b74-6955a843ce04
STEP: Creating a pod to test consume configMaps
Feb 24 10:09:18.880: INFO: Waiting up to 5m0s for pod "pod-configmaps-03fa3a29-0361-47bc-b185-737e93ac1cea" in namespace "configmap-860" to be "success or failure"
Feb 24 10:09:18.885: INFO: Pod "pod-configmaps-03fa3a29-0361-47bc-b185-737e93ac1cea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.011763ms
Feb 24 10:09:20.887: INFO: Pod "pod-configmaps-03fa3a29-0361-47bc-b185-737e93ac1cea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007048162s
STEP: Saw pod success
Feb 24 10:09:20.887: INFO: Pod "pod-configmaps-03fa3a29-0361-47bc-b185-737e93ac1cea" satisfied condition "success or failure"
Feb 24 10:09:20.889: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-configmaps-03fa3a29-0361-47bc-b185-737e93ac1cea container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 10:09:20.901: INFO: Waiting for pod pod-configmaps-03fa3a29-0361-47bc-b185-737e93ac1cea to disappear
Feb 24 10:09:20.903: INFO: Pod pod-configmaps-03fa3a29-0361-47bc-b185-737e93ac1cea no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:09:20.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-860" for this suite.
Feb 24 10:09:26.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:09:26.977: INFO: namespace configmap-860 deletion completed in 6.072435052s

• [SLOW TEST:8.126 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:09:26.977: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:09:43.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-264" for this suite.
Feb 24 10:09:49.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:09:49.153: INFO: namespace resourcequota-264 deletion completed in 6.095872003s

• [SLOW TEST:22.175 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:09:49.153: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-2bc71a9c-e0da-4cff-a820-ee80b5122f68
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:09:49.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3720" for this suite.
Feb 24 10:09:55.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:09:55.341: INFO: namespace secrets-3720 deletion completed in 6.113453598s

• [SLOW TEST:6.188 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:09:55.342: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 10:09:55.665: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 10:09:57.671: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135795, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135795, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135795, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718135795, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 10:10:00.684: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:10:12.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4452" for this suite.
Feb 24 10:10:18.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:10:18.849: INFO: namespace webhook-4452 deletion completed in 6.091073569s
STEP: Destroying namespace "webhook-4452-markers" for this suite.
Feb 24 10:10:24.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:10:24.939: INFO: namespace webhook-4452-markers deletion completed in 6.0896732s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:29.605 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:10:24.946: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:10:25.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2618" for this suite.
Feb 24 10:10:31.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:10:31.103: INFO: namespace custom-resource-definition-2618 deletion completed in 6.080240147s

• [SLOW TEST:6.157 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:10:31.103: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb 24 10:10:31.180: INFO: namespace kubectl-6571
Feb 24 10:10:31.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 create -f - --namespace=kubectl-6571'
Feb 24 10:10:31.346: INFO: stderr: ""
Feb 24 10:10:31.346: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 24 10:10:32.348: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 10:10:32.348: INFO: Found 0 / 1
Feb 24 10:10:33.348: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 10:10:33.348: INFO: Found 1 / 1
Feb 24 10:10:33.348: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 24 10:10:33.350: INFO: Selector matched 1 pods for map[app:redis]
Feb 24 10:10:33.350: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 24 10:10:33.350: INFO: wait on redis-master startup in kubectl-6571 
Feb 24 10:10:33.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 logs redis-master-pzwlv redis-master --namespace=kubectl-6571'
Feb 24 10:10:33.425: INFO: stderr: ""
Feb 24 10:10:33.425: INFO: stdout: "1:C 24 Feb 2020 10:10:32.681 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 24 Feb 2020 10:10:32.681 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 24 Feb 2020 10:10:32.681 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 24 Feb 2020 10:10:32.682 * Running mode=standalone, port=6379.\n1:M 24 Feb 2020 10:10:32.682 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 24 Feb 2020 10:10:32.682 # Server initialized\n1:M 24 Feb 2020 10:10:32.682 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 24 Feb 2020 10:10:32.682 * Ready to accept connections\n"
STEP: exposing RC
Feb 24 10:10:33.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6571'
Feb 24 10:10:33.500: INFO: stderr: ""
Feb 24 10:10:33.500: INFO: stdout: "service/rm2 exposed\n"
Feb 24 10:10:33.502: INFO: Service rm2 in namespace kubectl-6571 found.
STEP: exposing service
Feb 24 10:10:35.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6571'
Feb 24 10:10:35.581: INFO: stderr: ""
Feb 24 10:10:35.581: INFO: stdout: "service/rm3 exposed\n"
Feb 24 10:10:35.584: INFO: Service rm3 in namespace kubectl-6571 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:10:37.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6571" for this suite.
Feb 24 10:11:05.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:11:05.661: INFO: namespace kubectl-6571 deletion completed in 28.071642293s

• [SLOW TEST:34.558 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:11:05.662: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 24 10:11:05.682: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 24 10:11:05.688: INFO: Waiting for terminating namespaces to be deleted...
Feb 24 10:11:05.690: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-135.eu-west-1.compute.internal before test
Feb 24 10:11:05.704: INFO: minio-0 from kube-system started at 2020-02-24 08:34:46 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container minio ready: true, restart count 0
Feb 24 10:11:05.704: INFO: calico-node-phn96 from kube-system started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container calico-node ready: true, restart count 0
Feb 24 10:11:05.704: INFO: velero-restic-rx97v from kube-system started at 2020-02-24 08:33:05 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container restic ready: true, restart count 0
Feb 24 10:11:05.704: INFO: prometheus-operator-748c7fffd8-68gvp from monitoring started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb 24 10:11:05.704: INFO: minio-setup-j6w9s from kube-system started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container mc ready: false, restart count 2
Feb 24 10:11:05.704: INFO: cert-manager-54bb694dc-hhltb from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container cert-manager ready: true, restart count 0
Feb 24 10:11:05.704: INFO: elasticsearch-0 from logging started at 2020-02-24 08:34:47 +0000 UTC (2 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container elasticsearch ready: true, restart count 0
Feb 24 10:11:05.704: INFO: 	Container exporter ready: true, restart count 0
Feb 24 10:11:05.704: INFO: sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-rzsmv from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 24 10:11:05.704: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 10:11:05.704: INFO: kube-proxy-wpbzf from kube-system started at 2020-02-24 08:25:43 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 10:11:05.704: INFO: nginx-ingress-controller-wgp6c from ingress-nginx started at 2020-02-24 08:33:05 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 24 10:11:05.704: INFO: kibana-756b6ddfcd-4s9ml from logging started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container kibana ready: true, restart count 0
Feb 24 10:11:05.704: INFO: velero-79446c99cd-b99nf from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container velero ready: true, restart count 0
Feb 24 10:11:05.704: INFO: fluentd-64hh4 from logging started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container fluentd ready: true, restart count 0
Feb 24 10:11:05.704: INFO: coredns-5644d7b6d9-p22w4 from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container coredns ready: true, restart count 0
Feb 24 10:11:05.704: INFO: calico-kube-controllers-655bb9f786-gx8ws from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 24 10:11:05.704: INFO: cerebro-d67c8c48-xs4h6 from logging started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container cerebro ready: true, restart count 0
Feb 24 10:11:05.704: INFO: grafana-864bdcc8d4-qrbtv from monitoring started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container grafana ready: true, restart count 0
Feb 24 10:11:05.704: INFO: local-path-provisioner-58b55cb6b6-vnzz8 from local-path-storage started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container local-path-provisioner ready: true, restart count 0
Feb 24 10:11:05.704: INFO: forecastle-744778954f-xqj69 from ingress-nginx started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container forecastle ready: true, restart count 0
Feb 24 10:11:05.704: INFO: cert-manager-cainjector-898cb7556-ff586 from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container cainjector ready: true, restart count 0
Feb 24 10:11:05.704: INFO: kube-state-metrics-58f8cfc86c-cn6fm from monitoring started at 2020-02-24 08:33:09 +0000 UTC (2 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 24 10:11:05.704: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 24 10:11:05.704: INFO: node-exporter-hn87r from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container node-exporter ready: true, restart count 0
Feb 24 10:11:05.704: INFO: coredns-5644d7b6d9-n6pvc from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container coredns ready: true, restart count 0
Feb 24 10:11:05.704: INFO: cert-manager-webhook-b65959699-5bd7k from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container webhook ready: true, restart count 0
Feb 24 10:11:05.704: INFO: goldpinger-kmzxp from monitoring started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.704: INFO: 	Container goldpinger ready: true, restart count 0
Feb 24 10:11:05.704: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-76.eu-west-1.compute.internal before test
Feb 24 10:11:05.712: INFO: prometheus-k8s-0 from monitoring started at 2020-02-24 09:53:32 +0000 UTC (3 container statuses recorded)
Feb 24 10:11:05.712: INFO: 	Container prometheus ready: true, restart count 0
Feb 24 10:11:05.712: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb 24 10:11:05.712: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Feb 24 10:11:05.712: INFO: sonobuoy-e2e-job-e55756929f3b41bc from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:11:05.712: INFO: 	Container e2e ready: true, restart count 0
Feb 24 10:11:05.712: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 10:11:05.712: INFO: sonobuoy from sonobuoy started at 2020-02-24 08:38:00 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.712: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 24 10:11:05.712: INFO: nginx-ingress-controller-mz97z from ingress-nginx started at 2020-02-24 09:53:24 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.712: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 24 10:11:05.712: INFO: sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-7vc7s from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:11:05.712: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 24 10:11:05.712: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 10:11:05.712: INFO: fluentd-47t8s from logging started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.712: INFO: 	Container fluentd ready: true, restart count 0
Feb 24 10:11:05.712: INFO: kube-proxy-59p45 from kube-system started at 2020-02-24 08:25:43 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.712: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 10:11:05.712: INFO: node-exporter-cbcbp from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.712: INFO: 	Container node-exporter ready: true, restart count 0
Feb 24 10:11:05.712: INFO: velero-restic-v74rb from kube-system started at 2020-02-24 09:53:24 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.712: INFO: 	Container restic ready: true, restart count 0
Feb 24 10:11:05.712: INFO: calico-node-66z5c from kube-system started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.712: INFO: 	Container calico-node ready: true, restart count 0
Feb 24 10:11:05.712: INFO: goldpinger-c9h65 from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:11:05.712: INFO: 	Container goldpinger ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f3311351-60a9-4ec7-a5bd-b28f5319162b 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-f3311351-60a9-4ec7-a5bd-b28f5319162b off the node ip-10-100-10-76.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f3311351-60a9-4ec7-a5bd-b28f5319162b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:16:11.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6390" for this suite.
Feb 24 10:16:21.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:16:21.915: INFO: namespace sched-pred-6390 deletion completed in 10.097829633s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:316.253 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:16:21.915: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb 24 10:16:22.160: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Feb 24 10:16:24.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718136182, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718136182, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718136182, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718136182, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 10:16:27.178: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:16:27.180: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:16:28.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-226" for this suite.
Feb 24 10:16:34.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:16:34.338: INFO: namespace crd-webhook-226 deletion completed in 6.074062438s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:12.430 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:16:34.345: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 24 10:16:40.400: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 24 10:16:40.402: INFO: Pod pod-with-poststart-http-hook still exists
Feb 24 10:16:42.402: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 24 10:16:42.404: INFO: Pod pod-with-poststart-http-hook still exists
Feb 24 10:16:44.402: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 24 10:16:44.405: INFO: Pod pod-with-poststart-http-hook still exists
Feb 24 10:16:46.402: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 24 10:16:46.405: INFO: Pod pod-with-poststart-http-hook still exists
Feb 24 10:16:48.402: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 24 10:16:48.405: INFO: Pod pod-with-poststart-http-hook still exists
Feb 24 10:16:50.402: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 24 10:16:50.405: INFO: Pod pod-with-poststart-http-hook still exists
Feb 24 10:16:52.402: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 24 10:16:52.405: INFO: Pod pod-with-poststart-http-hook still exists
Feb 24 10:16:54.402: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 24 10:16:54.405: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:16:54.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6390" for this suite.
Feb 24 10:17:06.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:17:06.492: INFO: namespace container-lifecycle-hook-6390 deletion completed in 12.084657613s

• [SLOW TEST:32.147 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:17:06.492: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 24 10:17:06.512: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 24 10:17:06.517: INFO: Waiting for terminating namespaces to be deleted...
Feb 24 10:17:06.519: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-135.eu-west-1.compute.internal before test
Feb 24 10:17:06.544: INFO: cert-manager-webhook-b65959699-5bd7k from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container webhook ready: true, restart count 0
Feb 24 10:17:06.544: INFO: goldpinger-kmzxp from monitoring started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container goldpinger ready: true, restart count 0
Feb 24 10:17:06.544: INFO: calico-node-phn96 from kube-system started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container calico-node ready: true, restart count 0
Feb 24 10:17:06.544: INFO: minio-0 from kube-system started at 2020-02-24 08:34:46 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container minio ready: true, restart count 0
Feb 24 10:17:06.544: INFO: cert-manager-54bb694dc-hhltb from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container cert-manager ready: true, restart count 0
Feb 24 10:17:06.544: INFO: elasticsearch-0 from logging started at 2020-02-24 08:34:47 +0000 UTC (2 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container elasticsearch ready: true, restart count 0
Feb 24 10:17:06.544: INFO: 	Container exporter ready: true, restart count 0
Feb 24 10:17:06.544: INFO: sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-rzsmv from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 24 10:17:06.544: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 10:17:06.544: INFO: kube-proxy-wpbzf from kube-system started at 2020-02-24 08:25:43 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 10:17:06.544: INFO: velero-restic-rx97v from kube-system started at 2020-02-24 08:33:05 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container restic ready: true, restart count 0
Feb 24 10:17:06.544: INFO: prometheus-operator-748c7fffd8-68gvp from monitoring started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container prometheus-operator ready: true, restart count 0
Feb 24 10:17:06.544: INFO: minio-setup-j6w9s from kube-system started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container mc ready: false, restart count 2
Feb 24 10:17:06.544: INFO: fluentd-64hh4 from logging started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container fluentd ready: true, restart count 0
Feb 24 10:17:06.544: INFO: nginx-ingress-controller-wgp6c from ingress-nginx started at 2020-02-24 08:33:05 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 24 10:17:06.544: INFO: kibana-756b6ddfcd-4s9ml from logging started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container kibana ready: true, restart count 0
Feb 24 10:17:06.544: INFO: velero-79446c99cd-b99nf from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container velero ready: true, restart count 0
Feb 24 10:17:06.544: INFO: cerebro-d67c8c48-xs4h6 from logging started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container cerebro ready: true, restart count 0
Feb 24 10:17:06.544: INFO: coredns-5644d7b6d9-p22w4 from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container coredns ready: true, restart count 0
Feb 24 10:17:06.544: INFO: calico-kube-controllers-655bb9f786-gx8ws from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 24 10:17:06.544: INFO: cert-manager-cainjector-898cb7556-ff586 from cert-manager started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container cainjector ready: true, restart count 0
Feb 24 10:17:06.544: INFO: kube-state-metrics-58f8cfc86c-cn6fm from monitoring started at 2020-02-24 08:33:09 +0000 UTC (2 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container addon-resizer ready: true, restart count 0
Feb 24 10:17:06.544: INFO: 	Container kube-state-metrics ready: true, restart count 0
Feb 24 10:17:06.544: INFO: node-exporter-hn87r from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container node-exporter ready: true, restart count 0
Feb 24 10:17:06.544: INFO: grafana-864bdcc8d4-qrbtv from monitoring started at 2020-02-24 08:33:06 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container grafana ready: true, restart count 0
Feb 24 10:17:06.544: INFO: local-path-provisioner-58b55cb6b6-vnzz8 from local-path-storage started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container local-path-provisioner ready: true, restart count 0
Feb 24 10:17:06.544: INFO: forecastle-744778954f-xqj69 from ingress-nginx started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container forecastle ready: true, restart count 0
Feb 24 10:17:06.544: INFO: coredns-5644d7b6d9-n6pvc from kube-system started at 2020-02-24 08:33:08 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.544: INFO: 	Container coredns ready: true, restart count 0
Feb 24 10:17:06.544: INFO: 
Logging pods the kubelet thinks is on node ip-10-100-10-76.eu-west-1.compute.internal before test
Feb 24 10:17:06.556: INFO: sonobuoy-e2e-job-e55756929f3b41bc from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:17:06.556: INFO: 	Container e2e ready: true, restart count 0
Feb 24 10:17:06.556: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 24 10:17:06.556: INFO: sonobuoy from sonobuoy started at 2020-02-24 08:38:00 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.556: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 24 10:17:06.556: INFO: nginx-ingress-controller-mz97z from ingress-nginx started at 2020-02-24 09:53:24 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.556: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Feb 24 10:17:06.556: INFO: sonobuoy-systemd-logs-daemon-set-75cb2cf1b1ea47dd-7vc7s from sonobuoy started at 2020-02-24 08:38:06 +0000 UTC (2 container statuses recorded)
Feb 24 10:17:06.556: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 24 10:17:06.556: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 24 10:17:06.556: INFO: fluentd-47t8s from logging started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.556: INFO: 	Container fluentd ready: true, restart count 0
Feb 24 10:17:06.556: INFO: kube-proxy-59p45 from kube-system started at 2020-02-24 08:25:43 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.556: INFO: 	Container kube-proxy ready: true, restart count 0
Feb 24 10:17:06.556: INFO: node-exporter-cbcbp from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.556: INFO: 	Container node-exporter ready: true, restart count 0
Feb 24 10:17:06.556: INFO: velero-restic-v74rb from kube-system started at 2020-02-24 09:53:24 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.556: INFO: 	Container restic ready: true, restart count 0
Feb 24 10:17:06.556: INFO: calico-node-66z5c from kube-system started at 2020-02-24 08:32:52 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.556: INFO: 	Container calico-node ready: true, restart count 0
Feb 24 10:17:06.556: INFO: goldpinger-c9h65 from monitoring started at 2020-02-24 08:32:53 +0000 UTC (1 container statuses recorded)
Feb 24 10:17:06.556: INFO: 	Container goldpinger ready: true, restart count 0
Feb 24 10:17:06.556: INFO: prometheus-k8s-0 from monitoring started at 2020-02-24 09:53:32 +0000 UTC (3 container statuses recorded)
Feb 24 10:17:06.556: INFO: 	Container prometheus ready: true, restart count 0
Feb 24 10:17:06.556: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Feb 24 10:17:06.556: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-e624c9f5-9df9-4a33-9273-77b1018583d8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-e624c9f5-9df9-4a33-9273-77b1018583d8 off the node ip-10-100-10-76.eu-west-1.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e624c9f5-9df9-4a33-9273-77b1018583d8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:17:14.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7689" for this suite.
Feb 24 10:17:22.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:17:22.718: INFO: namespace sched-pred-7689 deletion completed in 8.078851992s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:16.225 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:17:22.718: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Feb 24 10:17:22.742: INFO: Waiting up to 5m0s for pod "client-containers-f4eb15db-7714-4cec-b6a0-67885ddf2bd8" in namespace "containers-8465" to be "success or failure"
Feb 24 10:17:22.745: INFO: Pod "client-containers-f4eb15db-7714-4cec-b6a0-67885ddf2bd8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.062106ms
Feb 24 10:17:24.748: INFO: Pod "client-containers-f4eb15db-7714-4cec-b6a0-67885ddf2bd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005147551s
Feb 24 10:17:26.750: INFO: Pod "client-containers-f4eb15db-7714-4cec-b6a0-67885ddf2bd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007330108s
STEP: Saw pod success
Feb 24 10:17:26.750: INFO: Pod "client-containers-f4eb15db-7714-4cec-b6a0-67885ddf2bd8" satisfied condition "success or failure"
Feb 24 10:17:26.752: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod client-containers-f4eb15db-7714-4cec-b6a0-67885ddf2bd8 container test-container: <nil>
STEP: delete the pod
Feb 24 10:17:26.764: INFO: Waiting for pod client-containers-f4eb15db-7714-4cec-b6a0-67885ddf2bd8 to disappear
Feb 24 10:17:26.765: INFO: Pod client-containers-f4eb15db-7714-4cec-b6a0-67885ddf2bd8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:17:26.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8465" for this suite.
Feb 24 10:17:32.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:17:32.852: INFO: namespace containers-8465 deletion completed in 6.083748808s

• [SLOW TEST:10.134 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:17:32.853: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-fff2b73c-1796-49e5-b658-7cd711ea88d5
STEP: Creating secret with name s-test-opt-upd-3efbb703-f086-47da-acff-896af23abde9
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-fff2b73c-1796-49e5-b658-7cd711ea88d5
STEP: Updating secret s-test-opt-upd-3efbb703-f086-47da-acff-896af23abde9
STEP: Creating secret with name s-test-opt-create-5e3f303a-b55d-47f3-8323-cf69df9aeb81
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:19:05.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2855" for this suite.
Feb 24 10:19:33.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:19:33.271: INFO: namespace projected-2855 deletion completed in 28.075902001s

• [SLOW TEST:120.418 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:19:33.271: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-ccf7231b-048d-4ea7-9010-ad795dbb594f
STEP: Creating a pod to test consume configMaps
Feb 24 10:19:33.295: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d6561f86-3343-43a5-9707-ca3d15402479" in namespace "projected-4120" to be "success or failure"
Feb 24 10:19:33.297: INFO: Pod "pod-projected-configmaps-d6561f86-3343-43a5-9707-ca3d15402479": Phase="Pending", Reason="", readiness=false. Elapsed: 1.612736ms
Feb 24 10:19:35.299: INFO: Pod "pod-projected-configmaps-d6561f86-3343-43a5-9707-ca3d15402479": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003704274s
Feb 24 10:19:37.301: INFO: Pod "pod-projected-configmaps-d6561f86-3343-43a5-9707-ca3d15402479": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005782258s
STEP: Saw pod success
Feb 24 10:19:37.301: INFO: Pod "pod-projected-configmaps-d6561f86-3343-43a5-9707-ca3d15402479" satisfied condition "success or failure"
Feb 24 10:19:37.303: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-configmaps-d6561f86-3343-43a5-9707-ca3d15402479 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 10:19:37.315: INFO: Waiting for pod pod-projected-configmaps-d6561f86-3343-43a5-9707-ca3d15402479 to disappear
Feb 24 10:19:37.317: INFO: Pod pod-projected-configmaps-d6561f86-3343-43a5-9707-ca3d15402479 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:19:37.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4120" for this suite.
Feb 24 10:19:43.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:19:43.404: INFO: namespace projected-4120 deletion completed in 6.084286338s

• [SLOW TEST:10.133 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:19:43.404: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1812
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1812
STEP: creating replication controller externalsvc in namespace services-1812
I0224 10:19:43.465600      21 runners.go:184] Created replication controller with name: externalsvc, namespace: services-1812, replica count: 2
I0224 10:19:46.516018      21 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Feb 24 10:19:46.530: INFO: Creating new exec pod
Feb 24 10:19:50.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 exec --namespace=services-1812 execpodbhkd7 -- /bin/sh -x -c nslookup nodeport-service'
Feb 24 10:19:50.903: INFO: stderr: "+ nslookup nodeport-service\n"
Feb 24 10:19:50.903: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-1812.svc.cluster.local\tcanonical name = externalsvc.services-1812.svc.cluster.local.\nName:\texternalsvc.services-1812.svc.cluster.local\nAddress: 10.99.253.157\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1812, will wait for the garbage collector to delete the pods
Feb 24 10:19:50.961: INFO: Deleting ReplicationController externalsvc took: 5.090261ms
Feb 24 10:19:51.461: INFO: Terminating ReplicationController externalsvc pods took: 500.1896ms
Feb 24 10:19:55.885: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:19:55.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1812" for this suite.
Feb 24 10:20:01.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:20:01.992: INFO: namespace services-1812 deletion completed in 6.08276368s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.588 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:20:01.992: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-368bbcc2-ebf9-40bb-b05e-91a8a518e6c6 in namespace container-probe-8984
Feb 24 10:20:04.019: INFO: Started pod busybox-368bbcc2-ebf9-40bb-b05e-91a8a518e6c6 in namespace container-probe-8984
STEP: checking the pod's current state and verifying that restartCount is present
Feb 24 10:20:04.021: INFO: Initial restart count of pod busybox-368bbcc2-ebf9-40bb-b05e-91a8a518e6c6 is 0
Feb 24 10:20:58.079: INFO: Restart count of pod container-probe-8984/busybox-368bbcc2-ebf9-40bb-b05e-91a8a518e6c6 is now 1 (54.058830008s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:20:58.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8984" for this suite.
Feb 24 10:21:04.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:21:04.172: INFO: namespace container-probe-8984 deletion completed in 6.080046616s

• [SLOW TEST:62.179 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:21:04.172: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Feb 24 10:21:04.719: INFO: created pod pod-service-account-defaultsa
Feb 24 10:21:04.720: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 24 10:21:04.727: INFO: created pod pod-service-account-mountsa
Feb 24 10:21:04.727: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 24 10:21:04.734: INFO: created pod pod-service-account-nomountsa
Feb 24 10:21:04.734: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 24 10:21:04.748: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 24 10:21:04.748: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 24 10:21:04.761: INFO: created pod pod-service-account-mountsa-mountspec
Feb 24 10:21:04.761: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 24 10:21:04.767: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 24 10:21:04.767: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 24 10:21:04.774: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 24 10:21:04.774: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 24 10:21:04.787: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 24 10:21:04.787: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 24 10:21:04.813: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 24 10:21:04.813: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:21:04.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5488" for this suite.
Feb 24 10:21:16.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:21:16.907: INFO: namespace svcaccounts-5488 deletion completed in 12.089021437s

• [SLOW TEST:12.735 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:21:16.907: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 24 10:21:16.951: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:16.961: INFO: Number of nodes with available pods: 0
Feb 24 10:21:16.961: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:17.964: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:17.966: INFO: Number of nodes with available pods: 0
Feb 24 10:21:17.966: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:18.964: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:18.966: INFO: Number of nodes with available pods: 1
Feb 24 10:21:18.966: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:19.964: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:19.966: INFO: Number of nodes with available pods: 2
Feb 24 10:21:19.966: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 24 10:21:19.976: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:19.977: INFO: Number of nodes with available pods: 1
Feb 24 10:21:19.977: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:20.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:20.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:20.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:21.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:21.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:21.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:22.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:22.983: INFO: Number of nodes with available pods: 1
Feb 24 10:21:22.983: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:23.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:23.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:23.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:24.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:24.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:24.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:25.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:25.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:25.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:26.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:26.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:26.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:27.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:27.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:27.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:28.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:28.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:28.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:29.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:29.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:29.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:30.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:30.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:30.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:31.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:31.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:31.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:32.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:32.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:32.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:33.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:33.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:33.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:34.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:34.982: INFO: Number of nodes with available pods: 1
Feb 24 10:21:34.982: INFO: Node ip-10-100-10-76.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:21:35.980: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:21:35.982: INFO: Number of nodes with available pods: 2
Feb 24 10:21:35.982: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8682, will wait for the garbage collector to delete the pods
Feb 24 10:21:36.040: INFO: Deleting DaemonSet.extensions daemon-set took: 3.727649ms
Feb 24 10:21:36.541: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.184697ms
Feb 24 10:21:43.443: INFO: Number of nodes with available pods: 0
Feb 24 10:21:43.443: INFO: Number of running nodes: 0, number of available pods: 0
Feb 24 10:21:43.444: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8682/daemonsets","resourceVersion":"35665"},"items":null}

Feb 24 10:21:43.445: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8682/pods","resourceVersion":"35665"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:21:43.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8682" for this suite.
Feb 24 10:21:49.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:21:49.528: INFO: namespace daemonsets-8682 deletion completed in 6.075218671s

• [SLOW TEST:32.621 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:21:49.529: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:21:49.564: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 24 10:21:52.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-664 create -f -'
Feb 24 10:21:53.356: INFO: stderr: ""
Feb 24 10:21:53.356: INFO: stdout: "e2e-test-crd-publish-openapi-5885-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 24 10:21:53.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-664 delete e2e-test-crd-publish-openapi-5885-crds test-cr'
Feb 24 10:21:53.416: INFO: stderr: ""
Feb 24 10:21:53.416: INFO: stdout: "e2e-test-crd-publish-openapi-5885-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Feb 24 10:21:53.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-664 apply -f -'
Feb 24 10:21:53.551: INFO: stderr: ""
Feb 24 10:21:53.551: INFO: stdout: "e2e-test-crd-publish-openapi-5885-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 24 10:21:53.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 --namespace=crd-publish-openapi-664 delete e2e-test-crd-publish-openapi-5885-crds test-cr'
Feb 24 10:21:53.612: INFO: stderr: ""
Feb 24 10:21:53.612: INFO: stdout: "e2e-test-crd-publish-openapi-5885-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb 24 10:21:53.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 explain e2e-test-crd-publish-openapi-5885-crds'
Feb 24 10:21:53.766: INFO: stderr: ""
Feb 24 10:21:53.766: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5885-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:21:56.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-664" for this suite.
Feb 24 10:22:02.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:22:02.790: INFO: namespace crd-publish-openapi-664 deletion completed in 6.076177088s

• [SLOW TEST:13.262 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:22:02.790: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-2c09a969-4929-4aa4-9184-fca8f9072300
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-2c09a969-4929-4aa4-9184-fca8f9072300
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:22:06.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4221" for this suite.
Feb 24 10:22:18.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:22:18.939: INFO: namespace configmap-4221 deletion completed in 12.075368033s

• [SLOW TEST:16.149 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:22:18.940: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 24 10:22:18.964: INFO: Waiting up to 5m0s for pod "pod-cbedf173-8197-40dc-a3a0-a603602b1196" in namespace "emptydir-9726" to be "success or failure"
Feb 24 10:22:18.968: INFO: Pod "pod-cbedf173-8197-40dc-a3a0-a603602b1196": Phase="Pending", Reason="", readiness=false. Elapsed: 3.933559ms
Feb 24 10:22:20.971: INFO: Pod "pod-cbedf173-8197-40dc-a3a0-a603602b1196": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007016629s
Feb 24 10:22:22.973: INFO: Pod "pod-cbedf173-8197-40dc-a3a0-a603602b1196": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009473485s
STEP: Saw pod success
Feb 24 10:22:22.973: INFO: Pod "pod-cbedf173-8197-40dc-a3a0-a603602b1196" satisfied condition "success or failure"
Feb 24 10:22:22.975: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-cbedf173-8197-40dc-a3a0-a603602b1196 container test-container: <nil>
STEP: delete the pod
Feb 24 10:22:22.989: INFO: Waiting for pod pod-cbedf173-8197-40dc-a3a0-a603602b1196 to disappear
Feb 24 10:22:22.991: INFO: Pod pod-cbedf173-8197-40dc-a3a0-a603602b1196 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:22:22.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9726" for this suite.
Feb 24 10:22:29.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:22:29.074: INFO: namespace emptydir-9726 deletion completed in 6.080217517s

• [SLOW TEST:10.134 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:22:29.074: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:22:29.105: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 24 10:22:29.109: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:29.111: INFO: Number of nodes with available pods: 0
Feb 24 10:22:29.111: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:22:30.114: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:30.116: INFO: Number of nodes with available pods: 0
Feb 24 10:22:30.116: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:22:31.114: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:31.116: INFO: Number of nodes with available pods: 1
Feb 24 10:22:31.116: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:22:32.114: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:32.116: INFO: Number of nodes with available pods: 2
Feb 24 10:22:32.116: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 24 10:22:32.130: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:32.130: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:32.132: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:33.134: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:33.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:33.136: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:34.137: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:34.137: INFO: Pod daemon-set-h6j7b is not available
Feb 24 10:22:34.137: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:34.140: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:35.134: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:35.134: INFO: Pod daemon-set-h6j7b is not available
Feb 24 10:22:35.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:35.137: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:36.134: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:36.134: INFO: Pod daemon-set-h6j7b is not available
Feb 24 10:22:36.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:36.137: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:37.134: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:37.134: INFO: Pod daemon-set-h6j7b is not available
Feb 24 10:22:37.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:37.143: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:38.134: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:38.134: INFO: Pod daemon-set-h6j7b is not available
Feb 24 10:22:38.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:38.137: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:39.134: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:39.134: INFO: Pod daemon-set-h6j7b is not available
Feb 24 10:22:39.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:39.137: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:40.134: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:40.134: INFO: Pod daemon-set-h6j7b is not available
Feb 24 10:22:40.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:40.136: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:41.134: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:41.134: INFO: Pod daemon-set-h6j7b is not available
Feb 24 10:22:41.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:41.136: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:42.134: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:42.134: INFO: Pod daemon-set-h6j7b is not available
Feb 24 10:22:42.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:42.137: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:43.134: INFO: Wrong image for pod: daemon-set-h6j7b. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:43.134: INFO: Pod daemon-set-h6j7b is not available
Feb 24 10:22:43.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:43.137: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:44.134: INFO: Pod daemon-set-cbwkn is not available
Feb 24 10:22:44.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:44.138: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:45.135: INFO: Pod daemon-set-cbwkn is not available
Feb 24 10:22:45.135: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:45.137: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:46.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:46.136: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:47.134: INFO: Wrong image for pod: daemon-set-mw2ds. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 24 10:22:47.134: INFO: Pod daemon-set-mw2ds is not available
Feb 24 10:22:47.137: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:48.134: INFO: Pod daemon-set-wwlfs is not available
Feb 24 10:22:48.137: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 24 10:22:48.139: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:48.141: INFO: Number of nodes with available pods: 1
Feb 24 10:22:48.141: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:22:49.143: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:49.147: INFO: Number of nodes with available pods: 1
Feb 24 10:22:49.147: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:22:50.143: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:22:50.145: INFO: Number of nodes with available pods: 2
Feb 24 10:22:50.145: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-609, will wait for the garbage collector to delete the pods
Feb 24 10:22:50.209: INFO: Deleting DaemonSet.extensions daemon-set took: 3.664944ms
Feb 24 10:22:50.709: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.192764ms
Feb 24 10:23:03.411: INFO: Number of nodes with available pods: 0
Feb 24 10:23:03.411: INFO: Number of running nodes: 0, number of available pods: 0
Feb 24 10:23:03.413: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-609/daemonsets","resourceVersion":"36092"},"items":null}

Feb 24 10:23:03.414: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-609/pods","resourceVersion":"36092"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:23:03.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-609" for this suite.
Feb 24 10:23:09.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:23:09.495: INFO: namespace daemonsets-609 deletion completed in 6.072571058s

• [SLOW TEST:40.421 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:23:09.495: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Feb 24 10:23:09.520: INFO: Waiting up to 5m0s for pod "var-expansion-57ee6ad4-5701-43aa-8d38-25ce6703884b" in namespace "var-expansion-1064" to be "success or failure"
Feb 24 10:23:09.523: INFO: Pod "var-expansion-57ee6ad4-5701-43aa-8d38-25ce6703884b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.793393ms
Feb 24 10:23:11.525: INFO: Pod "var-expansion-57ee6ad4-5701-43aa-8d38-25ce6703884b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004935404s
Feb 24 10:23:13.527: INFO: Pod "var-expansion-57ee6ad4-5701-43aa-8d38-25ce6703884b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00695643s
STEP: Saw pod success
Feb 24 10:23:13.527: INFO: Pod "var-expansion-57ee6ad4-5701-43aa-8d38-25ce6703884b" satisfied condition "success or failure"
Feb 24 10:23:13.529: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod var-expansion-57ee6ad4-5701-43aa-8d38-25ce6703884b container dapi-container: <nil>
STEP: delete the pod
Feb 24 10:23:13.541: INFO: Waiting for pod var-expansion-57ee6ad4-5701-43aa-8d38-25ce6703884b to disappear
Feb 24 10:23:13.543: INFO: Pod var-expansion-57ee6ad4-5701-43aa-8d38-25ce6703884b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:23:13.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1064" for this suite.
Feb 24 10:23:19.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:23:19.619: INFO: namespace var-expansion-1064 deletion completed in 6.074022273s

• [SLOW TEST:10.124 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:23:19.619: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:23:23.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3921" for this suite.
Feb 24 10:24:07.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:24:07.732: INFO: namespace kubelet-test-3921 deletion completed in 44.076182753s

• [SLOW TEST:48.112 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:24:07.732: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0224 10:24:17.764224      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 24 10:24:17.764: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:24:17.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-94" for this suite.
Feb 24 10:24:23.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:24:23.839: INFO: namespace gc-94 deletion completed in 6.073215578s

• [SLOW TEST:16.107 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:24:23.839: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:24:23.871: INFO: Create a RollingUpdate DaemonSet
Feb 24 10:24:23.874: INFO: Check that daemon pods launch on every node of the cluster
Feb 24 10:24:23.884: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:24:23.887: INFO: Number of nodes with available pods: 0
Feb 24 10:24:23.887: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:24:24.889: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:24:24.891: INFO: Number of nodes with available pods: 0
Feb 24 10:24:24.891: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:24:25.890: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:24:25.892: INFO: Number of nodes with available pods: 1
Feb 24 10:24:25.893: INFO: Node ip-10-100-10-135.eu-west-1.compute.internal is running more than one daemon pod
Feb 24 10:24:26.890: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:24:26.892: INFO: Number of nodes with available pods: 2
Feb 24 10:24:26.892: INFO: Number of running nodes: 2, number of available pods: 2
Feb 24 10:24:26.892: INFO: Update the DaemonSet to trigger a rollout
Feb 24 10:24:26.902: INFO: Updating DaemonSet daemon-set
Feb 24 10:24:30.911: INFO: Roll back the DaemonSet before rollout is complete
Feb 24 10:24:30.915: INFO: Updating DaemonSet daemon-set
Feb 24 10:24:30.915: INFO: Make sure DaemonSet rollback is complete
Feb 24 10:24:30.918: INFO: Wrong image for pod: daemon-set-tzwdf. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 24 10:24:30.918: INFO: Pod daemon-set-tzwdf is not available
Feb 24 10:24:30.921: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:24:31.923: INFO: Wrong image for pod: daemon-set-tzwdf. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 24 10:24:31.923: INFO: Pod daemon-set-tzwdf is not available
Feb 24 10:24:31.925: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 24 10:24:32.928: INFO: Pod daemon-set-98ptl is not available
Feb 24 10:24:32.930: INFO: DaemonSet pods can't tolerate node ip-10-100-0-248.eu-west-1.compute.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5611, will wait for the garbage collector to delete the pods
Feb 24 10:24:32.989: INFO: Deleting DaemonSet.extensions daemon-set took: 4.337757ms
Feb 24 10:24:33.490: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.287029ms
Feb 24 10:25:53.392: INFO: Number of nodes with available pods: 0
Feb 24 10:25:53.392: INFO: Number of running nodes: 0, number of available pods: 0
Feb 24 10:25:53.394: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5611/daemonsets","resourceVersion":"36809"},"items":null}

Feb 24 10:25:53.396: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5611/pods","resourceVersion":"36809"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:25:53.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5611" for this suite.
Feb 24 10:25:59.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:25:59.478: INFO: namespace daemonsets-5611 deletion completed in 6.074698599s

• [SLOW TEST:95.639 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:25:59.478: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:25:59.523: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-7ee16c99-71dc-4d08-b150-625bfebd29f1" in namespace "security-context-test-7564" to be "success or failure"
Feb 24 10:25:59.528: INFO: Pod "busybox-privileged-false-7ee16c99-71dc-4d08-b150-625bfebd29f1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.72714ms
Feb 24 10:26:01.530: INFO: Pod "busybox-privileged-false-7ee16c99-71dc-4d08-b150-625bfebd29f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006725409s
Feb 24 10:26:03.532: INFO: Pod "busybox-privileged-false-7ee16c99-71dc-4d08-b150-625bfebd29f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008887747s
Feb 24 10:26:03.532: INFO: Pod "busybox-privileged-false-7ee16c99-71dc-4d08-b150-625bfebd29f1" satisfied condition "success or failure"
Feb 24 10:26:03.543: INFO: Got logs for pod "busybox-privileged-false-7ee16c99-71dc-4d08-b150-625bfebd29f1": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:26:03.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7564" for this suite.
Feb 24 10:26:09.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:26:09.620: INFO: namespace security-context-test-7564 deletion completed in 6.074785791s

• [SLOW TEST:10.142 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:26:09.620: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 10:26:10.032: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 10:26:12.042: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718136770, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718136770, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718136770, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718136770, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 10:26:15.055: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:26:15.057: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7659-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:26:16.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8775" for this suite.
Feb 24 10:26:22.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:26:22.360: INFO: namespace webhook-8775 deletion completed in 6.089919664s
STEP: Destroying namespace "webhook-8775-markers" for this suite.
Feb 24 10:26:28.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:26:28.441: INFO: namespace webhook-8775-markers deletion completed in 6.0814149s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.827 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:26:28.448: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 24 10:26:28.473: INFO: Waiting up to 5m0s for pod "pod-a3595b91-a7de-4974-9231-70f18a517017" in namespace "emptydir-6605" to be "success or failure"
Feb 24 10:26:28.475: INFO: Pod "pod-a3595b91-a7de-4974-9231-70f18a517017": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075612ms
Feb 24 10:26:30.477: INFO: Pod "pod-a3595b91-a7de-4974-9231-70f18a517017": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004196027s
STEP: Saw pod success
Feb 24 10:26:30.477: INFO: Pod "pod-a3595b91-a7de-4974-9231-70f18a517017" satisfied condition "success or failure"
Feb 24 10:26:30.479: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-a3595b91-a7de-4974-9231-70f18a517017 container test-container: <nil>
STEP: delete the pod
Feb 24 10:26:30.492: INFO: Waiting for pod pod-a3595b91-a7de-4974-9231-70f18a517017 to disappear
Feb 24 10:26:30.493: INFO: Pod pod-a3595b91-a7de-4974-9231-70f18a517017 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:26:30.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6605" for this suite.
Feb 24 10:26:36.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:26:36.573: INFO: namespace emptydir-6605 deletion completed in 6.076241557s

• [SLOW TEST:8.125 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:26:36.573: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 24 10:26:36.624: INFO: Waiting up to 5m0s for pod "pod-4025c2e8-ba8f-475a-836a-51a2f3161124" in namespace "emptydir-8308" to be "success or failure"
Feb 24 10:26:36.626: INFO: Pod "pod-4025c2e8-ba8f-475a-836a-51a2f3161124": Phase="Pending", Reason="", readiness=false. Elapsed: 2.498922ms
Feb 24 10:26:38.629: INFO: Pod "pod-4025c2e8-ba8f-475a-836a-51a2f3161124": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004652409s
STEP: Saw pod success
Feb 24 10:26:38.629: INFO: Pod "pod-4025c2e8-ba8f-475a-836a-51a2f3161124" satisfied condition "success or failure"
Feb 24 10:26:38.631: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-4025c2e8-ba8f-475a-836a-51a2f3161124 container test-container: <nil>
STEP: delete the pod
Feb 24 10:26:38.641: INFO: Waiting for pod pod-4025c2e8-ba8f-475a-836a-51a2f3161124 to disappear
Feb 24 10:26:38.644: INFO: Pod pod-4025c2e8-ba8f-475a-836a-51a2f3161124 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:26:38.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8308" for this suite.
Feb 24 10:26:44.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:26:44.719: INFO: namespace emptydir-8308 deletion completed in 6.072725632s

• [SLOW TEST:8.146 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:26:44.720: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 24 10:26:49.315: INFO: Successfully updated pod "pod-update-3fc48ebd-e037-4127-9946-41e2455b2c96"
STEP: verifying the updated pod is in kubernetes
Feb 24 10:26:49.324: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:26:49.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8815" for this suite.
Feb 24 10:27:17.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:27:17.402: INFO: namespace pods-8815 deletion completed in 28.075337557s

• [SLOW TEST:32.682 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:27:17.402: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 24 10:27:17.475: INFO: Waiting up to 5m0s for pod "pod-7e66167c-caee-45b1-9383-6c4eb7e5163c" in namespace "emptydir-4370" to be "success or failure"
Feb 24 10:27:17.477: INFO: Pod "pod-7e66167c-caee-45b1-9383-6c4eb7e5163c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05172ms
Feb 24 10:27:19.479: INFO: Pod "pod-7e66167c-caee-45b1-9383-6c4eb7e5163c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003960507s
STEP: Saw pod success
Feb 24 10:27:19.479: INFO: Pod "pod-7e66167c-caee-45b1-9383-6c4eb7e5163c" satisfied condition "success or failure"
Feb 24 10:27:19.481: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-7e66167c-caee-45b1-9383-6c4eb7e5163c container test-container: <nil>
STEP: delete the pod
Feb 24 10:27:19.500: INFO: Waiting for pod pod-7e66167c-caee-45b1-9383-6c4eb7e5163c to disappear
Feb 24 10:27:19.502: INFO: Pod pod-7e66167c-caee-45b1-9383-6c4eb7e5163c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:27:19.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4370" for this suite.
Feb 24 10:27:25.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:27:25.579: INFO: namespace emptydir-4370 deletion completed in 6.073206949s

• [SLOW TEST:8.177 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:27:25.579: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-6d1e49b8-b31d-439c-9be3-cdfd34305dda
STEP: Creating a pod to test consume secrets
Feb 24 10:27:25.606: INFO: Waiting up to 5m0s for pod "pod-secrets-d0a9f2be-4323-467f-8316-ab0fbad77e04" in namespace "secrets-9489" to be "success or failure"
Feb 24 10:27:25.609: INFO: Pod "pod-secrets-d0a9f2be-4323-467f-8316-ab0fbad77e04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.679978ms
Feb 24 10:27:27.611: INFO: Pod "pod-secrets-d0a9f2be-4323-467f-8316-ab0fbad77e04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004606097s
STEP: Saw pod success
Feb 24 10:27:27.611: INFO: Pod "pod-secrets-d0a9f2be-4323-467f-8316-ab0fbad77e04" satisfied condition "success or failure"
Feb 24 10:27:27.612: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-secrets-d0a9f2be-4323-467f-8316-ab0fbad77e04 container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 10:27:27.625: INFO: Waiting for pod pod-secrets-d0a9f2be-4323-467f-8316-ab0fbad77e04 to disappear
Feb 24 10:27:27.626: INFO: Pod pod-secrets-d0a9f2be-4323-467f-8316-ab0fbad77e04 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:27:27.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9489" for this suite.
Feb 24 10:27:33.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:27:33.700: INFO: namespace secrets-9489 deletion completed in 6.071214005s

• [SLOW TEST:8.121 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:27:33.700: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-svvv
STEP: Creating a pod to test atomic-volume-subpath
Feb 24 10:27:33.730: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-svvv" in namespace "subpath-1571" to be "success or failure"
Feb 24 10:27:33.732: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Pending", Reason="", readiness=false. Elapsed: 1.888613ms
Feb 24 10:27:35.734: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Running", Reason="", readiness=true. Elapsed: 2.004025229s
Feb 24 10:27:37.736: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Running", Reason="", readiness=true. Elapsed: 4.006109119s
Feb 24 10:27:39.738: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Running", Reason="", readiness=true. Elapsed: 6.008273364s
Feb 24 10:27:41.740: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Running", Reason="", readiness=true. Elapsed: 8.010314901s
Feb 24 10:27:43.742: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Running", Reason="", readiness=true. Elapsed: 10.012449809s
Feb 24 10:27:45.744: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Running", Reason="", readiness=true. Elapsed: 12.014609872s
Feb 24 10:27:47.747: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Running", Reason="", readiness=true. Elapsed: 14.016834088s
Feb 24 10:27:49.749: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Running", Reason="", readiness=true. Elapsed: 16.019006705s
Feb 24 10:27:51.751: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Running", Reason="", readiness=true. Elapsed: 18.021168376s
Feb 24 10:27:53.753: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Running", Reason="", readiness=true. Elapsed: 20.023269306s
Feb 24 10:27:55.755: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Running", Reason="", readiness=true. Elapsed: 22.025284165s
Feb 24 10:27:57.757: INFO: Pod "pod-subpath-test-downwardapi-svvv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.027522673s
STEP: Saw pod success
Feb 24 10:27:57.757: INFO: Pod "pod-subpath-test-downwardapi-svvv" satisfied condition "success or failure"
Feb 24 10:27:57.759: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-subpath-test-downwardapi-svvv container test-container-subpath-downwardapi-svvv: <nil>
STEP: delete the pod
Feb 24 10:27:57.774: INFO: Waiting for pod pod-subpath-test-downwardapi-svvv to disappear
Feb 24 10:27:57.776: INFO: Pod pod-subpath-test-downwardapi-svvv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-svvv
Feb 24 10:27:57.776: INFO: Deleting pod "pod-subpath-test-downwardapi-svvv" in namespace "subpath-1571"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:27:57.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1571" for this suite.
Feb 24 10:28:03.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:28:03.855: INFO: namespace subpath-1571 deletion completed in 6.075400958s

• [SLOW TEST:30.156 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:28:03.856: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 24 10:28:07.893: INFO: &Pod{ObjectMeta:{send-events-cad55be3-77df-4b36-b31d-b6578733eab6  events-1651 /api/v1/namespaces/events-1651/pods/send-events-cad55be3-77df-4b36-b31d-b6578733eab6 09b4df6b-0790-4f7f-abb6-7a7972405f47 37508 0 2020-02-24 10:28:03 +0000 UTC <nil> <nil> map[name:foo time:873367578] map[cni.projectcalico.org/podIP:172.16.14.225/32] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sqq6c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sqq6c,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sqq6c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-100-10-76.eu-west-1.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:28:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:28:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:28:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-24 10:28:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.100.10.76,PodIP:172.16.14.225,StartTime:2020-02-24 10:28:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-24 10:28:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://ea677c5fd3e56ec4cdf627ad1062b7fc49ae50bc831e55b4af14f82469b8fea8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.14.225,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Feb 24 10:28:09.896: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 24 10:28:11.899: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:28:11.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1651" for this suite.
Feb 24 10:28:55.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:28:56.001: INFO: namespace events-1651 deletion completed in 44.091221909s

• [SLOW TEST:52.146 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:28:56.002: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 24 10:28:59.053: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:28:59.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4109" for this suite.
Feb 24 10:29:05.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:29:05.171: INFO: namespace container-runtime-4109 deletion completed in 6.106417252s

• [SLOW TEST:9.169 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:29:05.171: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Feb 24 10:29:05.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-4379 -- logs-generator --log-lines-total 100 --run-duration 20s'
Feb 24 10:29:05.289: INFO: stderr: ""
Feb 24 10:29:05.289: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Feb 24 10:29:05.289: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Feb 24 10:29:05.289: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-4379" to be "running and ready, or succeeded"
Feb 24 10:29:05.313: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 24.056465ms
Feb 24 10:29:07.315: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026367838s
Feb 24 10:29:09.317: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.028453225s
Feb 24 10:29:09.317: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Feb 24 10:29:09.317: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Feb 24 10:29:09.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 logs logs-generator logs-generator --namespace=kubectl-4379'
Feb 24 10:29:09.386: INFO: stderr: ""
Feb 24 10:29:09.386: INFO: stdout: "I0224 10:29:06.741080       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/7z6 596\nI0224 10:29:06.941148       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/t4wx 347\nI0224 10:29:07.141282       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/5gt 444\nI0224 10:29:07.341259       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/vbr 574\nI0224 10:29:07.541174       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/ljjw 253\nI0224 10:29:07.741213       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/vngc 466\nI0224 10:29:07.941182       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/xfvr 360\nI0224 10:29:08.141182       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/95x 420\nI0224 10:29:08.341206       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/tbv 244\nI0224 10:29:08.541191       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/hds 524\nI0224 10:29:08.741184       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/dftr 248\nI0224 10:29:08.941172       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/xnqd 571\nI0224 10:29:09.141169       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/xqh 424\nI0224 10:29:09.341190       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/9w6h 508\n"
STEP: limiting log lines
Feb 24 10:29:09.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 logs logs-generator logs-generator --namespace=kubectl-4379 --tail=1'
Feb 24 10:29:09.452: INFO: stderr: ""
Feb 24 10:29:09.452: INFO: stdout: "I0224 10:29:09.341190       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/9w6h 508\n"
STEP: limiting log bytes
Feb 24 10:29:09.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 logs logs-generator logs-generator --namespace=kubectl-4379 --limit-bytes=1'
Feb 24 10:29:09.519: INFO: stderr: ""
Feb 24 10:29:09.519: INFO: stdout: "I"
STEP: exposing timestamps
Feb 24 10:29:09.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 logs logs-generator logs-generator --namespace=kubectl-4379 --tail=1 --timestamps'
Feb 24 10:29:09.589: INFO: stderr: ""
Feb 24 10:29:09.589: INFO: stdout: "2020-02-24T10:29:09.541340787Z I0224 10:29:09.541189       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/p6qc 501\n"
STEP: restricting to a time range
Feb 24 10:29:12.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 logs logs-generator logs-generator --namespace=kubectl-4379 --since=1s'
Feb 24 10:29:12.156: INFO: stderr: ""
Feb 24 10:29:12.156: INFO: stdout: "I0224 10:29:11.341179       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/bkd 489\nI0224 10:29:11.541183       1 logs_generator.go:76] 24 POST /api/v1/namespaces/kube-system/pods/fts 536\nI0224 10:29:11.741184       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/ns/pods/5fl6 507\nI0224 10:29:11.941177       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/default/pods/xr77 270\nI0224 10:29:12.141182       1 logs_generator.go:76] 27 POST /api/v1/namespaces/default/pods/997 548\n"
Feb 24 10:29:12.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 logs logs-generator logs-generator --namespace=kubectl-4379 --since=24h'
Feb 24 10:29:12.223: INFO: stderr: ""
Feb 24 10:29:12.223: INFO: stdout: "I0224 10:29:06.741080       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/7z6 596\nI0224 10:29:06.941148       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/t4wx 347\nI0224 10:29:07.141282       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/5gt 444\nI0224 10:29:07.341259       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/vbr 574\nI0224 10:29:07.541174       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/ljjw 253\nI0224 10:29:07.741213       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/vngc 466\nI0224 10:29:07.941182       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/xfvr 360\nI0224 10:29:08.141182       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/95x 420\nI0224 10:29:08.341206       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/tbv 244\nI0224 10:29:08.541191       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/hds 524\nI0224 10:29:08.741184       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/dftr 248\nI0224 10:29:08.941172       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/xnqd 571\nI0224 10:29:09.141169       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/xqh 424\nI0224 10:29:09.341190       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/9w6h 508\nI0224 10:29:09.541189       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/p6qc 501\nI0224 10:29:09.741182       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/rlk9 219\nI0224 10:29:09.941174       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/mmm 456\nI0224 10:29:10.141192       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/5qhk 253\nI0224 10:29:10.341172       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/8lsk 515\nI0224 10:29:10.541208       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/bdt 570\nI0224 10:29:10.741195       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/wp8 365\nI0224 10:29:10.941184       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/ncf 438\nI0224 10:29:11.141207       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/lb2 473\nI0224 10:29:11.341179       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/bkd 489\nI0224 10:29:11.541183       1 logs_generator.go:76] 24 POST /api/v1/namespaces/kube-system/pods/fts 536\nI0224 10:29:11.741184       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/ns/pods/5fl6 507\nI0224 10:29:11.941177       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/default/pods/xr77 270\nI0224 10:29:12.141182       1 logs_generator.go:76] 27 POST /api/v1/namespaces/default/pods/997 548\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Feb 24 10:29:12.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-533328996 delete pod logs-generator --namespace=kubectl-4379'
Feb 24 10:29:23.332: INFO: stderr: ""
Feb 24 10:29:23.332: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:29:23.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4379" for this suite.
Feb 24 10:29:29.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:29:29.413: INFO: namespace kubectl-4379 deletion completed in 6.073439384s

• [SLOW TEST:24.242 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:29:29.413: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:29:29.437: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-98f651d8-6477-41e0-9eb6-33de6ba15399" in namespace "security-context-test-7279" to be "success or failure"
Feb 24 10:29:29.442: INFO: Pod "busybox-readonly-false-98f651d8-6477-41e0-9eb6-33de6ba15399": Phase="Pending", Reason="", readiness=false. Elapsed: 4.821605ms
Feb 24 10:29:31.444: INFO: Pod "busybox-readonly-false-98f651d8-6477-41e0-9eb6-33de6ba15399": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00680063s
Feb 24 10:29:33.446: INFO: Pod "busybox-readonly-false-98f651d8-6477-41e0-9eb6-33de6ba15399": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008879494s
Feb 24 10:29:33.446: INFO: Pod "busybox-readonly-false-98f651d8-6477-41e0-9eb6-33de6ba15399" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:29:33.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7279" for this suite.
Feb 24 10:29:39.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:29:39.524: INFO: namespace security-context-test-7279 deletion completed in 6.075736511s

• [SLOW TEST:10.111 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:29:39.524: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:29:39.544: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Creating first CR 
Feb 24 10:29:40.124: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T10:29:40Z generation:1 name:name1 resourceVersion:37882 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:64c73f5b-edf9-486d-909a-50ce29ba92a7] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Feb 24 10:29:50.127: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T10:29:50Z generation:1 name:name2 resourceVersion:37908 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:a4fcfd69-509a-435f-8fd5-e20f01d2084c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Feb 24 10:30:00.131: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T10:29:40Z generation:2 name:name1 resourceVersion:37935 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:64c73f5b-edf9-486d-909a-50ce29ba92a7] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Feb 24 10:30:10.134: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T10:29:50Z generation:2 name:name2 resourceVersion:37965 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:a4fcfd69-509a-435f-8fd5-e20f01d2084c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Feb 24 10:30:20.138: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T10:29:40Z generation:2 name:name1 resourceVersion:37993 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:64c73f5b-edf9-486d-909a-50ce29ba92a7] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Feb 24 10:30:30.143: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-24T10:29:50Z generation:2 name:name2 resourceVersion:38020 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:a4fcfd69-509a-435f-8fd5-e20f01d2084c] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:30:40.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-5942" for this suite.
Feb 24 10:30:46.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:30:46.733: INFO: namespace crd-watch-5942 deletion completed in 6.079025809s

• [SLOW TEST:67.209 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:30:46.733: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Feb 24 10:30:46.758: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Feb 24 10:30:47.139: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Feb 24 10:30:49.180: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 10:30:51.182: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 10:30:53.182: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 10:30:55.198: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 10:30:57.182: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137047, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 24 10:31:00.037: INFO: Waited 814.403736ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:31:00.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4685" for this suite.
Feb 24 10:31:06.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:31:07.025: INFO: namespace aggregator-4685 deletion completed in 6.199045457s

• [SLOW TEST:20.292 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:31:07.025: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-0a90a4b9-56a5-4df4-a0c5-a6f92b889220
STEP: Creating a pod to test consume configMaps
Feb 24 10:31:07.050: INFO: Waiting up to 5m0s for pod "pod-configmaps-3fd07a99-2b2b-4756-a1a9-cc7436d09615" in namespace "configmap-6141" to be "success or failure"
Feb 24 10:31:07.053: INFO: Pod "pod-configmaps-3fd07a99-2b2b-4756-a1a9-cc7436d09615": Phase="Pending", Reason="", readiness=false. Elapsed: 2.772544ms
Feb 24 10:31:09.055: INFO: Pod "pod-configmaps-3fd07a99-2b2b-4756-a1a9-cc7436d09615": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005101127s
STEP: Saw pod success
Feb 24 10:31:09.055: INFO: Pod "pod-configmaps-3fd07a99-2b2b-4756-a1a9-cc7436d09615" satisfied condition "success or failure"
Feb 24 10:31:09.057: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-configmaps-3fd07a99-2b2b-4756-a1a9-cc7436d09615 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 10:31:09.076: INFO: Waiting for pod pod-configmaps-3fd07a99-2b2b-4756-a1a9-cc7436d09615 to disappear
Feb 24 10:31:09.078: INFO: Pod pod-configmaps-3fd07a99-2b2b-4756-a1a9-cc7436d09615 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:31:09.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6141" for this suite.
Feb 24 10:31:15.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:31:15.228: INFO: namespace configmap-6141 deletion completed in 6.148133253s

• [SLOW TEST:8.203 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:31:15.228: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 24 10:31:19.349: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 24 10:31:19.351: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 24 10:31:21.351: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 24 10:31:21.353: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 24 10:31:23.351: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 24 10:31:23.354: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 24 10:31:25.351: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 24 10:31:25.354: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:31:25.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5370" for this suite.
Feb 24 10:31:53.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:31:53.429: INFO: namespace container-lifecycle-hook-5370 deletion completed in 28.073361641s

• [SLOW TEST:38.201 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:31:53.430: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 10:31:53.973: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 10:31:55.979: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137113, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137113, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137113, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137113, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 10:31:58.991: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:31:58.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-583" for this suite.
Feb 24 10:32:05.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:32:05.086: INFO: namespace webhook-583 deletion completed in 6.08577591s
STEP: Destroying namespace "webhook-583-markers" for this suite.
Feb 24 10:32:11.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:32:11.169: INFO: namespace webhook-583-markers deletion completed in 6.082048575s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.746 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:32:11.176: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-438b4cad-67c5-4a86-ab55-7b028c6880ab
STEP: Creating a pod to test consume configMaps
Feb 24 10:32:11.203: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-01b98af9-46a1-408e-b3da-6465d51a4160" in namespace "projected-7983" to be "success or failure"
Feb 24 10:32:11.205: INFO: Pod "pod-projected-configmaps-01b98af9-46a1-408e-b3da-6465d51a4160": Phase="Pending", Reason="", readiness=false. Elapsed: 2.410627ms
Feb 24 10:32:13.208: INFO: Pod "pod-projected-configmaps-01b98af9-46a1-408e-b3da-6465d51a4160": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004584349s
STEP: Saw pod success
Feb 24 10:32:13.208: INFO: Pod "pod-projected-configmaps-01b98af9-46a1-408e-b3da-6465d51a4160" satisfied condition "success or failure"
Feb 24 10:32:13.209: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-configmaps-01b98af9-46a1-408e-b3da-6465d51a4160 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 24 10:32:13.223: INFO: Waiting for pod pod-projected-configmaps-01b98af9-46a1-408e-b3da-6465d51a4160 to disappear
Feb 24 10:32:13.224: INFO: Pod pod-projected-configmaps-01b98af9-46a1-408e-b3da-6465d51a4160 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:32:13.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7983" for this suite.
Feb 24 10:32:19.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:32:19.312: INFO: namespace projected-7983 deletion completed in 6.086186861s

• [SLOW TEST:8.136 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:32:19.313: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:32:34.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4786" for this suite.
Feb 24 10:32:40.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:32:40.592: INFO: namespace namespaces-4786 deletion completed in 6.105888081s
STEP: Destroying namespace "nsdeletetest-7147" for this suite.
Feb 24 10:32:40.595: INFO: Namespace nsdeletetest-7147 was already deleted
STEP: Destroying namespace "nsdeletetest-1579" for this suite.
Feb 24 10:32:46.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:32:46.668: INFO: namespace nsdeletetest-1579 deletion completed in 6.073052502s

• [SLOW TEST:27.355 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:32:46.668: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-3c96e553-7de7-4beb-9f06-2cccdd6036e6
STEP: Creating a pod to test consume secrets
Feb 24 10:32:46.695: INFO: Waiting up to 5m0s for pod "pod-secrets-a134e493-d04b-43dc-a247-edf77cde1e0f" in namespace "secrets-3336" to be "success or failure"
Feb 24 10:32:46.702: INFO: Pod "pod-secrets-a134e493-d04b-43dc-a247-edf77cde1e0f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.946934ms
Feb 24 10:32:48.705: INFO: Pod "pod-secrets-a134e493-d04b-43dc-a247-edf77cde1e0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009516575s
STEP: Saw pod success
Feb 24 10:32:48.705: INFO: Pod "pod-secrets-a134e493-d04b-43dc-a247-edf77cde1e0f" satisfied condition "success or failure"
Feb 24 10:32:48.707: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-secrets-a134e493-d04b-43dc-a247-edf77cde1e0f container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 10:32:48.720: INFO: Waiting for pod pod-secrets-a134e493-d04b-43dc-a247-edf77cde1e0f to disappear
Feb 24 10:32:48.722: INFO: Pod pod-secrets-a134e493-d04b-43dc-a247-edf77cde1e0f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:32:48.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3336" for this suite.
Feb 24 10:32:54.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:32:54.812: INFO: namespace secrets-3336 deletion completed in 6.087101168s

• [SLOW TEST:8.144 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:32:54.812: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:32:54.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4183" for this suite.
Feb 24 10:33:00.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:33:00.942: INFO: namespace kubelet-test-4183 deletion completed in 6.082018731s

• [SLOW TEST:6.130 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:33:00.942: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 24 10:33:01.359: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 24 10:33:03.364: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137181, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137181, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137181, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718137181, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 24 10:33:06.375: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:33:06.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1738" for this suite.
Feb 24 10:33:18.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:33:18.493: INFO: namespace webhook-1738 deletion completed in 12.078527573s
STEP: Destroying namespace "webhook-1738-markers" for this suite.
Feb 24 10:33:24.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:33:24.567: INFO: namespace webhook-1738-markers deletion completed in 6.074107967s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.631 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:33:24.574: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-67e5faa5-3c64-4b45-a9be-2ca0436d0443
STEP: Creating a pod to test consume secrets
Feb 24 10:33:24.599: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-28e85146-1ea3-4fd7-a5a2-cf33d9fda19c" in namespace "projected-5627" to be "success or failure"
Feb 24 10:33:24.601: INFO: Pod "pod-projected-secrets-28e85146-1ea3-4fd7-a5a2-cf33d9fda19c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.877809ms
Feb 24 10:33:26.603: INFO: Pod "pod-projected-secrets-28e85146-1ea3-4fd7-a5a2-cf33d9fda19c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004037717s
STEP: Saw pod success
Feb 24 10:33:26.603: INFO: Pod "pod-projected-secrets-28e85146-1ea3-4fd7-a5a2-cf33d9fda19c" satisfied condition "success or failure"
Feb 24 10:33:26.605: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-secrets-28e85146-1ea3-4fd7-a5a2-cf33d9fda19c container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 24 10:33:26.626: INFO: Waiting for pod pod-projected-secrets-28e85146-1ea3-4fd7-a5a2-cf33d9fda19c to disappear
Feb 24 10:33:26.628: INFO: Pod pod-projected-secrets-28e85146-1ea3-4fd7-a5a2-cf33d9fda19c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:33:26.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5627" for this suite.
Feb 24 10:33:32.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:33:32.710: INFO: namespace projected-5627 deletion completed in 6.079722314s

• [SLOW TEST:8.136 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:33:32.710: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-d70d183e-2e93-4baf-ab47-89f4a811df51 in namespace container-probe-8603
Feb 24 10:33:36.738: INFO: Started pod test-webserver-d70d183e-2e93-4baf-ab47-89f4a811df51 in namespace container-probe-8603
STEP: checking the pod's current state and verifying that restartCount is present
Feb 24 10:33:36.740: INFO: Initial restart count of pod test-webserver-d70d183e-2e93-4baf-ab47-89f4a811df51 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:37:37.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8603" for this suite.
Feb 24 10:37:43.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:37:43.095: INFO: namespace container-probe-8603 deletion completed in 6.07604436s

• [SLOW TEST:250.385 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:37:43.095: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-v2hf
STEP: Creating a pod to test atomic-volume-subpath
Feb 24 10:37:43.122: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-v2hf" in namespace "subpath-6373" to be "success or failure"
Feb 24 10:37:43.132: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.131859ms
Feb 24 10:37:45.135: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Running", Reason="", readiness=true. Elapsed: 2.012824374s
Feb 24 10:37:47.137: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Running", Reason="", readiness=true. Elapsed: 4.014949164s
Feb 24 10:37:49.139: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Running", Reason="", readiness=true. Elapsed: 6.017075224s
Feb 24 10:37:51.141: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Running", Reason="", readiness=true. Elapsed: 8.019135579s
Feb 24 10:37:53.144: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Running", Reason="", readiness=true. Elapsed: 10.021333371s
Feb 24 10:37:55.148: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Running", Reason="", readiness=true. Elapsed: 12.025449256s
Feb 24 10:37:57.150: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Running", Reason="", readiness=true. Elapsed: 14.027542687s
Feb 24 10:37:59.152: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Running", Reason="", readiness=true. Elapsed: 16.029794773s
Feb 24 10:38:01.154: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Running", Reason="", readiness=true. Elapsed: 18.032119159s
Feb 24 10:38:03.158: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Running", Reason="", readiness=true. Elapsed: 20.035761955s
Feb 24 10:38:05.162: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Running", Reason="", readiness=true. Elapsed: 22.039386755s
Feb 24 10:38:07.164: INFO: Pod "pod-subpath-test-configmap-v2hf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.041522008s
STEP: Saw pod success
Feb 24 10:38:07.164: INFO: Pod "pod-subpath-test-configmap-v2hf" satisfied condition "success or failure"
Feb 24 10:38:07.166: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-subpath-test-configmap-v2hf container test-container-subpath-configmap-v2hf: <nil>
STEP: delete the pod
Feb 24 10:38:07.189: INFO: Waiting for pod pod-subpath-test-configmap-v2hf to disappear
Feb 24 10:38:07.192: INFO: Pod pod-subpath-test-configmap-v2hf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-v2hf
Feb 24 10:38:07.192: INFO: Deleting pod "pod-subpath-test-configmap-v2hf" in namespace "subpath-6373"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:38:07.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6373" for this suite.
Feb 24 10:38:13.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:38:13.270: INFO: namespace subpath-6373 deletion completed in 6.074234574s

• [SLOW TEST:30.174 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:38:13.270: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Feb 24 10:38:17.301: INFO: Pod pod-hostip-2964064f-cf1c-4249-9700-911eb6efc00a has hostIP: 10.100.10.76
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:38:17.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-529" for this suite.
Feb 24 10:38:45.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:38:45.382: INFO: namespace pods-529 deletion completed in 28.078741295s

• [SLOW TEST:32.112 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:38:45.383: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-e0662424-f17e-4b05-99c6-abc8280b9b7e
STEP: Creating a pod to test consume secrets
Feb 24 10:38:45.420: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cb275c36-296c-40ff-a22a-bacbf7546932" in namespace "projected-775" to be "success or failure"
Feb 24 10:38:45.423: INFO: Pod "pod-projected-secrets-cb275c36-296c-40ff-a22a-bacbf7546932": Phase="Pending", Reason="", readiness=false. Elapsed: 2.79189ms
Feb 24 10:38:47.425: INFO: Pod "pod-projected-secrets-cb275c36-296c-40ff-a22a-bacbf7546932": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004943369s
Feb 24 10:38:49.428: INFO: Pod "pod-projected-secrets-cb275c36-296c-40ff-a22a-bacbf7546932": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00802988s
STEP: Saw pod success
Feb 24 10:38:49.428: INFO: Pod "pod-projected-secrets-cb275c36-296c-40ff-a22a-bacbf7546932" satisfied condition "success or failure"
Feb 24 10:38:49.431: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-projected-secrets-cb275c36-296c-40ff-a22a-bacbf7546932 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 24 10:38:49.444: INFO: Waiting for pod pod-projected-secrets-cb275c36-296c-40ff-a22a-bacbf7546932 to disappear
Feb 24 10:38:49.447: INFO: Pod pod-projected-secrets-cb275c36-296c-40ff-a22a-bacbf7546932 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:38:49.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-775" for this suite.
Feb 24 10:38:55.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:38:55.525: INFO: namespace projected-775 deletion completed in 6.075658523s

• [SLOW TEST:10.142 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:38:55.525: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 24 10:38:55.548: INFO: Waiting up to 5m0s for pod "downwardapi-volume-898ce9f9-4e1a-4123-8bd3-81384f77aba7" in namespace "downward-api-2828" to be "success or failure"
Feb 24 10:38:55.551: INFO: Pod "downwardapi-volume-898ce9f9-4e1a-4123-8bd3-81384f77aba7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.224313ms
Feb 24 10:38:57.553: INFO: Pod "downwardapi-volume-898ce9f9-4e1a-4123-8bd3-81384f77aba7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004384478s
Feb 24 10:38:59.555: INFO: Pod "downwardapi-volume-898ce9f9-4e1a-4123-8bd3-81384f77aba7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00654372s
STEP: Saw pod success
Feb 24 10:38:59.555: INFO: Pod "downwardapi-volume-898ce9f9-4e1a-4123-8bd3-81384f77aba7" satisfied condition "success or failure"
Feb 24 10:38:59.557: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod downwardapi-volume-898ce9f9-4e1a-4123-8bd3-81384f77aba7 container client-container: <nil>
STEP: delete the pod
Feb 24 10:38:59.568: INFO: Waiting for pod downwardapi-volume-898ce9f9-4e1a-4123-8bd3-81384f77aba7 to disappear
Feb 24 10:38:59.570: INFO: Pod downwardapi-volume-898ce9f9-4e1a-4123-8bd3-81384f77aba7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:38:59.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2828" for this suite.
Feb 24 10:39:05.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:39:05.654: INFO: namespace downward-api-2828 deletion completed in 6.081468756s

• [SLOW TEST:10.130 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:39:05.655: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 24 10:39:05.676: INFO: Waiting up to 5m0s for pod "pod-9bcaf3ac-ef13-4cbc-9460-74486056556c" in namespace "emptydir-5536" to be "success or failure"
Feb 24 10:39:05.679: INFO: Pod "pod-9bcaf3ac-ef13-4cbc-9460-74486056556c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.933926ms
Feb 24 10:39:07.681: INFO: Pod "pod-9bcaf3ac-ef13-4cbc-9460-74486056556c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004766968s
STEP: Saw pod success
Feb 24 10:39:07.681: INFO: Pod "pod-9bcaf3ac-ef13-4cbc-9460-74486056556c" satisfied condition "success or failure"
Feb 24 10:39:07.682: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-9bcaf3ac-ef13-4cbc-9460-74486056556c container test-container: <nil>
STEP: delete the pod
Feb 24 10:39:07.695: INFO: Waiting for pod pod-9bcaf3ac-ef13-4cbc-9460-74486056556c to disappear
Feb 24 10:39:07.697: INFO: Pod pod-9bcaf3ac-ef13-4cbc-9460-74486056556c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:39:07.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5536" for this suite.
Feb 24 10:39:13.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:39:13.785: INFO: namespace emptydir-5536 deletion completed in 6.086672425s

• [SLOW TEST:8.131 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:39:13.786: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:39:13.804: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Feb 24 10:39:14.826: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:39:14.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3929" for this suite.
Feb 24 10:39:20.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:39:20.906: INFO: namespace replication-controller-3929 deletion completed in 6.075125194s

• [SLOW TEST:7.119 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:39:20.906: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-fd61629f-fc54-4cc7-9070-af0eab76fd08
STEP: Creating a pod to test consume secrets
Feb 24 10:39:20.959: INFO: Waiting up to 5m0s for pod "pod-secrets-69c8a0e7-a26e-4d30-a075-c4f9fd532f77" in namespace "secrets-7032" to be "success or failure"
Feb 24 10:39:20.972: INFO: Pod "pod-secrets-69c8a0e7-a26e-4d30-a075-c4f9fd532f77": Phase="Pending", Reason="", readiness=false. Elapsed: 13.557393ms
Feb 24 10:39:22.974: INFO: Pod "pod-secrets-69c8a0e7-a26e-4d30-a075-c4f9fd532f77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015417238s
STEP: Saw pod success
Feb 24 10:39:22.974: INFO: Pod "pod-secrets-69c8a0e7-a26e-4d30-a075-c4f9fd532f77" satisfied condition "success or failure"
Feb 24 10:39:22.976: INFO: Trying to get logs from node ip-10-100-10-76.eu-west-1.compute.internal pod pod-secrets-69c8a0e7-a26e-4d30-a075-c4f9fd532f77 container secret-volume-test: <nil>
STEP: delete the pod
Feb 24 10:39:22.990: INFO: Waiting for pod pod-secrets-69c8a0e7-a26e-4d30-a075-c4f9fd532f77 to disappear
Feb 24 10:39:22.992: INFO: Pod pod-secrets-69c8a0e7-a26e-4d30-a075-c4f9fd532f77 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:39:22.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7032" for this suite.
Feb 24 10:39:29.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:39:29.068: INFO: namespace secrets-7032 deletion completed in 6.073982409s

• [SLOW TEST:8.162 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:39:29.068: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-690352f2-24fb-426b-8a20-a15538968c6f
STEP: Creating secret with name s-test-opt-upd-48080d46-cd23-4a56-a6c4-7e662b2356b7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-690352f2-24fb-426b-8a20-a15538968c6f
STEP: Updating secret s-test-opt-upd-48080d46-cd23-4a56-a6c4-7e662b2356b7
STEP: Creating secret with name s-test-opt-create-aa08df57-389b-4736-9a4b-5c52c0f65a87
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:39:35.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6955" for this suite.
Feb 24 10:39:59.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:39:59.256: INFO: namespace secrets-6955 deletion completed in 24.080160995s

• [SLOW TEST:30.188 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:39:59.256: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 24 10:39:59.275: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:40:02.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8590" for this suite.
Feb 24 10:40:08.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:40:08.567: INFO: namespace init-container-8590 deletion completed in 6.08105275s

• [SLOW TEST:9.311 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:40:08.567: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:40:08.597: INFO: (0) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 8.878113ms)
Feb 24 10:40:08.601: INFO: (1) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 4.686864ms)
Feb 24 10:40:08.604: INFO: (2) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.516958ms)
Feb 24 10:40:08.606: INFO: (3) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.346234ms)
Feb 24 10:40:08.609: INFO: (4) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.305378ms)
Feb 24 10:40:08.611: INFO: (5) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.353967ms)
Feb 24 10:40:08.613: INFO: (6) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.267172ms)
Feb 24 10:40:08.616: INFO: (7) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.310588ms)
Feb 24 10:40:08.618: INFO: (8) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.290843ms)
Feb 24 10:40:08.620: INFO: (9) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.083694ms)
Feb 24 10:40:08.622: INFO: (10) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.019571ms)
Feb 24 10:40:08.626: INFO: (11) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.704008ms)
Feb 24 10:40:08.628: INFO: (12) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.210794ms)
Feb 24 10:40:08.630: INFO: (13) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.240013ms)
Feb 24 10:40:08.633: INFO: (14) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.009792ms)
Feb 24 10:40:08.635: INFO: (15) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.105712ms)
Feb 24 10:40:08.637: INFO: (16) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.554146ms)
Feb 24 10:40:08.640: INFO: (17) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.315915ms)
Feb 24 10:40:08.643: INFO: (18) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.278901ms)
Feb 24 10:40:08.646: INFO: (19) /api/v1/nodes/ip-10-100-10-135.eu-west-1.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.030969ms)
[AfterEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:40:08.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1683" for this suite.
Feb 24 10:40:14.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:40:14.722: INFO: namespace proxy-1683 deletion completed in 6.073594749s

• [SLOW TEST:6.155 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:40:14.722: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 24 10:40:14.759: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-d1edd4a0-cd35-4fc8-99e8-d9be45cc3fa1" in namespace "security-context-test-7442" to be "success or failure"
Feb 24 10:40:14.773: INFO: Pod "alpine-nnp-false-d1edd4a0-cd35-4fc8-99e8-d9be45cc3fa1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.308857ms
Feb 24 10:40:16.776: INFO: Pod "alpine-nnp-false-d1edd4a0-cd35-4fc8-99e8-d9be45cc3fa1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01714225s
Feb 24 10:40:18.779: INFO: Pod "alpine-nnp-false-d1edd4a0-cd35-4fc8-99e8-d9be45cc3fa1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0201332s
Feb 24 10:40:18.779: INFO: Pod "alpine-nnp-false-d1edd4a0-cd35-4fc8-99e8-d9be45cc3fa1" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:40:18.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7442" for this suite.
Feb 24 10:40:24.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:40:24.864: INFO: namespace security-context-test-7442 deletion completed in 6.075808676s

• [SLOW TEST:10.141 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:40:24.864: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:40:26.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1624" for this suite.
Feb 24 10:41:14.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:41:14.978: INFO: namespace kubelet-test-1624 deletion completed in 48.077128602s

• [SLOW TEST:50.114 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 24 10:41:14.978: INFO: >>> kubeConfig: /tmp/kubeconfig-533328996
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 24 10:41:19.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7082" for this suite.
Feb 24 10:41:37.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 24 10:41:37.092: INFO: namespace containers-7082 deletion completed in 18.07572594s

• [SLOW TEST:22.114 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSFeb 24 10:41:37.092: INFO: Running AfterSuite actions on all nodes
Feb 24 10:41:37.092: INFO: Running AfterSuite actions on node 1
Feb 24 10:41:37.092: INFO: Skipping dumping logs from cluster

Ran 276 of 4731 Specs in 7379.199 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4455 Skipped
PASS

Ginkgo ran 1 suite in 2h3m0.428916782s
Test Suite Passed
