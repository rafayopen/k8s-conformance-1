I1024 01:09:31.770839      23 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-000479258
I1024 01:09:31.771242      23 e2e.go:92] Starting e2e run "c04632e8-d5d0-4941-ba72-1b323093fdb3" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1571879368 - Will randomize all specs
Will run 274 of 4897 specs

Oct 24 01:09:31.908: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:09:31.914: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 24 01:09:31.943: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 24 01:09:32.001: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 24 01:09:32.001: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Oct 24 01:09:32.001: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 24 01:09:32.017: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Oct 24 01:09:32.017: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct 24 01:09:32.017: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kubedirector-fsmount' (0 seconds elapsed)
Oct 24 01:09:32.017: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-device-plugin-daemonset' (0 seconds elapsed)
Oct 24 01:09:32.017: INFO: e2e test version: v1.16.2
Oct 24 01:09:32.018: INFO: kube-apiserver version: v1.16.2
Oct 24 01:09:32.018: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:09:32.027: INFO: Cluster IP family: ipv4
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:09:32.027: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename services
Oct 24 01:09:32.086: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:09:32.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4387" for this suite.
Oct 24 01:09:38.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:09:38.269: INFO: namespace services-4387 deletion completed in 6.171726193s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.242 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:09:38.270: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-dfb7a176-9be3-4c93-8476-d514af3035c2
STEP: Creating a pod to test consume secrets
Oct 24 01:09:38.333: INFO: Waiting up to 5m0s for pod "pod-secrets-297b4f8e-7995-4a95-b779-955a66d29072" in namespace "secrets-9012" to be "success or failure"
Oct 24 01:09:38.341: INFO: Pod "pod-secrets-297b4f8e-7995-4a95-b779-955a66d29072": Phase="Pending", Reason="", readiness=false. Elapsed: 7.250999ms
Oct 24 01:09:40.345: INFO: Pod "pod-secrets-297b4f8e-7995-4a95-b779-955a66d29072": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011529068s
STEP: Saw pod success
Oct 24 01:09:40.345: INFO: Pod "pod-secrets-297b4f8e-7995-4a95-b779-955a66d29072" satisfied condition "success or failure"
Oct 24 01:09:40.348: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-297b4f8e-7995-4a95-b779-955a66d29072 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 01:09:40.399: INFO: Waiting for pod pod-secrets-297b4f8e-7995-4a95-b779-955a66d29072 to disappear
Oct 24 01:09:40.403: INFO: Pod pod-secrets-297b4f8e-7995-4a95-b779-955a66d29072 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:09:40.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9012" for this suite.
Oct 24 01:09:46.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:09:46.567: INFO: namespace secrets-9012 deletion completed in 6.159604004s

• [SLOW TEST:8.298 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:09:46.568: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Oct 24 01:09:46.621: INFO: Waiting up to 5m0s for pod "var-expansion-ddafc185-4d4a-41d9-92dd-0fb01674742a" in namespace "var-expansion-9859" to be "success or failure"
Oct 24 01:09:46.625: INFO: Pod "var-expansion-ddafc185-4d4a-41d9-92dd-0fb01674742a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020393ms
Oct 24 01:09:48.630: INFO: Pod "var-expansion-ddafc185-4d4a-41d9-92dd-0fb01674742a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008742253s
STEP: Saw pod success
Oct 24 01:09:48.630: INFO: Pod "var-expansion-ddafc185-4d4a-41d9-92dd-0fb01674742a" satisfied condition "success or failure"
Oct 24 01:09:48.634: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod var-expansion-ddafc185-4d4a-41d9-92dd-0fb01674742a container dapi-container: <nil>
STEP: delete the pod
Oct 24 01:09:48.659: INFO: Waiting for pod var-expansion-ddafc185-4d4a-41d9-92dd-0fb01674742a to disappear
Oct 24 01:09:48.663: INFO: Pod var-expansion-ddafc185-4d4a-41d9-92dd-0fb01674742a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:09:48.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9859" for this suite.
Oct 24 01:09:54.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:09:54.817: INFO: namespace var-expansion-9859 deletion completed in 6.149015568s

• [SLOW TEST:8.249 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:09:54.818: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:09:55.415: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 24 01:09:57.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:09:59.436: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:10:01.435: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:10:03.436: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476195, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:10:06.448: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:10:06.453: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8372-crds.webhook.example.com via the AdmissionRegistration API
Oct 24 01:10:06.520: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:10:07.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6090" for this suite.
Oct 24 01:10:13.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:10:13.868: INFO: namespace webhook-6090 deletion completed in 6.152231067s
STEP: Destroying namespace "webhook-6090-markers" for this suite.
Oct 24 01:10:19.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:10:20.020: INFO: namespace webhook-6090-markers deletion completed in 6.152533001s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.222 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:10:20.040: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 24 01:10:20.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5536'
Oct 24 01:10:20.427: INFO: stderr: ""
Oct 24 01:10:20.427: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Oct 24 01:10:20.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete pods e2e-test-httpd-pod --namespace=kubectl-5536'
Oct 24 01:10:27.209: INFO: stderr: ""
Oct 24 01:10:27.209: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:10:27.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5536" for this suite.
Oct 24 01:10:33.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:10:33.354: INFO: namespace kubectl-5536 deletion completed in 6.139015848s

• [SLOW TEST:13.314 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:10:33.354: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 24 01:10:33.409: INFO: Waiting up to 5m0s for pod "pod-629d91a7-978e-4a4b-965c-b6d3ee9efa6f" in namespace "emptydir-1975" to be "success or failure"
Oct 24 01:10:33.416: INFO: Pod "pod-629d91a7-978e-4a4b-965c-b6d3ee9efa6f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.865272ms
Oct 24 01:10:35.421: INFO: Pod "pod-629d91a7-978e-4a4b-965c-b6d3ee9efa6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011862145s
STEP: Saw pod success
Oct 24 01:10:35.421: INFO: Pod "pod-629d91a7-978e-4a4b-965c-b6d3ee9efa6f" satisfied condition "success or failure"
Oct 24 01:10:35.425: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-629d91a7-978e-4a4b-965c-b6d3ee9efa6f container test-container: <nil>
STEP: delete the pod
Oct 24 01:10:35.459: INFO: Waiting for pod pod-629d91a7-978e-4a4b-965c-b6d3ee9efa6f to disappear
Oct 24 01:10:35.463: INFO: Pod pod-629d91a7-978e-4a4b-965c-b6d3ee9efa6f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:10:35.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1975" for this suite.
Oct 24 01:10:41.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:10:41.615: INFO: namespace emptydir-1975 deletion completed in 6.146569792s

• [SLOW TEST:8.260 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:10:41.616: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 24 01:10:41.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-5357'
Oct 24 01:10:41.846: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 24 01:10:41.846: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Oct 24 01:10:43.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete deployment e2e-test-httpd-deployment --namespace=kubectl-5357'
Oct 24 01:10:44.070: INFO: stderr: ""
Oct 24 01:10:44.070: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:10:44.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5357" for this suite.
Oct 24 01:10:50.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:10:50.222: INFO: namespace kubectl-5357 deletion completed in 6.144308909s

• [SLOW TEST:8.606 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:10:50.222: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct 24 01:10:50.266: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 01:10:50.284: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 01:10:50.289: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm40.mip.storage.hpecorp.net before test
Oct 24 01:10:50.298: INFO: canal-gwnsd from kube-system started at 2019-10-24 00:04:16 +0000 UTC (3 container statuses recorded)
Oct 24 01:10:50.298: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 01:10:50.298: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 01:10:50.298: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 01:10:50.298: INFO: kubedirector-fsmount-7g9kv from kube-system started at 2019-10-24 00:48:32 +0000 UTC (1 container statuses recorded)
Oct 24 01:10:50.298: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 01:10:50.298: INFO: taint-eviction-4 from taint-single-pod-9185 started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:10:50.298: INFO: 	Container pause ready: true, restart count 0
Oct 24 01:10:50.298: INFO: kube-proxy-vr6tb from kube-system started at 2019-10-24 00:03:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:10:50.298: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 01:10:50.298: INFO: sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-vzlsf from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:10:50.298: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:10:50.298: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 01:10:50.298: INFO: coredns-5644d7b6d9-dvtzq from kube-system started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:10:50.298: INFO: 	Container coredns ready: true, restart count 0
Oct 24 01:10:50.298: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm41.mip.storage.hpecorp.net before test
Oct 24 01:10:50.331: INFO: sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-wwg5x from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:10:50.332: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:10:50.332: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 01:10:50.332: INFO: kube-proxy-bmwmz from kube-system started at 2019-10-24 00:03:38 +0000 UTC (1 container statuses recorded)
Oct 24 01:10:50.332: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 01:10:50.332: INFO: kubedirector-5bbd74594b-99xvf from kube-system started at 2019-10-24 00:04:10 +0000 UTC (1 container statuses recorded)
Oct 24 01:10:50.332: INFO: 	Container kubedirector ready: true, restart count 0
Oct 24 01:10:50.332: INFO: sonobuoy from sonobuoy started at 2019-10-24 01:09:14 +0000 UTC (1 container statuses recorded)
Oct 24 01:10:50.332: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 24 01:10:50.332: INFO: sonobuoy-e2e-job-203e2c4356d04dbd from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:10:50.332: INFO: 	Container e2e ready: true, restart count 0
Oct 24 01:10:50.332: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:10:50.332: INFO: kube-state-metrics-5fdb6fdffd-r42bd from kube-system started at 2019-10-24 00:04:06 +0000 UTC (1 container statuses recorded)
Oct 24 01:10:50.332: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 24 01:10:50.332: INFO: canal-zjdkh from kube-system started at 2019-10-24 00:04:16 +0000 UTC (3 container statuses recorded)
Oct 24 01:10:50.332: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 01:10:50.332: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 01:10:50.332: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 01:10:50.332: INFO: kubedirector-fsmount-9w6pk from kube-system started at 2019-10-24 00:05:24 +0000 UTC (1 container statuses recorded)
Oct 24 01:10:50.332: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 01:10:50.332: INFO: kubernetes-dashboard-7c54d59f66-c2jgr from kube-system started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:10:50.332: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-75191299-d889-4976-83b0-cba00358522a 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-75191299-d889-4976-83b0-cba00358522a off the node mip-bd-vm40.mip.storage.hpecorp.net
STEP: verifying the node doesn't have the label kubernetes.io/e2e-75191299-d889-4976-83b0-cba00358522a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:11:02.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2039" for this suite.
Oct 24 01:11:22.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:11:22.585: INFO: namespace sched-pred-2039 deletion completed in 20.140822201s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:32.363 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:11:22.586: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 24 01:11:22.638: INFO: Waiting up to 5m0s for pod "pod-b6ee14ce-a272-4211-8ea5-69316e6437f0" in namespace "emptydir-9146" to be "success or failure"
Oct 24 01:11:22.647: INFO: Pod "pod-b6ee14ce-a272-4211-8ea5-69316e6437f0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.608416ms
Oct 24 01:11:24.653: INFO: Pod "pod-b6ee14ce-a272-4211-8ea5-69316e6437f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015026991s
STEP: Saw pod success
Oct 24 01:11:24.653: INFO: Pod "pod-b6ee14ce-a272-4211-8ea5-69316e6437f0" satisfied condition "success or failure"
Oct 24 01:11:24.657: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-b6ee14ce-a272-4211-8ea5-69316e6437f0 container test-container: <nil>
STEP: delete the pod
Oct 24 01:11:24.686: INFO: Waiting for pod pod-b6ee14ce-a272-4211-8ea5-69316e6437f0 to disappear
Oct 24 01:11:24.690: INFO: Pod pod-b6ee14ce-a272-4211-8ea5-69316e6437f0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:11:24.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9146" for this suite.
Oct 24 01:11:30.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:11:30.836: INFO: namespace emptydir-9146 deletion completed in 6.142405219s

• [SLOW TEST:8.251 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:11:30.837: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Oct 24 01:11:30.886: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:11:35.053: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:11:52.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-171" for this suite.
Oct 24 01:11:58.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:11:58.898: INFO: namespace crd-publish-openapi-171 deletion completed in 6.176834374s

• [SLOW TEST:28.062 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:11:58.899: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Oct 24 01:11:58.980: INFO: Waiting up to 5m0s for pod "client-containers-5d53ac3a-de61-4dcb-914a-553fa8a243b5" in namespace "containers-7165" to be "success or failure"
Oct 24 01:11:58.987: INFO: Pod "client-containers-5d53ac3a-de61-4dcb-914a-553fa8a243b5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.242053ms
Oct 24 01:12:00.992: INFO: Pod "client-containers-5d53ac3a-de61-4dcb-914a-553fa8a243b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011390898s
STEP: Saw pod success
Oct 24 01:12:00.992: INFO: Pod "client-containers-5d53ac3a-de61-4dcb-914a-553fa8a243b5" satisfied condition "success or failure"
Oct 24 01:12:00.996: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod client-containers-5d53ac3a-de61-4dcb-914a-553fa8a243b5 container test-container: <nil>
STEP: delete the pod
Oct 24 01:12:01.023: INFO: Waiting for pod client-containers-5d53ac3a-de61-4dcb-914a-553fa8a243b5 to disappear
Oct 24 01:12:01.029: INFO: Pod client-containers-5d53ac3a-de61-4dcb-914a-553fa8a243b5 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:12:01.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7165" for this suite.
Oct 24 01:12:07.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:12:07.190: INFO: namespace containers-7165 deletion completed in 6.157474505s

• [SLOW TEST:8.292 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:12:07.191: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 24 01:12:07.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-2989'
Oct 24 01:12:07.428: INFO: stderr: ""
Oct 24 01:12:07.428: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Oct 24 01:12:12.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pod e2e-test-httpd-pod --namespace=kubectl-2989 -o json'
Oct 24 01:12:12.660: INFO: stderr: ""
Oct 24 01:12:12.660: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.244.1.30/32\"\n        },\n        \"creationTimestamp\": \"2019-10-24T01:12:07Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2989\",\n        \"resourceVersion\": \"7910\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-2989/pods/e2e-test-httpd-pod\",\n        \"uid\": \"d3a35425-88dc-4001-9590-7a1b9ad993b3\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-zjf8t\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"mip-bd-vm40.mip.storage.hpecorp.net\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-zjf8t\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-zjf8t\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-24T01:12:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-24T01:12:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-24T01:12:08Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-24T01:12:07Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://cdbf8b795be23e392d5a8288b00c8c01724a04a4665c6601114a3b4b93d01277\",\n                \"image\": \"docker.io/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://docker.io/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-24T01:12:08Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"16.143.20.137\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.30\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.1.30\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-24T01:12:07Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 24 01:12:12.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 replace -f - --namespace=kubectl-2989'
Oct 24 01:12:13.167: INFO: stderr: ""
Oct 24 01:12:13.167: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Oct 24 01:12:13.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete pods e2e-test-httpd-pod --namespace=kubectl-2989'
Oct 24 01:12:15.650: INFO: stderr: ""
Oct 24 01:12:15.650: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:12:15.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2989" for this suite.
Oct 24 01:12:21.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:12:21.798: INFO: namespace kubectl-2989 deletion completed in 6.142430472s

• [SLOW TEST:14.608 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:12:21.799: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-9vtc
STEP: Creating a pod to test atomic-volume-subpath
Oct 24 01:12:21.873: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9vtc" in namespace "subpath-8272" to be "success or failure"
Oct 24 01:12:21.877: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.986453ms
Oct 24 01:12:23.882: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Running", Reason="", readiness=true. Elapsed: 2.008966526s
Oct 24 01:12:25.888: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Running", Reason="", readiness=true. Elapsed: 4.014615652s
Oct 24 01:12:27.894: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Running", Reason="", readiness=true. Elapsed: 6.020806276s
Oct 24 01:12:29.900: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Running", Reason="", readiness=true. Elapsed: 8.026547808s
Oct 24 01:12:31.905: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Running", Reason="", readiness=true. Elapsed: 10.031657511s
Oct 24 01:12:33.911: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Running", Reason="", readiness=true. Elapsed: 12.037305173s
Oct 24 01:12:35.916: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Running", Reason="", readiness=true. Elapsed: 14.042548928s
Oct 24 01:12:37.921: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Running", Reason="", readiness=true. Elapsed: 16.047633909s
Oct 24 01:12:39.927: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Running", Reason="", readiness=true. Elapsed: 18.05366372s
Oct 24 01:12:41.932: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Running", Reason="", readiness=true. Elapsed: 20.05833114s
Oct 24 01:12:43.938: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Running", Reason="", readiness=true. Elapsed: 22.064620935s
Oct 24 01:12:45.943: INFO: Pod "pod-subpath-test-configmap-9vtc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.069762619s
STEP: Saw pod success
Oct 24 01:12:45.943: INFO: Pod "pod-subpath-test-configmap-9vtc" satisfied condition "success or failure"
Oct 24 01:12:45.947: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-subpath-test-configmap-9vtc container test-container-subpath-configmap-9vtc: <nil>
STEP: delete the pod
Oct 24 01:12:45.979: INFO: Waiting for pod pod-subpath-test-configmap-9vtc to disappear
Oct 24 01:12:45.984: INFO: Pod pod-subpath-test-configmap-9vtc no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9vtc
Oct 24 01:12:45.984: INFO: Deleting pod "pod-subpath-test-configmap-9vtc" in namespace "subpath-8272"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:12:45.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8272" for this suite.
Oct 24 01:12:52.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:12:52.134: INFO: namespace subpath-8272 deletion completed in 6.142784451s

• [SLOW TEST:30.336 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:12:52.135: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct 24 01:12:52.181: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:12:56.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4858" for this suite.
Oct 24 01:13:02.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:13:02.321: INFO: namespace init-container-4858 deletion completed in 6.156087649s

• [SLOW TEST:10.187 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:13:02.323: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:13:13.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1864" for this suite.
Oct 24 01:13:19.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:13:19.569: INFO: namespace resourcequota-1864 deletion completed in 6.148411638s

• [SLOW TEST:17.247 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:13:19.570: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Oct 24 01:13:19.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-8827'
Oct 24 01:13:19.964: INFO: stderr: ""
Oct 24 01:13:19.964: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 24 01:13:20.969: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:20.969: INFO: Found 0 / 1
Oct 24 01:13:21.970: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:21.970: INFO: Found 0 / 1
Oct 24 01:13:22.970: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:22.970: INFO: Found 0 / 1
Oct 24 01:13:23.970: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:23.971: INFO: Found 0 / 1
Oct 24 01:13:24.970: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:24.970: INFO: Found 0 / 1
Oct 24 01:13:25.971: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:25.971: INFO: Found 0 / 1
Oct 24 01:13:26.971: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:26.971: INFO: Found 0 / 1
Oct 24 01:13:27.970: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:27.970: INFO: Found 0 / 1
Oct 24 01:13:28.981: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:28.981: INFO: Found 0 / 1
Oct 24 01:13:29.971: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:29.971: INFO: Found 0 / 1
Oct 24 01:13:30.970: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:30.970: INFO: Found 0 / 1
Oct 24 01:13:31.970: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:31.970: INFO: Found 0 / 1
Oct 24 01:13:32.972: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:32.972: INFO: Found 0 / 1
Oct 24 01:13:33.971: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:33.971: INFO: Found 0 / 1
Oct 24 01:13:34.970: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:34.970: INFO: Found 0 / 1
Oct 24 01:13:35.972: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:35.972: INFO: Found 1 / 1
Oct 24 01:13:35.972: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 24 01:13:35.976: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:35.976: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 24 01:13:35.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 patch pod redis-master-szx44 --namespace=kubectl-8827 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 24 01:13:36.168: INFO: stderr: ""
Oct 24 01:13:36.168: INFO: stdout: "pod/redis-master-szx44 patched\n"
STEP: checking annotations
Oct 24 01:13:36.173: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:13:36.173: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:13:36.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8827" for this suite.
Oct 24 01:13:48.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:13:48.325: INFO: namespace kubectl-8827 deletion completed in 12.148235045s

• [SLOW TEST:28.756 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:13:48.326: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-44bd5cfb-c810-4d9f-828e-a63de9079b46
STEP: Creating a pod to test consume configMaps
Oct 24 01:13:48.382: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-401f5ec9-c366-4a32-bf48-0faf385e0a34" in namespace "projected-9696" to be "success or failure"
Oct 24 01:13:48.388: INFO: Pod "pod-projected-configmaps-401f5ec9-c366-4a32-bf48-0faf385e0a34": Phase="Pending", Reason="", readiness=false. Elapsed: 5.550757ms
Oct 24 01:13:50.393: INFO: Pod "pod-projected-configmaps-401f5ec9-c366-4a32-bf48-0faf385e0a34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010398774s
STEP: Saw pod success
Oct 24 01:13:50.393: INFO: Pod "pod-projected-configmaps-401f5ec9-c366-4a32-bf48-0faf385e0a34" satisfied condition "success or failure"
Oct 24 01:13:50.396: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-401f5ec9-c366-4a32-bf48-0faf385e0a34 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 01:13:50.423: INFO: Waiting for pod pod-projected-configmaps-401f5ec9-c366-4a32-bf48-0faf385e0a34 to disappear
Oct 24 01:13:50.427: INFO: Pod pod-projected-configmaps-401f5ec9-c366-4a32-bf48-0faf385e0a34 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:13:50.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9696" for this suite.
Oct 24 01:13:56.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:13:56.585: INFO: namespace projected-9696 deletion completed in 6.152561541s

• [SLOW TEST:8.260 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:13:56.586: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Oct 24 01:13:56.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 cluster-info'
Oct 24 01:13:56.815: INFO: stderr: ""
Oct 24 01:13:56.815: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:13:56.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6193" for this suite.
Oct 24 01:14:02.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:14:02.972: INFO: namespace kubectl-6193 deletion completed in 6.153281316s

• [SLOW TEST:6.386 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:14:02.973: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Oct 24 01:14:03.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=kubectl-5446 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 24 01:14:04.462: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 24 01:14:04.462: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:14:06.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5446" for this suite.
Oct 24 01:14:20.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:14:20.628: INFO: namespace kubectl-5446 deletion completed in 14.153009087s

• [SLOW TEST:17.655 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:14:20.628: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 24 01:14:20.699: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2401 /api/v1/namespaces/watch-2401/configmaps/e2e-watch-test-label-changed 967fd03e-14c0-4d59-b6f8-18b5ae0abfa8 8325 0 2019-10-24 01:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 24 01:14:20.700: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2401 /api/v1/namespaces/watch-2401/configmaps/e2e-watch-test-label-changed 967fd03e-14c0-4d59-b6f8-18b5ae0abfa8 8326 0 2019-10-24 01:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 24 01:14:20.700: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2401 /api/v1/namespaces/watch-2401/configmaps/e2e-watch-test-label-changed 967fd03e-14c0-4d59-b6f8-18b5ae0abfa8 8327 0 2019-10-24 01:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 24 01:14:30.733: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2401 /api/v1/namespaces/watch-2401/configmaps/e2e-watch-test-label-changed 967fd03e-14c0-4d59-b6f8-18b5ae0abfa8 8343 0 2019-10-24 01:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 24 01:14:30.733: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2401 /api/v1/namespaces/watch-2401/configmaps/e2e-watch-test-label-changed 967fd03e-14c0-4d59-b6f8-18b5ae0abfa8 8344 0 2019-10-24 01:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 24 01:14:30.734: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2401 /api/v1/namespaces/watch-2401/configmaps/e2e-watch-test-label-changed 967fd03e-14c0-4d59-b6f8-18b5ae0abfa8 8345 0 2019-10-24 01:14:20 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:14:30.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2401" for this suite.
Oct 24 01:14:36.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:14:36.919: INFO: namespace watch-2401 deletion completed in 6.181801425s

• [SLOW TEST:16.291 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:14:36.920: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct 24 01:14:39.533: INFO: Successfully updated pod "labelsupdatef904185f-b29f-4341-9138-0e6ea1d731ce"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:14:41.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4385" for this suite.
Oct 24 01:14:57.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:14:57.721: INFO: namespace projected-4385 deletion completed in 16.152148185s

• [SLOW TEST:20.802 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:14:57.722: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 24 01:14:57.790: INFO: Waiting up to 5m0s for pod "pod-5c598bb8-7a89-4ad5-b664-dfc744f3a0d2" in namespace "emptydir-9670" to be "success or failure"
Oct 24 01:14:57.795: INFO: Pod "pod-5c598bb8-7a89-4ad5-b664-dfc744f3a0d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.784269ms
Oct 24 01:14:59.800: INFO: Pod "pod-5c598bb8-7a89-4ad5-b664-dfc744f3a0d2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010606348s
Oct 24 01:15:01.806: INFO: Pod "pod-5c598bb8-7a89-4ad5-b664-dfc744f3a0d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015939007s
STEP: Saw pod success
Oct 24 01:15:01.806: INFO: Pod "pod-5c598bb8-7a89-4ad5-b664-dfc744f3a0d2" satisfied condition "success or failure"
Oct 24 01:15:01.810: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-5c598bb8-7a89-4ad5-b664-dfc744f3a0d2 container test-container: <nil>
STEP: delete the pod
Oct 24 01:15:01.837: INFO: Waiting for pod pod-5c598bb8-7a89-4ad5-b664-dfc744f3a0d2 to disappear
Oct 24 01:15:01.844: INFO: Pod pod-5c598bb8-7a89-4ad5-b664-dfc744f3a0d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:15:01.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9670" for this suite.
Oct 24 01:15:07.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:15:08.010: INFO: namespace emptydir-9670 deletion completed in 6.157475258s

• [SLOW TEST:10.287 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:15:08.010: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 24 01:15:20.111: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5747 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 01:15:20.111: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:15:20.260: INFO: Exec stderr: ""
Oct 24 01:15:20.260: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5747 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 01:15:20.260: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:15:20.401: INFO: Exec stderr: ""
Oct 24 01:15:20.401: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5747 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 01:15:20.401: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:15:20.544: INFO: Exec stderr: ""
Oct 24 01:15:20.544: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5747 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 01:15:20.544: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:15:20.688: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 24 01:15:20.688: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5747 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 01:15:20.688: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:15:20.834: INFO: Exec stderr: ""
Oct 24 01:15:20.834: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5747 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 01:15:20.834: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:15:20.985: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 24 01:15:20.985: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5747 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 01:15:20.985: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:15:21.139: INFO: Exec stderr: ""
Oct 24 01:15:21.139: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5747 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 01:15:21.139: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:15:21.288: INFO: Exec stderr: ""
Oct 24 01:15:21.288: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5747 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 01:15:21.288: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:15:21.428: INFO: Exec stderr: ""
Oct 24 01:15:21.428: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5747 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 01:15:21.428: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:15:21.573: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:15:21.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5747" for this suite.
Oct 24 01:16:09.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:16:09.721: INFO: namespace e2e-kubelet-etc-hosts-5747 deletion completed in 48.143506739s

• [SLOW TEST:61.711 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:16:09.722: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Oct 24 01:16:19.800: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:16:19.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1024 01:16:19.799942      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-8413" for this suite.
Oct 24 01:16:25.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:16:25.953: INFO: namespace gc-8413 deletion completed in 6.148779757s

• [SLOW TEST:16.232 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:16:25.954: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Oct 24 01:16:26.016: INFO: Waiting up to 5m0s for pod "client-containers-bd6ce99b-90d1-48f4-972d-fe244fb94840" in namespace "containers-5854" to be "success or failure"
Oct 24 01:16:26.020: INFO: Pod "client-containers-bd6ce99b-90d1-48f4-972d-fe244fb94840": Phase="Pending", Reason="", readiness=false. Elapsed: 4.393516ms
Oct 24 01:16:28.025: INFO: Pod "client-containers-bd6ce99b-90d1-48f4-972d-fe244fb94840": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009117738s
STEP: Saw pod success
Oct 24 01:16:28.025: INFO: Pod "client-containers-bd6ce99b-90d1-48f4-972d-fe244fb94840" satisfied condition "success or failure"
Oct 24 01:16:28.028: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod client-containers-bd6ce99b-90d1-48f4-972d-fe244fb94840 container test-container: <nil>
STEP: delete the pod
Oct 24 01:16:28.062: INFO: Waiting for pod client-containers-bd6ce99b-90d1-48f4-972d-fe244fb94840 to disappear
Oct 24 01:16:28.068: INFO: Pod client-containers-bd6ce99b-90d1-48f4-972d-fe244fb94840 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:16:28.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5854" for this suite.
Oct 24 01:16:34.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:16:34.226: INFO: namespace containers-5854 deletion completed in 6.153559445s

• [SLOW TEST:8.273 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:16:34.226: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2739
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-2739
STEP: Creating statefulset with conflicting port in namespace statefulset-2739
STEP: Waiting until pod test-pod will start running in namespace statefulset-2739
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2739
Oct 24 01:16:38.338: INFO: Observed stateful pod in namespace: statefulset-2739, name: ss-0, uid: 11f2b2b8-da2b-4634-a85a-b7bfc81309d0, status phase: Pending. Waiting for statefulset controller to delete.
Oct 24 01:16:38.909: INFO: Observed stateful pod in namespace: statefulset-2739, name: ss-0, uid: 11f2b2b8-da2b-4634-a85a-b7bfc81309d0, status phase: Failed. Waiting for statefulset controller to delete.
Oct 24 01:16:38.919: INFO: Observed stateful pod in namespace: statefulset-2739, name: ss-0, uid: 11f2b2b8-da2b-4634-a85a-b7bfc81309d0, status phase: Failed. Waiting for statefulset controller to delete.
Oct 24 01:16:38.924: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2739
STEP: Removing pod with conflicting port in namespace statefulset-2739
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2739 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 24 01:16:42.970: INFO: Deleting all statefulset in ns statefulset-2739
Oct 24 01:16:42.974: INFO: Scaling statefulset ss to 0
Oct 24 01:16:52.995: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 01:16:52.999: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:16:53.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2739" for this suite.
Oct 24 01:17:05.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:17:05.182: INFO: namespace statefulset-2739 deletion completed in 12.15474576s

• [SLOW TEST:30.955 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:17:05.182: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 24 01:17:07.257: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:17:07.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3028" for this suite.
Oct 24 01:17:13.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:17:13.428: INFO: namespace container-runtime-3028 deletion completed in 6.148920477s

• [SLOW TEST:8.247 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:17:13.429: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-3644/configmap-test-7d75da1e-4105-4e51-b856-3ed6a56e3ba8
STEP: Creating a pod to test consume configMaps
Oct 24 01:17:13.485: INFO: Waiting up to 5m0s for pod "pod-configmaps-cf7d5d8f-a405-48c5-8080-16a717eec290" in namespace "configmap-3644" to be "success or failure"
Oct 24 01:17:13.490: INFO: Pod "pod-configmaps-cf7d5d8f-a405-48c5-8080-16a717eec290": Phase="Pending", Reason="", readiness=false. Elapsed: 4.549933ms
Oct 24 01:17:15.495: INFO: Pod "pod-configmaps-cf7d5d8f-a405-48c5-8080-16a717eec290": Phase="Running", Reason="", readiness=true. Elapsed: 2.009677485s
Oct 24 01:17:17.502: INFO: Pod "pod-configmaps-cf7d5d8f-a405-48c5-8080-16a717eec290": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016144275s
STEP: Saw pod success
Oct 24 01:17:17.502: INFO: Pod "pod-configmaps-cf7d5d8f-a405-48c5-8080-16a717eec290" satisfied condition "success or failure"
Oct 24 01:17:17.505: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-cf7d5d8f-a405-48c5-8080-16a717eec290 container env-test: <nil>
STEP: delete the pod
Oct 24 01:17:17.535: INFO: Waiting for pod pod-configmaps-cf7d5d8f-a405-48c5-8080-16a717eec290 to disappear
Oct 24 01:17:17.539: INFO: Pod pod-configmaps-cf7d5d8f-a405-48c5-8080-16a717eec290 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:17:17.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3644" for this suite.
Oct 24 01:17:23.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:17:23.698: INFO: namespace configmap-3644 deletion completed in 6.155154755s

• [SLOW TEST:10.270 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:17:23.699: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 01:17:23.767: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4cde3e2c-910d-4ea3-a59f-279aa9f1601f" in namespace "downward-api-5778" to be "success or failure"
Oct 24 01:17:23.772: INFO: Pod "downwardapi-volume-4cde3e2c-910d-4ea3-a59f-279aa9f1601f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.135977ms
Oct 24 01:17:25.776: INFO: Pod "downwardapi-volume-4cde3e2c-910d-4ea3-a59f-279aa9f1601f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009611881s
STEP: Saw pod success
Oct 24 01:17:25.776: INFO: Pod "downwardapi-volume-4cde3e2c-910d-4ea3-a59f-279aa9f1601f" satisfied condition "success or failure"
Oct 24 01:17:25.781: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-4cde3e2c-910d-4ea3-a59f-279aa9f1601f container client-container: <nil>
STEP: delete the pod
Oct 24 01:17:25.806: INFO: Waiting for pod downwardapi-volume-4cde3e2c-910d-4ea3-a59f-279aa9f1601f to disappear
Oct 24 01:17:25.810: INFO: Pod downwardapi-volume-4cde3e2c-910d-4ea3-a59f-279aa9f1601f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:17:25.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5778" for this suite.
Oct 24 01:17:31.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:17:31.969: INFO: namespace downward-api-5778 deletion completed in 6.154971736s

• [SLOW TEST:8.270 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:17:31.969: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-5916f2e3-d695-4f2d-b4ac-ddbb637fd52b
STEP: Creating a pod to test consume secrets
Oct 24 01:17:32.030: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-692abac6-0e98-4ddf-bf35-35eb11df890e" in namespace "projected-6924" to be "success or failure"
Oct 24 01:17:32.036: INFO: Pod "pod-projected-secrets-692abac6-0e98-4ddf-bf35-35eb11df890e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.302623ms
Oct 24 01:17:34.040: INFO: Pod "pod-projected-secrets-692abac6-0e98-4ddf-bf35-35eb11df890e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009681098s
STEP: Saw pod success
Oct 24 01:17:34.040: INFO: Pod "pod-projected-secrets-692abac6-0e98-4ddf-bf35-35eb11df890e" satisfied condition "success or failure"
Oct 24 01:17:34.044: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-692abac6-0e98-4ddf-bf35-35eb11df890e container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 24 01:17:34.074: INFO: Waiting for pod pod-projected-secrets-692abac6-0e98-4ddf-bf35-35eb11df890e to disappear
Oct 24 01:17:34.079: INFO: Pod pod-projected-secrets-692abac6-0e98-4ddf-bf35-35eb11df890e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:17:34.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6924" for this suite.
Oct 24 01:17:40.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:17:40.233: INFO: namespace projected-6924 deletion completed in 6.148475155s

• [SLOW TEST:8.264 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:17:40.233: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:17:40.287: INFO: Waiting up to 5m0s for pod "busybox-user-65534-e261a913-6c19-4e05-8d98-939528ea1abe" in namespace "security-context-test-1316" to be "success or failure"
Oct 24 01:17:40.290: INFO: Pod "busybox-user-65534-e261a913-6c19-4e05-8d98-939528ea1abe": Phase="Pending", Reason="", readiness=false. Elapsed: 3.562903ms
Oct 24 01:17:42.295: INFO: Pod "busybox-user-65534-e261a913-6c19-4e05-8d98-939528ea1abe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008146709s
Oct 24 01:17:42.295: INFO: Pod "busybox-user-65534-e261a913-6c19-4e05-8d98-939528ea1abe" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:17:42.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1316" for this suite.
Oct 24 01:17:48.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:17:48.440: INFO: namespace security-context-test-1316 deletion completed in 6.140001741s

• [SLOW TEST:8.207 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:17:48.440: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct 24 01:17:51.027: INFO: Successfully updated pod "labelsupdate59108da4-ce81-4be6-ac38-2064e2480934"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:17:53.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2547" for this suite.
Oct 24 01:18:09.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:18:09.206: INFO: namespace downward-api-2547 deletion completed in 16.141107247s

• [SLOW TEST:20.765 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:18:09.206: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct 24 01:18:09.250: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 01:18:09.264: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 01:18:09.268: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm40.mip.storage.hpecorp.net before test
Oct 24 01:18:09.278: INFO: kube-proxy-vr6tb from kube-system started at 2019-10-24 00:03:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:18:09.278: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 01:18:09.278: INFO: sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-vzlsf from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:18:09.278: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:18:09.278: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 01:18:09.278: INFO: coredns-5644d7b6d9-dvtzq from kube-system started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:18:09.278: INFO: 	Container coredns ready: true, restart count 0
Oct 24 01:18:09.278: INFO: canal-gwnsd from kube-system started at 2019-10-24 00:04:16 +0000 UTC (3 container statuses recorded)
Oct 24 01:18:09.278: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 01:18:09.278: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 01:18:09.278: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 01:18:09.278: INFO: kubedirector-fsmount-7g9kv from kube-system started at 2019-10-24 00:48:32 +0000 UTC (1 container statuses recorded)
Oct 24 01:18:09.278: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 01:18:09.278: INFO: taint-eviction-4 from taint-single-pod-9185 started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:18:09.278: INFO: 	Container pause ready: true, restart count 0
Oct 24 01:18:09.278: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm41.mip.storage.hpecorp.net before test
Oct 24 01:18:09.327: INFO: kube-state-metrics-5fdb6fdffd-r42bd from kube-system started at 2019-10-24 00:04:06 +0000 UTC (1 container statuses recorded)
Oct 24 01:18:09.327: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 24 01:18:09.327: INFO: canal-zjdkh from kube-system started at 2019-10-24 00:04:16 +0000 UTC (3 container statuses recorded)
Oct 24 01:18:09.327: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 01:18:09.327: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 01:18:09.327: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 01:18:09.327: INFO: kubedirector-fsmount-9w6pk from kube-system started at 2019-10-24 00:05:24 +0000 UTC (1 container statuses recorded)
Oct 24 01:18:09.327: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 01:18:09.327: INFO: kubernetes-dashboard-7c54d59f66-c2jgr from kube-system started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:18:09.327: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 24 01:18:09.327: INFO: sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-wwg5x from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:18:09.327: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:18:09.327: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 01:18:09.327: INFO: kube-proxy-bmwmz from kube-system started at 2019-10-24 00:03:38 +0000 UTC (1 container statuses recorded)
Oct 24 01:18:09.327: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 01:18:09.328: INFO: kubedirector-5bbd74594b-99xvf from kube-system started at 2019-10-24 00:04:10 +0000 UTC (1 container statuses recorded)
Oct 24 01:18:09.328: INFO: 	Container kubedirector ready: true, restart count 0
Oct 24 01:18:09.328: INFO: sonobuoy from sonobuoy started at 2019-10-24 01:09:14 +0000 UTC (1 container statuses recorded)
Oct 24 01:18:09.328: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 24 01:18:09.328: INFO: sonobuoy-e2e-job-203e2c4356d04dbd from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:18:09.328: INFO: 	Container e2e ready: true, restart count 0
Oct 24 01:18:09.328: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-4f55e8da-e34a-4c93-adf3-f261b82ebf94 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-4f55e8da-e34a-4c93-adf3-f261b82ebf94 off the node mip-bd-vm40.mip.storage.hpecorp.net
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4f55e8da-e34a-4c93-adf3-f261b82ebf94
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:18:13.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5071" for this suite.
Oct 24 01:18:33.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:18:33.582: INFO: namespace sched-pred-5071 deletion completed in 20.151054465s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:24.376 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:18:33.582: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 24 01:18:33.641: INFO: Waiting up to 5m0s for pod "pod-ce6d8e9e-0aaa-4eb9-abe2-841873fb0651" in namespace "emptydir-3361" to be "success or failure"
Oct 24 01:18:33.647: INFO: Pod "pod-ce6d8e9e-0aaa-4eb9-abe2-841873fb0651": Phase="Pending", Reason="", readiness=false. Elapsed: 6.492032ms
Oct 24 01:18:35.653: INFO: Pod "pod-ce6d8e9e-0aaa-4eb9-abe2-841873fb0651": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011897649s
STEP: Saw pod success
Oct 24 01:18:35.653: INFO: Pod "pod-ce6d8e9e-0aaa-4eb9-abe2-841873fb0651" satisfied condition "success or failure"
Oct 24 01:18:35.657: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-ce6d8e9e-0aaa-4eb9-abe2-841873fb0651 container test-container: <nil>
STEP: delete the pod
Oct 24 01:18:35.687: INFO: Waiting for pod pod-ce6d8e9e-0aaa-4eb9-abe2-841873fb0651 to disappear
Oct 24 01:18:35.707: INFO: Pod pod-ce6d8e9e-0aaa-4eb9-abe2-841873fb0651 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:18:35.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3361" for this suite.
Oct 24 01:18:41.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:18:41.864: INFO: namespace emptydir-3361 deletion completed in 6.1502996s

• [SLOW TEST:8.281 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:18:41.865: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 24 01:18:41.923: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4290 /api/v1/namespaces/watch-4290/configmaps/e2e-watch-test-watch-closed 57b5f5a3-4533-41db-a5d0-2b810c16304c 9298 0 2019-10-24 01:18:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 24 01:18:41.923: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4290 /api/v1/namespaces/watch-4290/configmaps/e2e-watch-test-watch-closed 57b5f5a3-4533-41db-a5d0-2b810c16304c 9299 0 2019-10-24 01:18:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 24 01:18:41.942: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4290 /api/v1/namespaces/watch-4290/configmaps/e2e-watch-test-watch-closed 57b5f5a3-4533-41db-a5d0-2b810c16304c 9300 0 2019-10-24 01:18:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 24 01:18:41.942: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-4290 /api/v1/namespaces/watch-4290/configmaps/e2e-watch-test-watch-closed 57b5f5a3-4533-41db-a5d0-2b810c16304c 9301 0 2019-10-24 01:18:41 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:18:41.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4290" for this suite.
Oct 24 01:18:47.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:18:48.100: INFO: namespace watch-4290 deletion completed in 6.152795372s

• [SLOW TEST:6.235 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:18:48.100: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7620
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-7620
I1024 01:18:48.220386      23 runners.go:184] Created replication controller with name: externalname-service, namespace: services-7620, replica count: 2
I1024 01:18:51.271059      23 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 01:18:51.271: INFO: Creating new exec pod
Oct 24 01:18:54.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-7620 execpodjvbts -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Oct 24 01:18:54.638: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct 24 01:18:54.638: INFO: stdout: ""
Oct 24 01:18:54.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-7620 execpodjvbts -- /bin/sh -x -c nc -zv -t -w 2 10.96.19.152 80'
Oct 24 01:18:54.974: INFO: stderr: "+ nc -zv -t -w 2 10.96.19.152 80\nConnection to 10.96.19.152 80 port [tcp/http] succeeded!\n"
Oct 24 01:18:54.974: INFO: stdout: ""
Oct 24 01:18:54.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-7620 execpodjvbts -- /bin/sh -x -c nc -zv -t -w 2 16.143.20.137 31723'
Oct 24 01:18:55.306: INFO: stderr: "+ nc -zv -t -w 2 16.143.20.137 31723\nConnection to 16.143.20.137 31723 port [tcp/31723] succeeded!\n"
Oct 24 01:18:55.306: INFO: stdout: ""
Oct 24 01:18:55.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-7620 execpodjvbts -- /bin/sh -x -c nc -zv -t -w 2 16.143.20.138 31723'
Oct 24 01:18:55.648: INFO: stderr: "+ nc -zv -t -w 2 16.143.20.138 31723\nConnection to 16.143.20.138 31723 port [tcp/31723] succeeded!\n"
Oct 24 01:18:55.648: INFO: stdout: ""
Oct 24 01:18:55.648: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:18:55.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7620" for this suite.
Oct 24 01:19:01.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:19:01.832: INFO: namespace services-7620 deletion completed in 6.149041025s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.732 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:19:01.832: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:19:02.474: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 24 01:19:04.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476742, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476742, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476742, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476742, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:19:07.513: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:19:07.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6441" for this suite.
Oct 24 01:19:19.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:19:19.720: INFO: namespace webhook-6441 deletion completed in 12.149428609s
STEP: Destroying namespace "webhook-6441-markers" for this suite.
Oct 24 01:19:25.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:19:25.877: INFO: namespace webhook-6441-markers deletion completed in 6.157335501s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.063 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:19:25.895: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-65995e01-7e5f-4173-ab25-f335bccacdfb
STEP: Creating a pod to test consume configMaps
Oct 24 01:19:25.964: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aee763fa-5df8-433c-9ba1-cfdbca20ecb7" in namespace "projected-2134" to be "success or failure"
Oct 24 01:19:25.971: INFO: Pod "pod-projected-configmaps-aee763fa-5df8-433c-9ba1-cfdbca20ecb7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.230689ms
Oct 24 01:19:27.975: INFO: Pod "pod-projected-configmaps-aee763fa-5df8-433c-9ba1-cfdbca20ecb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010667976s
STEP: Saw pod success
Oct 24 01:19:27.975: INFO: Pod "pod-projected-configmaps-aee763fa-5df8-433c-9ba1-cfdbca20ecb7" satisfied condition "success or failure"
Oct 24 01:19:27.978: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-aee763fa-5df8-433c-9ba1-cfdbca20ecb7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 01:19:28.004: INFO: Waiting for pod pod-projected-configmaps-aee763fa-5df8-433c-9ba1-cfdbca20ecb7 to disappear
Oct 24 01:19:28.008: INFO: Pod pod-projected-configmaps-aee763fa-5df8-433c-9ba1-cfdbca20ecb7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:19:28.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2134" for this suite.
Oct 24 01:19:34.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:19:34.155: INFO: namespace projected-2134 deletion completed in 6.142068575s

• [SLOW TEST:8.260 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:19:34.155: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-21a807a2-2409-4b04-ac0b-6e40042750fc
STEP: Creating configMap with name cm-test-opt-upd-fc26686e-e342-4508-95d5-eb2f06831a07
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-21a807a2-2409-4b04-ac0b-6e40042750fc
STEP: Updating configmap cm-test-opt-upd-fc26686e-e342-4508-95d5-eb2f06831a07
STEP: Creating configMap with name cm-test-opt-create-833aafac-64df-4c26-b2ed-48d310fafcf0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:19:38.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6825" for this suite.
Oct 24 01:19:50.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:19:50.491: INFO: namespace configmap-6825 deletion completed in 12.147052933s

• [SLOW TEST:16.336 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:19:50.491: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:19:51.513: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 24 01:19:53.527: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476791, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476791, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476791, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707476791, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:19:56.544: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:19:56.550: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5489-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:19:57.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6982" for this suite.
Oct 24 01:20:09.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:20:10.098: INFO: namespace webhook-6982 deletion completed in 12.148654535s
STEP: Destroying namespace "webhook-6982-markers" for this suite.
Oct 24 01:20:16.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:20:16.257: INFO: namespace webhook-6982-markers deletion completed in 6.158954234s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.784 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:20:16.276: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Oct 24 01:20:18.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec pod-sharedvolume-3c3b1078-1c23-4442-b4dc-8d460f2216a6 -c busybox-main-container --namespace=emptydir-5535 -- cat /usr/share/volumeshare/shareddata.txt'
Oct 24 01:20:18.684: INFO: stderr: ""
Oct 24 01:20:18.684: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:20:18.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5535" for this suite.
Oct 24 01:20:24.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:20:24.836: INFO: namespace emptydir-5535 deletion completed in 6.146441512s

• [SLOW TEST:8.560 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:20:24.837: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct 24 01:20:24.895: INFO: Waiting up to 5m0s for pod "downward-api-43c841d6-0434-4ed5-86f8-fe16bd9b7eed" in namespace "downward-api-5480" to be "success or failure"
Oct 24 01:20:24.902: INFO: Pod "downward-api-43c841d6-0434-4ed5-86f8-fe16bd9b7eed": Phase="Pending", Reason="", readiness=false. Elapsed: 7.670183ms
Oct 24 01:20:26.908: INFO: Pod "downward-api-43c841d6-0434-4ed5-86f8-fe16bd9b7eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012796666s
Oct 24 01:20:28.914: INFO: Pod "downward-api-43c841d6-0434-4ed5-86f8-fe16bd9b7eed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019260409s
STEP: Saw pod success
Oct 24 01:20:28.914: INFO: Pod "downward-api-43c841d6-0434-4ed5-86f8-fe16bd9b7eed" satisfied condition "success or failure"
Oct 24 01:20:28.919: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downward-api-43c841d6-0434-4ed5-86f8-fe16bd9b7eed container dapi-container: <nil>
STEP: delete the pod
Oct 24 01:20:28.958: INFO: Waiting for pod downward-api-43c841d6-0434-4ed5-86f8-fe16bd9b7eed to disappear
Oct 24 01:20:28.963: INFO: Pod downward-api-43c841d6-0434-4ed5-86f8-fe16bd9b7eed no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:20:28.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5480" for this suite.
Oct 24 01:20:34.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:20:35.119: INFO: namespace downward-api-5480 deletion completed in 6.151704169s

• [SLOW TEST:10.282 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:20:35.121: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Oct 24 01:20:35.179: INFO: Waiting up to 5m0s for pod "client-containers-d010e8f6-8281-4ee7-a990-7baba010b620" in namespace "containers-8696" to be "success or failure"
Oct 24 01:20:35.182: INFO: Pod "client-containers-d010e8f6-8281-4ee7-a990-7baba010b620": Phase="Pending", Reason="", readiness=false. Elapsed: 3.613288ms
Oct 24 01:20:37.188: INFO: Pod "client-containers-d010e8f6-8281-4ee7-a990-7baba010b620": Phase="Running", Reason="", readiness=true. Elapsed: 2.009189723s
Oct 24 01:20:39.193: INFO: Pod "client-containers-d010e8f6-8281-4ee7-a990-7baba010b620": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014332427s
STEP: Saw pod success
Oct 24 01:20:39.193: INFO: Pod "client-containers-d010e8f6-8281-4ee7-a990-7baba010b620" satisfied condition "success or failure"
Oct 24 01:20:39.198: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod client-containers-d010e8f6-8281-4ee7-a990-7baba010b620 container test-container: <nil>
STEP: delete the pod
Oct 24 01:20:39.225: INFO: Waiting for pod client-containers-d010e8f6-8281-4ee7-a990-7baba010b620 to disappear
Oct 24 01:20:39.228: INFO: Pod client-containers-d010e8f6-8281-4ee7-a990-7baba010b620 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:20:39.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8696" for this suite.
Oct 24 01:20:45.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:20:45.384: INFO: namespace containers-8696 deletion completed in 6.151550181s

• [SLOW TEST:10.263 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:20:45.385: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 24 01:20:48.469: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:20:48.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1420" for this suite.
Oct 24 01:20:54.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:20:54.648: INFO: namespace container-runtime-1420 deletion completed in 6.157405008s

• [SLOW TEST:9.263 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:20:54.649: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:20:54.694: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:20:55.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5638" for this suite.
Oct 24 01:21:01.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:21:01.878: INFO: namespace custom-resource-definition-5638 deletion completed in 6.140886918s

• [SLOW TEST:7.230 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:21:01.879: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-f840149d-3d3f-4e36-8508-c738ae2cc19a
STEP: Creating a pod to test consume secrets
Oct 24 01:21:01.935: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-084499f1-446f-4c3b-883a-b35af6788f5f" in namespace "projected-7090" to be "success or failure"
Oct 24 01:21:01.941: INFO: Pod "pod-projected-secrets-084499f1-446f-4c3b-883a-b35af6788f5f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.715649ms
Oct 24 01:21:03.945: INFO: Pod "pod-projected-secrets-084499f1-446f-4c3b-883a-b35af6788f5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010244809s
STEP: Saw pod success
Oct 24 01:21:03.945: INFO: Pod "pod-projected-secrets-084499f1-446f-4c3b-883a-b35af6788f5f" satisfied condition "success or failure"
Oct 24 01:21:03.949: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-084499f1-446f-4c3b-883a-b35af6788f5f container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 24 01:21:03.977: INFO: Waiting for pod pod-projected-secrets-084499f1-446f-4c3b-883a-b35af6788f5f to disappear
Oct 24 01:21:03.981: INFO: Pod pod-projected-secrets-084499f1-446f-4c3b-883a-b35af6788f5f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:21:03.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7090" for this suite.
Oct 24 01:21:10.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:21:10.130: INFO: namespace projected-7090 deletion completed in 6.144515339s

• [SLOW TEST:8.251 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:21:10.131: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct 24 01:21:10.184: INFO: Waiting up to 5m0s for pod "downward-api-568181f5-77fb-444c-94b0-cba4c4eefdbc" in namespace "downward-api-3574" to be "success or failure"
Oct 24 01:21:10.190: INFO: Pod "downward-api-568181f5-77fb-444c-94b0-cba4c4eefdbc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.763918ms
Oct 24 01:21:12.195: INFO: Pod "downward-api-568181f5-77fb-444c-94b0-cba4c4eefdbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010866006s
Oct 24 01:21:14.203: INFO: Pod "downward-api-568181f5-77fb-444c-94b0-cba4c4eefdbc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018993482s
Oct 24 01:21:16.207: INFO: Pod "downward-api-568181f5-77fb-444c-94b0-cba4c4eefdbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.023307397s
STEP: Saw pod success
Oct 24 01:21:16.207: INFO: Pod "downward-api-568181f5-77fb-444c-94b0-cba4c4eefdbc" satisfied condition "success or failure"
Oct 24 01:21:16.211: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downward-api-568181f5-77fb-444c-94b0-cba4c4eefdbc container dapi-container: <nil>
STEP: delete the pod
Oct 24 01:21:16.263: INFO: Waiting for pod downward-api-568181f5-77fb-444c-94b0-cba4c4eefdbc to disappear
Oct 24 01:21:16.268: INFO: Pod downward-api-568181f5-77fb-444c-94b0-cba4c4eefdbc no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:21:16.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3574" for this suite.
Oct 24 01:21:22.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:21:22.411: INFO: namespace downward-api-3574 deletion completed in 6.138625325s

• [SLOW TEST:12.280 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:21:22.411: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:21:22.487: INFO: Create a RollingUpdate DaemonSet
Oct 24 01:21:22.492: INFO: Check that daemon pods launch on every node of the cluster
Oct 24 01:21:22.498: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:22.502: INFO: Number of nodes with available pods: 0
Oct 24 01:21:22.503: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:23.509: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:23.513: INFO: Number of nodes with available pods: 0
Oct 24 01:21:23.513: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:24.510: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:24.515: INFO: Number of nodes with available pods: 1
Oct 24 01:21:24.515: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:25.509: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:25.513: INFO: Number of nodes with available pods: 1
Oct 24 01:21:25.513: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:26.509: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:26.513: INFO: Number of nodes with available pods: 1
Oct 24 01:21:26.513: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:27.510: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:27.514: INFO: Number of nodes with available pods: 1
Oct 24 01:21:27.514: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:28.509: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:28.513: INFO: Number of nodes with available pods: 1
Oct 24 01:21:28.514: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:29.508: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:29.512: INFO: Number of nodes with available pods: 1
Oct 24 01:21:29.512: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:30.509: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:30.513: INFO: Number of nodes with available pods: 1
Oct 24 01:21:30.513: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:31.509: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:31.513: INFO: Number of nodes with available pods: 1
Oct 24 01:21:31.513: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:32.509: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:32.513: INFO: Number of nodes with available pods: 1
Oct 24 01:21:32.513: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:33.508: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:33.513: INFO: Number of nodes with available pods: 1
Oct 24 01:21:33.513: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:34.509: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:34.514: INFO: Number of nodes with available pods: 1
Oct 24 01:21:34.514: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:35.510: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:35.515: INFO: Number of nodes with available pods: 1
Oct 24 01:21:35.515: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:36.509: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:36.514: INFO: Number of nodes with available pods: 1
Oct 24 01:21:36.514: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:37.510: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:37.515: INFO: Number of nodes with available pods: 1
Oct 24 01:21:37.515: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:21:38.509: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:38.514: INFO: Number of nodes with available pods: 2
Oct 24 01:21:38.514: INFO: Number of running nodes: 2, number of available pods: 2
Oct 24 01:21:38.514: INFO: Update the DaemonSet to trigger a rollout
Oct 24 01:21:38.525: INFO: Updating DaemonSet daemon-set
Oct 24 01:21:46.545: INFO: Roll back the DaemonSet before rollout is complete
Oct 24 01:21:46.554: INFO: Updating DaemonSet daemon-set
Oct 24 01:21:46.554: INFO: Make sure DaemonSet rollback is complete
Oct 24 01:21:46.558: INFO: Wrong image for pod: daemon-set-r5dll. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Oct 24 01:21:46.558: INFO: Pod daemon-set-r5dll is not available
Oct 24 01:21:46.563: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:47.569: INFO: Wrong image for pod: daemon-set-r5dll. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Oct 24 01:21:47.569: INFO: Pod daemon-set-r5dll is not available
Oct 24 01:21:47.574: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:48.569: INFO: Wrong image for pod: daemon-set-r5dll. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Oct 24 01:21:48.569: INFO: Pod daemon-set-r5dll is not available
Oct 24 01:21:48.574: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:21:49.570: INFO: Pod daemon-set-q472w is not available
Oct 24 01:21:49.576: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7866, will wait for the garbage collector to delete the pods
Oct 24 01:21:49.653: INFO: Deleting DaemonSet.extensions daemon-set took: 9.181832ms
Oct 24 01:21:50.054: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.316179ms
Oct 24 01:21:53.958: INFO: Number of nodes with available pods: 0
Oct 24 01:21:53.958: INFO: Number of running nodes: 0, number of available pods: 0
Oct 24 01:21:53.966: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7866/daemonsets","resourceVersion":"10162"},"items":null}

Oct 24 01:21:53.970: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7866/pods","resourceVersion":"10162"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:21:53.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7866" for this suite.
Oct 24 01:22:00.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:22:00.139: INFO: namespace daemonsets-7866 deletion completed in 6.15152631s

• [SLOW TEST:37.728 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:22:00.140: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:22:16.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5601" for this suite.
Oct 24 01:22:22.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:22:22.453: INFO: namespace resourcequota-5601 deletion completed in 6.145154196s

• [SLOW TEST:22.313 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:22:22.453: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Oct 24 01:23:02.543: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1024 01:23:02.543766      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:23:02.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-818" for this suite.
Oct 24 01:23:08.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:23:08.728: INFO: namespace gc-818 deletion completed in 6.179864374s

• [SLOW TEST:46.275 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:23:08.728: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1024 01:23:18.861944      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 24 01:23:18.862: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:23:18.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3047" for this suite.
Oct 24 01:23:24.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:23:25.013: INFO: namespace gc-3047 deletion completed in 6.147460888s

• [SLOW TEST:16.285 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:23:25.013: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-5724/configmap-test-026da252-b49e-4851-8f24-c9db47e39306
STEP: Creating a pod to test consume configMaps
Oct 24 01:23:25.074: INFO: Waiting up to 5m0s for pod "pod-configmaps-1c06e13b-dec8-45bd-a2d1-c1c7d57480d9" in namespace "configmap-5724" to be "success or failure"
Oct 24 01:23:25.080: INFO: Pod "pod-configmaps-1c06e13b-dec8-45bd-a2d1-c1c7d57480d9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.821995ms
Oct 24 01:23:27.084: INFO: Pod "pod-configmaps-1c06e13b-dec8-45bd-a2d1-c1c7d57480d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01021209s
STEP: Saw pod success
Oct 24 01:23:27.084: INFO: Pod "pod-configmaps-1c06e13b-dec8-45bd-a2d1-c1c7d57480d9" satisfied condition "success or failure"
Oct 24 01:23:27.088: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-1c06e13b-dec8-45bd-a2d1-c1c7d57480d9 container env-test: <nil>
STEP: delete the pod
Oct 24 01:23:27.131: INFO: Waiting for pod pod-configmaps-1c06e13b-dec8-45bd-a2d1-c1c7d57480d9 to disappear
Oct 24 01:23:27.138: INFO: Pod pod-configmaps-1c06e13b-dec8-45bd-a2d1-c1c7d57480d9 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:23:27.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5724" for this suite.
Oct 24 01:23:33.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:23:33.287: INFO: namespace configmap-5724 deletion completed in 6.144647555s

• [SLOW TEST:8.274 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:23:33.287: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 24 01:23:33.341: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 24 01:23:38.347: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:23:39.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4818" for this suite.
Oct 24 01:23:45.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:23:45.526: INFO: namespace replication-controller-4818 deletion completed in 6.152822707s

• [SLOW TEST:12.239 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:23:45.527: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:23:46.576: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 24 01:23:48.589: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477026, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477026, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477026, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477026, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:23:51.605: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Oct 24 01:23:53.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 attach --namespace=webhook-6139 to-be-attached-pod -i -c=container1'
Oct 24 01:23:53.963: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:23:53.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6139" for this suite.
Oct 24 01:24:05.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:24:06.136: INFO: namespace webhook-6139 deletion completed in 12.158275242s
STEP: Destroying namespace "webhook-6139-markers" for this suite.
Oct 24 01:24:12.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:24:12.278: INFO: namespace webhook-6139-markers deletion completed in 6.142619684s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.770 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:24:12.297: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 24 01:24:12.397: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-580 /api/v1/namespaces/watch-580/configmaps/e2e-watch-test-resource-version cca8a9d1-6a9f-4449-bd3d-e4604069adf2 11062 0 2019-10-24 01:24:12 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 24 01:24:12.397: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-580 /api/v1/namespaces/watch-580/configmaps/e2e-watch-test-resource-version cca8a9d1-6a9f-4449-bd3d-e4604069adf2 11063 0 2019-10-24 01:24:12 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:24:12.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-580" for this suite.
Oct 24 01:24:18.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:24:18.553: INFO: namespace watch-580 deletion completed in 6.151607814s

• [SLOW TEST:6.257 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:24:18.554: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:24:18.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8822" for this suite.
Oct 24 01:24:30.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:24:30.774: INFO: namespace kubelet-test-8822 deletion completed in 12.146468333s

• [SLOW TEST:12.220 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:24:30.774: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-f4e928dc-bd31-4e0d-a533-68e6a8662ae5
STEP: Creating a pod to test consume secrets
Oct 24 01:24:30.834: INFO: Waiting up to 5m0s for pod "pod-secrets-36d30399-65e6-4711-b243-dbb41e656299" in namespace "secrets-9376" to be "success or failure"
Oct 24 01:24:30.839: INFO: Pod "pod-secrets-36d30399-65e6-4711-b243-dbb41e656299": Phase="Pending", Reason="", readiness=false. Elapsed: 4.270984ms
Oct 24 01:24:32.845: INFO: Pod "pod-secrets-36d30399-65e6-4711-b243-dbb41e656299": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010407268s
STEP: Saw pod success
Oct 24 01:24:32.845: INFO: Pod "pod-secrets-36d30399-65e6-4711-b243-dbb41e656299" satisfied condition "success or failure"
Oct 24 01:24:32.849: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-36d30399-65e6-4711-b243-dbb41e656299 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 01:24:32.876: INFO: Waiting for pod pod-secrets-36d30399-65e6-4711-b243-dbb41e656299 to disappear
Oct 24 01:24:32.879: INFO: Pod pod-secrets-36d30399-65e6-4711-b243-dbb41e656299 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:24:32.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9376" for this suite.
Oct 24 01:24:38.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:24:39.038: INFO: namespace secrets-9376 deletion completed in 6.154429787s

• [SLOW TEST:8.264 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:24:39.039: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-7566/secret-test-4e4b7728-d05a-41f3-ab07-479601fa7fe5
STEP: Creating a pod to test consume secrets
Oct 24 01:24:39.099: INFO: Waiting up to 5m0s for pod "pod-configmaps-98b82f78-21ba-47ee-b3ab-5aef062f9c51" in namespace "secrets-7566" to be "success or failure"
Oct 24 01:24:39.104: INFO: Pod "pod-configmaps-98b82f78-21ba-47ee-b3ab-5aef062f9c51": Phase="Pending", Reason="", readiness=false. Elapsed: 4.739099ms
Oct 24 01:24:41.108: INFO: Pod "pod-configmaps-98b82f78-21ba-47ee-b3ab-5aef062f9c51": Phase="Running", Reason="", readiness=true. Elapsed: 2.009531915s
Oct 24 01:24:43.114: INFO: Pod "pod-configmaps-98b82f78-21ba-47ee-b3ab-5aef062f9c51": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01485879s
STEP: Saw pod success
Oct 24 01:24:43.114: INFO: Pod "pod-configmaps-98b82f78-21ba-47ee-b3ab-5aef062f9c51" satisfied condition "success or failure"
Oct 24 01:24:43.117: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-98b82f78-21ba-47ee-b3ab-5aef062f9c51 container env-test: <nil>
STEP: delete the pod
Oct 24 01:24:43.146: INFO: Waiting for pod pod-configmaps-98b82f78-21ba-47ee-b3ab-5aef062f9c51 to disappear
Oct 24 01:24:43.149: INFO: Pod pod-configmaps-98b82f78-21ba-47ee-b3ab-5aef062f9c51 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:24:43.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7566" for this suite.
Oct 24 01:24:49.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:24:49.309: INFO: namespace secrets-7566 deletion completed in 6.153633454s

• [SLOW TEST:10.270 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:24:49.310: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Oct 24 01:25:19.895: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:25:19.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1024 01:25:19.895173      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-5491" for this suite.
Oct 24 01:25:25.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:25:26.053: INFO: namespace gc-5491 deletion completed in 6.153906353s

• [SLOW TEST:36.743 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:25:26.054: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-c6d2d9e4-71bd-42f0-ba40-76e752666326
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:25:26.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9464" for this suite.
Oct 24 01:25:32.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:25:32.255: INFO: namespace configmap-9464 deletion completed in 6.145505654s

• [SLOW TEST:6.201 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:25:32.256: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:25:32.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-5308'
Oct 24 01:25:32.799: INFO: stderr: ""
Oct 24 01:25:32.799: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 24 01:25:32.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-5308'
Oct 24 01:25:33.130: INFO: stderr: ""
Oct 24 01:25:33.130: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 24 01:25:34.135: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:25:34.135: INFO: Found 1 / 1
Oct 24 01:25:34.135: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 24 01:25:34.139: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 01:25:34.139: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 24 01:25:34.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 describe pod redis-master-h8vw5 --namespace=kubectl-5308'
Oct 24 01:25:34.332: INFO: stderr: ""
Oct 24 01:25:34.332: INFO: stdout: "Name:         redis-master-h8vw5\nNamespace:    kubectl-5308\nPriority:     0\nNode:         mip-bd-vm40.mip.storage.hpecorp.net/16.143.20.137\nStart Time:   Thu, 24 Oct 2019 01:25:32 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 10.244.1.84/32\nStatus:       Running\nIP:           10.244.1.84\nIPs:\n  IP:           10.244.1.84\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://d64fb3cc5a58467bef58139addf9d910e5dcf50f33148744497d734ebf34be3e\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://docker.io/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 24 Oct 2019 01:25:33 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-v4wfs (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-v4wfs:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-v4wfs\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                          Message\n  ----    ------     ----       ----                                          -------\n  Normal  Scheduled  <unknown>  default-scheduler                             Successfully assigned kubectl-5308/redis-master-h8vw5 to mip-bd-vm40.mip.storage.hpecorp.net\n  Normal  Pulled     1s         kubelet, mip-bd-vm40.mip.storage.hpecorp.net  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s         kubelet, mip-bd-vm40.mip.storage.hpecorp.net  Created container redis-master\n  Normal  Started    1s         kubelet, mip-bd-vm40.mip.storage.hpecorp.net  Started container redis-master\n"
Oct 24 01:25:34.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 describe rc redis-master --namespace=kubectl-5308'
Oct 24 01:25:34.542: INFO: stderr: ""
Oct 24 01:25:34.542: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5308\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-h8vw5\n"
Oct 24 01:25:34.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 describe service redis-master --namespace=kubectl-5308'
Oct 24 01:25:34.722: INFO: stderr: ""
Oct 24 01:25:34.722: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5308\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.96.16.248\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.84:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 24 01:25:34.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 describe node mip-bd-vm39.mip.storage.hpecorp.net'
Oct 24 01:25:34.935: INFO: stderr: ""
Oct 24 01:25:34.935: INFO: stdout: "Name:               mip-bd-vm39.mip.storage.hpecorp.net\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=mip-bd-vm39.mip.storage.hpecorp.net\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"ee:fc:89:7f:b5:3c\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 16.143.20.136\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 24 Oct 2019 00:02:42 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 24 Oct 2019 01:25:08 +0000   Thu, 24 Oct 2019 00:02:42 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 24 Oct 2019 01:25:08 +0000   Thu, 24 Oct 2019 00:02:42 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 24 Oct 2019 01:25:08 +0000   Thu, 24 Oct 2019 00:02:42 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 24 Oct 2019 01:25:08 +0000   Thu, 24 Oct 2019 00:04:43 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  16.143.20.136\n  Hostname:    mip-bd-vm39.mip.storage.hpecorp.net\nCapacity:\n cpu:                4\n ephemeral-storage:  401682812Ki\n hugepages-2Mi:      0\n memory:             32780580Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  370190878927\n hugepages-2Mi:      0\n memory:             32678180Ki\n pods:               110\nSystem Info:\n Machine ID:                 e5bf42bded154965be4edc4be6e4615f\n System UUID:                54D22B42-093C-E1CA-E7F7-88C7E15728CA\n Boot ID:                    39afc37f-049b-44de-89ed-20d435c65bf6\n Kernel Version:             3.10.0-1062.4.1.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://1.13.1\n Kubelet Version:            v1.16.2\n Kube-Proxy Version:         v1.16.2\nPodCIDR:                     10.244.0.0/24\nPodCIDRs:                    10.244.0.0/24\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                           CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                           ------------  ----------  ---------------  -------------  ---\n  kube-system                canal-nfspt                                                    250m (6%)     0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                coredns-5644d7b6d9-kr75t                                       100m (2%)     0 (0%)      70Mi (0%)        170Mi (0%)     37m\n  kube-system                etcd-mip-bd-vm39.mip.storage.hpecorp.net                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                kube-apiserver-mip-bd-vm39.mip.storage.hpecorp.net             250m (6%)     0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                kube-controller-manager-mip-bd-vm39.mip.storage.hpecorp.net    200m (5%)     0 (0%)      0 (0%)           0 (0%)         82m\n  kube-system                kube-proxy-8sld2                                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\n  kube-system                kube-scheduler-mip-bd-vm39.mip.storage.hpecorp.net             100m (2%)     0 (0%)      0 (0%)           0 (0%)         81m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-rht2g        0 (0%)        0 (0%)      0 (0%)           0 (0%)         16m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                900m (22%)  0 (0%)\n  memory             70Mi (0%)   170Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Oct 24 01:25:34.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 describe namespace kubectl-5308'
Oct 24 01:25:35.118: INFO: stderr: ""
Oct 24 01:25:35.118: INFO: stdout: "Name:         kubectl-5308\nLabels:       e2e-framework=kubectl\n              e2e-run=c04632e8-d5d0-4941-ba72-1b323093fdb3\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:25:35.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5308" for this suite.
Oct 24 01:25:47.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:25:47.276: INFO: namespace kubectl-5308 deletion completed in 12.153084543s

• [SLOW TEST:15.021 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:25:47.278: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4333.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4333.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4333.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4333.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4333.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4333.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4333.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4333.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4333.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4333.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4333.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 127.21.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.21.127_udp@PTR;check="$$(dig +tcp +noall +answer +search 127.21.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.21.127_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4333.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4333.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4333.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4333.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4333.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4333.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4333.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4333.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4333.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4333.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4333.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 127.21.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.21.127_udp@PTR;check="$$(dig +tcp +noall +answer +search 127.21.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.21.127_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 24 01:26:33.407: INFO: Unable to read wheezy_udp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:33.413: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:33.418: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:33.423: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:33.459: INFO: Unable to read jessie_udp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:33.464: INFO: Unable to read jessie_tcp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:33.469: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:33.475: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:33.505: INFO: Lookups using dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0 failed for: [wheezy_udp@dns-test-service.dns-4333.svc.cluster.local wheezy_tcp@dns-test-service.dns-4333.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local jessie_udp@dns-test-service.dns-4333.svc.cluster.local jessie_tcp@dns-test-service.dns-4333.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local]

Oct 24 01:26:38.514: INFO: Unable to read wheezy_udp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:38.518: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:38.524: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:38.529: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:38.568: INFO: Unable to read jessie_udp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:38.574: INFO: Unable to read jessie_tcp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:38.578: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:38.583: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:38.611: INFO: Lookups using dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0 failed for: [wheezy_udp@dns-test-service.dns-4333.svc.cluster.local wheezy_tcp@dns-test-service.dns-4333.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local jessie_udp@dns-test-service.dns-4333.svc.cluster.local jessie_tcp@dns-test-service.dns-4333.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local]

Oct 24 01:26:43.513: INFO: Unable to read wheezy_udp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:43.518: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:43.523: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:43.527: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:43.560: INFO: Unable to read jessie_udp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:43.564: INFO: Unable to read jessie_tcp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:43.570: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:43.575: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:43.605: INFO: Lookups using dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0 failed for: [wheezy_udp@dns-test-service.dns-4333.svc.cluster.local wheezy_tcp@dns-test-service.dns-4333.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local jessie_udp@dns-test-service.dns-4333.svc.cluster.local jessie_tcp@dns-test-service.dns-4333.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local]

Oct 24 01:26:48.513: INFO: Unable to read wheezy_udp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:48.518: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:48.523: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:48.528: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:48.562: INFO: Unable to read jessie_udp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:48.567: INFO: Unable to read jessie_tcp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:48.572: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:48.576: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:48.611: INFO: Lookups using dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0 failed for: [wheezy_udp@dns-test-service.dns-4333.svc.cluster.local wheezy_tcp@dns-test-service.dns-4333.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local jessie_udp@dns-test-service.dns-4333.svc.cluster.local jessie_tcp@dns-test-service.dns-4333.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local]

Oct 24 01:26:53.514: INFO: Unable to read wheezy_udp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:53.519: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:53.525: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:53.530: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:53.567: INFO: Unable to read jessie_udp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:53.573: INFO: Unable to read jessie_tcp@dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:53.577: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:53.582: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:53.610: INFO: Lookups using dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0 failed for: [wheezy_udp@dns-test-service.dns-4333.svc.cluster.local wheezy_tcp@dns-test-service.dns-4333.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local jessie_udp@dns-test-service.dns-4333.svc.cluster.local jessie_tcp@dns-test-service.dns-4333.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local]

Oct 24 01:26:58.583: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local from pod dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0: the server could not find the requested resource (get pods dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0)
Oct 24 01:26:58.624: INFO: Lookups using dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0 failed for: [jessie_tcp@_http._tcp.dns-test-service.dns-4333.svc.cluster.local]

Oct 24 01:27:03.607: INFO: DNS probes using dns-4333/dns-test-a280e4e3-03f5-4467-8e4c-421f975178d0 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:27:03.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4333" for this suite.
Oct 24 01:27:09.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:27:09.860: INFO: namespace dns-4333 deletion completed in 6.145889543s

• [SLOW TEST:82.582 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:27:09.860: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 24 01:27:10.148: INFO: Pod name wrapped-volume-race-a26847bc-1afc-41df-9b29-fb4b17a051af: Found 0 pods out of 5
Oct 24 01:27:15.159: INFO: Pod name wrapped-volume-race-a26847bc-1afc-41df-9b29-fb4b17a051af: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a26847bc-1afc-41df-9b29-fb4b17a051af in namespace emptydir-wrapper-9729, will wait for the garbage collector to delete the pods
Oct 24 01:27:25.256: INFO: Deleting ReplicationController wrapped-volume-race-a26847bc-1afc-41df-9b29-fb4b17a051af took: 11.720813ms
Oct 24 01:27:25.661: INFO: Terminating ReplicationController wrapped-volume-race-a26847bc-1afc-41df-9b29-fb4b17a051af pods took: 405.301325ms
STEP: Creating RC which spawns configmap-volume pods
Oct 24 01:28:07.387: INFO: Pod name wrapped-volume-race-ec3e43a0-45ff-4ce4-ab80-b89b5dc40d9a: Found 0 pods out of 5
Oct 24 01:28:12.396: INFO: Pod name wrapped-volume-race-ec3e43a0-45ff-4ce4-ab80-b89b5dc40d9a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ec3e43a0-45ff-4ce4-ab80-b89b5dc40d9a in namespace emptydir-wrapper-9729, will wait for the garbage collector to delete the pods
Oct 24 01:28:22.490: INFO: Deleting ReplicationController wrapped-volume-race-ec3e43a0-45ff-4ce4-ab80-b89b5dc40d9a took: 9.269833ms
Oct 24 01:28:22.990: INFO: Terminating ReplicationController wrapped-volume-race-ec3e43a0-45ff-4ce4-ab80-b89b5dc40d9a pods took: 500.28902ms
STEP: Creating RC which spawns configmap-volume pods
Oct 24 01:29:08.315: INFO: Pod name wrapped-volume-race-d68f7b87-0222-4317-a2fc-3e8b5cd5092c: Found 0 pods out of 5
Oct 24 01:29:13.325: INFO: Pod name wrapped-volume-race-d68f7b87-0222-4317-a2fc-3e8b5cd5092c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d68f7b87-0222-4317-a2fc-3e8b5cd5092c in namespace emptydir-wrapper-9729, will wait for the garbage collector to delete the pods
Oct 24 01:29:23.416: INFO: Deleting ReplicationController wrapped-volume-race-d68f7b87-0222-4317-a2fc-3e8b5cd5092c took: 9.119837ms
Oct 24 01:29:23.916: INFO: Terminating ReplicationController wrapped-volume-race-d68f7b87-0222-4317-a2fc-3e8b5cd5092c pods took: 500.290401ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:30:00.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9729" for this suite.
Oct 24 01:30:08.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:30:08.848: INFO: namespace emptydir-wrapper-9729 deletion completed in 8.150933687s

• [SLOW TEST:178.988 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:30:08.849: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 24 01:30:11.444: INFO: Successfully updated pod "pod-update-0aac5518-b7e2-4c60-a2be-8beb4fc21aa5"
STEP: verifying the updated pod is in kubernetes
Oct 24 01:30:11.452: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:30:11.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5511" for this suite.
Oct 24 01:30:39.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:30:39.610: INFO: namespace pods-5511 deletion completed in 28.151744523s

• [SLOW TEST:30.761 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:30:39.610: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:30:41.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3325" for this suite.
Oct 24 01:31:29.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:31:29.868: INFO: namespace kubelet-test-3325 deletion completed in 48.1493996s

• [SLOW TEST:50.258 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:31:29.869: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:31:29.927: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-32640db0-18f5-456f-a4a9-fe04fd53bdba" in namespace "security-context-test-1047" to be "success or failure"
Oct 24 01:31:29.933: INFO: Pod "busybox-readonly-false-32640db0-18f5-456f-a4a9-fe04fd53bdba": Phase="Pending", Reason="", readiness=false. Elapsed: 5.910545ms
Oct 24 01:31:31.938: INFO: Pod "busybox-readonly-false-32640db0-18f5-456f-a4a9-fe04fd53bdba": Phase="Running", Reason="", readiness=true. Elapsed: 2.011111921s
Oct 24 01:31:33.943: INFO: Pod "busybox-readonly-false-32640db0-18f5-456f-a4a9-fe04fd53bdba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01631548s
Oct 24 01:31:33.943: INFO: Pod "busybox-readonly-false-32640db0-18f5-456f-a4a9-fe04fd53bdba" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:31:33.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1047" for this suite.
Oct 24 01:31:40.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:31:40.137: INFO: namespace security-context-test-1047 deletion completed in 6.188587801s

• [SLOW TEST:10.268 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:31:40.137: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:31:40.186: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:31:42.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9962" for this suite.
Oct 24 01:32:26.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:32:26.491: INFO: namespace pods-9962 deletion completed in 44.153804205s

• [SLOW TEST:46.355 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:32:26.492: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct 24 01:32:26.544: INFO: Waiting up to 5m0s for pod "downward-api-1adbf0b3-ca1e-41de-92bc-0443a35b72c4" in namespace "downward-api-4832" to be "success or failure"
Oct 24 01:32:26.549: INFO: Pod "downward-api-1adbf0b3-ca1e-41de-92bc-0443a35b72c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.694355ms
Oct 24 01:32:28.554: INFO: Pod "downward-api-1adbf0b3-ca1e-41de-92bc-0443a35b72c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009778541s
STEP: Saw pod success
Oct 24 01:32:28.554: INFO: Pod "downward-api-1adbf0b3-ca1e-41de-92bc-0443a35b72c4" satisfied condition "success or failure"
Oct 24 01:32:28.558: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downward-api-1adbf0b3-ca1e-41de-92bc-0443a35b72c4 container dapi-container: <nil>
STEP: delete the pod
Oct 24 01:32:28.609: INFO: Waiting for pod downward-api-1adbf0b3-ca1e-41de-92bc-0443a35b72c4 to disappear
Oct 24 01:32:28.614: INFO: Pod downward-api-1adbf0b3-ca1e-41de-92bc-0443a35b72c4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:32:28.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4832" for this suite.
Oct 24 01:32:34.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:32:34.772: INFO: namespace downward-api-4832 deletion completed in 6.149445513s

• [SLOW TEST:8.280 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:32:34.773: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 24 01:32:34.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-6098'
Oct 24 01:32:35.017: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 24 01:32:35.017: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Oct 24 01:32:37.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete deployment e2e-test-httpd-deployment --namespace=kubectl-6098'
Oct 24 01:32:37.199: INFO: stderr: ""
Oct 24 01:32:37.199: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:32:37.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6098" for this suite.
Oct 24 01:32:49.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:32:49.355: INFO: namespace kubectl-6098 deletion completed in 12.149448085s

• [SLOW TEST:14.582 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:32:49.355: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:32:49.399: INFO: Creating deployment "test-recreate-deployment"
Oct 24 01:32:49.404: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 24 01:32:49.416: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Oct 24 01:32:51.425: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 24 01:32:51.428: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 24 01:32:51.437: INFO: Updating deployment test-recreate-deployment
Oct 24 01:32:51.437: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct 24 01:32:51.538: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-7707 /apis/apps/v1/namespaces/deployment-7707/deployments/test-recreate-deployment f8bbc082-9477-4945-9d4d-a555b5d86ba2 13163 2 2019-10-24 01:32:49 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004ab2f58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-10-24 01:32:51 +0000 UTC,LastTransitionTime:2019-10-24 01:32:51 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-10-24 01:32:51 +0000 UTC,LastTransitionTime:2019-10-24 01:32:49 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Oct 24 01:32:51.544: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-7707 /apis/apps/v1/namespaces/deployment-7707/replicasets/test-recreate-deployment-5f94c574ff 220a6c67-44c0-45c0-93c2-38f9785863fb 13162 1 2019-10-24 01:32:51 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment f8bbc082-9477-4945-9d4d-a555b5d86ba2 0xc004ab34a7 0xc004ab34a8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004ab3508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 01:32:51.544: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 24 01:32:51.544: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-7707 /apis/apps/v1/namespaces/deployment-7707/replicasets/test-recreate-deployment-68fc85c7bb bbca7608-4899-4fb2-88e8-732f1c829d6a 13151 2 2019-10-24 01:32:49 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment f8bbc082-9477-4945-9d4d-a555b5d86ba2 0xc004ab3577 0xc004ab3578}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004ab35d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 01:32:51.549: INFO: Pod "test-recreate-deployment-5f94c574ff-zqckg" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-zqckg test-recreate-deployment-5f94c574ff- deployment-7707 /api/v1/namespaces/deployment-7707/pods/test-recreate-deployment-5f94c574ff-zqckg baab9529-abc2-4a13-b143-8b0d97473a2d 13161 0 2019-10-24 01:32:51 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 220a6c67-44c0-45c0-93c2-38f9785863fb 0xc004ab3a47 0xc004ab3a48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wpd49,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wpd49,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wpd49,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 01:32:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 01:32:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 01:32:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 01:32:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 01:32:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:32:51.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7707" for this suite.
Oct 24 01:32:57.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:32:57.719: INFO: namespace deployment-7707 deletion completed in 6.164745991s

• [SLOW TEST:8.364 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:32:57.720: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:32:58.555: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Oct 24 01:33:00.568: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477578, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477578, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477578, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477578, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:33:03.587: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:33:03.591: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:33:05.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4346" for this suite.
Oct 24 01:33:11.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:33:11.176: INFO: namespace crd-webhook-4346 deletion completed in 6.141757441s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.474 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:33:11.194: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5800.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5800.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5800.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5800.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5800.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5800.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5800.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5800.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5800.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5800.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 24 01:33:37.284: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:37.289: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:37.294: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:37.300: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:37.316: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:37.321: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:37.326: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:37.330: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:37.340: INFO: Lookups using dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5800.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5800.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local jessie_udp@dns-test-service-2.dns-5800.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5800.svc.cluster.local]

Oct 24 01:33:42.347: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:42.353: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:42.358: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:42.362: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:42.377: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:42.383: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:42.388: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:42.392: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:42.402: INFO: Lookups using dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5800.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5800.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local jessie_udp@dns-test-service-2.dns-5800.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5800.svc.cluster.local]

Oct 24 01:33:47.347: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:47.351: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:47.356: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:47.361: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:47.376: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:47.382: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:47.386: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:47.391: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5800.svc.cluster.local from pod dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf: the server could not find the requested resource (get pods dns-test-9e38474a-d3d2-4369-8eed-816075f83caf)
Oct 24 01:33:47.400: INFO: Lookups using dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local wheezy_udp@dns-test-service-2.dns-5800.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5800.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-5800.svc.cluster.local jessie_udp@dns-test-service-2.dns-5800.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5800.svc.cluster.local]

Oct 24 01:33:52.417: INFO: DNS probes using dns-5800/dns-test-9e38474a-d3d2-4369-8eed-816075f83caf succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:33:52.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5800" for this suite.
Oct 24 01:33:58.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:33:58.658: INFO: namespace dns-5800 deletion completed in 6.196611891s

• [SLOW TEST:47.464 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:33:58.658: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:34:02.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3267" for this suite.
Oct 24 01:34:08.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:34:08.885: INFO: namespace kubelet-test-3267 deletion completed in 6.145157071s

• [SLOW TEST:10.227 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:34:08.885: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 24 01:34:08.953: INFO: Waiting up to 5m0s for pod "pod-62edb60a-d4d8-4e9b-86c0-cd91ddb90f24" in namespace "emptydir-1630" to be "success or failure"
Oct 24 01:34:08.983: INFO: Pod "pod-62edb60a-d4d8-4e9b-86c0-cd91ddb90f24": Phase="Pending", Reason="", readiness=false. Elapsed: 29.790766ms
Oct 24 01:34:10.988: INFO: Pod "pod-62edb60a-d4d8-4e9b-86c0-cd91ddb90f24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034959121s
STEP: Saw pod success
Oct 24 01:34:10.988: INFO: Pod "pod-62edb60a-d4d8-4e9b-86c0-cd91ddb90f24" satisfied condition "success or failure"
Oct 24 01:34:10.992: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-62edb60a-d4d8-4e9b-86c0-cd91ddb90f24 container test-container: <nil>
STEP: delete the pod
Oct 24 01:34:11.039: INFO: Waiting for pod pod-62edb60a-d4d8-4e9b-86c0-cd91ddb90f24 to disappear
Oct 24 01:34:11.042: INFO: Pod pod-62edb60a-d4d8-4e9b-86c0-cd91ddb90f24 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:34:11.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1630" for this suite.
Oct 24 01:34:17.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:34:17.202: INFO: namespace emptydir-1630 deletion completed in 6.155174772s

• [SLOW TEST:8.317 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:34:17.202: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Oct 24 01:34:17.248: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-000479258 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:34:17.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3208" for this suite.
Oct 24 01:34:23.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:34:23.552: INFO: namespace kubectl-3208 deletion completed in 6.150417297s

• [SLOW TEST:6.350 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:34:23.552: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 24 01:34:23.611: INFO: Waiting up to 5m0s for pod "pod-2bfaabe0-dbc2-481a-a6a5-a253f9704f71" in namespace "emptydir-329" to be "success or failure"
Oct 24 01:34:23.615: INFO: Pod "pod-2bfaabe0-dbc2-481a-a6a5-a253f9704f71": Phase="Pending", Reason="", readiness=false. Elapsed: 3.823151ms
Oct 24 01:34:25.619: INFO: Pod "pod-2bfaabe0-dbc2-481a-a6a5-a253f9704f71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008204777s
STEP: Saw pod success
Oct 24 01:34:25.619: INFO: Pod "pod-2bfaabe0-dbc2-481a-a6a5-a253f9704f71" satisfied condition "success or failure"
Oct 24 01:34:25.622: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-2bfaabe0-dbc2-481a-a6a5-a253f9704f71 container test-container: <nil>
STEP: delete the pod
Oct 24 01:34:25.653: INFO: Waiting for pod pod-2bfaabe0-dbc2-481a-a6a5-a253f9704f71 to disappear
Oct 24 01:34:25.657: INFO: Pod pod-2bfaabe0-dbc2-481a-a6a5-a253f9704f71 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:34:25.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-329" for this suite.
Oct 24 01:34:31.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:34:31.819: INFO: namespace emptydir-329 deletion completed in 6.156838922s

• [SLOW TEST:8.266 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:34:31.819: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:34:33.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1624" for this suite.
Oct 24 01:34:39.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:34:40.092: INFO: namespace emptydir-wrapper-1624 deletion completed in 6.149847609s

• [SLOW TEST:8.273 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:34:40.093: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:35:09.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4011" for this suite.
Oct 24 01:35:15.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:35:15.407: INFO: namespace namespaces-4011 deletion completed in 6.145321094s
STEP: Destroying namespace "nsdeletetest-2358" for this suite.
Oct 24 01:35:15.411: INFO: Namespace nsdeletetest-2358 was already deleted
STEP: Destroying namespace "nsdeletetest-6312" for this suite.
Oct 24 01:35:21.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:35:21.560: INFO: namespace nsdeletetest-6312 deletion completed in 6.149323242s

• [SLOW TEST:41.468 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:35:21.563: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-4bs9
STEP: Creating a pod to test atomic-volume-subpath
Oct 24 01:35:21.636: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-4bs9" in namespace "subpath-6679" to be "success or failure"
Oct 24 01:35:21.641: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.608665ms
Oct 24 01:35:23.646: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Running", Reason="", readiness=true. Elapsed: 2.010208193s
Oct 24 01:35:25.652: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Running", Reason="", readiness=true. Elapsed: 4.016200279s
Oct 24 01:35:27.658: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Running", Reason="", readiness=true. Elapsed: 6.021482733s
Oct 24 01:35:29.663: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Running", Reason="", readiness=true. Elapsed: 8.026862099s
Oct 24 01:35:31.668: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Running", Reason="", readiness=true. Elapsed: 10.031680138s
Oct 24 01:35:33.673: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Running", Reason="", readiness=true. Elapsed: 12.036945578s
Oct 24 01:35:35.678: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Running", Reason="", readiness=true. Elapsed: 14.042007859s
Oct 24 01:35:37.683: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Running", Reason="", readiness=true. Elapsed: 16.04653724s
Oct 24 01:35:39.687: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Running", Reason="", readiness=true. Elapsed: 18.051030815s
Oct 24 01:35:41.692: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Running", Reason="", readiness=true. Elapsed: 20.055545495s
Oct 24 01:35:43.696: INFO: Pod "pod-subpath-test-downwardapi-4bs9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.059915483s
STEP: Saw pod success
Oct 24 01:35:43.696: INFO: Pod "pod-subpath-test-downwardapi-4bs9" satisfied condition "success or failure"
Oct 24 01:35:43.700: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-subpath-test-downwardapi-4bs9 container test-container-subpath-downwardapi-4bs9: <nil>
STEP: delete the pod
Oct 24 01:35:43.752: INFO: Waiting for pod pod-subpath-test-downwardapi-4bs9 to disappear
Oct 24 01:35:43.756: INFO: Pod pod-subpath-test-downwardapi-4bs9 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-4bs9
Oct 24 01:35:43.756: INFO: Deleting pod "pod-subpath-test-downwardapi-4bs9" in namespace "subpath-6679"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:35:43.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6679" for this suite.
Oct 24 01:35:49.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:35:49.907: INFO: namespace subpath-6679 deletion completed in 6.14251327s

• [SLOW TEST:28.344 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:35:49.907: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:35:49.965: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-99c8ae45-1c08-4d2f-8304-04135fbc3795" in namespace "security-context-test-7669" to be "success or failure"
Oct 24 01:35:49.970: INFO: Pod "busybox-privileged-false-99c8ae45-1c08-4d2f-8304-04135fbc3795": Phase="Pending", Reason="", readiness=false. Elapsed: 4.696781ms
Oct 24 01:35:51.975: INFO: Pod "busybox-privileged-false-99c8ae45-1c08-4d2f-8304-04135fbc3795": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009269821s
Oct 24 01:35:51.975: INFO: Pod "busybox-privileged-false-99c8ae45-1c08-4d2f-8304-04135fbc3795" satisfied condition "success or failure"
Oct 24 01:35:51.987: INFO: Got logs for pod "busybox-privileged-false-99c8ae45-1c08-4d2f-8304-04135fbc3795": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:35:51.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7669" for this suite.
Oct 24 01:35:58.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:35:58.133: INFO: namespace security-context-test-7669 deletion completed in 6.140865937s

• [SLOW TEST:8.226 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:35:58.133: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 01:35:58.191: INFO: Waiting up to 5m0s for pod "downwardapi-volume-379532f0-176b-4407-9ace-8054d24741ec" in namespace "projected-8992" to be "success or failure"
Oct 24 01:35:58.194: INFO: Pod "downwardapi-volume-379532f0-176b-4407-9ace-8054d24741ec": Phase="Pending", Reason="", readiness=false. Elapsed: 3.802523ms
Oct 24 01:36:00.199: INFO: Pod "downwardapi-volume-379532f0-176b-4407-9ace-8054d24741ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008486742s
STEP: Saw pod success
Oct 24 01:36:00.199: INFO: Pod "downwardapi-volume-379532f0-176b-4407-9ace-8054d24741ec" satisfied condition "success or failure"
Oct 24 01:36:00.203: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-379532f0-176b-4407-9ace-8054d24741ec container client-container: <nil>
STEP: delete the pod
Oct 24 01:36:00.236: INFO: Waiting for pod downwardapi-volume-379532f0-176b-4407-9ace-8054d24741ec to disappear
Oct 24 01:36:00.239: INFO: Pod downwardapi-volume-379532f0-176b-4407-9ace-8054d24741ec no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:36:00.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8992" for this suite.
Oct 24 01:36:06.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:36:06.391: INFO: namespace projected-8992 deletion completed in 6.146528094s

• [SLOW TEST:8.257 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:36:06.391: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:36:06.949: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:36:09.974: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Oct 24 01:36:10.004: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:36:10.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4216" for this suite.
Oct 24 01:36:16.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:36:16.379: INFO: namespace webhook-4216 deletion completed in 6.14769202s
STEP: Destroying namespace "webhook-4216-markers" for this suite.
Oct 24 01:36:22.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:36:22.524: INFO: namespace webhook-4216-markers deletion completed in 6.14533816s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.154 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:36:22.545: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:36:23.122: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:36:26.147: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:36:26.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5703" for this suite.
Oct 24 01:36:38.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:36:38.394: INFO: namespace webhook-5703 deletion completed in 12.154675654s
STEP: Destroying namespace "webhook-5703-markers" for this suite.
Oct 24 01:36:44.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:36:44.557: INFO: namespace webhook-5703-markers deletion completed in 6.163845934s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.042 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:36:44.587: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct 24 01:36:44.635: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 01:36:44.650: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 01:36:44.654: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm40.mip.storage.hpecorp.net before test
Oct 24 01:36:44.664: INFO: canal-gwnsd from kube-system started at 2019-10-24 00:04:16 +0000 UTC (3 container statuses recorded)
Oct 24 01:36:44.664: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 01:36:44.664: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 01:36:44.664: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 01:36:44.664: INFO: kubedirector-fsmount-7g9kv from kube-system started at 2019-10-24 00:48:32 +0000 UTC (1 container statuses recorded)
Oct 24 01:36:44.664: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 01:36:44.664: INFO: taint-eviction-4 from taint-single-pod-9185 started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:36:44.664: INFO: 	Container pause ready: true, restart count 0
Oct 24 01:36:44.664: INFO: kube-proxy-vr6tb from kube-system started at 2019-10-24 00:03:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:36:44.664: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 01:36:44.664: INFO: sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-vzlsf from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:36:44.664: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:36:44.664: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 01:36:44.664: INFO: coredns-5644d7b6d9-dvtzq from kube-system started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:36:44.664: INFO: 	Container coredns ready: true, restart count 0
Oct 24 01:36:44.664: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm41.mip.storage.hpecorp.net before test
Oct 24 01:36:44.695: INFO: kubernetes-dashboard-7c54d59f66-c2jgr from kube-system started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:36:44.695: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 24 01:36:44.695: INFO: kubedirector-fsmount-9w6pk from kube-system started at 2019-10-24 00:05:24 +0000 UTC (1 container statuses recorded)
Oct 24 01:36:44.695: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 01:36:44.695: INFO: kubedirector-5bbd74594b-99xvf from kube-system started at 2019-10-24 00:04:10 +0000 UTC (1 container statuses recorded)
Oct 24 01:36:44.695: INFO: 	Container kubedirector ready: true, restart count 0
Oct 24 01:36:44.695: INFO: canal-zjdkh from kube-system started at 2019-10-24 00:04:16 +0000 UTC (3 container statuses recorded)
Oct 24 01:36:44.695: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 01:36:44.695: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 01:36:44.695: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 01:36:44.695: INFO: kube-state-metrics-5fdb6fdffd-r42bd from kube-system started at 2019-10-24 00:04:06 +0000 UTC (1 container statuses recorded)
Oct 24 01:36:44.695: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 24 01:36:44.695: INFO: sonobuoy from sonobuoy started at 2019-10-24 01:09:14 +0000 UTC (1 container statuses recorded)
Oct 24 01:36:44.695: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 24 01:36:44.695: INFO: sonobuoy-e2e-job-203e2c4356d04dbd from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:36:44.695: INFO: 	Container e2e ready: true, restart count 0
Oct 24 01:36:44.695: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:36:44.695: INFO: sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-wwg5x from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:36:44.695: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:36:44.695: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 01:36:44.695: INFO: kube-proxy-bmwmz from kube-system started at 2019-10-24 00:03:38 +0000 UTC (1 container statuses recorded)
Oct 24 01:36:44.695: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d07172138567b9], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d07172144190fb], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:36:45.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9251" for this suite.
Oct 24 01:36:51.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:36:51.876: INFO: namespace sched-pred-9251 deletion completed in 6.145031605s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.289 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:36:51.877: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 24 01:36:51.931: INFO: Waiting up to 5m0s for pod "pod-cc211178-360b-4644-93a5-cf5d22974fd7" in namespace "emptydir-3866" to be "success or failure"
Oct 24 01:36:51.935: INFO: Pod "pod-cc211178-360b-4644-93a5-cf5d22974fd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.812582ms
Oct 24 01:36:53.940: INFO: Pod "pod-cc211178-360b-4644-93a5-cf5d22974fd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008536328s
STEP: Saw pod success
Oct 24 01:36:53.940: INFO: Pod "pod-cc211178-360b-4644-93a5-cf5d22974fd7" satisfied condition "success or failure"
Oct 24 01:36:53.943: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-cc211178-360b-4644-93a5-cf5d22974fd7 container test-container: <nil>
STEP: delete the pod
Oct 24 01:36:53.974: INFO: Waiting for pod pod-cc211178-360b-4644-93a5-cf5d22974fd7 to disappear
Oct 24 01:36:53.977: INFO: Pod pod-cc211178-360b-4644-93a5-cf5d22974fd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:36:53.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3866" for this suite.
Oct 24 01:37:00.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:37:00.140: INFO: namespace emptydir-3866 deletion completed in 6.158797263s

• [SLOW TEST:8.263 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:37:00.141: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-4qz4
STEP: Creating a pod to test atomic-volume-subpath
Oct 24 01:37:00.205: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-4qz4" in namespace "subpath-8409" to be "success or failure"
Oct 24 01:37:00.209: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.65931ms
Oct 24 01:37:02.214: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Running", Reason="", readiness=true. Elapsed: 2.008397853s
Oct 24 01:37:04.219: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Running", Reason="", readiness=true. Elapsed: 4.013060091s
Oct 24 01:37:06.223: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Running", Reason="", readiness=true. Elapsed: 6.017897074s
Oct 24 01:37:08.228: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Running", Reason="", readiness=true. Elapsed: 8.02223874s
Oct 24 01:37:10.232: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Running", Reason="", readiness=true. Elapsed: 10.026678983s
Oct 24 01:37:12.238: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Running", Reason="", readiness=true. Elapsed: 12.032789994s
Oct 24 01:37:14.243: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Running", Reason="", readiness=true. Elapsed: 14.037367421s
Oct 24 01:37:16.248: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Running", Reason="", readiness=true. Elapsed: 16.042743853s
Oct 24 01:37:18.253: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Running", Reason="", readiness=true. Elapsed: 18.047670774s
Oct 24 01:37:20.257: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Running", Reason="", readiness=true. Elapsed: 20.051896563s
Oct 24 01:37:22.262: INFO: Pod "pod-subpath-test-projected-4qz4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.056066519s
STEP: Saw pod success
Oct 24 01:37:22.262: INFO: Pod "pod-subpath-test-projected-4qz4" satisfied condition "success or failure"
Oct 24 01:37:22.265: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-subpath-test-projected-4qz4 container test-container-subpath-projected-4qz4: <nil>
STEP: delete the pod
Oct 24 01:37:22.303: INFO: Waiting for pod pod-subpath-test-projected-4qz4 to disappear
Oct 24 01:37:22.307: INFO: Pod pod-subpath-test-projected-4qz4 no longer exists
STEP: Deleting pod pod-subpath-test-projected-4qz4
Oct 24 01:37:22.307: INFO: Deleting pod "pod-subpath-test-projected-4qz4" in namespace "subpath-8409"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:37:22.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8409" for this suite.
Oct 24 01:37:28.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:37:28.458: INFO: namespace subpath-8409 deletion completed in 6.141592814s

• [SLOW TEST:28.317 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:37:28.458: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-e402ef8a-132a-4451-9f2f-9feef8fc8369
STEP: Creating a pod to test consume configMaps
Oct 24 01:37:28.521: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-00d7d83c-061b-4ab9-81b8-d11f9a37af28" in namespace "projected-4958" to be "success or failure"
Oct 24 01:37:28.525: INFO: Pod "pod-projected-configmaps-00d7d83c-061b-4ab9-81b8-d11f9a37af28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.876926ms
Oct 24 01:37:30.530: INFO: Pod "pod-projected-configmaps-00d7d83c-061b-4ab9-81b8-d11f9a37af28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008740144s
STEP: Saw pod success
Oct 24 01:37:30.530: INFO: Pod "pod-projected-configmaps-00d7d83c-061b-4ab9-81b8-d11f9a37af28" satisfied condition "success or failure"
Oct 24 01:37:30.534: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-00d7d83c-061b-4ab9-81b8-d11f9a37af28 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 01:37:30.561: INFO: Waiting for pod pod-projected-configmaps-00d7d83c-061b-4ab9-81b8-d11f9a37af28 to disappear
Oct 24 01:37:30.564: INFO: Pod pod-projected-configmaps-00d7d83c-061b-4ab9-81b8-d11f9a37af28 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:37:30.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4958" for this suite.
Oct 24 01:37:36.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:37:36.732: INFO: namespace projected-4958 deletion completed in 6.160134683s

• [SLOW TEST:8.274 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:37:36.732: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:37:36.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9324" for this suite.
Oct 24 01:37:48.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:37:49.099: INFO: namespace pods-9324 deletion completed in 12.283815324s

• [SLOW TEST:12.367 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:37:49.099: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:37:50.102: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 24 01:37:52.115: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477870, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477870, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477870, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477870, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:37:55.133: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:37:55.138: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1107-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:37:56.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5942" for this suite.
Oct 24 01:38:08.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:38:08.736: INFO: namespace webhook-5942 deletion completed in 12.14723635s
STEP: Destroying namespace "webhook-5942-markers" for this suite.
Oct 24 01:38:14.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:38:14.877: INFO: namespace webhook-5942-markers deletion completed in 6.140693433s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.794 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:38:14.894: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Oct 24 01:38:14.942: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Oct 24 01:38:32.044: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 01:38:36.601: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:38:54.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6485" for this suite.
Oct 24 01:39:00.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:39:00.514: INFO: namespace crd-publish-openapi-6485 deletion completed in 6.151603413s

• [SLOW TEST:45.620 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:39:00.514: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 01:39:00.571: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be1cc3d3-5cfd-48b2-bf88-0c0b13d46382" in namespace "projected-5961" to be "success or failure"
Oct 24 01:39:00.575: INFO: Pod "downwardapi-volume-be1cc3d3-5cfd-48b2-bf88-0c0b13d46382": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054058ms
Oct 24 01:39:02.580: INFO: Pod "downwardapi-volume-be1cc3d3-5cfd-48b2-bf88-0c0b13d46382": Phase="Running", Reason="", readiness=true. Elapsed: 2.008590033s
Oct 24 01:39:04.585: INFO: Pod "downwardapi-volume-be1cc3d3-5cfd-48b2-bf88-0c0b13d46382": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013914375s
STEP: Saw pod success
Oct 24 01:39:04.585: INFO: Pod "downwardapi-volume-be1cc3d3-5cfd-48b2-bf88-0c0b13d46382" satisfied condition "success or failure"
Oct 24 01:39:04.589: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-be1cc3d3-5cfd-48b2-bf88-0c0b13d46382 container client-container: <nil>
STEP: delete the pod
Oct 24 01:39:04.634: INFO: Waiting for pod downwardapi-volume-be1cc3d3-5cfd-48b2-bf88-0c0b13d46382 to disappear
Oct 24 01:39:04.643: INFO: Pod downwardapi-volume-be1cc3d3-5cfd-48b2-bf88-0c0b13d46382 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:39:04.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5961" for this suite.
Oct 24 01:39:10.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:39:10.788: INFO: namespace projected-5961 deletion completed in 6.139859092s

• [SLOW TEST:10.274 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:39:10.789: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:39:10.833: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Oct 24 01:39:12.871: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:39:13.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2849" for this suite.
Oct 24 01:39:19.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:39:20.039: INFO: namespace replication-controller-2849 deletion completed in 6.154262804s

• [SLOW TEST:9.250 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:39:20.039: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Oct 24 01:39:20.086: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Oct 24 01:39:20.822: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Oct 24 01:39:22.867: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:24.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:26.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:28.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:30.873: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:32.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:34.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:36.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:38.873: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:40.871: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:42.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:44.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:46.872: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707477960, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 01:39:50.021: INFO: Waited 1.138856149s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:39:50.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1832" for this suite.
Oct 24 01:39:56.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:39:56.857: INFO: namespace aggregator-1832 deletion completed in 6.255715315s

• [SLOW TEST:36.817 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:39:56.857: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:39:56.920: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 24 01:40:01.926: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 24 01:40:01.926: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct 24 01:40:01.955: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2694 /apis/apps/v1/namespaces/deployment-2694/deployments/test-cleanup-deployment 4f09cef6-270d-49f0-bad0-2a9341b860ed 14777 1 2019-10-24 01:40:01 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00695f7d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Oct 24 01:40:01.961: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-2694 /apis/apps/v1/namespaces/deployment-2694/replicasets/test-cleanup-deployment-65db99849b c12385be-1e28-4e1e-b639-e7cec550ef84 14779 1 2019-10-24 01:40:01 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 4f09cef6-270d-49f0-bad0-2a9341b860ed 0xc00695fc27 0xc00695fc28}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00695fc88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 01:40:01.961: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Oct 24 01:40:01.961: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-2694 /apis/apps/v1/namespaces/deployment-2694/replicasets/test-cleanup-controller b3857329-dc97-4e07-a5b4-7512e13b567e 14778 1 2019-10-24 01:39:56 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 4f09cef6-270d-49f0-bad0-2a9341b860ed 0xc00695fb57 0xc00695fb58}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00695fbb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 24 01:40:01.975: INFO: Pod "test-cleanup-controller-wstd7" is available:
&Pod{ObjectMeta:{test-cleanup-controller-wstd7 test-cleanup-controller- deployment-2694 /api/v1/namespaces/deployment-2694/pods/test-cleanup-controller-wstd7 ac7ac5ca-55cb-4aa1-a038-44b9cb9cddb8 14770 0 2019-10-24 01:39:56 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:10.244.1.128/32] [{apps/v1 ReplicaSet test-cleanup-controller b3857329-dc97-4e07-a5b4-7512e13b567e 0xc005efd977 0xc005efd978}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-dcj5q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-dcj5q,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-dcj5q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 01:39:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 01:39:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 01:39:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 01:39:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.1.128,StartTime:2019-10-24 01:39:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 01:39:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/httpd:2.4.38-alpine,ImageID:docker-pullable://docker.io/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://e81642b2ad43fa26b708bff0048e9b024a40610888488315a58e23e88f2be26e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.128,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 01:40:01.975: INFO: Pod "test-cleanup-deployment-65db99849b-964xf" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-964xf test-cleanup-deployment-65db99849b- deployment-2694 /api/v1/namespaces/deployment-2694/pods/test-cleanup-deployment-65db99849b-964xf b458ddd3-8caf-4bc4-ad33-2b2b25b1e289 14781 0 2019-10-24 01:40:01 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b c12385be-1e28-4e1e-b639-e7cec550ef84 0xc005efdb87 0xc005efdb88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-dcj5q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-dcj5q,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-dcj5q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:40:01.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2694" for this suite.
Oct 24 01:40:08.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:40:08.163: INFO: namespace deployment-2694 deletion completed in 6.176724791s

• [SLOW TEST:11.306 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:40:08.163: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:40:08.228: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 24 01:40:08.236: INFO: Number of nodes with available pods: 0
Oct 24 01:40:08.236: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 24 01:40:08.276: INFO: Number of nodes with available pods: 0
Oct 24 01:40:08.276: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:40:09.281: INFO: Number of nodes with available pods: 0
Oct 24 01:40:09.281: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:40:10.282: INFO: Number of nodes with available pods: 1
Oct 24 01:40:10.282: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 24 01:40:10.300: INFO: Number of nodes with available pods: 1
Oct 24 01:40:10.300: INFO: Number of running nodes: 0, number of available pods: 1
Oct 24 01:40:11.306: INFO: Number of nodes with available pods: 0
Oct 24 01:40:11.306: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 24 01:40:11.327: INFO: Number of nodes with available pods: 0
Oct 24 01:40:11.327: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:40:12.331: INFO: Number of nodes with available pods: 0
Oct 24 01:40:12.331: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:40:13.332: INFO: Number of nodes with available pods: 0
Oct 24 01:40:13.332: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:40:14.331: INFO: Number of nodes with available pods: 0
Oct 24 01:40:14.331: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:40:15.331: INFO: Number of nodes with available pods: 1
Oct 24 01:40:15.331: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1844, will wait for the garbage collector to delete the pods
Oct 24 01:40:15.401: INFO: Deleting DaemonSet.extensions daemon-set took: 8.174827ms
Oct 24 01:40:15.801: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.328685ms
Oct 24 01:40:19.305: INFO: Number of nodes with available pods: 0
Oct 24 01:40:19.305: INFO: Number of running nodes: 0, number of available pods: 0
Oct 24 01:40:19.309: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1844/daemonsets","resourceVersion":"14902"},"items":null}

Oct 24 01:40:19.312: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1844/pods","resourceVersion":"14902"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:40:19.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1844" for this suite.
Oct 24 01:40:25.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:40:25.493: INFO: namespace daemonsets-1844 deletion completed in 6.152443473s

• [SLOW TEST:17.331 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:40:25.494: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 01:40:25.545: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43643b09-fb2f-44c2-82c5-6047fd5632e6" in namespace "downward-api-3320" to be "success or failure"
Oct 24 01:40:25.550: INFO: Pod "downwardapi-volume-43643b09-fb2f-44c2-82c5-6047fd5632e6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.433762ms
Oct 24 01:40:27.554: INFO: Pod "downwardapi-volume-43643b09-fb2f-44c2-82c5-6047fd5632e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009329687s
STEP: Saw pod success
Oct 24 01:40:27.555: INFO: Pod "downwardapi-volume-43643b09-fb2f-44c2-82c5-6047fd5632e6" satisfied condition "success or failure"
Oct 24 01:40:27.558: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-43643b09-fb2f-44c2-82c5-6047fd5632e6 container client-container: <nil>
STEP: delete the pod
Oct 24 01:40:27.596: INFO: Waiting for pod downwardapi-volume-43643b09-fb2f-44c2-82c5-6047fd5632e6 to disappear
Oct 24 01:40:27.604: INFO: Pod downwardapi-volume-43643b09-fb2f-44c2-82c5-6047fd5632e6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:40:27.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3320" for this suite.
Oct 24 01:40:33.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:40:33.762: INFO: namespace downward-api-3320 deletion completed in 6.153074259s

• [SLOW TEST:8.268 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:40:33.762: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:40:34.715: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 24 01:40:36.731: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707478034, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707478034, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707478034, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707478034, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:40:39.749: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:40:39.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4511" for this suite.
Oct 24 01:40:51.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:40:51.982: INFO: namespace webhook-4511 deletion completed in 12.144176505s
STEP: Destroying namespace "webhook-4511-markers" for this suite.
Oct 24 01:40:57.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:40:58.131: INFO: namespace webhook-4511-markers deletion completed in 6.148937067s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.386 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:40:58.148: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:40:58.202: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct 24 01:41:02.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-9316 create -f -'
Oct 24 01:41:03.463: INFO: stderr: ""
Oct 24 01:41:03.463: INFO: stdout: "e2e-test-crd-publish-openapi-3673-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct 24 01:41:03.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-9316 delete e2e-test-crd-publish-openapi-3673-crds test-cr'
Oct 24 01:41:03.662: INFO: stderr: ""
Oct 24 01:41:03.662: INFO: stdout: "e2e-test-crd-publish-openapi-3673-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Oct 24 01:41:03.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-9316 apply -f -'
Oct 24 01:41:04.010: INFO: stderr: ""
Oct 24 01:41:04.010: INFO: stdout: "e2e-test-crd-publish-openapi-3673-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct 24 01:41:04.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-9316 delete e2e-test-crd-publish-openapi-3673-crds test-cr'
Oct 24 01:41:04.190: INFO: stderr: ""
Oct 24 01:41:04.190: INFO: stdout: "e2e-test-crd-publish-openapi-3673-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Oct 24 01:41:04.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 explain e2e-test-crd-publish-openapi-3673-crds'
Oct 24 01:41:04.502: INFO: stderr: ""
Oct 24 01:41:04.502: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3673-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:41:08.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9316" for this suite.
Oct 24 01:41:14.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:41:14.591: INFO: namespace crd-publish-openapi-9316 deletion completed in 6.152308064s

• [SLOW TEST:16.443 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:41:14.591: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:41:14.638: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Creating first CR 
Oct 24 01:41:15.248: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-24T01:41:15Z generation:1 name:name1 resourceVersion:15143 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cfd09fc0-ac87-46fd-94fd-2d2ab4d8989a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Oct 24 01:41:25.256: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-24T01:41:25Z generation:1 name:name2 resourceVersion:15158 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:90aea5f8-b5a9-447c-a3a7-5a0ea760b188] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Oct 24 01:41:35.265: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-24T01:41:15Z generation:2 name:name1 resourceVersion:15173 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cfd09fc0-ac87-46fd-94fd-2d2ab4d8989a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Oct 24 01:41:45.272: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-24T01:41:25Z generation:2 name:name2 resourceVersion:15188 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:90aea5f8-b5a9-447c-a3a7-5a0ea760b188] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Oct 24 01:41:55.283: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-24T01:41:15Z generation:2 name:name1 resourceVersion:15203 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cfd09fc0-ac87-46fd-94fd-2d2ab4d8989a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Oct 24 01:42:05.294: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-24T01:41:25Z generation:2 name:name2 resourceVersion:15220 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:90aea5f8-b5a9-447c-a3a7-5a0ea760b188] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:42:15.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-2707" for this suite.
Oct 24 01:42:21.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:42:21.957: INFO: namespace crd-watch-2707 deletion completed in 6.144478109s

• [SLOW TEST:67.366 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:42:21.958: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:42:22.475: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:42:25.502: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:42:25.507: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:42:26.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5273" for this suite.
Oct 24 01:42:38.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:42:38.857: INFO: namespace crd-webhook-5273 deletion completed in 12.140895722s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:16.916 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:42:38.873: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:42:39.683: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:42:42.711: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:42:42.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-983" for this suite.
Oct 24 01:42:54.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:42:54.878: INFO: namespace webhook-983 deletion completed in 12.151503182s
STEP: Destroying namespace "webhook-983-markers" for this suite.
Oct 24 01:43:00.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:43:01.019: INFO: namespace webhook-983-markers deletion completed in 6.140645912s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.163 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:43:01.037: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:43:01.085: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct 24 01:43:05.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-1959 create -f -'
Oct 24 01:43:05.710: INFO: stderr: ""
Oct 24 01:43:05.710: INFO: stdout: "e2e-test-crd-publish-openapi-1936-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct 24 01:43:05.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-1959 delete e2e-test-crd-publish-openapi-1936-crds test-cr'
Oct 24 01:43:05.892: INFO: stderr: ""
Oct 24 01:43:05.892: INFO: stdout: "e2e-test-crd-publish-openapi-1936-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Oct 24 01:43:05.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-1959 apply -f -'
Oct 24 01:43:06.230: INFO: stderr: ""
Oct 24 01:43:06.230: INFO: stdout: "e2e-test-crd-publish-openapi-1936-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct 24 01:43:06.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-1959 delete e2e-test-crd-publish-openapi-1936-crds test-cr'
Oct 24 01:43:06.416: INFO: stderr: ""
Oct 24 01:43:06.417: INFO: stdout: "e2e-test-crd-publish-openapi-1936-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Oct 24 01:43:06.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 explain e2e-test-crd-publish-openapi-1936-crds'
Oct 24 01:43:06.774: INFO: stderr: ""
Oct 24 01:43:06.774: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1936-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:43:11.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1959" for this suite.
Oct 24 01:43:17.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:43:17.491: INFO: namespace crd-publish-openapi-1959 deletion completed in 6.152754287s

• [SLOW TEST:16.454 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:43:17.491: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Oct 24 01:43:17.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-6410'
Oct 24 01:43:18.013: INFO: stderr: ""
Oct 24 01:43:18.013: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 01:43:18.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6410'
Oct 24 01:43:18.186: INFO: stderr: ""
Oct 24 01:43:18.186: INFO: stdout: "update-demo-nautilus-bljw5 update-demo-nautilus-xgtzz "
Oct 24 01:43:18.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-bljw5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6410'
Oct 24 01:43:18.360: INFO: stderr: ""
Oct 24 01:43:18.360: INFO: stdout: ""
Oct 24 01:43:18.360: INFO: update-demo-nautilus-bljw5 is created but not running
Oct 24 01:43:23.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6410'
Oct 24 01:43:23.537: INFO: stderr: ""
Oct 24 01:43:23.537: INFO: stdout: "update-demo-nautilus-bljw5 update-demo-nautilus-xgtzz "
Oct 24 01:43:23.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-bljw5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6410'
Oct 24 01:43:23.723: INFO: stderr: ""
Oct 24 01:43:23.723: INFO: stdout: "true"
Oct 24 01:43:23.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-bljw5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6410'
Oct 24 01:43:23.896: INFO: stderr: ""
Oct 24 01:43:23.896: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 01:43:23.896: INFO: validating pod update-demo-nautilus-bljw5
Oct 24 01:43:23.904: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 01:43:23.905: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 01:43:23.905: INFO: update-demo-nautilus-bljw5 is verified up and running
Oct 24 01:43:23.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-xgtzz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6410'
Oct 24 01:43:24.090: INFO: stderr: ""
Oct 24 01:43:24.090: INFO: stdout: "true"
Oct 24 01:43:24.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-xgtzz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6410'
Oct 24 01:43:24.259: INFO: stderr: ""
Oct 24 01:43:24.259: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 01:43:24.259: INFO: validating pod update-demo-nautilus-xgtzz
Oct 24 01:43:24.266: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 01:43:24.266: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 01:43:24.266: INFO: update-demo-nautilus-xgtzz is verified up and running
STEP: rolling-update to new replication controller
Oct 24 01:43:24.269: INFO: scanned /root for discovery docs: <nil>
Oct 24 01:43:24.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6410'
Oct 24 01:43:46.961: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 24 01:43:46.961: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 01:43:46.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6410'
Oct 24 01:43:47.144: INFO: stderr: ""
Oct 24 01:43:47.144: INFO: stdout: "update-demo-kitten-58wdw update-demo-kitten-v2m5m "
Oct 24 01:43:47.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-kitten-58wdw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6410'
Oct 24 01:43:47.331: INFO: stderr: ""
Oct 24 01:43:47.331: INFO: stdout: "true"
Oct 24 01:43:47.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-kitten-58wdw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6410'
Oct 24 01:43:47.502: INFO: stderr: ""
Oct 24 01:43:47.502: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 24 01:43:47.502: INFO: validating pod update-demo-kitten-58wdw
Oct 24 01:43:47.510: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 24 01:43:47.510: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 24 01:43:47.510: INFO: update-demo-kitten-58wdw is verified up and running
Oct 24 01:43:47.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-kitten-v2m5m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6410'
Oct 24 01:43:47.680: INFO: stderr: ""
Oct 24 01:43:47.680: INFO: stdout: "true"
Oct 24 01:43:47.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-kitten-v2m5m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6410'
Oct 24 01:43:47.844: INFO: stderr: ""
Oct 24 01:43:47.845: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 24 01:43:47.845: INFO: validating pod update-demo-kitten-v2m5m
Oct 24 01:43:47.853: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 24 01:43:47.853: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 24 01:43:47.853: INFO: update-demo-kitten-v2m5m is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:43:47.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6410" for this suite.
Oct 24 01:44:15.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:44:16.003: INFO: namespace kubectl-6410 deletion completed in 28.144537462s

• [SLOW TEST:58.512 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:44:16.003: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct 24 01:44:16.050: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 01:44:16.064: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 01:44:16.068: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm40.mip.storage.hpecorp.net before test
Oct 24 01:44:16.096: INFO: taint-eviction-4 from taint-single-pod-9185 started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:44:16.096: INFO: 	Container pause ready: true, restart count 0
Oct 24 01:44:16.097: INFO: canal-gwnsd from kube-system started at 2019-10-24 00:04:16 +0000 UTC (3 container statuses recorded)
Oct 24 01:44:16.097: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 01:44:16.097: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 01:44:16.097: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 01:44:16.097: INFO: kubedirector-fsmount-7g9kv from kube-system started at 2019-10-24 00:48:32 +0000 UTC (1 container statuses recorded)
Oct 24 01:44:16.097: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 01:44:16.097: INFO: coredns-5644d7b6d9-dvtzq from kube-system started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:44:16.097: INFO: 	Container coredns ready: true, restart count 0
Oct 24 01:44:16.097: INFO: kube-proxy-vr6tb from kube-system started at 2019-10-24 00:03:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:44:16.097: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 01:44:16.097: INFO: sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-vzlsf from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:44:16.097: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:44:16.097: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 01:44:16.097: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm41.mip.storage.hpecorp.net before test
Oct 24 01:44:16.124: INFO: kubedirector-5bbd74594b-99xvf from kube-system started at 2019-10-24 00:04:10 +0000 UTC (1 container statuses recorded)
Oct 24 01:44:16.124: INFO: 	Container kubedirector ready: true, restart count 0
Oct 24 01:44:16.124: INFO: kube-state-metrics-5fdb6fdffd-r42bd from kube-system started at 2019-10-24 00:04:06 +0000 UTC (1 container statuses recorded)
Oct 24 01:44:16.124: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 24 01:44:16.124: INFO: canal-zjdkh from kube-system started at 2019-10-24 00:04:16 +0000 UTC (3 container statuses recorded)
Oct 24 01:44:16.124: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 01:44:16.124: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 01:44:16.124: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 01:44:16.124: INFO: sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-wwg5x from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:44:16.124: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:44:16.124: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 01:44:16.124: INFO: kube-proxy-bmwmz from kube-system started at 2019-10-24 00:03:38 +0000 UTC (1 container statuses recorded)
Oct 24 01:44:16.124: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 01:44:16.124: INFO: sonobuoy from sonobuoy started at 2019-10-24 01:09:14 +0000 UTC (1 container statuses recorded)
Oct 24 01:44:16.124: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 24 01:44:16.124: INFO: sonobuoy-e2e-job-203e2c4356d04dbd from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:44:16.124: INFO: 	Container e2e ready: true, restart count 0
Oct 24 01:44:16.124: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:44:16.124: INFO: kubedirector-fsmount-9w6pk from kube-system started at 2019-10-24 00:05:24 +0000 UTC (1 container statuses recorded)
Oct 24 01:44:16.124: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 01:44:16.124: INFO: kubernetes-dashboard-7c54d59f66-c2jgr from kube-system started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:44:16.124: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node mip-bd-vm40.mip.storage.hpecorp.net
STEP: verifying the node has the label node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod canal-gwnsd requesting resource cpu=250m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod canal-zjdkh requesting resource cpu=250m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod coredns-5644d7b6d9-dvtzq requesting resource cpu=100m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod kube-proxy-bmwmz requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod kube-proxy-vr6tb requesting resource cpu=0m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod kube-state-metrics-5fdb6fdffd-r42bd requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod kubedirector-5bbd74594b-99xvf requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod kubedirector-fsmount-7g9kv requesting resource cpu=250m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod kubedirector-fsmount-9w6pk requesting resource cpu=250m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod kubernetes-dashboard-7c54d59f66-c2jgr requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod sonobuoy requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod sonobuoy-e2e-job-203e2c4356d04dbd requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-vzlsf requesting resource cpu=0m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-wwg5x requesting resource cpu=0m on Node mip-bd-vm41.mip.storage.hpecorp.net
Oct 24 01:44:16.175: INFO: Pod taint-eviction-4 requesting resource cpu=0m on Node mip-bd-vm40.mip.storage.hpecorp.net
STEP: Starting Pods to consume most of the cluster CPU.
Oct 24 01:44:16.175: INFO: Creating a pod which consumes cpu=2380m on Node mip-bd-vm40.mip.storage.hpecorp.net
Oct 24 01:44:16.184: INFO: Creating a pod which consumes cpu=2450m on Node mip-bd-vm41.mip.storage.hpecorp.net
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-27e31a52-d13d-443a-b06e-6c601bacaf5c.15d071db31f69459], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7877/filler-pod-27e31a52-d13d-443a-b06e-6c601bacaf5c to mip-bd-vm41.mip.storage.hpecorp.net]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-27e31a52-d13d-443a-b06e-6c601bacaf5c.15d071db62e5b59e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-27e31a52-d13d-443a-b06e-6c601bacaf5c.15d071db65408fa1], Reason = [Created], Message = [Created container filler-pod-27e31a52-d13d-443a-b06e-6c601bacaf5c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-27e31a52-d13d-443a-b06e-6c601bacaf5c.15d071db706217b0], Reason = [Started], Message = [Started container filler-pod-27e31a52-d13d-443a-b06e-6c601bacaf5c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-695be684-e80f-40ff-b0b5-25193f41278f.15d071db319879e7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7877/filler-pod-695be684-e80f-40ff-b0b5-25193f41278f to mip-bd-vm40.mip.storage.hpecorp.net]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-695be684-e80f-40ff-b0b5-25193f41278f.15d071db60a01a4c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-695be684-e80f-40ff-b0b5-25193f41278f.15d071db62ca477a], Reason = [Created], Message = [Created container filler-pod-695be684-e80f-40ff-b0b5-25193f41278f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-695be684-e80f-40ff-b0b5-25193f41278f.15d071db6e364613], Reason = [Started], Message = [Started container filler-pod-695be684-e80f-40ff-b0b5-25193f41278f]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d071dbaaccb48c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node mip-bd-vm40.mip.storage.hpecorp.net
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node mip-bd-vm41.mip.storage.hpecorp.net
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:44:19.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7877" for this suite.
Oct 24 01:44:25.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:44:25.429: INFO: namespace sched-pred-7877 deletion completed in 6.150580102s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:9.426 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:44:25.430: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 01:44:25.482: INFO: Waiting up to 5m0s for pod "downwardapi-volume-50bd1346-2716-40d2-8ee2-c9d181ae2055" in namespace "projected-2803" to be "success or failure"
Oct 24 01:44:25.486: INFO: Pod "downwardapi-volume-50bd1346-2716-40d2-8ee2-c9d181ae2055": Phase="Pending", Reason="", readiness=false. Elapsed: 3.936672ms
Oct 24 01:44:27.492: INFO: Pod "downwardapi-volume-50bd1346-2716-40d2-8ee2-c9d181ae2055": Phase="Running", Reason="", readiness=true. Elapsed: 2.009517868s
Oct 24 01:44:29.497: INFO: Pod "downwardapi-volume-50bd1346-2716-40d2-8ee2-c9d181ae2055": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014726289s
STEP: Saw pod success
Oct 24 01:44:29.497: INFO: Pod "downwardapi-volume-50bd1346-2716-40d2-8ee2-c9d181ae2055" satisfied condition "success or failure"
Oct 24 01:44:29.501: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-50bd1346-2716-40d2-8ee2-c9d181ae2055 container client-container: <nil>
STEP: delete the pod
Oct 24 01:44:29.528: INFO: Waiting for pod downwardapi-volume-50bd1346-2716-40d2-8ee2-c9d181ae2055 to disappear
Oct 24 01:44:29.532: INFO: Pod downwardapi-volume-50bd1346-2716-40d2-8ee2-c9d181ae2055 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:44:29.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2803" for this suite.
Oct 24 01:44:35.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:44:35.694: INFO: namespace projected-2803 deletion completed in 6.157337002s

• [SLOW TEST:10.265 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:44:35.694: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 01:44:35.763: INFO: Waiting up to 5m0s for pod "downwardapi-volume-de54102f-8ce2-48a9-a981-5cb364dd386d" in namespace "downward-api-2153" to be "success or failure"
Oct 24 01:44:35.776: INFO: Pod "downwardapi-volume-de54102f-8ce2-48a9-a981-5cb364dd386d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.276103ms
Oct 24 01:44:37.782: INFO: Pod "downwardapi-volume-de54102f-8ce2-48a9-a981-5cb364dd386d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018923283s
STEP: Saw pod success
Oct 24 01:44:37.782: INFO: Pod "downwardapi-volume-de54102f-8ce2-48a9-a981-5cb364dd386d" satisfied condition "success or failure"
Oct 24 01:44:37.785: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-de54102f-8ce2-48a9-a981-5cb364dd386d container client-container: <nil>
STEP: delete the pod
Oct 24 01:44:37.815: INFO: Waiting for pod downwardapi-volume-de54102f-8ce2-48a9-a981-5cb364dd386d to disappear
Oct 24 01:44:37.818: INFO: Pod downwardapi-volume-de54102f-8ce2-48a9-a981-5cb364dd386d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:44:37.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2153" for this suite.
Oct 24 01:44:43.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:44:43.983: INFO: namespace downward-api-2153 deletion completed in 6.159584345s

• [SLOW TEST:8.289 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:44:43.984: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 24 01:44:46.569: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e2571df8-f0ee-4b8f-85dc-bc83dab3cdd0"
Oct 24 01:44:46.569: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e2571df8-f0ee-4b8f-85dc-bc83dab3cdd0" in namespace "pods-8017" to be "terminated due to deadline exceeded"
Oct 24 01:44:46.573: INFO: Pod "pod-update-activedeadlineseconds-e2571df8-f0ee-4b8f-85dc-bc83dab3cdd0": Phase="Running", Reason="", readiness=true. Elapsed: 3.877884ms
Oct 24 01:44:48.579: INFO: Pod "pod-update-activedeadlineseconds-e2571df8-f0ee-4b8f-85dc-bc83dab3cdd0": Phase="Running", Reason="", readiness=true. Elapsed: 2.009749157s
Oct 24 01:44:50.584: INFO: Pod "pod-update-activedeadlineseconds-e2571df8-f0ee-4b8f-85dc-bc83dab3cdd0": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.015233876s
Oct 24 01:44:50.584: INFO: Pod "pod-update-activedeadlineseconds-e2571df8-f0ee-4b8f-85dc-bc83dab3cdd0" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:44:50.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8017" for this suite.
Oct 24 01:44:56.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:44:56.735: INFO: namespace pods-8017 deletion completed in 6.145621312s

• [SLOW TEST:12.751 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:44:56.736: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:44:56.797: INFO: (0) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 8.588253ms)
Oct 24 01:44:56.804: INFO: (1) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 6.596808ms)
Oct 24 01:44:56.809: INFO: (2) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.346968ms)
Oct 24 01:44:56.815: INFO: (3) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.347462ms)
Oct 24 01:44:56.820: INFO: (4) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.223448ms)
Oct 24 01:44:56.825: INFO: (5) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.53562ms)
Oct 24 01:44:56.832: INFO: (6) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 6.032099ms)
Oct 24 01:44:56.837: INFO: (7) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.261112ms)
Oct 24 01:44:56.846: INFO: (8) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 8.78685ms)
Oct 24 01:44:56.851: INFO: (9) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.080543ms)
Oct 24 01:44:56.858: INFO: (10) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 7.12283ms)
Oct 24 01:44:56.863: INFO: (11) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.9467ms)
Oct 24 01:44:56.868: INFO: (12) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.72185ms)
Oct 24 01:44:56.873: INFO: (13) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.246098ms)
Oct 24 01:44:56.879: INFO: (14) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.580334ms)
Oct 24 01:44:56.884: INFO: (15) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.184443ms)
Oct 24 01:44:56.889: INFO: (16) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.048682ms)
Oct 24 01:44:56.894: INFO: (17) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.29447ms)
Oct 24 01:44:56.900: INFO: (18) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.351226ms)
Oct 24 01:44:56.905: INFO: (19) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.016712ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:44:56.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2960" for this suite.
Oct 24 01:45:02.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:45:03.068: INFO: namespace proxy-2960 deletion completed in 6.159415242s

• [SLOW TEST:6.333 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:45:03.070: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:45:03.855: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:45:06.882: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:45:19.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6348" for this suite.
Oct 24 01:45:31.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:45:31.218: INFO: namespace webhook-6348 deletion completed in 12.145311061s
STEP: Destroying namespace "webhook-6348-markers" for this suite.
Oct 24 01:45:37.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:45:37.371: INFO: namespace webhook-6348-markers deletion completed in 6.153119371s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:34.318 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:45:37.388: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8886
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8886
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8886
Oct 24 01:45:37.461: INFO: Found 0 stateful pods, waiting for 1
Oct 24 01:45:47.467: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 24 01:45:47.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-8886 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 01:45:47.809: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 01:45:47.809: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 01:45:47.809: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 01:45:47.814: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 24 01:45:57.820: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 01:45:57.820: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 01:45:57.843: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999483s
Oct 24 01:45:58.849: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990971163s
Oct 24 01:45:59.855: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.984848734s
Oct 24 01:46:00.861: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.978939075s
Oct 24 01:46:01.867: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.972919885s
Oct 24 01:46:02.871: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.967183395s
Oct 24 01:46:03.877: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.962264311s
Oct 24 01:46:04.883: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.957197143s
Oct 24 01:46:05.890: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.95092813s
Oct 24 01:46:06.901: INFO: Verifying statefulset ss doesn't scale past 1 for another 943.806462ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8886
Oct 24 01:46:07.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-8886 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 01:46:08.245: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 01:46:08.245: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 01:46:08.245: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 01:46:08.250: INFO: Found 1 stateful pods, waiting for 3
Oct 24 01:46:18.256: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 01:46:18.256: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 01:46:18.256: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 24 01:46:18.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-8886 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 01:46:18.592: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 01:46:18.592: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 01:46:18.592: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 01:46:18.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-8886 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 01:46:18.911: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 01:46:18.911: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 01:46:18.911: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 01:46:18.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-8886 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 01:46:19.233: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 01:46:19.233: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 01:46:19.233: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 01:46:19.233: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 01:46:19.238: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 24 01:46:29.249: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 01:46:29.249: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 01:46:29.249: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 01:46:29.262: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999453s
Oct 24 01:46:30.269: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995357841s
Oct 24 01:46:31.277: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988390892s
Oct 24 01:46:32.284: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.980300618s
Oct 24 01:46:33.290: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.973797791s
Oct 24 01:46:34.297: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.967440926s
Oct 24 01:46:35.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.960493547s
Oct 24 01:46:36.309: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.954486192s
Oct 24 01:46:37.315: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.94869261s
Oct 24 01:46:38.321: INFO: Verifying statefulset ss doesn't scale past 3 for another 942.731129ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8886
Oct 24 01:46:39.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-8886 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 01:46:39.668: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 01:46:39.668: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 01:46:39.668: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 01:46:39.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-8886 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 01:46:40.013: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 01:46:40.013: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 01:46:40.013: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 01:46:40.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-8886 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 01:46:40.350: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 01:46:40.350: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 01:46:40.350: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 01:46:40.350: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 24 01:47:00.373: INFO: Deleting all statefulset in ns statefulset-8886
Oct 24 01:47:00.378: INFO: Scaling statefulset ss to 0
Oct 24 01:47:00.390: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 01:47:00.393: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:47:00.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8886" for this suite.
Oct 24 01:47:06.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:47:06.573: INFO: namespace statefulset-8886 deletion completed in 6.157035643s

• [SLOW TEST:89.186 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:47:06.574: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:47:22.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5044" for this suite.
Oct 24 01:47:28.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:47:28.917: INFO: namespace resourcequota-5044 deletion completed in 6.16421336s

• [SLOW TEST:22.343 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:47:28.917: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 24 01:47:30.997: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:47:31.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-495" for this suite.
Oct 24 01:47:37.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:47:37.169: INFO: namespace container-runtime-495 deletion completed in 6.150129159s

• [SLOW TEST:8.252 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:47:37.170: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Oct 24 01:47:37.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-9095 -- logs-generator --log-lines-total 100 --run-duration 20s'
Oct 24 01:47:37.412: INFO: stderr: ""
Oct 24 01:47:37.412: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Oct 24 01:47:37.412: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Oct 24 01:47:37.412: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-9095" to be "running and ready, or succeeded"
Oct 24 01:47:37.417: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.429046ms
Oct 24 01:47:39.423: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.011328828s
Oct 24 01:47:39.423: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Oct 24 01:47:39.423: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Oct 24 01:47:39.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 logs logs-generator logs-generator --namespace=kubectl-9095'
Oct 24 01:47:39.664: INFO: stderr: ""
Oct 24 01:47:39.664: INFO: stdout: "I1024 01:47:38.445349       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/cp27 554\nI1024 01:47:38.645634       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/znj 435\nI1024 01:47:38.845592       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/cbv 549\nI1024 01:47:39.045601       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/62m7 398\nI1024 01:47:39.245614       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/mht 598\nI1024 01:47:39.445576       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/fnhf 303\nI1024 01:47:39.645563       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/rrt 242\n"
Oct 24 01:47:41.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 logs logs-generator logs-generator --namespace=kubectl-9095'
Oct 24 01:47:41.854: INFO: stderr: ""
Oct 24 01:47:41.854: INFO: stdout: "I1024 01:47:38.445349       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/cp27 554\nI1024 01:47:38.645634       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/znj 435\nI1024 01:47:38.845592       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/cbv 549\nI1024 01:47:39.045601       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/62m7 398\nI1024 01:47:39.245614       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/mht 598\nI1024 01:47:39.445576       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/fnhf 303\nI1024 01:47:39.645563       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/rrt 242\nI1024 01:47:39.845579       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/pl7 443\nI1024 01:47:40.045629       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/h8c 428\nI1024 01:47:40.245609       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/7ht 271\nI1024 01:47:40.445613       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/ntmw 318\nI1024 01:47:40.645647       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/jtj 484\nI1024 01:47:40.845573       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/n9qw 288\nI1024 01:47:41.045634       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/j52 269\nI1024 01:47:41.245597       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/5qmt 206\nI1024 01:47:41.445616       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/7hhq 328\nI1024 01:47:41.645587       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/wmm5 295\nI1024 01:47:41.845519       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/ts7l 205\n"
STEP: limiting log lines
Oct 24 01:47:41.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 logs logs-generator logs-generator --namespace=kubectl-9095 --tail=1'
Oct 24 01:47:42.045: INFO: stderr: ""
Oct 24 01:47:42.045: INFO: stdout: "I1024 01:47:41.845519       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/ts7l 205\n"
STEP: limiting log bytes
Oct 24 01:47:42.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 logs logs-generator logs-generator --namespace=kubectl-9095 --limit-bytes=1'
Oct 24 01:47:42.233: INFO: stderr: ""
Oct 24 01:47:42.233: INFO: stdout: "I"
STEP: exposing timestamps
Oct 24 01:47:42.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 logs logs-generator logs-generator --namespace=kubectl-9095 --tail=1 --timestamps'
Oct 24 01:47:42.420: INFO: stderr: ""
Oct 24 01:47:42.420: INFO: stdout: "2019-10-24T01:47:42.245887444Z I1024 01:47:42.245621       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/hpmk 357\n"
STEP: restricting to a time range
Oct 24 01:47:44.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 logs logs-generator logs-generator --namespace=kubectl-9095 --since=1s'
Oct 24 01:47:45.111: INFO: stderr: ""
Oct 24 01:47:45.111: INFO: stdout: "I1024 01:47:44.245664       1 logs_generator.go:76] 29 GET /api/v1/namespaces/kube-system/pods/cgc2 216\nI1024 01:47:44.445673       1 logs_generator.go:76] 30 GET /api/v1/namespaces/ns/pods/jh4 342\nI1024 01:47:44.645683       1 logs_generator.go:76] 31 GET /api/v1/namespaces/default/pods/l64t 456\nI1024 01:47:44.845671       1 logs_generator.go:76] 32 GET /api/v1/namespaces/default/pods/p64 235\nI1024 01:47:45.045743       1 logs_generator.go:76] 33 POST /api/v1/namespaces/kube-system/pods/zlj2 203\n"
Oct 24 01:47:45.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 logs logs-generator logs-generator --namespace=kubectl-9095 --since=24h'
Oct 24 01:47:45.311: INFO: stderr: ""
Oct 24 01:47:45.311: INFO: stdout: "I1024 01:47:38.445349       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/cp27 554\nI1024 01:47:38.645634       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/znj 435\nI1024 01:47:38.845592       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/cbv 549\nI1024 01:47:39.045601       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/62m7 398\nI1024 01:47:39.245614       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/mht 598\nI1024 01:47:39.445576       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/fnhf 303\nI1024 01:47:39.645563       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/rrt 242\nI1024 01:47:39.845579       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/pl7 443\nI1024 01:47:40.045629       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/h8c 428\nI1024 01:47:40.245609       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/7ht 271\nI1024 01:47:40.445613       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/ntmw 318\nI1024 01:47:40.645647       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/jtj 484\nI1024 01:47:40.845573       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/n9qw 288\nI1024 01:47:41.045634       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/j52 269\nI1024 01:47:41.245597       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/5qmt 206\nI1024 01:47:41.445616       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/7hhq 328\nI1024 01:47:41.645587       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/wmm5 295\nI1024 01:47:41.845519       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/ts7l 205\nI1024 01:47:42.045595       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/mp8 452\nI1024 01:47:42.245621       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/hpmk 357\nI1024 01:47:42.445629       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/5rz8 535\nI1024 01:47:42.645616       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/4lwl 342\nI1024 01:47:42.845582       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/4t9 551\nI1024 01:47:43.045631       1 logs_generator.go:76] 23 POST /api/v1/namespaces/kube-system/pods/lv5 572\nI1024 01:47:43.245626       1 logs_generator.go:76] 24 POST /api/v1/namespaces/ns/pods/6xh 303\nI1024 01:47:43.445548       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/ns/pods/97g 594\nI1024 01:47:43.645537       1 logs_generator.go:76] 26 GET /api/v1/namespaces/kube-system/pods/kq7p 301\nI1024 01:47:43.845623       1 logs_generator.go:76] 27 GET /api/v1/namespaces/default/pods/52zg 325\nI1024 01:47:44.045647       1 logs_generator.go:76] 28 POST /api/v1/namespaces/ns/pods/lps 334\nI1024 01:47:44.245664       1 logs_generator.go:76] 29 GET /api/v1/namespaces/kube-system/pods/cgc2 216\nI1024 01:47:44.445673       1 logs_generator.go:76] 30 GET /api/v1/namespaces/ns/pods/jh4 342\nI1024 01:47:44.645683       1 logs_generator.go:76] 31 GET /api/v1/namespaces/default/pods/l64t 456\nI1024 01:47:44.845671       1 logs_generator.go:76] 32 GET /api/v1/namespaces/default/pods/p64 235\nI1024 01:47:45.045743       1 logs_generator.go:76] 33 POST /api/v1/namespaces/kube-system/pods/zlj2 203\nI1024 01:47:45.245647       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/default/pods/zs6 301\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Oct 24 01:47:45.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete pod logs-generator --namespace=kubectl-9095'
Oct 24 01:47:47.581: INFO: stderr: ""
Oct 24 01:47:47.582: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:47:47.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9095" for this suite.
Oct 24 01:47:53.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:47:53.754: INFO: namespace kubectl-9095 deletion completed in 6.16696331s

• [SLOW TEST:16.584 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:47:53.756: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-3ece3bd2-47a8-4abf-8487-8669ef0fee13
STEP: Creating secret with name s-test-opt-upd-6bf2d62a-9dae-4d69-a6aa-742bd1ad5a85
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3ece3bd2-47a8-4abf-8487-8669ef0fee13
STEP: Updating secret s-test-opt-upd-6bf2d62a-9dae-4d69-a6aa-742bd1ad5a85
STEP: Creating secret with name s-test-opt-create-cc2a72be-ba64-47cb-a5b5-4135cf6b6769
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:47:57.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9707" for this suite.
Oct 24 01:48:09.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:48:10.109: INFO: namespace projected-9707 deletion completed in 12.146822226s

• [SLOW TEST:16.353 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:48:10.109: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:48:10.162: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:48:16.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7178" for this suite.
Oct 24 01:48:22.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:48:22.808: INFO: namespace custom-resource-definition-7178 deletion completed in 6.190421629s

• [SLOW TEST:12.698 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:48:22.808: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 01:48:22.863: INFO: Waiting up to 5m0s for pod "downwardapi-volume-53399592-d7b4-469c-98b5-e84e6c1805df" in namespace "downward-api-1737" to be "success or failure"
Oct 24 01:48:22.868: INFO: Pod "downwardapi-volume-53399592-d7b4-469c-98b5-e84e6c1805df": Phase="Pending", Reason="", readiness=false. Elapsed: 4.663706ms
Oct 24 01:48:24.873: INFO: Pod "downwardapi-volume-53399592-d7b4-469c-98b5-e84e6c1805df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010020756s
STEP: Saw pod success
Oct 24 01:48:24.873: INFO: Pod "downwardapi-volume-53399592-d7b4-469c-98b5-e84e6c1805df" satisfied condition "success or failure"
Oct 24 01:48:24.877: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-53399592-d7b4-469c-98b5-e84e6c1805df container client-container: <nil>
STEP: delete the pod
Oct 24 01:48:24.902: INFO: Waiting for pod downwardapi-volume-53399592-d7b4-469c-98b5-e84e6c1805df to disappear
Oct 24 01:48:24.907: INFO: Pod downwardapi-volume-53399592-d7b4-469c-98b5-e84e6c1805df no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:48:24.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1737" for this suite.
Oct 24 01:48:30.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:48:31.058: INFO: namespace downward-api-1737 deletion completed in 6.145428191s

• [SLOW TEST:8.251 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:48:31.059: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3906.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3906.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 24 01:48:35.147: INFO: DNS probes using dns-test-9c9ae74d-c1c1-4719-bcbb-78108cce0486 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3906.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3906.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 24 01:48:39.207: INFO: File wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local from pod  dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 01:48:39.213: INFO: File jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local from pod  dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 01:48:39.213: INFO: Lookups using dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 failed for: [wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local]

Oct 24 01:48:44.220: INFO: File wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local from pod  dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 01:48:44.225: INFO: File jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local from pod  dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 01:48:44.225: INFO: Lookups using dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 failed for: [wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local]

Oct 24 01:48:49.220: INFO: File wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local from pod  dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 01:48:49.225: INFO: File jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local from pod  dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 01:48:49.225: INFO: Lookups using dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 failed for: [wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local]

Oct 24 01:48:54.219: INFO: File wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local from pod  dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 01:48:54.224: INFO: File jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local from pod  dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 01:48:54.224: INFO: Lookups using dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 failed for: [wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local]

Oct 24 01:48:59.220: INFO: File wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local from pod  dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 01:48:59.226: INFO: File jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local from pod  dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct 24 01:48:59.226: INFO: Lookups using dns-3906/dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 failed for: [wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local]

Oct 24 01:49:04.224: INFO: DNS probes using dns-test-6e540670-116d-4f0b-8d67-2d7e71b70321 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3906.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3906.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3906.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3906.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 24 01:49:06.318: INFO: DNS probes using dns-test-887c40af-e66a-4e7d-aa2a-dda3a58e3211 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:49:06.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3906" for this suite.
Oct 24 01:49:12.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:49:12.504: INFO: namespace dns-3906 deletion completed in 6.147116882s

• [SLOW TEST:41.445 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:49:12.504: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-95a13260-20ec-488f-a37c-3e3809e091c6
STEP: Creating a pod to test consume configMaps
Oct 24 01:49:12.581: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-394a9e99-64d0-407c-ba82-ce0b9cb5db47" in namespace "projected-9568" to be "success or failure"
Oct 24 01:49:12.586: INFO: Pod "pod-projected-configmaps-394a9e99-64d0-407c-ba82-ce0b9cb5db47": Phase="Pending", Reason="", readiness=false. Elapsed: 4.767336ms
Oct 24 01:49:14.592: INFO: Pod "pod-projected-configmaps-394a9e99-64d0-407c-ba82-ce0b9cb5db47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010730749s
STEP: Saw pod success
Oct 24 01:49:14.592: INFO: Pod "pod-projected-configmaps-394a9e99-64d0-407c-ba82-ce0b9cb5db47" satisfied condition "success or failure"
Oct 24 01:49:14.596: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-394a9e99-64d0-407c-ba82-ce0b9cb5db47 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 01:49:14.637: INFO: Waiting for pod pod-projected-configmaps-394a9e99-64d0-407c-ba82-ce0b9cb5db47 to disappear
Oct 24 01:49:14.641: INFO: Pod pod-projected-configmaps-394a9e99-64d0-407c-ba82-ce0b9cb5db47 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:49:14.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9568" for this suite.
Oct 24 01:49:20.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:49:20.791: INFO: namespace projected-9568 deletion completed in 6.145139052s

• [SLOW TEST:8.287 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:49:20.792: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8a6b1b4d-7bb5-414c-9a61-ad2ebb090dd4
STEP: Creating a pod to test consume configMaps
Oct 24 01:49:20.850: INFO: Waiting up to 5m0s for pod "pod-configmaps-84626b9b-91d6-4bfc-9699-8f76b214e227" in namespace "configmap-9558" to be "success or failure"
Oct 24 01:49:20.853: INFO: Pod "pod-configmaps-84626b9b-91d6-4bfc-9699-8f76b214e227": Phase="Pending", Reason="", readiness=false. Elapsed: 3.197671ms
Oct 24 01:49:22.857: INFO: Pod "pod-configmaps-84626b9b-91d6-4bfc-9699-8f76b214e227": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007657978s
STEP: Saw pod success
Oct 24 01:49:22.857: INFO: Pod "pod-configmaps-84626b9b-91d6-4bfc-9699-8f76b214e227" satisfied condition "success or failure"
Oct 24 01:49:22.861: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-84626b9b-91d6-4bfc-9699-8f76b214e227 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 01:49:22.889: INFO: Waiting for pod pod-configmaps-84626b9b-91d6-4bfc-9699-8f76b214e227 to disappear
Oct 24 01:49:22.893: INFO: Pod pod-configmaps-84626b9b-91d6-4bfc-9699-8f76b214e227 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:49:22.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9558" for this suite.
Oct 24 01:49:28.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:49:29.068: INFO: namespace configmap-9558 deletion completed in 6.170531347s

• [SLOW TEST:8.276 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:49:29.068: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 24 01:49:29.123: INFO: Waiting up to 5m0s for pod "pod-af104a3e-ec40-4adb-8734-3b62c11a9651" in namespace "emptydir-167" to be "success or failure"
Oct 24 01:49:29.126: INFO: Pod "pod-af104a3e-ec40-4adb-8734-3b62c11a9651": Phase="Pending", Reason="", readiness=false. Elapsed: 3.188213ms
Oct 24 01:49:31.131: INFO: Pod "pod-af104a3e-ec40-4adb-8734-3b62c11a9651": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008154921s
STEP: Saw pod success
Oct 24 01:49:31.131: INFO: Pod "pod-af104a3e-ec40-4adb-8734-3b62c11a9651" satisfied condition "success or failure"
Oct 24 01:49:31.135: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-af104a3e-ec40-4adb-8734-3b62c11a9651 container test-container: <nil>
STEP: delete the pod
Oct 24 01:49:31.160: INFO: Waiting for pod pod-af104a3e-ec40-4adb-8734-3b62c11a9651 to disappear
Oct 24 01:49:31.165: INFO: Pod pod-af104a3e-ec40-4adb-8734-3b62c11a9651 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:49:31.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-167" for this suite.
Oct 24 01:49:37.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:49:37.319: INFO: namespace emptydir-167 deletion completed in 6.149791906s

• [SLOW TEST:8.251 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:49:37.319: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct 24 01:49:37.364: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 24 01:49:37.380: INFO: Waiting for terminating namespaces to be deleted...
Oct 24 01:49:37.384: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm40.mip.storage.hpecorp.net before test
Oct 24 01:49:37.394: INFO: coredns-5644d7b6d9-dvtzq from kube-system started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:49:37.394: INFO: 	Container coredns ready: true, restart count 0
Oct 24 01:49:37.394: INFO: kube-proxy-vr6tb from kube-system started at 2019-10-24 00:03:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:49:37.394: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 01:49:37.394: INFO: sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-vzlsf from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:49:37.394: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:49:37.394: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 01:49:37.394: INFO: taint-eviction-4 from taint-single-pod-9185 started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:49:37.394: INFO: 	Container pause ready: true, restart count 0
Oct 24 01:49:37.394: INFO: canal-gwnsd from kube-system started at 2019-10-24 00:04:16 +0000 UTC (3 container statuses recorded)
Oct 24 01:49:37.394: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 01:49:37.394: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 01:49:37.394: INFO: 	Container kube-flannel ready: true, restart count 0
Oct 24 01:49:37.394: INFO: kubedirector-fsmount-7g9kv from kube-system started at 2019-10-24 00:48:32 +0000 UTC (1 container statuses recorded)
Oct 24 01:49:37.395: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 01:49:37.395: INFO: 
Logging pods the kubelet thinks is on node mip-bd-vm41.mip.storage.hpecorp.net before test
Oct 24 01:49:37.426: INFO: kube-proxy-bmwmz from kube-system started at 2019-10-24 00:03:38 +0000 UTC (1 container statuses recorded)
Oct 24 01:49:37.426: INFO: 	Container kube-proxy ready: true, restart count 0
Oct 24 01:49:37.426: INFO: sonobuoy from sonobuoy started at 2019-10-24 01:09:14 +0000 UTC (1 container statuses recorded)
Oct 24 01:49:37.426: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 24 01:49:37.426: INFO: sonobuoy-e2e-job-203e2c4356d04dbd from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:49:37.426: INFO: 	Container e2e ready: true, restart count 0
Oct 24 01:49:37.426: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:49:37.426: INFO: sonobuoy-systemd-logs-daemon-set-54a1e96646204e73-wwg5x from sonobuoy started at 2019-10-24 01:09:25 +0000 UTC (2 container statuses recorded)
Oct 24 01:49:37.426: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 24 01:49:37.426: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 24 01:49:37.426: INFO: kubedirector-fsmount-9w6pk from kube-system started at 2019-10-24 00:05:24 +0000 UTC (1 container statuses recorded)
Oct 24 01:49:37.426: INFO: 	Container kubedirector-fsmount ready: true, restart count 0
Oct 24 01:49:37.426: INFO: kubernetes-dashboard-7c54d59f66-c2jgr from kube-system started at 2019-10-24 00:48:27 +0000 UTC (1 container statuses recorded)
Oct 24 01:49:37.426: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 24 01:49:37.426: INFO: kubedirector-5bbd74594b-99xvf from kube-system started at 2019-10-24 00:04:10 +0000 UTC (1 container statuses recorded)
Oct 24 01:49:37.426: INFO: 	Container kubedirector ready: true, restart count 0
Oct 24 01:49:37.426: INFO: kube-state-metrics-5fdb6fdffd-r42bd from kube-system started at 2019-10-24 00:04:06 +0000 UTC (1 container statuses recorded)
Oct 24 01:49:37.426: INFO: 	Container kube-state-metrics ready: true, restart count 0
Oct 24 01:49:37.426: INFO: canal-zjdkh from kube-system started at 2019-10-24 00:04:16 +0000 UTC (3 container statuses recorded)
Oct 24 01:49:37.426: INFO: 	Container calico-node ready: true, restart count 0
Oct 24 01:49:37.426: INFO: 	Container install-cni ready: true, restart count 0
Oct 24 01:49:37.426: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-67c0c884-18f2-41fa-87d6-402611fb9a59 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-67c0c884-18f2-41fa-87d6-402611fb9a59 off the node mip-bd-vm40.mip.storage.hpecorp.net
STEP: verifying the node doesn't have the label kubernetes.io/e2e-67c0c884-18f2-41fa-87d6-402611fb9a59
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:54:41.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7393" for this suite.
Oct 24 01:55:01.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:55:01.721: INFO: namespace sched-pred-7393 deletion completed in 20.161813876s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:324.402 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:55:01.721: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 01:55:02.264: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 24 01:55:04.279: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707478902, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707478902, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707478902, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707478902, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 01:55:07.297: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 01:55:07.302: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:55:08.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-596" for this suite.
Oct 24 01:55:14.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:55:14.983: INFO: namespace webhook-596 deletion completed in 6.210467807s
STEP: Destroying namespace "webhook-596-markers" for this suite.
Oct 24 01:55:20.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:55:21.128: INFO: namespace webhook-596-markers deletion completed in 6.145067489s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.424 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:55:21.145: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 24 01:55:21.224: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:55:21.231: INFO: Number of nodes with available pods: 0
Oct 24 01:55:21.231: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:55:22.238: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:55:22.241: INFO: Number of nodes with available pods: 0
Oct 24 01:55:22.241: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 01:55:23.237: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:55:23.241: INFO: Number of nodes with available pods: 2
Oct 24 01:55:23.241: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 24 01:55:23.263: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 01:55:23.268: INFO: Number of nodes with available pods: 2
Oct 24 01:55:23.268: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9936, will wait for the garbage collector to delete the pods
Oct 24 01:55:24.347: INFO: Deleting DaemonSet.extensions daemon-set took: 8.089952ms
Oct 24 01:55:24.447: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.30697ms
Oct 24 01:56:49.552: INFO: Number of nodes with available pods: 0
Oct 24 01:56:49.552: INFO: Number of running nodes: 0, number of available pods: 0
Oct 24 01:56:49.556: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9936/daemonsets","resourceVersion":"17894"},"items":null}

Oct 24 01:56:49.560: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9936/pods","resourceVersion":"17894"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:56:49.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9936" for this suite.
Oct 24 01:56:55.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:56:55.730: INFO: namespace daemonsets-9936 deletion completed in 6.151966524s

• [SLOW TEST:94.585 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:56:55.730: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:57:06.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5149" for this suite.
Oct 24 01:57:12.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:57:13.001: INFO: namespace resourcequota-5149 deletion completed in 6.156528387s

• [SLOW TEST:17.270 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:57:13.001: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:58:13.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9929" for this suite.
Oct 24 01:58:41.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:58:41.227: INFO: namespace container-probe-9929 deletion completed in 28.159870333s

• [SLOW TEST:88.226 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:58:41.228: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-7cb2dd12-8ac8-48a8-a3d6-f4655bde010d
STEP: Creating a pod to test consume configMaps
Oct 24 01:58:41.291: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6dccf606-0f00-4b53-9cb4-82c53b3cd05c" in namespace "projected-8330" to be "success or failure"
Oct 24 01:58:41.294: INFO: Pod "pod-projected-configmaps-6dccf606-0f00-4b53-9cb4-82c53b3cd05c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.346541ms
Oct 24 01:58:43.299: INFO: Pod "pod-projected-configmaps-6dccf606-0f00-4b53-9cb4-82c53b3cd05c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008280112s
STEP: Saw pod success
Oct 24 01:58:43.299: INFO: Pod "pod-projected-configmaps-6dccf606-0f00-4b53-9cb4-82c53b3cd05c" satisfied condition "success or failure"
Oct 24 01:58:43.303: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-6dccf606-0f00-4b53-9cb4-82c53b3cd05c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 01:58:43.350: INFO: Waiting for pod pod-projected-configmaps-6dccf606-0f00-4b53-9cb4-82c53b3cd05c to disappear
Oct 24 01:58:43.354: INFO: Pod pod-projected-configmaps-6dccf606-0f00-4b53-9cb4-82c53b3cd05c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:58:43.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8330" for this suite.
Oct 24 01:58:49.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:58:49.502: INFO: namespace projected-8330 deletion completed in 6.143149682s

• [SLOW TEST:8.274 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:58:49.502: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 01:58:49.558: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ae2f6948-4dc7-4d34-8731-46b36a5c7dc0" in namespace "downward-api-9479" to be "success or failure"
Oct 24 01:58:49.565: INFO: Pod "downwardapi-volume-ae2f6948-4dc7-4d34-8731-46b36a5c7dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.625764ms
Oct 24 01:58:51.570: INFO: Pod "downwardapi-volume-ae2f6948-4dc7-4d34-8731-46b36a5c7dc0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011369555s
STEP: Saw pod success
Oct 24 01:58:51.570: INFO: Pod "downwardapi-volume-ae2f6948-4dc7-4d34-8731-46b36a5c7dc0" satisfied condition "success or failure"
Oct 24 01:58:51.573: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-ae2f6948-4dc7-4d34-8731-46b36a5c7dc0 container client-container: <nil>
STEP: delete the pod
Oct 24 01:58:51.602: INFO: Waiting for pod downwardapi-volume-ae2f6948-4dc7-4d34-8731-46b36a5c7dc0 to disappear
Oct 24 01:58:51.607: INFO: Pod downwardapi-volume-ae2f6948-4dc7-4d34-8731-46b36a5c7dc0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:58:51.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9479" for this suite.
Oct 24 01:58:57.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:58:57.771: INFO: namespace downward-api-9479 deletion completed in 6.159657759s

• [SLOW TEST:8.269 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:58:57.772: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 24 01:59:00.885: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:59:01.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6421" for this suite.
Oct 24 01:59:29.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:59:30.056: INFO: namespace replicaset-6421 deletion completed in 28.147260579s

• [SLOW TEST:32.285 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:59:30.057: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct 24 01:59:30.114: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 24 01:59:37.156: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 01:59:37.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3977" for this suite.
Oct 24 01:59:43.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 01:59:43.314: INFO: namespace pods-3977 deletion completed in 6.147966612s

• [SLOW TEST:13.257 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 01:59:43.314: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7900
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 24 01:59:43.365: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 24 02:00:05.470: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.167 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7900 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 02:00:05.470: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 02:00:06.615: INFO: Found all expected endpoints: [netserver-0]
Oct 24 02:00:06.620: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.35 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7900 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 02:00:06.620: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 02:00:07.769: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:00:07.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7900" for this suite.
Oct 24 02:00:19.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:00:19.922: INFO: namespace pod-network-test-7900 deletion completed in 12.14724743s

• [SLOW TEST:36.608 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:00:19.923: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8115
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 24 02:00:19.970: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 24 02:00:42.069: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.170:8080/dial?request=hostName&protocol=http&host=10.244.2.36&port=8080&tries=1'] Namespace:pod-network-test-8115 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 02:00:42.069: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 02:00:42.236: INFO: Waiting for endpoints: map[]
Oct 24 02:00:42.240: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.170:8080/dial?request=hostName&protocol=http&host=10.244.1.169&port=8080&tries=1'] Namespace:pod-network-test-8115 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 02:00:42.240: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 02:00:42.390: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:00:42.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8115" for this suite.
Oct 24 02:00:54.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:00:54.544: INFO: namespace pod-network-test-8115 deletion completed in 12.14895796s

• [SLOW TEST:34.621 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:00:54.544: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:01:07.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8545" for this suite.
Oct 24 02:01:13.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:01:13.842: INFO: namespace resourcequota-8545 deletion completed in 6.152111915s

• [SLOW TEST:19.298 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:01:13.843: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 24 02:01:17.947: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 02:01:17.952: INFO: Pod pod-with-prestop-http-hook still exists
Oct 24 02:01:19.952: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 02:01:19.958: INFO: Pod pod-with-prestop-http-hook still exists
Oct 24 02:01:21.952: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 02:01:21.957: INFO: Pod pod-with-prestop-http-hook still exists
Oct 24 02:01:23.952: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 02:01:23.957: INFO: Pod pod-with-prestop-http-hook still exists
Oct 24 02:01:25.952: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 02:01:25.958: INFO: Pod pod-with-prestop-http-hook still exists
Oct 24 02:01:27.952: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 24 02:01:27.958: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:01:27.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4229" for this suite.
Oct 24 02:01:40.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:01:40.148: INFO: namespace container-lifecycle-hook-4229 deletion completed in 12.152634507s

• [SLOW TEST:26.305 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:01:40.149: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 02:01:40.956: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 24 02:01:42.970: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707479300, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707479300, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707479301, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707479300, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 02:01:45.990: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:01:46.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7980" for this suite.
Oct 24 02:01:58.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:01:58.352: INFO: namespace webhook-7980 deletion completed in 12.149756128s
STEP: Destroying namespace "webhook-7980-markers" for this suite.
Oct 24 02:02:04.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:02:04.490: INFO: namespace webhook-7980-markers deletion completed in 6.137954364s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.360 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:02:04.509: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-b4a78967-8cad-4aab-bd72-27a07a627e47
STEP: Creating a pod to test consume secrets
Oct 24 02:02:04.573: INFO: Waiting up to 5m0s for pod "pod-secrets-f2b58f31-ba12-4f51-ac70-bf4415b5d209" in namespace "secrets-9517" to be "success or failure"
Oct 24 02:02:04.579: INFO: Pod "pod-secrets-f2b58f31-ba12-4f51-ac70-bf4415b5d209": Phase="Pending", Reason="", readiness=false. Elapsed: 5.54146ms
Oct 24 02:02:06.583: INFO: Pod "pod-secrets-f2b58f31-ba12-4f51-ac70-bf4415b5d209": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010039113s
STEP: Saw pod success
Oct 24 02:02:06.583: INFO: Pod "pod-secrets-f2b58f31-ba12-4f51-ac70-bf4415b5d209" satisfied condition "success or failure"
Oct 24 02:02:06.590: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-f2b58f31-ba12-4f51-ac70-bf4415b5d209 container secret-env-test: <nil>
STEP: delete the pod
Oct 24 02:02:06.620: INFO: Waiting for pod pod-secrets-f2b58f31-ba12-4f51-ac70-bf4415b5d209 to disappear
Oct 24 02:02:06.625: INFO: Pod pod-secrets-f2b58f31-ba12-4f51-ac70-bf4415b5d209 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:02:06.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9517" for this suite.
Oct 24 02:02:12.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:02:12.790: INFO: namespace secrets-9517 deletion completed in 6.157505507s

• [SLOW TEST:8.281 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:02:12.790: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:02:15.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8170" for this suite.
Oct 24 02:02:43.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:02:44.041: INFO: namespace replication-controller-8170 deletion completed in 28.14489819s

• [SLOW TEST:31.250 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:02:44.041: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-a0199b01-1aa2-4625-a127-5f7b60b6cd55
STEP: Creating a pod to test consume configMaps
Oct 24 02:02:44.101: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f4f87fb-65d7-4f1e-b0c4-d98ab68021aa" in namespace "configmap-4159" to be "success or failure"
Oct 24 02:02:44.105: INFO: Pod "pod-configmaps-9f4f87fb-65d7-4f1e-b0c4-d98ab68021aa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026153ms
Oct 24 02:02:46.110: INFO: Pod "pod-configmaps-9f4f87fb-65d7-4f1e-b0c4-d98ab68021aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009423786s
STEP: Saw pod success
Oct 24 02:02:46.111: INFO: Pod "pod-configmaps-9f4f87fb-65d7-4f1e-b0c4-d98ab68021aa" satisfied condition "success or failure"
Oct 24 02:02:46.115: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-9f4f87fb-65d7-4f1e-b0c4-d98ab68021aa container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 02:02:46.142: INFO: Waiting for pod pod-configmaps-9f4f87fb-65d7-4f1e-b0c4-d98ab68021aa to disappear
Oct 24 02:02:46.149: INFO: Pod pod-configmaps-9f4f87fb-65d7-4f1e-b0c4-d98ab68021aa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:02:46.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4159" for this suite.
Oct 24 02:02:52.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:02:52.313: INFO: namespace configmap-4159 deletion completed in 6.15880084s

• [SLOW TEST:8.272 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:02:52.315: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:02:54.402: INFO: Waiting up to 5m0s for pod "client-envvars-35d3d0a4-9a4e-431b-89c7-92c6efcabd5b" in namespace "pods-6820" to be "success or failure"
Oct 24 02:02:54.411: INFO: Pod "client-envvars-35d3d0a4-9a4e-431b-89c7-92c6efcabd5b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.111083ms
Oct 24 02:02:56.416: INFO: Pod "client-envvars-35d3d0a4-9a4e-431b-89c7-92c6efcabd5b": Phase="Running", Reason="", readiness=true. Elapsed: 2.013670464s
Oct 24 02:02:58.421: INFO: Pod "client-envvars-35d3d0a4-9a4e-431b-89c7-92c6efcabd5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018613994s
STEP: Saw pod success
Oct 24 02:02:58.421: INFO: Pod "client-envvars-35d3d0a4-9a4e-431b-89c7-92c6efcabd5b" satisfied condition "success or failure"
Oct 24 02:02:58.424: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod client-envvars-35d3d0a4-9a4e-431b-89c7-92c6efcabd5b container env3cont: <nil>
STEP: delete the pod
Oct 24 02:02:58.451: INFO: Waiting for pod client-envvars-35d3d0a4-9a4e-431b-89c7-92c6efcabd5b to disappear
Oct 24 02:02:58.456: INFO: Pod client-envvars-35d3d0a4-9a4e-431b-89c7-92c6efcabd5b no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:02:58.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6820" for this suite.
Oct 24 02:03:10.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:03:10.612: INFO: namespace pods-6820 deletion completed in 12.151408762s

• [SLOW TEST:18.297 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:03:10.613: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:03:10.673: INFO: (0) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 8.451498ms)
Oct 24 02:03:10.679: INFO: (1) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.624743ms)
Oct 24 02:03:10.684: INFO: (2) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.129459ms)
Oct 24 02:03:10.689: INFO: (3) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.858061ms)
Oct 24 02:03:10.694: INFO: (4) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.981744ms)
Oct 24 02:03:10.699: INFO: (5) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.312531ms)
Oct 24 02:03:10.704: INFO: (6) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.212201ms)
Oct 24 02:03:10.710: INFO: (7) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.302938ms)
Oct 24 02:03:10.716: INFO: (8) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.859367ms)
Oct 24 02:03:10.721: INFO: (9) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.419958ms)
Oct 24 02:03:10.726: INFO: (10) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.189035ms)
Oct 24 02:03:10.732: INFO: (11) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.816181ms)
Oct 24 02:03:10.738: INFO: (12) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.473615ms)
Oct 24 02:03:10.744: INFO: (13) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 6.469055ms)
Oct 24 02:03:10.750: INFO: (14) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.844812ms)
Oct 24 02:03:10.755: INFO: (15) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.087776ms)
Oct 24 02:03:10.760: INFO: (16) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.006879ms)
Oct 24 02:03:10.766: INFO: (17) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.20267ms)
Oct 24 02:03:10.771: INFO: (18) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 5.133126ms)
Oct 24 02:03:10.776: INFO: (19) /api/v1/nodes/mip-bd-vm40.mip.storage.hpecorp.net/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="bluedata/">bluedata/... (200; 4.96975ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:03:10.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1376" for this suite.
Oct 24 02:03:16.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:03:16.922: INFO: namespace proxy-1376 deletion completed in 6.14168268s

• [SLOW TEST:6.310 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:03:16.923: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9920.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9920.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9920.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9920.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9920.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9920.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 24 02:03:19.041: INFO: DNS probes using dns-9920/dns-test-f4a61717-bff1-4880-9a8e-86717250f710 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:03:19.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9920" for this suite.
Oct 24 02:03:25.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:03:25.206: INFO: namespace dns-9920 deletion completed in 6.136825181s

• [SLOW TEST:8.283 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:03:25.206: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 02:03:25.258: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93e03ea0-a5f5-4799-8f03-ac477604e264" in namespace "downward-api-5245" to be "success or failure"
Oct 24 02:03:25.262: INFO: Pod "downwardapi-volume-93e03ea0-a5f5-4799-8f03-ac477604e264": Phase="Pending", Reason="", readiness=false. Elapsed: 4.430798ms
Oct 24 02:03:27.267: INFO: Pod "downwardapi-volume-93e03ea0-a5f5-4799-8f03-ac477604e264": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008965405s
STEP: Saw pod success
Oct 24 02:03:27.267: INFO: Pod "downwardapi-volume-93e03ea0-a5f5-4799-8f03-ac477604e264" satisfied condition "success or failure"
Oct 24 02:03:27.270: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-93e03ea0-a5f5-4799-8f03-ac477604e264 container client-container: <nil>
STEP: delete the pod
Oct 24 02:03:27.299: INFO: Waiting for pod downwardapi-volume-93e03ea0-a5f5-4799-8f03-ac477604e264 to disappear
Oct 24 02:03:27.302: INFO: Pod downwardapi-volume-93e03ea0-a5f5-4799-8f03-ac477604e264 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:03:27.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5245" for this suite.
Oct 24 02:03:33.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:03:33.455: INFO: namespace downward-api-5245 deletion completed in 6.147477317s

• [SLOW TEST:8.249 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:03:33.456: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-556b2184-1bad-497c-a9cc-c27f2d1fa5d2
STEP: Creating a pod to test consume configMaps
Oct 24 02:03:33.516: INFO: Waiting up to 5m0s for pod "pod-configmaps-0f43eaf4-4489-4948-b8c4-0c32bbade1d4" in namespace "configmap-102" to be "success or failure"
Oct 24 02:03:33.521: INFO: Pod "pod-configmaps-0f43eaf4-4489-4948-b8c4-0c32bbade1d4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.631581ms
Oct 24 02:03:35.529: INFO: Pod "pod-configmaps-0f43eaf4-4489-4948-b8c4-0c32bbade1d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012789313s
STEP: Saw pod success
Oct 24 02:03:35.529: INFO: Pod "pod-configmaps-0f43eaf4-4489-4948-b8c4-0c32bbade1d4" satisfied condition "success or failure"
Oct 24 02:03:35.533: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-0f43eaf4-4489-4948-b8c4-0c32bbade1d4 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 02:03:35.559: INFO: Waiting for pod pod-configmaps-0f43eaf4-4489-4948-b8c4-0c32bbade1d4 to disappear
Oct 24 02:03:35.569: INFO: Pod pod-configmaps-0f43eaf4-4489-4948-b8c4-0c32bbade1d4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:03:35.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-102" for this suite.
Oct 24 02:03:41.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:03:41.720: INFO: namespace configmap-102 deletion completed in 6.145696882s

• [SLOW TEST:8.265 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:03:41.721: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-a396409a-180c-41fb-8213-0d421f907af7 in namespace container-probe-6751
Oct 24 02:03:43.781: INFO: Started pod test-webserver-a396409a-180c-41fb-8213-0d421f907af7 in namespace container-probe-6751
STEP: checking the pod's current state and verifying that restartCount is present
Oct 24 02:03:43.785: INFO: Initial restart count of pod test-webserver-a396409a-180c-41fb-8213-0d421f907af7 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:07:44.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6751" for this suite.
Oct 24 02:07:50.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:07:50.588: INFO: namespace container-probe-6751 deletion completed in 6.153541674s

• [SLOW TEST:248.867 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:07:50.588: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-snjsj in namespace proxy-9883
I1024 02:07:50.654262      23 runners.go:184] Created replication controller with name: proxy-service-snjsj, namespace: proxy-9883, replica count: 1
I1024 02:07:51.705008      23 runners.go:184] proxy-service-snjsj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1024 02:07:52.705330      23 runners.go:184] proxy-service-snjsj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1024 02:07:53.705604      23 runners.go:184] proxy-service-snjsj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1024 02:07:54.706000      23 runners.go:184] proxy-service-snjsj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1024 02:07:55.706291      23 runners.go:184] proxy-service-snjsj Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 02:07:55.710: INFO: setup took 5.078112071s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 24 02:07:55.720: INFO: (0) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 9.535661ms)
Oct 24 02:07:55.720: INFO: (0) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 8.172094ms)
Oct 24 02:07:55.723: INFO: (0) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 9.990246ms)
Oct 24 02:07:55.725: INFO: (0) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 13.194429ms)
Oct 24 02:07:55.726: INFO: (0) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 13.377106ms)
Oct 24 02:07:55.726: INFO: (0) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 13.523063ms)
Oct 24 02:07:55.726: INFO: (0) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 13.344742ms)
Oct 24 02:07:55.728: INFO: (0) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 16.859027ms)
Oct 24 02:07:55.731: INFO: (0) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 19.18633ms)
Oct 24 02:07:55.731: INFO: (0) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 18.208764ms)
Oct 24 02:07:55.734: INFO: (0) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 23.266181ms)
Oct 24 02:07:55.734: INFO: (0) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 22.127542ms)
Oct 24 02:07:55.735: INFO: (0) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 22.119108ms)
Oct 24 02:07:55.735: INFO: (0) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 22.596889ms)
Oct 24 02:07:55.736: INFO: (0) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 23.339353ms)
Oct 24 02:07:55.741: INFO: (0) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 28.569592ms)
Oct 24 02:07:55.755: INFO: (1) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 13.086146ms)
Oct 24 02:07:55.755: INFO: (1) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 11.446815ms)
Oct 24 02:07:55.755: INFO: (1) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 12.774792ms)
Oct 24 02:07:55.756: INFO: (1) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 11.195096ms)
Oct 24 02:07:55.756: INFO: (1) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 13.66783ms)
Oct 24 02:07:55.757: INFO: (1) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 12.282841ms)
Oct 24 02:07:55.757: INFO: (1) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 13.897987ms)
Oct 24 02:07:55.757: INFO: (1) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 13.210172ms)
Oct 24 02:07:55.758: INFO: (1) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 16.528344ms)
Oct 24 02:07:55.758: INFO: (1) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 15.611261ms)
Oct 24 02:07:55.758: INFO: (1) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 15.172943ms)
Oct 24 02:07:55.760: INFO: (1) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 18.103619ms)
Oct 24 02:07:55.760: INFO: (1) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 15.126933ms)
Oct 24 02:07:55.760: INFO: (1) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 18.476724ms)
Oct 24 02:07:55.761: INFO: (1) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 16.713429ms)
Oct 24 02:07:55.761: INFO: (1) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 17.764989ms)
Oct 24 02:07:55.767: INFO: (2) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 6.395343ms)
Oct 24 02:07:55.769: INFO: (2) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 7.763076ms)
Oct 24 02:07:55.770: INFO: (2) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 8.215594ms)
Oct 24 02:07:55.773: INFO: (2) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 11.088081ms)
Oct 24 02:07:55.774: INFO: (2) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 12.77631ms)
Oct 24 02:07:55.775: INFO: (2) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 12.920424ms)
Oct 24 02:07:55.776: INFO: (2) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 14.73956ms)
Oct 24 02:07:55.777: INFO: (2) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 14.448219ms)
Oct 24 02:07:55.777: INFO: (2) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 14.383888ms)
Oct 24 02:07:55.777: INFO: (2) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 14.33749ms)
Oct 24 02:07:55.781: INFO: (2) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 18.980682ms)
Oct 24 02:07:55.782: INFO: (2) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 19.758073ms)
Oct 24 02:07:55.782: INFO: (2) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 19.535903ms)
Oct 24 02:07:55.782: INFO: (2) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 20.248022ms)
Oct 24 02:07:55.782: INFO: (2) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 20.618599ms)
Oct 24 02:07:55.785: INFO: (2) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 22.580599ms)
Oct 24 02:07:55.795: INFO: (3) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 10.40487ms)
Oct 24 02:07:55.796: INFO: (3) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 10.964632ms)
Oct 24 02:07:55.797: INFO: (3) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 10.868998ms)
Oct 24 02:07:55.797: INFO: (3) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 11.559819ms)
Oct 24 02:07:55.797: INFO: (3) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 11.685448ms)
Oct 24 02:07:55.797: INFO: (3) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 12.241847ms)
Oct 24 02:07:55.797: INFO: (3) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 12.170938ms)
Oct 24 02:07:55.798: INFO: (3) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 12.057743ms)
Oct 24 02:07:55.798: INFO: (3) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 12.612057ms)
Oct 24 02:07:55.798: INFO: (3) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 12.023353ms)
Oct 24 02:07:55.798: INFO: (3) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 12.536629ms)
Oct 24 02:07:55.799: INFO: (3) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 14.194271ms)
Oct 24 02:07:55.799: INFO: (3) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 14.172499ms)
Oct 24 02:07:55.800: INFO: (3) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 14.439039ms)
Oct 24 02:07:55.802: INFO: (3) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 16.463766ms)
Oct 24 02:07:55.802: INFO: (3) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 17.312968ms)
Oct 24 02:07:55.809: INFO: (4) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 6.728533ms)
Oct 24 02:07:55.809: INFO: (4) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 6.531457ms)
Oct 24 02:07:55.814: INFO: (4) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 10.564441ms)
Oct 24 02:07:55.815: INFO: (4) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 11.995537ms)
Oct 24 02:07:55.815: INFO: (4) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 12.194598ms)
Oct 24 02:07:55.816: INFO: (4) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 10.62405ms)
Oct 24 02:07:55.816: INFO: (4) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 12.239711ms)
Oct 24 02:07:55.816: INFO: (4) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 12.13811ms)
Oct 24 02:07:55.820: INFO: (4) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 16.879562ms)
Oct 24 02:07:55.820: INFO: (4) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 16.84046ms)
Oct 24 02:07:55.820: INFO: (4) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 15.662287ms)
Oct 24 02:07:55.821: INFO: (4) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 16.535153ms)
Oct 24 02:07:55.822: INFO: (4) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 17.496991ms)
Oct 24 02:07:55.822: INFO: (4) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 17.146612ms)
Oct 24 02:07:55.822: INFO: (4) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 18.695508ms)
Oct 24 02:07:55.822: INFO: (4) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 18.230304ms)
Oct 24 02:07:55.830: INFO: (5) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 6.685337ms)
Oct 24 02:07:55.831: INFO: (5) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 6.032659ms)
Oct 24 02:07:55.836: INFO: (5) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 12.390569ms)
Oct 24 02:07:55.836: INFO: (5) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 13.039899ms)
Oct 24 02:07:55.836: INFO: (5) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 12.143467ms)
Oct 24 02:07:55.838: INFO: (5) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 13.614983ms)
Oct 24 02:07:55.838: INFO: (5) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 15.408165ms)
Oct 24 02:07:55.839: INFO: (5) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 16.055282ms)
Oct 24 02:07:55.839: INFO: (5) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 14.548862ms)
Oct 24 02:07:55.840: INFO: (5) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 15.214227ms)
Oct 24 02:07:55.841: INFO: (5) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 15.792134ms)
Oct 24 02:07:55.841: INFO: (5) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 16.766414ms)
Oct 24 02:07:55.841: INFO: (5) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 18.5455ms)
Oct 24 02:07:55.841: INFO: (5) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 17.628784ms)
Oct 24 02:07:55.841: INFO: (5) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 18.214786ms)
Oct 24 02:07:55.842: INFO: (5) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 17.363827ms)
Oct 24 02:07:55.849: INFO: (6) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 7.053897ms)
Oct 24 02:07:55.853: INFO: (6) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 9.705979ms)
Oct 24 02:07:55.853: INFO: (6) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 10.470669ms)
Oct 24 02:07:55.853: INFO: (6) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 10.74404ms)
Oct 24 02:07:55.854: INFO: (6) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 10.386866ms)
Oct 24 02:07:55.854: INFO: (6) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 10.477924ms)
Oct 24 02:07:55.854: INFO: (6) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 11.474182ms)
Oct 24 02:07:55.855: INFO: (6) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 10.755874ms)
Oct 24 02:07:55.855: INFO: (6) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 12.591909ms)
Oct 24 02:07:55.856: INFO: (6) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 12.51468ms)
Oct 24 02:07:55.860: INFO: (6) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 16.122047ms)
Oct 24 02:07:55.860: INFO: (6) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 17.509302ms)
Oct 24 02:07:55.860: INFO: (6) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 17.714263ms)
Oct 24 02:07:55.860: INFO: (6) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 16.998126ms)
Oct 24 02:07:55.860: INFO: (6) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 16.701873ms)
Oct 24 02:07:55.860: INFO: (6) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 17.203631ms)
Oct 24 02:07:55.870: INFO: (7) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 8.997638ms)
Oct 24 02:07:55.873: INFO: (7) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 11.95948ms)
Oct 24 02:07:55.873: INFO: (7) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 12.339143ms)
Oct 24 02:07:55.874: INFO: (7) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 12.516079ms)
Oct 24 02:07:55.876: INFO: (7) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 15.147162ms)
Oct 24 02:07:55.876: INFO: (7) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 14.875231ms)
Oct 24 02:07:55.876: INFO: (7) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 14.953642ms)
Oct 24 02:07:55.876: INFO: (7) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 15.540025ms)
Oct 24 02:07:55.877: INFO: (7) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 15.689732ms)
Oct 24 02:07:55.877: INFO: (7) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 16.477095ms)
Oct 24 02:07:55.877: INFO: (7) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 15.765293ms)
Oct 24 02:07:55.877: INFO: (7) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 16.057548ms)
Oct 24 02:07:55.877: INFO: (7) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 16.41588ms)
Oct 24 02:07:55.877: INFO: (7) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 16.705784ms)
Oct 24 02:07:55.877: INFO: (7) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 16.65088ms)
Oct 24 02:07:55.877: INFO: (7) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 16.265129ms)
Oct 24 02:07:55.883: INFO: (8) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 5.898627ms)
Oct 24 02:07:55.888: INFO: (8) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 8.515929ms)
Oct 24 02:07:55.888: INFO: (8) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 9.950467ms)
Oct 24 02:07:55.889: INFO: (8) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 10.781617ms)
Oct 24 02:07:55.889: INFO: (8) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 9.088954ms)
Oct 24 02:07:55.889: INFO: (8) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 9.098488ms)
Oct 24 02:07:55.889: INFO: (8) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 9.740513ms)
Oct 24 02:07:55.889: INFO: (8) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 10.017002ms)
Oct 24 02:07:55.889: INFO: (8) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 9.754452ms)
Oct 24 02:07:55.889: INFO: (8) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 10.987859ms)
Oct 24 02:07:55.889: INFO: (8) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 11.690564ms)
Oct 24 02:07:55.896: INFO: (8) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 17.396727ms)
Oct 24 02:07:55.896: INFO: (8) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 17.207238ms)
Oct 24 02:07:55.896: INFO: (8) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 16.348902ms)
Oct 24 02:07:55.898: INFO: (8) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 18.20636ms)
Oct 24 02:07:55.898: INFO: (8) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 18.38152ms)
Oct 24 02:07:55.909: INFO: (9) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 10.889596ms)
Oct 24 02:07:55.909: INFO: (9) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 11.074631ms)
Oct 24 02:07:55.911: INFO: (9) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 12.710316ms)
Oct 24 02:07:55.911: INFO: (9) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 12.637837ms)
Oct 24 02:07:55.912: INFO: (9) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 13.607948ms)
Oct 24 02:07:55.912: INFO: (9) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 13.504585ms)
Oct 24 02:07:55.912: INFO: (9) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 14.101173ms)
Oct 24 02:07:55.913: INFO: (9) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 13.755285ms)
Oct 24 02:07:55.913: INFO: (9) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 14.028576ms)
Oct 24 02:07:55.913: INFO: (9) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 14.113007ms)
Oct 24 02:07:55.916: INFO: (9) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 17.554228ms)
Oct 24 02:07:55.916: INFO: (9) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 17.507096ms)
Oct 24 02:07:55.916: INFO: (9) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 17.693252ms)
Oct 24 02:07:55.917: INFO: (9) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 18.465878ms)
Oct 24 02:07:55.917: INFO: (9) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 18.083221ms)
Oct 24 02:07:55.918: INFO: (9) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 18.856661ms)
Oct 24 02:07:55.926: INFO: (10) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 8.371812ms)
Oct 24 02:07:55.927: INFO: (10) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 8.906118ms)
Oct 24 02:07:55.929: INFO: (10) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 9.828255ms)
Oct 24 02:07:55.929: INFO: (10) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 9.206591ms)
Oct 24 02:07:55.929: INFO: (10) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 9.349376ms)
Oct 24 02:07:55.931: INFO: (10) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 11.297228ms)
Oct 24 02:07:55.931: INFO: (10) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 13.125441ms)
Oct 24 02:07:55.932: INFO: (10) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 12.211011ms)
Oct 24 02:07:55.932: INFO: (10) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 13.776476ms)
Oct 24 02:07:55.932: INFO: (10) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 12.993909ms)
Oct 24 02:07:55.932: INFO: (10) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 13.638252ms)
Oct 24 02:07:55.932: INFO: (10) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 12.264146ms)
Oct 24 02:07:55.932: INFO: (10) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 13.290519ms)
Oct 24 02:07:55.932: INFO: (10) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 13.643142ms)
Oct 24 02:07:55.932: INFO: (10) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 12.599545ms)
Oct 24 02:07:55.934: INFO: (10) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 16.388823ms)
Oct 24 02:07:55.945: INFO: (11) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 10.02634ms)
Oct 24 02:07:55.945: INFO: (11) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 10.48883ms)
Oct 24 02:07:55.945: INFO: (11) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 10.70311ms)
Oct 24 02:07:55.945: INFO: (11) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 10.607201ms)
Oct 24 02:07:55.945: INFO: (11) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 10.961076ms)
Oct 24 02:07:55.946: INFO: (11) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 11.010819ms)
Oct 24 02:07:55.946: INFO: (11) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 11.278623ms)
Oct 24 02:07:55.946: INFO: (11) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 11.75042ms)
Oct 24 02:07:55.947: INFO: (11) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 12.543654ms)
Oct 24 02:07:55.949: INFO: (11) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 14.256443ms)
Oct 24 02:07:55.951: INFO: (11) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 15.812635ms)
Oct 24 02:07:55.951: INFO: (11) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 16.684602ms)
Oct 24 02:07:55.951: INFO: (11) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 16.270302ms)
Oct 24 02:07:55.954: INFO: (11) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 19.331479ms)
Oct 24 02:07:55.954: INFO: (11) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 18.888832ms)
Oct 24 02:07:55.954: INFO: (11) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 19.141589ms)
Oct 24 02:07:55.963: INFO: (12) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 9.359437ms)
Oct 24 02:07:55.965: INFO: (12) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 11.025083ms)
Oct 24 02:07:55.967: INFO: (12) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 12.814315ms)
Oct 24 02:07:55.968: INFO: (12) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 13.875808ms)
Oct 24 02:07:55.968: INFO: (12) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 13.541411ms)
Oct 24 02:07:55.968: INFO: (12) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 13.48399ms)
Oct 24 02:07:55.968: INFO: (12) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 13.496768ms)
Oct 24 02:07:55.968: INFO: (12) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 13.913356ms)
Oct 24 02:07:55.968: INFO: (12) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 13.780078ms)
Oct 24 02:07:55.968: INFO: (12) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 14.158236ms)
Oct 24 02:07:55.973: INFO: (12) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 18.326416ms)
Oct 24 02:07:55.973: INFO: (12) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 18.12866ms)
Oct 24 02:07:55.973: INFO: (12) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 18.086334ms)
Oct 24 02:07:55.973: INFO: (12) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 18.978646ms)
Oct 24 02:07:55.973: INFO: (12) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 18.404667ms)
Oct 24 02:07:55.973: INFO: (12) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 18.358514ms)
Oct 24 02:07:55.978: INFO: (13) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 4.65368ms)
Oct 24 02:07:55.984: INFO: (13) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 9.496877ms)
Oct 24 02:07:55.984: INFO: (13) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 10.661217ms)
Oct 24 02:07:55.984: INFO: (13) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 10.95481ms)
Oct 24 02:07:55.984: INFO: (13) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 10.084649ms)
Oct 24 02:07:55.985: INFO: (13) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 10.987803ms)
Oct 24 02:07:55.985: INFO: (13) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 9.897172ms)
Oct 24 02:07:55.988: INFO: (13) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 12.232239ms)
Oct 24 02:07:55.989: INFO: (13) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 14.487378ms)
Oct 24 02:07:55.989: INFO: (13) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 14.709319ms)
Oct 24 02:07:55.989: INFO: (13) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 13.713974ms)
Oct 24 02:07:55.989: INFO: (13) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 14.056174ms)
Oct 24 02:07:55.989: INFO: (13) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 13.27923ms)
Oct 24 02:07:55.991: INFO: (13) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 14.81395ms)
Oct 24 02:07:55.993: INFO: (13) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 17.92392ms)
Oct 24 02:07:55.993: INFO: (13) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 18.323276ms)
Oct 24 02:07:56.008: INFO: (14) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 12.366027ms)
Oct 24 02:07:56.009: INFO: (14) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 15.444301ms)
Oct 24 02:07:56.009: INFO: (14) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 13.669589ms)
Oct 24 02:07:56.010: INFO: (14) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 14.370408ms)
Oct 24 02:07:56.010: INFO: (14) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 15.024934ms)
Oct 24 02:07:56.011: INFO: (14) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 16.53858ms)
Oct 24 02:07:56.011: INFO: (14) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 17.154291ms)
Oct 24 02:07:56.014: INFO: (14) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 18.408624ms)
Oct 24 02:07:56.014: INFO: (14) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 20.542497ms)
Oct 24 02:07:56.014: INFO: (14) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 18.588617ms)
Oct 24 02:07:56.015: INFO: (14) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 20.762405ms)
Oct 24 02:07:56.015: INFO: (14) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 20.257256ms)
Oct 24 02:07:56.015: INFO: (14) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 20.306382ms)
Oct 24 02:07:56.016: INFO: (14) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 22.156632ms)
Oct 24 02:07:56.016: INFO: (14) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 21.167261ms)
Oct 24 02:07:56.017: INFO: (14) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 22.626633ms)
Oct 24 02:07:56.022: INFO: (15) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 5.166788ms)
Oct 24 02:07:56.026: INFO: (15) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 9.739819ms)
Oct 24 02:07:56.029: INFO: (15) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 11.735065ms)
Oct 24 02:07:56.029: INFO: (15) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 12.065913ms)
Oct 24 02:07:56.029: INFO: (15) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 11.766426ms)
Oct 24 02:07:56.029: INFO: (15) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 12.36522ms)
Oct 24 02:07:56.029: INFO: (15) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 12.280316ms)
Oct 24 02:07:56.030: INFO: (15) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 13.006016ms)
Oct 24 02:07:56.033: INFO: (15) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 16.174798ms)
Oct 24 02:07:56.034: INFO: (15) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 16.755134ms)
Oct 24 02:07:56.035: INFO: (15) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 17.570352ms)
Oct 24 02:07:56.035: INFO: (15) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 17.649913ms)
Oct 24 02:07:56.036: INFO: (15) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 18.930527ms)
Oct 24 02:07:56.036: INFO: (15) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 18.952739ms)
Oct 24 02:07:56.036: INFO: (15) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 19.227698ms)
Oct 24 02:07:56.036: INFO: (15) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 19.574721ms)
Oct 24 02:07:56.048: INFO: (16) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 9.668138ms)
Oct 24 02:07:56.048: INFO: (16) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 8.882801ms)
Oct 24 02:07:56.048: INFO: (16) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 11.569189ms)
Oct 24 02:07:56.049: INFO: (16) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 9.416206ms)
Oct 24 02:07:56.050: INFO: (16) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 10.712726ms)
Oct 24 02:07:56.050: INFO: (16) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 10.244357ms)
Oct 24 02:07:56.051: INFO: (16) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 11.422801ms)
Oct 24 02:07:56.051: INFO: (16) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 12.623176ms)
Oct 24 02:07:56.051: INFO: (16) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 12.64089ms)
Oct 24 02:07:56.053: INFO: (16) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 16.092018ms)
Oct 24 02:07:56.055: INFO: (16) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 17.390198ms)
Oct 24 02:07:56.055: INFO: (16) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 17.963949ms)
Oct 24 02:07:56.055: INFO: (16) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 16.615069ms)
Oct 24 02:07:56.057: INFO: (16) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 18.911381ms)
Oct 24 02:07:56.060: INFO: (16) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 22.242892ms)
Oct 24 02:07:56.060: INFO: (16) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 20.190024ms)
Oct 24 02:07:56.075: INFO: (17) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 14.385258ms)
Oct 24 02:07:56.076: INFO: (17) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 14.870896ms)
Oct 24 02:07:56.076: INFO: (17) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 14.735936ms)
Oct 24 02:07:56.076: INFO: (17) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 15.241849ms)
Oct 24 02:07:56.077: INFO: (17) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 16.718826ms)
Oct 24 02:07:56.077: INFO: (17) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 15.816502ms)
Oct 24 02:07:56.077: INFO: (17) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 16.354559ms)
Oct 24 02:07:56.077: INFO: (17) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 16.054355ms)
Oct 24 02:07:56.077: INFO: (17) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 17.013323ms)
Oct 24 02:07:56.079: INFO: (17) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 17.983101ms)
Oct 24 02:07:56.079: INFO: (17) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 17.724472ms)
Oct 24 02:07:56.081: INFO: (17) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 20.252193ms)
Oct 24 02:07:56.081: INFO: (17) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 20.391235ms)
Oct 24 02:07:56.081: INFO: (17) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 20.266659ms)
Oct 24 02:07:56.081: INFO: (17) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 20.344921ms)
Oct 24 02:07:56.083: INFO: (17) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 21.865798ms)
Oct 24 02:07:56.096: INFO: (18) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 10.857758ms)
Oct 24 02:07:56.096: INFO: (18) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 12.042265ms)
Oct 24 02:07:56.097: INFO: (18) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 11.009358ms)
Oct 24 02:07:56.097: INFO: (18) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 11.716795ms)
Oct 24 02:07:56.097: INFO: (18) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 13.08968ms)
Oct 24 02:07:56.097: INFO: (18) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 12.501611ms)
Oct 24 02:07:56.097: INFO: (18) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 14.169246ms)
Oct 24 02:07:56.098: INFO: (18) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 14.681602ms)
Oct 24 02:07:56.098: INFO: (18) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 14.892263ms)
Oct 24 02:07:56.098: INFO: (18) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 14.361836ms)
Oct 24 02:07:56.099: INFO: (18) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 13.444732ms)
Oct 24 02:07:56.107: INFO: (18) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 23.18701ms)
Oct 24 02:07:56.107: INFO: (18) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 22.286829ms)
Oct 24 02:07:56.108: INFO: (18) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 23.660783ms)
Oct 24 02:07:56.108: INFO: (18) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 22.923842ms)
Oct 24 02:07:56.119: INFO: (18) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 35.253637ms)
Oct 24 02:07:56.130: INFO: (19) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 10.548232ms)
Oct 24 02:07:56.130: INFO: (19) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 10.48899ms)
Oct 24 02:07:56.135: INFO: (19) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">... (200; 15.404972ms)
Oct 24 02:07:56.135: INFO: (19) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:162/proxy/: bar (200; 15.684244ms)
Oct 24 02:07:56.136: INFO: (19) /api/v1/namespaces/proxy-9883/pods/http:proxy-service-snjsj-pbdj6:160/proxy/: foo (200; 16.284027ms)
Oct 24 02:07:56.137: INFO: (19) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname2/proxy/: bar (200; 17.170422ms)
Oct 24 02:07:56.137: INFO: (19) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:462/proxy/: tls qux (200; 17.233749ms)
Oct 24 02:07:56.137: INFO: (19) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6/proxy/rewriteme">test</a> (200; 17.331225ms)
Oct 24 02:07:56.137: INFO: (19) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:460/proxy/: tls baz (200; 17.371279ms)
Oct 24 02:07:56.138: INFO: (19) /api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/proxy-service-snjsj-pbdj6:1080/proxy/rewriteme">test<... (200; 18.211165ms)
Oct 24 02:07:56.139: INFO: (19) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname1/proxy/: tls baz (200; 18.994765ms)
Oct 24 02:07:56.139: INFO: (19) /api/v1/namespaces/proxy-9883/services/proxy-service-snjsj:portname1/proxy/: foo (200; 19.286597ms)
Oct 24 02:07:56.140: INFO: (19) /api/v1/namespaces/proxy-9883/services/https:proxy-service-snjsj:tlsportname2/proxy/: tls qux (200; 19.921363ms)
Oct 24 02:07:56.140: INFO: (19) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname2/proxy/: bar (200; 19.983935ms)
Oct 24 02:07:56.140: INFO: (19) /api/v1/namespaces/proxy-9883/services/http:proxy-service-snjsj:portname1/proxy/: foo (200; 20.264761ms)
Oct 24 02:07:56.141: INFO: (19) /api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/: <a href="/api/v1/namespaces/proxy-9883/pods/https:proxy-service-snjsj-pbdj6:443/proxy/tlsrewritem... (200; 21.415772ms)
STEP: deleting ReplicationController proxy-service-snjsj in namespace proxy-9883, will wait for the garbage collector to delete the pods
Oct 24 02:07:56.204: INFO: Deleting ReplicationController proxy-service-snjsj took: 9.27271ms
Oct 24 02:07:56.605: INFO: Terminating ReplicationController proxy-service-snjsj pods took: 400.837157ms
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:08:07.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9883" for this suite.
Oct 24 02:08:19.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:08:19.454: INFO: namespace proxy-9883 deletion completed in 12.142034728s

• [SLOW TEST:28.866 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:08:19.455: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 02:08:19.509: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ab703cf-6952-4192-ade0-ebb8dc709948" in namespace "downward-api-8484" to be "success or failure"
Oct 24 02:08:19.515: INFO: Pod "downwardapi-volume-1ab703cf-6952-4192-ade0-ebb8dc709948": Phase="Pending", Reason="", readiness=false. Elapsed: 5.604446ms
Oct 24 02:08:21.519: INFO: Pod "downwardapi-volume-1ab703cf-6952-4192-ade0-ebb8dc709948": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009790708s
STEP: Saw pod success
Oct 24 02:08:21.519: INFO: Pod "downwardapi-volume-1ab703cf-6952-4192-ade0-ebb8dc709948" satisfied condition "success or failure"
Oct 24 02:08:21.522: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-1ab703cf-6952-4192-ade0-ebb8dc709948 container client-container: <nil>
STEP: delete the pod
Oct 24 02:08:21.580: INFO: Waiting for pod downwardapi-volume-1ab703cf-6952-4192-ade0-ebb8dc709948 to disappear
Oct 24 02:08:21.584: INFO: Pod downwardapi-volume-1ab703cf-6952-4192-ade0-ebb8dc709948 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:08:21.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8484" for this suite.
Oct 24 02:08:27.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:08:27.752: INFO: namespace downward-api-8484 deletion completed in 6.163471346s

• [SLOW TEST:8.297 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:08:27.753: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct 24 02:08:27.814: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:08:30.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7090" for this suite.
Oct 24 02:08:36.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:08:36.780: INFO: namespace init-container-7090 deletion completed in 6.172263139s

• [SLOW TEST:9.027 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:08:36.781: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct 24 02:08:39.877: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:08:39.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-611" for this suite.
Oct 24 02:08:45.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:08:46.053: INFO: namespace container-runtime-611 deletion completed in 6.151603438s

• [SLOW TEST:9.272 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:08:46.053: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 02:08:46.114: INFO: Waiting up to 5m0s for pod "downwardapi-volume-059b0a73-3fbd-4797-adc2-99c9556ca52c" in namespace "projected-4815" to be "success or failure"
Oct 24 02:08:46.118: INFO: Pod "downwardapi-volume-059b0a73-3fbd-4797-adc2-99c9556ca52c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.409168ms
Oct 24 02:08:48.123: INFO: Pod "downwardapi-volume-059b0a73-3fbd-4797-adc2-99c9556ca52c": Phase="Running", Reason="", readiness=true. Elapsed: 2.008679286s
Oct 24 02:08:50.128: INFO: Pod "downwardapi-volume-059b0a73-3fbd-4797-adc2-99c9556ca52c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014250017s
STEP: Saw pod success
Oct 24 02:08:50.128: INFO: Pod "downwardapi-volume-059b0a73-3fbd-4797-adc2-99c9556ca52c" satisfied condition "success or failure"
Oct 24 02:08:50.132: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-059b0a73-3fbd-4797-adc2-99c9556ca52c container client-container: <nil>
STEP: delete the pod
Oct 24 02:08:50.159: INFO: Waiting for pod downwardapi-volume-059b0a73-3fbd-4797-adc2-99c9556ca52c to disappear
Oct 24 02:08:50.163: INFO: Pod downwardapi-volume-059b0a73-3fbd-4797-adc2-99c9556ca52c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:08:50.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4815" for this suite.
Oct 24 02:08:56.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:08:56.317: INFO: namespace projected-4815 deletion completed in 6.148591473s

• [SLOW TEST:10.265 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:08:56.318: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-7786
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7786 to expose endpoints map[]
Oct 24 02:08:56.379: INFO: Get endpoints failed (3.676681ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Oct 24 02:08:57.384: INFO: successfully validated that service multi-endpoint-test in namespace services-7786 exposes endpoints map[] (1.009207936s elapsed)
STEP: Creating pod pod1 in namespace services-7786
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7786 to expose endpoints map[pod1:[100]]
Oct 24 02:08:59.426: INFO: successfully validated that service multi-endpoint-test in namespace services-7786 exposes endpoints map[pod1:[100]] (2.032783303s elapsed)
STEP: Creating pod pod2 in namespace services-7786
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7786 to expose endpoints map[pod1:[100] pod2:[101]]
Oct 24 02:09:01.480: INFO: successfully validated that service multi-endpoint-test in namespace services-7786 exposes endpoints map[pod1:[100] pod2:[101]] (2.047561781s elapsed)
STEP: Deleting pod pod1 in namespace services-7786
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7786 to expose endpoints map[pod2:[101]]
Oct 24 02:09:02.504: INFO: successfully validated that service multi-endpoint-test in namespace services-7786 exposes endpoints map[pod2:[101]] (1.017317109s elapsed)
STEP: Deleting pod pod2 in namespace services-7786
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7786 to expose endpoints map[]
Oct 24 02:09:03.521: INFO: successfully validated that service multi-endpoint-test in namespace services-7786 exposes endpoints map[] (1.01034959s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:09:03.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7786" for this suite.
Oct 24 02:09:31.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:09:31.714: INFO: namespace services-7786 deletion completed in 28.157071828s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:35.396 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:09:31.715: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct 24 02:09:31.768: INFO: PodSpec: initContainers in spec.initContainers
Oct 24 02:10:13.824: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-cda10b50-a59b-43d7-9c7f-a01608d0bfd6", GenerateName:"", Namespace:"init-container-1400", SelfLink:"/api/v1/namespaces/init-container-1400/pods/pod-init-cda10b50-a59b-43d7-9c7f-a01608d0bfd6", UID:"c580f9e2-89e7-4dbc-ae62-eb4b319cce3a", ResourceVersion:"20142", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63707479771, loc:(*time.Location)(0x84c02a0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"768493064"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.244.1.188/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-ghhtx", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00492c580), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ghhtx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ghhtx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-ghhtx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc006db2398), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"mip-bd-vm40.mip.storage.hpecorp.net", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0032412c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006db2410)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006db2430)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc006db2438), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc006db243c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707479771, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707479771, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707479771, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707479771, loc:(*time.Location)(0x84c02a0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"16.143.20.137", PodIP:"10.244.1.188", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.1.188"}}, StartTime:(*v1.Time)(0xc00341b140), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00354c380)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00354c3f0)}, Ready:false, RestartCount:3, Image:"docker.io/busybox:1.29", ImageID:"docker-pullable://docker.io/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://553d83b865a03963a746f24c3029e03bfcb4a4801922130e55108d6ce5781f6c", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00341b180), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00341b160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc006db24bf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:10:13.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1400" for this suite.
Oct 24 02:10:41.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:10:41.993: INFO: namespace init-container-1400 deletion completed in 28.162296634s

• [SLOW TEST:70.278 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:10:41.993: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 24 02:10:46.123: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 24 02:10:46.127: INFO: Pod pod-with-poststart-http-hook still exists
Oct 24 02:10:48.127: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 24 02:10:48.132: INFO: Pod pod-with-poststart-http-hook still exists
Oct 24 02:10:50.127: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 24 02:10:50.133: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:10:50.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1813" for this suite.
Oct 24 02:11:02.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:11:02.289: INFO: namespace container-lifecycle-hook-1813 deletion completed in 12.151315881s

• [SLOW TEST:20.296 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:11:02.291: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct 24 02:11:02.348: INFO: Waiting up to 5m0s for pod "downward-api-39100ccb-8f12-4466-b604-a1861f8597e2" in namespace "downward-api-8670" to be "success or failure"
Oct 24 02:11:02.357: INFO: Pod "downward-api-39100ccb-8f12-4466-b604-a1861f8597e2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.703663ms
Oct 24 02:11:04.362: INFO: Pod "downward-api-39100ccb-8f12-4466-b604-a1861f8597e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014092347s
STEP: Saw pod success
Oct 24 02:11:04.362: INFO: Pod "downward-api-39100ccb-8f12-4466-b604-a1861f8597e2" satisfied condition "success or failure"
Oct 24 02:11:04.366: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downward-api-39100ccb-8f12-4466-b604-a1861f8597e2 container dapi-container: <nil>
STEP: delete the pod
Oct 24 02:11:04.419: INFO: Waiting for pod downward-api-39100ccb-8f12-4466-b604-a1861f8597e2 to disappear
Oct 24 02:11:04.422: INFO: Pod downward-api-39100ccb-8f12-4466-b604-a1861f8597e2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:11:04.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8670" for this suite.
Oct 24 02:11:10.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:11:10.575: INFO: namespace downward-api-8670 deletion completed in 6.14792777s

• [SLOW TEST:8.284 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:11:10.575: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-9257
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9257
STEP: Deleting pre-stop pod
Oct 24 02:11:19.671: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:11:19.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9257" for this suite.
Oct 24 02:12:03.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:12:03.823: INFO: namespace prestop-9257 deletion completed in 44.14004235s

• [SLOW TEST:53.248 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:12:03.824: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:12:05.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-530" for this suite.
Oct 24 02:12:49.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:12:50.070: INFO: namespace kubelet-test-530 deletion completed in 44.151848995s

• [SLOW TEST:46.246 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:12:50.070: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2275
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-2275
Oct 24 02:12:50.142: INFO: Found 0 stateful pods, waiting for 1
Oct 24 02:13:00.148: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 24 02:13:00.181: INFO: Deleting all statefulset in ns statefulset-2275
Oct 24 02:13:00.185: INFO: Scaling statefulset ss to 0
Oct 24 02:13:10.216: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 02:13:10.223: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:13:10.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2275" for this suite.
Oct 24 02:13:22.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:13:22.401: INFO: namespace statefulset-2275 deletion completed in 12.154179122s

• [SLOW TEST:32.331 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:13:22.401: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 02:13:22.459: INFO: Waiting up to 5m0s for pod "downwardapi-volume-797d86a9-388d-4d10-aa4b-196566cd2ace" in namespace "downward-api-5156" to be "success or failure"
Oct 24 02:13:22.469: INFO: Pod "downwardapi-volume-797d86a9-388d-4d10-aa4b-196566cd2ace": Phase="Pending", Reason="", readiness=false. Elapsed: 10.18676ms
Oct 24 02:13:24.475: INFO: Pod "downwardapi-volume-797d86a9-388d-4d10-aa4b-196566cd2ace": Phase="Running", Reason="", readiness=true. Elapsed: 2.015837768s
Oct 24 02:13:26.480: INFO: Pod "downwardapi-volume-797d86a9-388d-4d10-aa4b-196566cd2ace": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021260997s
STEP: Saw pod success
Oct 24 02:13:26.480: INFO: Pod "downwardapi-volume-797d86a9-388d-4d10-aa4b-196566cd2ace" satisfied condition "success or failure"
Oct 24 02:13:26.485: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-797d86a9-388d-4d10-aa4b-196566cd2ace container client-container: <nil>
STEP: delete the pod
Oct 24 02:13:26.522: INFO: Waiting for pod downwardapi-volume-797d86a9-388d-4d10-aa4b-196566cd2ace to disappear
Oct 24 02:13:26.525: INFO: Pod downwardapi-volume-797d86a9-388d-4d10-aa4b-196566cd2ace no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:13:26.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5156" for this suite.
Oct 24 02:13:32.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:13:32.693: INFO: namespace downward-api-5156 deletion completed in 6.163072426s

• [SLOW TEST:10.292 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:13:32.694: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:13:32.739: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:13:34.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6023" for this suite.
Oct 24 02:14:18.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:14:18.942: INFO: namespace pods-6023 deletion completed in 44.14809308s

• [SLOW TEST:46.248 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:14:18.942: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7564
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-7564
I1024 02:14:19.044409      23 runners.go:184] Created replication controller with name: externalname-service, namespace: services-7564, replica count: 2
Oct 24 02:14:22.095: INFO: Creating new exec pod
I1024 02:14:22.095103      23 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 02:14:25.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-7564 execpod8cfwt -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Oct 24 02:14:25.593: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct 24 02:14:25.593: INFO: stdout: ""
Oct 24 02:14:25.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-7564 execpod8cfwt -- /bin/sh -x -c nc -zv -t -w 2 10.96.76.160 80'
Oct 24 02:14:25.966: INFO: stderr: "+ nc -zv -t -w 2 10.96.76.160 80\nConnection to 10.96.76.160 80 port [tcp/http] succeeded!\n"
Oct 24 02:14:25.966: INFO: stdout: ""
Oct 24 02:14:25.966: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:14:25.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7564" for this suite.
Oct 24 02:14:32.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:14:32.140: INFO: namespace services-7564 deletion completed in 6.138043599s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.198 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:14:32.140: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Oct 24 02:14:32.201: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-39" to be "success or failure"
Oct 24 02:14:32.205: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.484502ms
Oct 24 02:14:34.210: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009607701s
STEP: Saw pod success
Oct 24 02:14:34.210: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 24 02:14:34.214: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 24 02:14:34.245: INFO: Waiting for pod pod-host-path-test to disappear
Oct 24 02:14:34.251: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:14:34.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-39" for this suite.
Oct 24 02:14:40.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:14:40.409: INFO: namespace hostpath-39 deletion completed in 6.153267266s

• [SLOW TEST:8.269 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:14:40.409: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 02:14:40.466: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a672b069-f45f-44e4-a7b0-a20a55ed7256" in namespace "projected-1465" to be "success or failure"
Oct 24 02:14:40.470: INFO: Pod "downwardapi-volume-a672b069-f45f-44e4-a7b0-a20a55ed7256": Phase="Pending", Reason="", readiness=false. Elapsed: 4.323303ms
Oct 24 02:14:42.476: INFO: Pod "downwardapi-volume-a672b069-f45f-44e4-a7b0-a20a55ed7256": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009443777s
STEP: Saw pod success
Oct 24 02:14:42.476: INFO: Pod "downwardapi-volume-a672b069-f45f-44e4-a7b0-a20a55ed7256" satisfied condition "success or failure"
Oct 24 02:14:42.479: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-a672b069-f45f-44e4-a7b0-a20a55ed7256 container client-container: <nil>
STEP: delete the pod
Oct 24 02:14:42.509: INFO: Waiting for pod downwardapi-volume-a672b069-f45f-44e4-a7b0-a20a55ed7256 to disappear
Oct 24 02:14:42.513: INFO: Pod downwardapi-volume-a672b069-f45f-44e4-a7b0-a20a55ed7256 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:14:42.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1465" for this suite.
Oct 24 02:14:48.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:14:48.687: INFO: namespace projected-1465 deletion completed in 6.168382827s

• [SLOW TEST:8.277 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:14:48.687: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-681970e2-1f83-4b13-9327-8932610f2d7d in namespace container-probe-5669
Oct 24 02:14:50.753: INFO: Started pod busybox-681970e2-1f83-4b13-9327-8932610f2d7d in namespace container-probe-5669
STEP: checking the pod's current state and verifying that restartCount is present
Oct 24 02:14:50.757: INFO: Initial restart count of pod busybox-681970e2-1f83-4b13-9327-8932610f2d7d is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:18:51.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5669" for this suite.
Oct 24 02:18:57.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:18:57.606: INFO: namespace container-probe-5669 deletion completed in 6.160588006s

• [SLOW TEST:248.919 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:18:57.607: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 24 02:18:57.664: INFO: Waiting up to 5m0s for pod "pod-89f385f3-ffbc-49cb-b28c-f6edf9b60983" in namespace "emptydir-2807" to be "success or failure"
Oct 24 02:18:57.674: INFO: Pod "pod-89f385f3-ffbc-49cb-b28c-f6edf9b60983": Phase="Pending", Reason="", readiness=false. Elapsed: 9.58258ms
Oct 24 02:18:59.679: INFO: Pod "pod-89f385f3-ffbc-49cb-b28c-f6edf9b60983": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015029688s
STEP: Saw pod success
Oct 24 02:18:59.679: INFO: Pod "pod-89f385f3-ffbc-49cb-b28c-f6edf9b60983" satisfied condition "success or failure"
Oct 24 02:18:59.683: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-89f385f3-ffbc-49cb-b28c-f6edf9b60983 container test-container: <nil>
STEP: delete the pod
Oct 24 02:18:59.732: INFO: Waiting for pod pod-89f385f3-ffbc-49cb-b28c-f6edf9b60983 to disappear
Oct 24 02:18:59.735: INFO: Pod pod-89f385f3-ffbc-49cb-b28c-f6edf9b60983 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:18:59.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2807" for this suite.
Oct 24 02:19:05.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:19:05.916: INFO: namespace emptydir-2807 deletion completed in 6.176724125s

• [SLOW TEST:8.309 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:19:05.917: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-909793f1-1567-4c01-b684-fe77c23e1118
STEP: Creating a pod to test consume configMaps
Oct 24 02:19:05.989: INFO: Waiting up to 5m0s for pod "pod-configmaps-60bc8566-eb20-4d14-a08f-848852eb9f7e" in namespace "configmap-283" to be "success or failure"
Oct 24 02:19:05.999: INFO: Pod "pod-configmaps-60bc8566-eb20-4d14-a08f-848852eb9f7e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.779314ms
Oct 24 02:19:08.004: INFO: Pod "pod-configmaps-60bc8566-eb20-4d14-a08f-848852eb9f7e": Phase="Running", Reason="", readiness=true. Elapsed: 2.014932448s
Oct 24 02:19:10.010: INFO: Pod "pod-configmaps-60bc8566-eb20-4d14-a08f-848852eb9f7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021016453s
STEP: Saw pod success
Oct 24 02:19:10.010: INFO: Pod "pod-configmaps-60bc8566-eb20-4d14-a08f-848852eb9f7e" satisfied condition "success or failure"
Oct 24 02:19:10.014: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-60bc8566-eb20-4d14-a08f-848852eb9f7e container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 02:19:10.042: INFO: Waiting for pod pod-configmaps-60bc8566-eb20-4d14-a08f-848852eb9f7e to disappear
Oct 24 02:19:10.046: INFO: Pod pod-configmaps-60bc8566-eb20-4d14-a08f-848852eb9f7e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:19:10.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-283" for this suite.
Oct 24 02:19:16.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:19:16.208: INFO: namespace configmap-283 deletion completed in 6.156668435s

• [SLOW TEST:10.291 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:19:16.208: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:19:16.259: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct 24 02:19:20.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-9344 create -f -'
Oct 24 02:19:21.360: INFO: stderr: ""
Oct 24 02:19:21.360: INFO: stdout: "e2e-test-crd-publish-openapi-8156-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct 24 02:19:21.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-9344 delete e2e-test-crd-publish-openapi-8156-crds test-cr'
Oct 24 02:19:21.538: INFO: stderr: ""
Oct 24 02:19:21.538: INFO: stdout: "e2e-test-crd-publish-openapi-8156-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Oct 24 02:19:21.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-9344 apply -f -'
Oct 24 02:19:21.875: INFO: stderr: ""
Oct 24 02:19:21.875: INFO: stdout: "e2e-test-crd-publish-openapi-8156-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct 24 02:19:21.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-9344 delete e2e-test-crd-publish-openapi-8156-crds test-cr'
Oct 24 02:19:22.049: INFO: stderr: ""
Oct 24 02:19:22.049: INFO: stdout: "e2e-test-crd-publish-openapi-8156-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Oct 24 02:19:22.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 explain e2e-test-crd-publish-openapi-8156-crds'
Oct 24 02:19:22.352: INFO: stderr: ""
Oct 24 02:19:22.352: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8156-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:19:26.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9344" for this suite.
Oct 24 02:19:32.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:19:33.018: INFO: namespace crd-publish-openapi-9344 deletion completed in 6.151709189s

• [SLOW TEST:16.811 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:19:33.019: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:19:33.075: INFO: Creating ReplicaSet my-hostname-basic-69a07c8b-aa16-4b1a-9ec3-953e44812956
Oct 24 02:19:33.084: INFO: Pod name my-hostname-basic-69a07c8b-aa16-4b1a-9ec3-953e44812956: Found 0 pods out of 1
Oct 24 02:19:38.089: INFO: Pod name my-hostname-basic-69a07c8b-aa16-4b1a-9ec3-953e44812956: Found 1 pods out of 1
Oct 24 02:19:38.089: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-69a07c8b-aa16-4b1a-9ec3-953e44812956" is running
Oct 24 02:19:38.092: INFO: Pod "my-hostname-basic-69a07c8b-aa16-4b1a-9ec3-953e44812956-mhkp2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 02:19:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 02:19:34 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 02:19:34 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 02:19:33 +0000 UTC Reason: Message:}])
Oct 24 02:19:38.092: INFO: Trying to dial the pod
Oct 24 02:19:43.111: INFO: Controller my-hostname-basic-69a07c8b-aa16-4b1a-9ec3-953e44812956: Got expected result from replica 1 [my-hostname-basic-69a07c8b-aa16-4b1a-9ec3-953e44812956-mhkp2]: "my-hostname-basic-69a07c8b-aa16-4b1a-9ec3-953e44812956-mhkp2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:19:43.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4730" for this suite.
Oct 24 02:19:49.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:19:49.277: INFO: namespace replicaset-4730 deletion completed in 6.16108477s

• [SLOW TEST:16.258 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:19:49.277: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:19:56.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4848" for this suite.
Oct 24 02:20:02.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:20:02.496: INFO: namespace resourcequota-4848 deletion completed in 6.14580159s

• [SLOW TEST:13.219 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:20:02.496: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-f75c451e-0909-429b-823c-7bb6f5fd4678
STEP: Creating a pod to test consume configMaps
Oct 24 02:20:02.559: INFO: Waiting up to 5m0s for pod "pod-configmaps-80671392-cd18-47f7-9836-be5044da32e6" in namespace "configmap-9373" to be "success or failure"
Oct 24 02:20:02.564: INFO: Pod "pod-configmaps-80671392-cd18-47f7-9836-be5044da32e6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.113876ms
Oct 24 02:20:04.570: INFO: Pod "pod-configmaps-80671392-cd18-47f7-9836-be5044da32e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010417175s
STEP: Saw pod success
Oct 24 02:20:04.570: INFO: Pod "pod-configmaps-80671392-cd18-47f7-9836-be5044da32e6" satisfied condition "success or failure"
Oct 24 02:20:04.574: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-80671392-cd18-47f7-9836-be5044da32e6 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 02:20:04.608: INFO: Waiting for pod pod-configmaps-80671392-cd18-47f7-9836-be5044da32e6 to disappear
Oct 24 02:20:04.612: INFO: Pod pod-configmaps-80671392-cd18-47f7-9836-be5044da32e6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:20:04.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9373" for this suite.
Oct 24 02:20:10.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:20:10.771: INFO: namespace configmap-9373 deletion completed in 6.153852774s

• [SLOW TEST:8.275 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:20:10.772: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-76490c7d-931a-4b3b-9ed7-1a7eea04e510
STEP: Creating a pod to test consume secrets
Oct 24 02:20:10.834: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-af4117d0-5600-481e-b52a-bd347d37b6ee" in namespace "projected-3707" to be "success or failure"
Oct 24 02:20:10.838: INFO: Pod "pod-projected-secrets-af4117d0-5600-481e-b52a-bd347d37b6ee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.28673ms
Oct 24 02:20:12.843: INFO: Pod "pod-projected-secrets-af4117d0-5600-481e-b52a-bd347d37b6ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009038363s
STEP: Saw pod success
Oct 24 02:20:12.843: INFO: Pod "pod-projected-secrets-af4117d0-5600-481e-b52a-bd347d37b6ee" satisfied condition "success or failure"
Oct 24 02:20:12.847: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-af4117d0-5600-481e-b52a-bd347d37b6ee container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 24 02:20:12.879: INFO: Waiting for pod pod-projected-secrets-af4117d0-5600-481e-b52a-bd347d37b6ee to disappear
Oct 24 02:20:12.883: INFO: Pod pod-projected-secrets-af4117d0-5600-481e-b52a-bd347d37b6ee no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:20:12.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3707" for this suite.
Oct 24 02:20:18.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:20:19.031: INFO: namespace projected-3707 deletion completed in 6.143274526s

• [SLOW TEST:8.260 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:20:19.032: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 02:20:19.084: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7eaebc02-86ff-42d5-89df-679aa2bd6603" in namespace "projected-4461" to be "success or failure"
Oct 24 02:20:19.089: INFO: Pod "downwardapi-volume-7eaebc02-86ff-42d5-89df-679aa2bd6603": Phase="Pending", Reason="", readiness=false. Elapsed: 4.800746ms
Oct 24 02:20:21.094: INFO: Pod "downwardapi-volume-7eaebc02-86ff-42d5-89df-679aa2bd6603": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009276691s
STEP: Saw pod success
Oct 24 02:20:21.094: INFO: Pod "downwardapi-volume-7eaebc02-86ff-42d5-89df-679aa2bd6603" satisfied condition "success or failure"
Oct 24 02:20:21.097: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-7eaebc02-86ff-42d5-89df-679aa2bd6603 container client-container: <nil>
STEP: delete the pod
Oct 24 02:20:21.126: INFO: Waiting for pod downwardapi-volume-7eaebc02-86ff-42d5-89df-679aa2bd6603 to disappear
Oct 24 02:20:21.129: INFO: Pod downwardapi-volume-7eaebc02-86ff-42d5-89df-679aa2bd6603 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:20:21.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4461" for this suite.
Oct 24 02:20:27.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:20:27.273: INFO: namespace projected-4461 deletion completed in 6.139598981s

• [SLOW TEST:8.241 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:20:27.273: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 02:20:27.325: INFO: Waiting up to 5m0s for pod "downwardapi-volume-532d2e42-d6a1-4d04-8e1d-e212facef72d" in namespace "projected-6963" to be "success or failure"
Oct 24 02:20:27.330: INFO: Pod "downwardapi-volume-532d2e42-d6a1-4d04-8e1d-e212facef72d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.760759ms
Oct 24 02:20:29.337: INFO: Pod "downwardapi-volume-532d2e42-d6a1-4d04-8e1d-e212facef72d": Phase="Running", Reason="", readiness=true. Elapsed: 2.011501116s
Oct 24 02:20:31.343: INFO: Pod "downwardapi-volume-532d2e42-d6a1-4d04-8e1d-e212facef72d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017401135s
STEP: Saw pod success
Oct 24 02:20:31.343: INFO: Pod "downwardapi-volume-532d2e42-d6a1-4d04-8e1d-e212facef72d" satisfied condition "success or failure"
Oct 24 02:20:31.346: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-532d2e42-d6a1-4d04-8e1d-e212facef72d container client-container: <nil>
STEP: delete the pod
Oct 24 02:20:31.395: INFO: Waiting for pod downwardapi-volume-532d2e42-d6a1-4d04-8e1d-e212facef72d to disappear
Oct 24 02:20:31.399: INFO: Pod downwardapi-volume-532d2e42-d6a1-4d04-8e1d-e212facef72d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:20:31.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6963" for this suite.
Oct 24 02:20:37.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:20:37.560: INFO: namespace projected-6963 deletion completed in 6.15578397s

• [SLOW TEST:10.287 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:20:37.561: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-9884
STEP: creating replication controller nodeport-test in namespace services-9884
I1024 02:20:37.637117      23 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-9884, replica count: 2
Oct 24 02:20:40.687: INFO: Creating new exec pod
I1024 02:20:40.687637      23 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 02:20:43.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-9884 execpodvc6m6 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Oct 24 02:20:44.058: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct 24 02:20:44.058: INFO: stdout: ""
Oct 24 02:20:44.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-9884 execpodvc6m6 -- /bin/sh -x -c nc -zv -t -w 2 10.96.93.22 80'
Oct 24 02:20:44.378: INFO: stderr: "+ nc -zv -t -w 2 10.96.93.22 80\nConnection to 10.96.93.22 80 port [tcp/http] succeeded!\n"
Oct 24 02:20:44.378: INFO: stdout: ""
Oct 24 02:20:44.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-9884 execpodvc6m6 -- /bin/sh -x -c nc -zv -t -w 2 16.143.20.137 31254'
Oct 24 02:20:44.718: INFO: stderr: "+ nc -zv -t -w 2 16.143.20.137 31254\nConnection to 16.143.20.137 31254 port [tcp/31254] succeeded!\n"
Oct 24 02:20:44.718: INFO: stdout: ""
Oct 24 02:20:44.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-9884 execpodvc6m6 -- /bin/sh -x -c nc -zv -t -w 2 16.143.20.138 31254'
Oct 24 02:20:45.062: INFO: stderr: "+ nc -zv -t -w 2 16.143.20.138 31254\nConnection to 16.143.20.138 31254 port [tcp/31254] succeeded!\n"
Oct 24 02:20:45.062: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:20:45.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9884" for this suite.
Oct 24 02:20:51.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:20:51.210: INFO: namespace services-9884 deletion completed in 6.142728634s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.650 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:20:51.211: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct 24 02:20:55.809: INFO: Successfully updated pod "annotationupdatefce8a602-50fb-4a52-b0ea-61dff40af7d8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:20:57.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4921" for this suite.
Oct 24 02:21:09.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:21:10.004: INFO: namespace projected-4921 deletion completed in 12.147237469s

• [SLOW TEST:18.793 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:21:10.005: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 02:21:10.739: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 02:21:13.763: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:21:13.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2711" for this suite.
Oct 24 02:21:19.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:21:20.111: INFO: namespace webhook-2711 deletion completed in 6.159853671s
STEP: Destroying namespace "webhook-2711-markers" for this suite.
Oct 24 02:21:26.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:21:26.308: INFO: namespace webhook-2711-markers deletion completed in 6.197440593s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.320 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:21:26.326: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-1c95e3ca-dfc5-4d0a-bf7d-b929a4802b3b
STEP: Creating a pod to test consume configMaps
Oct 24 02:21:26.387: INFO: Waiting up to 5m0s for pod "pod-configmaps-d5471cd3-308e-4e81-94e2-2cbbc3a5f27f" in namespace "configmap-5819" to be "success or failure"
Oct 24 02:21:26.395: INFO: Pod "pod-configmaps-d5471cd3-308e-4e81-94e2-2cbbc3a5f27f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.354079ms
Oct 24 02:21:28.399: INFO: Pod "pod-configmaps-d5471cd3-308e-4e81-94e2-2cbbc3a5f27f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011990637s
STEP: Saw pod success
Oct 24 02:21:28.400: INFO: Pod "pod-configmaps-d5471cd3-308e-4e81-94e2-2cbbc3a5f27f" satisfied condition "success or failure"
Oct 24 02:21:28.403: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-d5471cd3-308e-4e81-94e2-2cbbc3a5f27f container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 02:21:28.431: INFO: Waiting for pod pod-configmaps-d5471cd3-308e-4e81-94e2-2cbbc3a5f27f to disappear
Oct 24 02:21:28.436: INFO: Pod pod-configmaps-d5471cd3-308e-4e81-94e2-2cbbc3a5f27f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:21:28.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5819" for this suite.
Oct 24 02:21:34.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:21:34.591: INFO: namespace configmap-5819 deletion completed in 6.150453209s

• [SLOW TEST:8.265 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:21:34.591: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-367, will wait for the garbage collector to delete the pods
Oct 24 02:21:36.715: INFO: Deleting Job.batch foo took: 9.945037ms
Oct 24 02:21:37.116: INFO: Terminating Job.batch foo pods took: 400.35606ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:22:17.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-367" for this suite.
Oct 24 02:22:23.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:22:23.468: INFO: namespace job-367 deletion completed in 6.143110797s

• [SLOW TEST:48.877 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:22:23.468: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-7b842eeb-1c61-4aef-9fe0-3a186fb95911
STEP: Creating a pod to test consume secrets
Oct 24 02:22:23.528: INFO: Waiting up to 5m0s for pod "pod-secrets-bb06aad8-7306-47d6-8d28-e1bf15aaaa16" in namespace "secrets-7375" to be "success or failure"
Oct 24 02:22:23.534: INFO: Pod "pod-secrets-bb06aad8-7306-47d6-8d28-e1bf15aaaa16": Phase="Pending", Reason="", readiness=false. Elapsed: 5.765968ms
Oct 24 02:22:25.539: INFO: Pod "pod-secrets-bb06aad8-7306-47d6-8d28-e1bf15aaaa16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010294631s
STEP: Saw pod success
Oct 24 02:22:25.539: INFO: Pod "pod-secrets-bb06aad8-7306-47d6-8d28-e1bf15aaaa16" satisfied condition "success or failure"
Oct 24 02:22:25.543: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-bb06aad8-7306-47d6-8d28-e1bf15aaaa16 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 02:22:25.574: INFO: Waiting for pod pod-secrets-bb06aad8-7306-47d6-8d28-e1bf15aaaa16 to disappear
Oct 24 02:22:25.578: INFO: Pod pod-secrets-bb06aad8-7306-47d6-8d28-e1bf15aaaa16 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:22:25.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7375" for this suite.
Oct 24 02:22:31.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:22:31.736: INFO: namespace secrets-7375 deletion completed in 6.151406167s

• [SLOW TEST:8.268 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:22:31.737: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 02:22:31.794: INFO: Waiting up to 5m0s for pod "downwardapi-volume-951c2fd5-7a1d-472d-b1e6-7a7e42efa6a2" in namespace "projected-4647" to be "success or failure"
Oct 24 02:22:31.799: INFO: Pod "downwardapi-volume-951c2fd5-7a1d-472d-b1e6-7a7e42efa6a2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.84693ms
Oct 24 02:22:33.804: INFO: Pod "downwardapi-volume-951c2fd5-7a1d-472d-b1e6-7a7e42efa6a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010263678s
STEP: Saw pod success
Oct 24 02:22:33.804: INFO: Pod "downwardapi-volume-951c2fd5-7a1d-472d-b1e6-7a7e42efa6a2" satisfied condition "success or failure"
Oct 24 02:22:33.808: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-951c2fd5-7a1d-472d-b1e6-7a7e42efa6a2 container client-container: <nil>
STEP: delete the pod
Oct 24 02:22:33.833: INFO: Waiting for pod downwardapi-volume-951c2fd5-7a1d-472d-b1e6-7a7e42efa6a2 to disappear
Oct 24 02:22:33.839: INFO: Pod downwardapi-volume-951c2fd5-7a1d-472d-b1e6-7a7e42efa6a2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:22:33.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4647" for this suite.
Oct 24 02:22:39.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:22:39.988: INFO: namespace projected-4647 deletion completed in 6.143022428s

• [SLOW TEST:8.251 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:22:39.989: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Oct 24 02:22:40.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 api-versions'
Oct 24 02:22:40.194: INFO: stderr: ""
Oct 24 02:22:40.194: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nkubedirector.bluedata.io/v1alpha1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:22:40.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7714" for this suite.
Oct 24 02:22:46.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:22:46.352: INFO: namespace kubectl-7714 deletion completed in 6.151842267s

• [SLOW TEST:6.363 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:22:46.352: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:22:57.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3846" for this suite.
Oct 24 02:23:03.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:23:03.666: INFO: namespace namespaces-3846 deletion completed in 6.14916814s
STEP: Destroying namespace "nsdeletetest-3418" for this suite.
Oct 24 02:23:03.669: INFO: Namespace nsdeletetest-3418 was already deleted
STEP: Destroying namespace "nsdeletetest-1003" for this suite.
Oct 24 02:23:09.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:23:09.812: INFO: namespace nsdeletetest-1003 deletion completed in 6.14267101s

• [SLOW TEST:23.459 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:23:09.812: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Oct 24 02:23:09.868: INFO: Waiting up to 5m0s for pod "var-expansion-fe4de582-311d-487b-9e37-f4f5e872f78b" in namespace "var-expansion-3117" to be "success or failure"
Oct 24 02:23:09.874: INFO: Pod "var-expansion-fe4de582-311d-487b-9e37-f4f5e872f78b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.260622ms
Oct 24 02:23:11.880: INFO: Pod "var-expansion-fe4de582-311d-487b-9e37-f4f5e872f78b": Phase="Running", Reason="", readiness=true. Elapsed: 2.011925124s
Oct 24 02:23:13.885: INFO: Pod "var-expansion-fe4de582-311d-487b-9e37-f4f5e872f78b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017452131s
STEP: Saw pod success
Oct 24 02:23:13.885: INFO: Pod "var-expansion-fe4de582-311d-487b-9e37-f4f5e872f78b" satisfied condition "success or failure"
Oct 24 02:23:13.889: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod var-expansion-fe4de582-311d-487b-9e37-f4f5e872f78b container dapi-container: <nil>
STEP: delete the pod
Oct 24 02:23:13.917: INFO: Waiting for pod var-expansion-fe4de582-311d-487b-9e37-f4f5e872f78b to disappear
Oct 24 02:23:13.921: INFO: Pod var-expansion-fe4de582-311d-487b-9e37-f4f5e872f78b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:23:13.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3117" for this suite.
Oct 24 02:23:19.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:23:20.070: INFO: namespace var-expansion-3117 deletion completed in 6.143679046s

• [SLOW TEST:10.257 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:23:20.070: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-358bb66a-d4f9-4331-a9e0-aed4b03afb28
STEP: Creating secret with name s-test-opt-upd-2c1e67cd-c7da-4bdd-84ab-6f4d2b5ff467
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-358bb66a-d4f9-4331-a9e0-aed4b03afb28
STEP: Updating secret s-test-opt-upd-2c1e67cd-c7da-4bdd-84ab-6f4d2b5ff467
STEP: Creating secret with name s-test-opt-create-6f7a05af-cfc6-403b-8c10-8571498587e9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:23:24.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5142" for this suite.
Oct 24 02:23:36.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:23:36.439: INFO: namespace secrets-5142 deletion completed in 12.14713077s

• [SLOW TEST:16.369 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:23:36.440: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Oct 24 02:23:37.016: INFO: created pod pod-service-account-defaultsa
Oct 24 02:23:37.016: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 24 02:23:37.021: INFO: created pod pod-service-account-mountsa
Oct 24 02:23:37.021: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 24 02:23:37.037: INFO: created pod pod-service-account-nomountsa
Oct 24 02:23:37.037: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 24 02:23:37.045: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 24 02:23:37.045: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 24 02:23:37.056: INFO: created pod pod-service-account-mountsa-mountspec
Oct 24 02:23:37.056: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 24 02:23:37.074: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 24 02:23:37.074: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 24 02:23:37.082: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 24 02:23:37.082: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 24 02:23:37.088: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 24 02:23:37.088: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 24 02:23:37.100: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 24 02:23:37.101: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:23:37.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5341" for this suite.
Oct 24 02:23:43.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:23:43.277: INFO: namespace svcaccounts-5341 deletion completed in 6.163367893s

• [SLOW TEST:6.838 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:23:43.278: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 24 02:23:43.333: INFO: Waiting up to 5m0s for pod "pod-e075ebb0-09ce-4c6b-9312-87371b47a118" in namespace "emptydir-9444" to be "success or failure"
Oct 24 02:23:43.340: INFO: Pod "pod-e075ebb0-09ce-4c6b-9312-87371b47a118": Phase="Pending", Reason="", readiness=false. Elapsed: 7.025365ms
Oct 24 02:23:45.346: INFO: Pod "pod-e075ebb0-09ce-4c6b-9312-87371b47a118": Phase="Running", Reason="", readiness=true. Elapsed: 2.012382708s
Oct 24 02:23:47.351: INFO: Pod "pod-e075ebb0-09ce-4c6b-9312-87371b47a118": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017286132s
STEP: Saw pod success
Oct 24 02:23:47.351: INFO: Pod "pod-e075ebb0-09ce-4c6b-9312-87371b47a118" satisfied condition "success or failure"
Oct 24 02:23:47.354: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-e075ebb0-09ce-4c6b-9312-87371b47a118 container test-container: <nil>
STEP: delete the pod
Oct 24 02:23:47.389: INFO: Waiting for pod pod-e075ebb0-09ce-4c6b-9312-87371b47a118 to disappear
Oct 24 02:23:47.392: INFO: Pod pod-e075ebb0-09ce-4c6b-9312-87371b47a118 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:23:47.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9444" for this suite.
Oct 24 02:23:53.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:23:53.549: INFO: namespace emptydir-9444 deletion completed in 6.152242444s

• [SLOW TEST:10.271 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:23:53.549: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 02:23:53.603: INFO: Waiting up to 5m0s for pod "downwardapi-volume-830bf6b4-1376-477b-9d9d-b5f69f6ea804" in namespace "projected-7264" to be "success or failure"
Oct 24 02:23:53.607: INFO: Pod "downwardapi-volume-830bf6b4-1376-477b-9d9d-b5f69f6ea804": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009662ms
Oct 24 02:23:55.612: INFO: Pod "downwardapi-volume-830bf6b4-1376-477b-9d9d-b5f69f6ea804": Phase="Running", Reason="", readiness=true. Elapsed: 2.009370732s
Oct 24 02:23:57.621: INFO: Pod "downwardapi-volume-830bf6b4-1376-477b-9d9d-b5f69f6ea804": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018444902s
STEP: Saw pod success
Oct 24 02:23:57.622: INFO: Pod "downwardapi-volume-830bf6b4-1376-477b-9d9d-b5f69f6ea804" satisfied condition "success or failure"
Oct 24 02:23:57.625: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downwardapi-volume-830bf6b4-1376-477b-9d9d-b5f69f6ea804 container client-container: <nil>
STEP: delete the pod
Oct 24 02:23:57.661: INFO: Waiting for pod downwardapi-volume-830bf6b4-1376-477b-9d9d-b5f69f6ea804 to disappear
Oct 24 02:23:57.665: INFO: Pod downwardapi-volume-830bf6b4-1376-477b-9d9d-b5f69f6ea804 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:23:57.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7264" for this suite.
Oct 24 02:24:03.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:24:03.816: INFO: namespace projected-7264 deletion completed in 6.14526992s

• [SLOW TEST:10.267 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:24:03.816: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3671
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3671
STEP: creating replication controller externalsvc in namespace services-3671
I1024 02:24:03.903132      23 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3671, replica count: 2
I1024 02:24:06.953700      23 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Oct 24 02:24:06.975: INFO: Creating new exec pod
Oct 24 02:24:08.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-3671 execpodjvttt -- /bin/sh -x -c nslookup clusterip-service'
Oct 24 02:24:09.344: INFO: stderr: "+ nslookup clusterip-service\n"
Oct 24 02:24:09.344: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-3671.svc.cluster.local\tcanonical name = externalsvc.services-3671.svc.cluster.local.\nName:\texternalsvc.services-3671.svc.cluster.local\nAddress: 10.96.188.230\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3671, will wait for the garbage collector to delete the pods
Oct 24 02:24:09.408: INFO: Deleting ReplicationController externalsvc took: 8.603515ms
Oct 24 02:24:09.810: INFO: Terminating ReplicationController externalsvc pods took: 401.648431ms
Oct 24 02:24:17.228: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:24:17.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3671" for this suite.
Oct 24 02:24:23.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:24:23.408: INFO: namespace services-3671 deletion completed in 6.15059427s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.592 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:24:23.408: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-2037fdba-317b-468c-bc06-2353e0dde7c5
STEP: Creating a pod to test consume secrets
Oct 24 02:24:23.471: INFO: Waiting up to 5m0s for pod "pod-secrets-beee3ce5-c233-4881-aef6-68c3d74b5747" in namespace "secrets-9235" to be "success or failure"
Oct 24 02:24:23.482: INFO: Pod "pod-secrets-beee3ce5-c233-4881-aef6-68c3d74b5747": Phase="Pending", Reason="", readiness=false. Elapsed: 10.564585ms
Oct 24 02:24:25.487: INFO: Pod "pod-secrets-beee3ce5-c233-4881-aef6-68c3d74b5747": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015478824s
STEP: Saw pod success
Oct 24 02:24:25.487: INFO: Pod "pod-secrets-beee3ce5-c233-4881-aef6-68c3d74b5747" satisfied condition "success or failure"
Oct 24 02:24:25.490: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-beee3ce5-c233-4881-aef6-68c3d74b5747 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 02:24:25.541: INFO: Waiting for pod pod-secrets-beee3ce5-c233-4881-aef6-68c3d74b5747 to disappear
Oct 24 02:24:25.544: INFO: Pod pod-secrets-beee3ce5-c233-4881-aef6-68c3d74b5747 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:24:25.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9235" for this suite.
Oct 24 02:24:31.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:24:31.702: INFO: namespace secrets-9235 deletion completed in 6.151956936s

• [SLOW TEST:8.294 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:24:31.702: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 24 02:24:35.798: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 02:24:35.808: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 02:24:37.808: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 02:24:37.813: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 24 02:24:39.808: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 24 02:24:39.813: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:24:39.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8925" for this suite.
Oct 24 02:25:07.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:25:07.992: INFO: namespace container-lifecycle-hook-8925 deletion completed in 28.158387992s

• [SLOW TEST:36.290 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:25:07.992: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-24d1cea9-f123-44ff-8d60-27b3ded6cf8f
STEP: Creating a pod to test consume secrets
Oct 24 02:25:08.058: INFO: Waiting up to 5m0s for pod "pod-secrets-d332de2b-cf23-4a11-95aa-9df7596e1c45" in namespace "secrets-7872" to be "success or failure"
Oct 24 02:25:08.062: INFO: Pod "pod-secrets-d332de2b-cf23-4a11-95aa-9df7596e1c45": Phase="Pending", Reason="", readiness=false. Elapsed: 4.08513ms
Oct 24 02:25:10.067: INFO: Pod "pod-secrets-d332de2b-cf23-4a11-95aa-9df7596e1c45": Phase="Running", Reason="", readiness=true. Elapsed: 2.009167785s
Oct 24 02:25:12.071: INFO: Pod "pod-secrets-d332de2b-cf23-4a11-95aa-9df7596e1c45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013882546s
STEP: Saw pod success
Oct 24 02:25:12.072: INFO: Pod "pod-secrets-d332de2b-cf23-4a11-95aa-9df7596e1c45" satisfied condition "success or failure"
Oct 24 02:25:12.075: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-d332de2b-cf23-4a11-95aa-9df7596e1c45 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 02:25:12.103: INFO: Waiting for pod pod-secrets-d332de2b-cf23-4a11-95aa-9df7596e1c45 to disappear
Oct 24 02:25:12.108: INFO: Pod pod-secrets-d332de2b-cf23-4a11-95aa-9df7596e1c45 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:25:12.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7872" for this suite.
Oct 24 02:25:18.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:25:18.267: INFO: namespace secrets-7872 deletion completed in 6.153823691s

• [SLOW TEST:10.275 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:25:18.267: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct 24 02:25:18.327: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e9cf92a7-41a4-4e9a-a675-7facdf90db62" in namespace "downward-api-2841" to be "success or failure"
Oct 24 02:25:18.331: INFO: Pod "downwardapi-volume-e9cf92a7-41a4-4e9a-a675-7facdf90db62": Phase="Pending", Reason="", readiness=false. Elapsed: 4.484436ms
Oct 24 02:25:20.348: INFO: Pod "downwardapi-volume-e9cf92a7-41a4-4e9a-a675-7facdf90db62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021404131s
STEP: Saw pod success
Oct 24 02:25:20.348: INFO: Pod "downwardapi-volume-e9cf92a7-41a4-4e9a-a675-7facdf90db62" satisfied condition "success or failure"
Oct 24 02:25:20.352: INFO: Trying to get logs from node mip-bd-vm41.mip.storage.hpecorp.net pod downwardapi-volume-e9cf92a7-41a4-4e9a-a675-7facdf90db62 container client-container: <nil>
STEP: delete the pod
Oct 24 02:25:20.396: INFO: Waiting for pod downwardapi-volume-e9cf92a7-41a4-4e9a-a675-7facdf90db62 to disappear
Oct 24 02:25:20.400: INFO: Pod downwardapi-volume-e9cf92a7-41a4-4e9a-a675-7facdf90db62 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:25:20.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2841" for this suite.
Oct 24 02:25:26.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:25:26.549: INFO: namespace downward-api-2841 deletion completed in 6.144510099s

• [SLOW TEST:8.282 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:25:26.549: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-885.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-885.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-885.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-885.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-885.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-885.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 24 02:25:28.693: INFO: DNS probes using dns-885/dns-test-e5ceae21-6c29-4f7b-a4d3-32399cc28056 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:25:28.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-885" for this suite.
Oct 24 02:25:34.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:25:34.908: INFO: namespace dns-885 deletion completed in 6.154091385s

• [SLOW TEST:8.359 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:25:34.909: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Oct 24 02:25:41.018: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:25:41.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1446" for this suite.
W1024 02:25:41.018460      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 24 02:25:47.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:25:47.169: INFO: namespace gc-1446 deletion completed in 6.14618853s

• [SLOW TEST:12.260 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:25:47.170: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:26:03.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7787" for this suite.
Oct 24 02:26:09.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:26:09.428: INFO: namespace resourcequota-7787 deletion completed in 6.154630399s

• [SLOW TEST:22.258 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:26:09.428: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:26:09.477: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Oct 24 02:26:13.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-234 create -f -'
Oct 24 02:26:14.057: INFO: stderr: ""
Oct 24 02:26:14.057: INFO: stdout: "e2e-test-crd-publish-openapi-9741-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct 24 02:26:14.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-234 delete e2e-test-crd-publish-openapi-9741-crds test-foo'
Oct 24 02:26:14.240: INFO: stderr: ""
Oct 24 02:26:14.240: INFO: stdout: "e2e-test-crd-publish-openapi-9741-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Oct 24 02:26:14.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-234 apply -f -'
Oct 24 02:26:14.597: INFO: stderr: ""
Oct 24 02:26:14.597: INFO: stdout: "e2e-test-crd-publish-openapi-9741-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct 24 02:26:14.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-234 delete e2e-test-crd-publish-openapi-9741-crds test-foo'
Oct 24 02:26:14.776: INFO: stderr: ""
Oct 24 02:26:14.776: INFO: stdout: "e2e-test-crd-publish-openapi-9741-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Oct 24 02:26:14.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-234 create -f -'
Oct 24 02:26:15.081: INFO: rc: 1
Oct 24 02:26:15.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-234 apply -f -'
Oct 24 02:26:15.396: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Oct 24 02:26:15.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-234 create -f -'
Oct 24 02:26:15.750: INFO: rc: 1
Oct 24 02:26:15.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 --namespace=crd-publish-openapi-234 apply -f -'
Oct 24 02:26:16.083: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Oct 24 02:26:16.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 explain e2e-test-crd-publish-openapi-9741-crds'
Oct 24 02:26:16.423: INFO: stderr: ""
Oct 24 02:26:16.423: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9741-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Oct 24 02:26:16.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 explain e2e-test-crd-publish-openapi-9741-crds.metadata'
Oct 24 02:26:16.751: INFO: stderr: ""
Oct 24 02:26:16.751: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9741-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Oct 24 02:26:16.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 explain e2e-test-crd-publish-openapi-9741-crds.spec'
Oct 24 02:26:17.078: INFO: stderr: ""
Oct 24 02:26:17.078: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9741-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Oct 24 02:26:17.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 explain e2e-test-crd-publish-openapi-9741-crds.spec.bars'
Oct 24 02:26:17.414: INFO: stderr: ""
Oct 24 02:26:17.414: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9741-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Oct 24 02:26:17.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 explain e2e-test-crd-publish-openapi-9741-crds.spec.bars2'
Oct 24 02:26:17.753: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:26:22.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-234" for this suite.
Oct 24 02:26:28.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:26:28.699: INFO: namespace crd-publish-openapi-234 deletion completed in 6.156850702s

• [SLOW TEST:19.270 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:26:28.699: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Oct 24 02:26:28.755: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 02:26:32.803: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:26:50.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1873" for this suite.
Oct 24 02:26:56.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:26:56.199: INFO: namespace crd-publish-openapi-1873 deletion completed in 6.155023542s

• [SLOW TEST:27.500 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:26:56.200: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:26:56.268: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 24 02:26:56.279: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:26:56.284: INFO: Number of nodes with available pods: 0
Oct 24 02:26:56.284: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:26:57.290: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:26:57.294: INFO: Number of nodes with available pods: 0
Oct 24 02:26:57.294: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:26:58.289: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:26:58.294: INFO: Number of nodes with available pods: 2
Oct 24 02:26:58.294: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 24 02:26:58.328: INFO: Wrong image for pod: daemon-set-7gw2t. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 24 02:26:58.328: INFO: Wrong image for pod: daemon-set-sgfst. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 24 02:26:58.332: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:26:59.337: INFO: Wrong image for pod: daemon-set-7gw2t. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 24 02:26:59.337: INFO: Wrong image for pod: daemon-set-sgfst. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 24 02:26:59.342: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:00.337: INFO: Wrong image for pod: daemon-set-7gw2t. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 24 02:27:00.338: INFO: Wrong image for pod: daemon-set-sgfst. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 24 02:27:00.345: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:01.339: INFO: Wrong image for pod: daemon-set-7gw2t. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 24 02:27:01.339: INFO: Wrong image for pod: daemon-set-sgfst. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 24 02:27:01.339: INFO: Pod daemon-set-sgfst is not available
Oct 24 02:27:01.344: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:02.344: INFO: Wrong image for pod: daemon-set-7gw2t. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 24 02:27:02.344: INFO: Pod daemon-set-9tzsq is not available
Oct 24 02:27:02.363: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:03.338: INFO: Wrong image for pod: daemon-set-7gw2t. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 24 02:27:03.343: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:04.338: INFO: Wrong image for pod: daemon-set-7gw2t. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct 24 02:27:04.338: INFO: Pod daemon-set-7gw2t is not available
Oct 24 02:27:04.342: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:05.338: INFO: Pod daemon-set-zcb2t is not available
Oct 24 02:27:05.343: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 24 02:27:05.348: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:05.352: INFO: Number of nodes with available pods: 1
Oct 24 02:27:05.352: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:27:06.358: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:06.363: INFO: Number of nodes with available pods: 1
Oct 24 02:27:06.363: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:27:07.359: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:07.364: INFO: Number of nodes with available pods: 1
Oct 24 02:27:07.364: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:27:08.358: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:08.363: INFO: Number of nodes with available pods: 1
Oct 24 02:27:08.363: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:27:09.359: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:09.363: INFO: Number of nodes with available pods: 1
Oct 24 02:27:09.363: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:27:10.358: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:10.363: INFO: Number of nodes with available pods: 1
Oct 24 02:27:10.363: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:27:11.358: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:11.363: INFO: Number of nodes with available pods: 1
Oct 24 02:27:11.363: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:27:12.359: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:12.363: INFO: Number of nodes with available pods: 1
Oct 24 02:27:12.363: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:27:13.358: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:13.363: INFO: Number of nodes with available pods: 1
Oct 24 02:27:13.363: INFO: Node mip-bd-vm41.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:27:14.358: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:27:14.362: INFO: Number of nodes with available pods: 2
Oct 24 02:27:14.362: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8390, will wait for the garbage collector to delete the pods
Oct 24 02:27:14.443: INFO: Deleting DaemonSet.extensions daemon-set took: 7.445618ms
Oct 24 02:27:14.844: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.25535ms
Oct 24 02:27:27.248: INFO: Number of nodes with available pods: 0
Oct 24 02:27:27.248: INFO: Number of running nodes: 0, number of available pods: 0
Oct 24 02:27:27.251: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8390/daemonsets","resourceVersion":"23595"},"items":null}

Oct 24 02:27:27.254: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8390/pods","resourceVersion":"23595"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:27:27.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8390" for this suite.
Oct 24 02:27:33.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:27:33.419: INFO: namespace daemonsets-8390 deletion completed in 6.146823368s

• [SLOW TEST:37.219 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:27:33.419: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Oct 24 02:27:33.464: INFO: namespace kubectl-6402
Oct 24 02:27:33.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-6402'
Oct 24 02:27:33.972: INFO: stderr: ""
Oct 24 02:27:33.972: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 24 02:27:34.977: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 02:27:34.977: INFO: Found 0 / 1
Oct 24 02:27:35.978: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 02:27:35.978: INFO: Found 1 / 1
Oct 24 02:27:35.978: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 24 02:27:35.983: INFO: Selector matched 1 pods for map[app:redis]
Oct 24 02:27:35.983: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 24 02:27:35.983: INFO: wait on redis-master startup in kubectl-6402 
Oct 24 02:27:35.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 logs redis-master-d6pjk redis-master --namespace=kubectl-6402'
Oct 24 02:27:36.210: INFO: stderr: ""
Oct 24 02:27:36.210: INFO: stdout: "1:C 24 Oct 2019 02:27:34.997 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 24 Oct 2019 02:27:34.997 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 24 Oct 2019 02:27:34.997 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 24 Oct 2019 02:27:35.000 * Running mode=standalone, port=6379.\n1:M 24 Oct 2019 02:27:35.001 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 24 Oct 2019 02:27:35.001 # Server initialized\n1:M 24 Oct 2019 02:27:35.001 * Ready to accept connections\n"
STEP: exposing RC
Oct 24 02:27:36.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6402'
Oct 24 02:27:36.421: INFO: stderr: ""
Oct 24 02:27:36.421: INFO: stdout: "service/rm2 exposed\n"
Oct 24 02:27:36.425: INFO: Service rm2 in namespace kubectl-6402 found.
STEP: exposing service
Oct 24 02:27:38.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6402'
Oct 24 02:27:38.649: INFO: stderr: ""
Oct 24 02:27:38.649: INFO: stdout: "service/rm3 exposed\n"
Oct 24 02:27:38.657: INFO: Service rm3 in namespace kubectl-6402 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:27:40.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6402" for this suite.
Oct 24 02:28:06.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:28:06.849: INFO: namespace kubectl-6402 deletion completed in 26.179161619s

• [SLOW TEST:33.430 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:28:06.850: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Oct 24 02:28:06.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-8207'
Oct 24 02:28:07.267: INFO: stderr: ""
Oct 24 02:28:07.267: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 02:28:07.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8207'
Oct 24 02:28:07.442: INFO: stderr: ""
Oct 24 02:28:07.442: INFO: stdout: "update-demo-nautilus-skc8b update-demo-nautilus-z4blm "
Oct 24 02:28:07.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-skc8b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8207'
Oct 24 02:28:07.616: INFO: stderr: ""
Oct 24 02:28:07.616: INFO: stdout: ""
Oct 24 02:28:07.616: INFO: update-demo-nautilus-skc8b is created but not running
Oct 24 02:28:12.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8207'
Oct 24 02:28:12.797: INFO: stderr: ""
Oct 24 02:28:12.797: INFO: stdout: "update-demo-nautilus-skc8b update-demo-nautilus-z4blm "
Oct 24 02:28:12.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-skc8b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8207'
Oct 24 02:28:12.957: INFO: stderr: ""
Oct 24 02:28:12.957: INFO: stdout: "true"
Oct 24 02:28:12.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-skc8b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8207'
Oct 24 02:28:13.119: INFO: stderr: ""
Oct 24 02:28:13.119: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 02:28:13.119: INFO: validating pod update-demo-nautilus-skc8b
Oct 24 02:28:13.127: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 02:28:13.127: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 02:28:13.127: INFO: update-demo-nautilus-skc8b is verified up and running
Oct 24 02:28:13.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-z4blm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8207'
Oct 24 02:28:13.293: INFO: stderr: ""
Oct 24 02:28:13.293: INFO: stdout: "true"
Oct 24 02:28:13.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-z4blm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8207'
Oct 24 02:28:13.457: INFO: stderr: ""
Oct 24 02:28:13.457: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 02:28:13.457: INFO: validating pod update-demo-nautilus-z4blm
Oct 24 02:28:13.465: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 02:28:13.465: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 02:28:13.465: INFO: update-demo-nautilus-z4blm is verified up and running
STEP: using delete to clean up resources
Oct 24 02:28:13.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete --grace-period=0 --force -f - --namespace=kubectl-8207'
Oct 24 02:28:13.627: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 02:28:13.627: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 24 02:28:13.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8207'
Oct 24 02:28:13.805: INFO: stderr: "No resources found in kubectl-8207 namespace.\n"
Oct 24 02:28:13.805: INFO: stdout: ""
Oct 24 02:28:13.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -l name=update-demo --namespace=kubectl-8207 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 02:28:13.974: INFO: stderr: ""
Oct 24 02:28:13.974: INFO: stdout: "update-demo-nautilus-skc8b\nupdate-demo-nautilus-z4blm\n"
Oct 24 02:28:14.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8207'
Oct 24 02:28:14.660: INFO: stderr: "No resources found in kubectl-8207 namespace.\n"
Oct 24 02:28:14.660: INFO: stdout: ""
Oct 24 02:28:14.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -l name=update-demo --namespace=kubectl-8207 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 02:28:14.833: INFO: stderr: ""
Oct 24 02:28:14.833: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:28:14.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8207" for this suite.
Oct 24 02:28:42.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:28:42.986: INFO: namespace kubectl-8207 deletion completed in 28.147651825s

• [SLOW TEST:36.136 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:28:42.987: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:29:03.057: INFO: Container started at 2019-10-24 02:28:44 +0000 UTC, pod became ready at 2019-10-24 02:29:02 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:29:03.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1159" for this suite.
Oct 24 02:29:31.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:29:31.206: INFO: namespace container-probe-1159 deletion completed in 28.143200256s

• [SLOW TEST:48.219 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:29:31.206: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:29:31.251: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:29:31.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6784" for this suite.
Oct 24 02:29:37.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:29:37.987: INFO: namespace custom-resource-definition-6784 deletion completed in 6.161785863s

• [SLOW TEST:6.780 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:29:37.987: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6035
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Oct 24 02:29:38.058: INFO: Found 0 stateful pods, waiting for 3
Oct 24 02:29:48.065: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 02:29:48.065: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 02:29:48.065: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Oct 24 02:29:48.099: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 24 02:29:58.139: INFO: Updating stateful set ss2
Oct 24 02:29:58.148: INFO: Waiting for Pod statefulset-6035/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Oct 24 02:30:08.213: INFO: Found 2 stateful pods, waiting for 3
Oct 24 02:30:18.220: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 02:30:18.220: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 02:30:18.220: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Oct 24 02:30:28.219: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 02:30:28.219: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 02:30:28.219: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 24 02:30:28.248: INFO: Updating stateful set ss2
Oct 24 02:30:28.256: INFO: Waiting for Pod statefulset-6035/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct 24 02:30:38.286: INFO: Updating stateful set ss2
Oct 24 02:30:38.300: INFO: Waiting for StatefulSet statefulset-6035/ss2 to complete update
Oct 24 02:30:38.300: INFO: Waiting for Pod statefulset-6035/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct 24 02:30:48.309: INFO: Waiting for StatefulSet statefulset-6035/ss2 to complete update
Oct 24 02:30:48.309: INFO: Waiting for Pod statefulset-6035/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct 24 02:30:58.311: INFO: Waiting for StatefulSet statefulset-6035/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 24 02:31:08.310: INFO: Deleting all statefulset in ns statefulset-6035
Oct 24 02:31:08.314: INFO: Scaling statefulset ss2 to 0
Oct 24 02:31:28.336: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 02:31:28.341: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:31:28.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6035" for this suite.
Oct 24 02:31:40.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:31:40.501: INFO: namespace statefulset-6035 deletion completed in 12.139724098s

• [SLOW TEST:122.514 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:31:40.502: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct 24 02:31:43.074: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1432 pod-service-account-d9477ca7-a83c-406c-9129-c7fa3cb76f5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct 24 02:31:43.407: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1432 pod-service-account-d9477ca7-a83c-406c-9129-c7fa3cb76f5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct 24 02:31:43.768: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1432 pod-service-account-d9477ca7-a83c-406c-9129-c7fa3cb76f5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:31:44.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1432" for this suite.
Oct 24 02:31:50.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:31:50.242: INFO: namespace svcaccounts-1432 deletion completed in 6.13984843s

• [SLOW TEST:9.740 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:31:50.242: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Oct 24 02:31:52.317: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-000479258 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct 24 02:32:07.491: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:32:07.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8173" for this suite.
Oct 24 02:32:13.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:32:13.654: INFO: namespace pods-8173 deletion completed in 6.154089163s

• [SLOW TEST:23.412 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:32:13.655: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-15f12456-17f7-477a-bc5a-02300b649063
STEP: Creating a pod to test consume secrets
Oct 24 02:32:13.711: INFO: Waiting up to 5m0s for pod "pod-secrets-c715464c-4bd9-4079-9597-120213a382b0" in namespace "secrets-645" to be "success or failure"
Oct 24 02:32:13.716: INFO: Pod "pod-secrets-c715464c-4bd9-4079-9597-120213a382b0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.060013ms
Oct 24 02:32:15.721: INFO: Pod "pod-secrets-c715464c-4bd9-4079-9597-120213a382b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010062934s
STEP: Saw pod success
Oct 24 02:32:15.722: INFO: Pod "pod-secrets-c715464c-4bd9-4079-9597-120213a382b0" satisfied condition "success or failure"
Oct 24 02:32:15.725: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-c715464c-4bd9-4079-9597-120213a382b0 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 02:32:15.752: INFO: Waiting for pod pod-secrets-c715464c-4bd9-4079-9597-120213a382b0 to disappear
Oct 24 02:32:15.756: INFO: Pod pod-secrets-c715464c-4bd9-4079-9597-120213a382b0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:32:15.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-645" for this suite.
Oct 24 02:32:21.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:32:21.901: INFO: namespace secrets-645 deletion completed in 6.140072492s

• [SLOW TEST:8.247 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:32:21.901: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-708e470c-3d0d-4e23-af82-04be87438702
STEP: Creating a pod to test consume secrets
Oct 24 02:32:21.955: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0151019e-16be-40cd-a397-56210781001b" in namespace "projected-3084" to be "success or failure"
Oct 24 02:32:21.958: INFO: Pod "pod-projected-secrets-0151019e-16be-40cd-a397-56210781001b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.254141ms
Oct 24 02:32:23.963: INFO: Pod "pod-projected-secrets-0151019e-16be-40cd-a397-56210781001b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007768037s
STEP: Saw pod success
Oct 24 02:32:23.963: INFO: Pod "pod-projected-secrets-0151019e-16be-40cd-a397-56210781001b" satisfied condition "success or failure"
Oct 24 02:32:23.966: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-0151019e-16be-40cd-a397-56210781001b container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 24 02:32:23.991: INFO: Waiting for pod pod-projected-secrets-0151019e-16be-40cd-a397-56210781001b to disappear
Oct 24 02:32:23.995: INFO: Pod pod-projected-secrets-0151019e-16be-40cd-a397-56210781001b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:32:23.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3084" for this suite.
Oct 24 02:32:30.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:32:30.153: INFO: namespace projected-3084 deletion completed in 6.15316802s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:32:30.153: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-3e773b19-49f1-45a1-a174-49f64d1083bf
STEP: Creating secret with name secret-projected-all-test-volume-18abccd6-400b-4e7b-8224-10552cba5efe
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 24 02:32:30.225: INFO: Waiting up to 5m0s for pod "projected-volume-cd720454-a5de-490b-9d67-e838ac1e4584" in namespace "projected-168" to be "success or failure"
Oct 24 02:32:30.230: INFO: Pod "projected-volume-cd720454-a5de-490b-9d67-e838ac1e4584": Phase="Pending", Reason="", readiness=false. Elapsed: 4.938165ms
Oct 24 02:32:32.240: INFO: Pod "projected-volume-cd720454-a5de-490b-9d67-e838ac1e4584": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014302122s
STEP: Saw pod success
Oct 24 02:32:32.240: INFO: Pod "projected-volume-cd720454-a5de-490b-9d67-e838ac1e4584" satisfied condition "success or failure"
Oct 24 02:32:32.246: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod projected-volume-cd720454-a5de-490b-9d67-e838ac1e4584 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 24 02:32:32.274: INFO: Waiting for pod projected-volume-cd720454-a5de-490b-9d67-e838ac1e4584 to disappear
Oct 24 02:32:32.278: INFO: Pod projected-volume-cd720454-a5de-490b-9d67-e838ac1e4584 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:32:32.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-168" for this suite.
Oct 24 02:32:38.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:32:38.431: INFO: namespace projected-168 deletion completed in 6.147104213s

• [SLOW TEST:8.278 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:32:38.431: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-5ac6b1e6-3e84-4450-9916-065d0442068c
STEP: Creating configMap with name cm-test-opt-upd-28aacc7b-d6fe-4ef6-a5b5-36561442a41c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5ac6b1e6-3e84-4450-9916-065d0442068c
STEP: Updating configmap cm-test-opt-upd-28aacc7b-d6fe-4ef6-a5b5-36561442a41c
STEP: Creating configMap with name cm-test-opt-create-06a04fb1-b59b-42f2-b8f3-3d5d722b02a1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:34:11.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9701" for this suite.
Oct 24 02:34:39.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:34:39.519: INFO: namespace projected-9701 deletion completed in 28.157001868s

• [SLOW TEST:121.088 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:34:39.519: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-d21d3119-ca13-4270-9b62-311554017eba
STEP: Creating a pod to test consume secrets
Oct 24 02:34:39.580: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a7f6afd4-fac6-44f0-93a2-b045414417cb" in namespace "projected-4760" to be "success or failure"
Oct 24 02:34:39.587: INFO: Pod "pod-projected-secrets-a7f6afd4-fac6-44f0-93a2-b045414417cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.54352ms
Oct 24 02:34:41.592: INFO: Pod "pod-projected-secrets-a7f6afd4-fac6-44f0-93a2-b045414417cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011800868s
STEP: Saw pod success
Oct 24 02:34:41.592: INFO: Pod "pod-projected-secrets-a7f6afd4-fac6-44f0-93a2-b045414417cb" satisfied condition "success or failure"
Oct 24 02:34:41.596: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-a7f6afd4-fac6-44f0-93a2-b045414417cb container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 02:34:41.642: INFO: Waiting for pod pod-projected-secrets-a7f6afd4-fac6-44f0-93a2-b045414417cb to disappear
Oct 24 02:34:41.645: INFO: Pod pod-projected-secrets-a7f6afd4-fac6-44f0-93a2-b045414417cb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:34:41.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4760" for this suite.
Oct 24 02:34:47.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:34:47.797: INFO: namespace projected-4760 deletion completed in 6.145224961s

• [SLOW TEST:8.277 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:34:47.797: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:34:47.869: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b33dd13e-9c0a-4f24-8cd4-46d656931f58", Controller:(*bool)(0xc005882d6a), BlockOwnerDeletion:(*bool)(0xc005882d6b)}}
Oct 24 02:34:47.890: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"2994b618-4a6d-4c7a-bd45-a0935e0b2a84", Controller:(*bool)(0xc002ef1796), BlockOwnerDeletion:(*bool)(0xc002ef1797)}}
Oct 24 02:34:47.897: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"be7b3c9e-cc04-4b54-8961-2d79d67fa709", Controller:(*bool)(0xc005882f26), BlockOwnerDeletion:(*bool)(0xc005882f27)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:34:52.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9813" for this suite.
Oct 24 02:34:58.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:34:59.088: INFO: namespace gc-9813 deletion completed in 6.161693764s

• [SLOW TEST:11.291 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:34:59.088: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Oct 24 02:35:01.158: INFO: Pod pod-hostip-4ba158b5-d210-4ee3-8803-abf92880c7b9 has hostIP: 16.143.20.137
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:35:01.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2233" for this suite.
Oct 24 02:35:13.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:35:13.328: INFO: namespace pods-2233 deletion completed in 12.16415285s

• [SLOW TEST:14.239 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:35:13.329: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:35:18.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6686" for this suite.
Oct 24 02:35:24.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:35:24.628: INFO: namespace watch-6686 deletion completed in 6.240276285s

• [SLOW TEST:11.299 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:35:24.628: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Oct 24 02:35:24.674: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 24 02:35:24.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-383'
Oct 24 02:35:25.016: INFO: stderr: ""
Oct 24 02:35:25.016: INFO: stdout: "service/redis-slave created\n"
Oct 24 02:35:25.017: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 24 02:35:25.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-383'
Oct 24 02:35:25.340: INFO: stderr: ""
Oct 24 02:35:25.340: INFO: stdout: "service/redis-master created\n"
Oct 24 02:35:25.340: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 24 02:35:25.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-383'
Oct 24 02:35:25.692: INFO: stderr: ""
Oct 24 02:35:25.692: INFO: stdout: "service/frontend created\n"
Oct 24 02:35:25.693: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 24 02:35:25.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-383'
Oct 24 02:35:26.044: INFO: stderr: ""
Oct 24 02:35:26.044: INFO: stdout: "deployment.apps/frontend created\n"
Oct 24 02:35:26.045: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 24 02:35:26.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-383'
Oct 24 02:35:26.375: INFO: stderr: ""
Oct 24 02:35:26.375: INFO: stdout: "deployment.apps/redis-master created\n"
Oct 24 02:35:26.376: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 24 02:35:26.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-383'
Oct 24 02:35:26.711: INFO: stderr: ""
Oct 24 02:35:26.711: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct 24 02:35:26.711: INFO: Waiting for all frontend pods to be Running.
Oct 24 02:36:01.767: INFO: Waiting for frontend to serve content.
Oct 24 02:36:01.795: INFO: Trying to add a new entry to the guestbook.
Oct 24 02:36:01.814: INFO: Verifying that added entry can be retrieved.
Oct 24 02:36:01.839: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 24 02:36:06.870: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 24 02:36:11.897: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 24 02:36:16.926: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 24 02:36:21.954: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Oct 24 02:36:26.981: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Oct 24 02:36:32.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete --grace-period=0 --force -f - --namespace=kubectl-383'
Oct 24 02:36:32.336: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 02:36:32.336: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 24 02:36:32.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete --grace-period=0 --force -f - --namespace=kubectl-383'
Oct 24 02:36:32.534: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 02:36:32.535: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 24 02:36:32.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete --grace-period=0 --force -f - --namespace=kubectl-383'
Oct 24 02:36:32.745: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 02:36:32.745: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 24 02:36:32.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete --grace-period=0 --force -f - --namespace=kubectl-383'
Oct 24 02:36:32.926: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 02:36:32.926: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 24 02:36:32.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete --grace-period=0 --force -f - --namespace=kubectl-383'
Oct 24 02:36:33.095: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 02:36:33.095: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 24 02:36:33.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete --grace-period=0 --force -f - --namespace=kubectl-383'
Oct 24 02:36:33.262: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 02:36:33.262: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:36:33.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-383" for this suite.
Oct 24 02:37:01.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:37:01.428: INFO: namespace kubectl-383 deletion completed in 28.158142214s

• [SLOW TEST:96.800 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:37:01.429: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:37:01.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9161" for this suite.
Oct 24 02:37:07.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:37:07.635: INFO: namespace tables-9161 deletion completed in 6.149652892s

• [SLOW TEST:6.207 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:37:07.635: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 02:37:08.312: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 02:37:11.336: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:37:21.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2786" for this suite.
Oct 24 02:37:27.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:37:27.929: INFO: namespace webhook-2786 deletion completed in 6.189067065s
STEP: Destroying namespace "webhook-2786-markers" for this suite.
Oct 24 02:37:33.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:37:34.077: INFO: namespace webhook-2786-markers deletion completed in 6.14765688s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.459 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:37:34.096: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-g7zx
STEP: Creating a pod to test atomic-volume-subpath
Oct 24 02:37:34.158: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-g7zx" in namespace "subpath-8936" to be "success or failure"
Oct 24 02:37:34.162: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Pending", Reason="", readiness=false. Elapsed: 3.723578ms
Oct 24 02:37:36.168: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Running", Reason="", readiness=true. Elapsed: 2.009195615s
Oct 24 02:37:38.172: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Running", Reason="", readiness=true. Elapsed: 4.013867777s
Oct 24 02:37:40.178: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Running", Reason="", readiness=true. Elapsed: 6.019360922s
Oct 24 02:37:42.183: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Running", Reason="", readiness=true. Elapsed: 8.024452289s
Oct 24 02:37:44.188: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Running", Reason="", readiness=true. Elapsed: 10.029141806s
Oct 24 02:37:46.193: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Running", Reason="", readiness=true. Elapsed: 12.034514243s
Oct 24 02:37:48.198: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Running", Reason="", readiness=true. Elapsed: 14.039229525s
Oct 24 02:37:50.203: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Running", Reason="", readiness=true. Elapsed: 16.04452996s
Oct 24 02:37:52.208: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Running", Reason="", readiness=true. Elapsed: 18.049825458s
Oct 24 02:37:54.214: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Running", Reason="", readiness=true. Elapsed: 20.055139822s
Oct 24 02:37:56.218: INFO: Pod "pod-subpath-test-configmap-g7zx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.060004565s
STEP: Saw pod success
Oct 24 02:37:56.219: INFO: Pod "pod-subpath-test-configmap-g7zx" satisfied condition "success or failure"
Oct 24 02:37:56.222: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-subpath-test-configmap-g7zx container test-container-subpath-configmap-g7zx: <nil>
STEP: delete the pod
Oct 24 02:37:56.274: INFO: Waiting for pod pod-subpath-test-configmap-g7zx to disappear
Oct 24 02:37:56.277: INFO: Pod pod-subpath-test-configmap-g7zx no longer exists
STEP: Deleting pod pod-subpath-test-configmap-g7zx
Oct 24 02:37:56.278: INFO: Deleting pod "pod-subpath-test-configmap-g7zx" in namespace "subpath-8936"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:37:56.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8936" for this suite.
Oct 24 02:38:02.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:38:02.443: INFO: namespace subpath-8936 deletion completed in 6.157494859s

• [SLOW TEST:28.348 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:38:02.444: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 02:38:03.327: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 24 02:38:05.340: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707481483, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707481483, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707481483, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707481483, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 02:38:08.364: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:38:08.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-569" for this suite.
Oct 24 02:38:20.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:38:20.622: INFO: namespace webhook-569 deletion completed in 12.151363815s
STEP: Destroying namespace "webhook-569-markers" for this suite.
Oct 24 02:38:26.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:38:26.776: INFO: namespace webhook-569-markers deletion completed in 6.153890375s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.351 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:38:26.795: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:38:50.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-625" for this suite.
Oct 24 02:38:56.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:38:56.272: INFO: namespace container-runtime-625 deletion completed in 6.149341668s

• [SLOW TEST:29.477 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:38:56.272: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Oct 24 02:38:56.320: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-000479258 proxy --unix-socket=/tmp/kubectl-proxy-unix337580217/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:38:56.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4098" for this suite.
Oct 24 02:39:02.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:39:02.627: INFO: namespace kubectl-4098 deletion completed in 6.146384761s

• [SLOW TEST:6.355 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:39:02.627: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:39:02.679: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-38d56f3e-41fb-42a9-943f-0e85162dfb6c" in namespace "security-context-test-5033" to be "success or failure"
Oct 24 02:39:02.683: INFO: Pod "alpine-nnp-false-38d56f3e-41fb-42a9-943f-0e85162dfb6c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.690113ms
Oct 24 02:39:04.688: INFO: Pod "alpine-nnp-false-38d56f3e-41fb-42a9-943f-0e85162dfb6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008898406s
Oct 24 02:39:06.694: INFO: Pod "alpine-nnp-false-38d56f3e-41fb-42a9-943f-0e85162dfb6c": Phase="Running", Reason="", readiness=true. Elapsed: 4.014327233s
Oct 24 02:39:08.700: INFO: Pod "alpine-nnp-false-38d56f3e-41fb-42a9-943f-0e85162dfb6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020256313s
Oct 24 02:39:08.700: INFO: Pod "alpine-nnp-false-38d56f3e-41fb-42a9-943f-0e85162dfb6c" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:39:08.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5033" for this suite.
Oct 24 02:39:14.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:39:14.877: INFO: namespace security-context-test-5033 deletion completed in 6.15776811s

• [SLOW TEST:12.250 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:39:14.877: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-34083d8d-ce46-43da-bdf6-1dcc664c0cc1
STEP: Creating a pod to test consume configMaps
Oct 24 02:39:14.943: INFO: Waiting up to 5m0s for pod "pod-configmaps-813b78da-3806-4e63-b569-f775bfb1d197" in namespace "configmap-8790" to be "success or failure"
Oct 24 02:39:14.949: INFO: Pod "pod-configmaps-813b78da-3806-4e63-b569-f775bfb1d197": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012195ms
Oct 24 02:39:16.953: INFO: Pod "pod-configmaps-813b78da-3806-4e63-b569-f775bfb1d197": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010328714s
STEP: Saw pod success
Oct 24 02:39:16.953: INFO: Pod "pod-configmaps-813b78da-3806-4e63-b569-f775bfb1d197" satisfied condition "success or failure"
Oct 24 02:39:16.957: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-configmaps-813b78da-3806-4e63-b569-f775bfb1d197 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 02:39:16.987: INFO: Waiting for pod pod-configmaps-813b78da-3806-4e63-b569-f775bfb1d197 to disappear
Oct 24 02:39:16.991: INFO: Pod pod-configmaps-813b78da-3806-4e63-b569-f775bfb1d197 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:39:16.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8790" for this suite.
Oct 24 02:39:23.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:39:23.148: INFO: namespace configmap-8790 deletion completed in 6.152143534s

• [SLOW TEST:8.271 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:39:23.149: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 24 02:39:23.225: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:23.229: INFO: Number of nodes with available pods: 0
Oct 24 02:39:23.229: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:24.236: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:24.240: INFO: Number of nodes with available pods: 0
Oct 24 02:39:24.240: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:25.235: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:25.239: INFO: Number of nodes with available pods: 2
Oct 24 02:39:25.239: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 24 02:39:25.258: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:25.262: INFO: Number of nodes with available pods: 1
Oct 24 02:39:25.262: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:26.269: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:26.275: INFO: Number of nodes with available pods: 1
Oct 24 02:39:26.275: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:27.268: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:27.272: INFO: Number of nodes with available pods: 1
Oct 24 02:39:27.272: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:28.268: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:28.272: INFO: Number of nodes with available pods: 1
Oct 24 02:39:28.272: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:29.268: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:29.274: INFO: Number of nodes with available pods: 1
Oct 24 02:39:29.274: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:30.268: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:30.272: INFO: Number of nodes with available pods: 1
Oct 24 02:39:30.272: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:31.269: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:31.274: INFO: Number of nodes with available pods: 1
Oct 24 02:39:31.274: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:32.268: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:32.273: INFO: Number of nodes with available pods: 1
Oct 24 02:39:32.273: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:33.268: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:33.272: INFO: Number of nodes with available pods: 1
Oct 24 02:39:33.272: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:34.269: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:34.273: INFO: Number of nodes with available pods: 1
Oct 24 02:39:34.273: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:35.269: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:35.274: INFO: Number of nodes with available pods: 1
Oct 24 02:39:35.274: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:36.268: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:36.273: INFO: Number of nodes with available pods: 1
Oct 24 02:39:36.273: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:37.269: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:37.273: INFO: Number of nodes with available pods: 1
Oct 24 02:39:37.273: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:38.269: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:38.275: INFO: Number of nodes with available pods: 1
Oct 24 02:39:38.275: INFO: Node mip-bd-vm40.mip.storage.hpecorp.net is running more than one daemon pod
Oct 24 02:39:39.269: INFO: DaemonSet pods can't tolerate node mip-bd-vm39.mip.storage.hpecorp.net with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct 24 02:39:39.275: INFO: Number of nodes with available pods: 2
Oct 24 02:39:39.275: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1836, will wait for the garbage collector to delete the pods
Oct 24 02:39:39.342: INFO: Deleting DaemonSet.extensions daemon-set took: 10.007702ms
Oct 24 02:39:39.743: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.350025ms
Oct 24 02:39:47.247: INFO: Number of nodes with available pods: 0
Oct 24 02:39:47.247: INFO: Number of running nodes: 0, number of available pods: 0
Oct 24 02:39:47.250: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1836/daemonsets","resourceVersion":"26124"},"items":null}

Oct 24 02:39:47.254: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1836/pods","resourceVersion":"26124"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:39:47.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1836" for this suite.
Oct 24 02:39:53.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:39:53.438: INFO: namespace daemonsets-1836 deletion completed in 6.166271497s

• [SLOW TEST:30.290 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:39:53.439: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Oct 24 02:39:53.488: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:40:15.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8533" for this suite.
Oct 24 02:40:21.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:40:21.817: INFO: namespace crd-publish-openapi-8533 deletion completed in 6.146066626s

• [SLOW TEST:28.379 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:40:21.818: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Oct 24 02:40:21.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-8910'
Oct 24 02:40:22.316: INFO: stderr: ""
Oct 24 02:40:22.316: INFO: stdout: "pod/pause created\n"
Oct 24 02:40:22.316: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 24 02:40:22.316: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8910" to be "running and ready"
Oct 24 02:40:22.321: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.109172ms
Oct 24 02:40:24.326: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009488551s
Oct 24 02:40:24.326: INFO: Pod "pause" satisfied condition "running and ready"
Oct 24 02:40:24.326: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 24 02:40:24.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 label pods pause testing-label=testing-label-value --namespace=kubectl-8910'
Oct 24 02:40:24.500: INFO: stderr: ""
Oct 24 02:40:24.500: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 24 02:40:24.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pod pause -L testing-label --namespace=kubectl-8910'
Oct 24 02:40:24.661: INFO: stderr: ""
Oct 24 02:40:24.661: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 24 02:40:24.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 label pods pause testing-label- --namespace=kubectl-8910'
Oct 24 02:40:24.831: INFO: stderr: ""
Oct 24 02:40:24.831: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 24 02:40:24.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pod pause -L testing-label --namespace=kubectl-8910'
Oct 24 02:40:24.991: INFO: stderr: ""
Oct 24 02:40:24.991: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Oct 24 02:40:24.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete --grace-period=0 --force -f - --namespace=kubectl-8910'
Oct 24 02:40:25.156: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 02:40:25.156: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 24 02:40:25.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get rc,svc -l name=pause --no-headers --namespace=kubectl-8910'
Oct 24 02:40:25.330: INFO: stderr: "No resources found in kubectl-8910 namespace.\n"
Oct 24 02:40:25.330: INFO: stdout: ""
Oct 24 02:40:25.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -l name=pause --namespace=kubectl-8910 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 02:40:25.493: INFO: stderr: ""
Oct 24 02:40:25.493: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:40:25.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8910" for this suite.
Oct 24 02:40:31.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:40:31.673: INFO: namespace kubectl-8910 deletion completed in 6.174312584s

• [SLOW TEST:9.856 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:40:31.673: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct 24 02:40:34.275: INFO: Successfully updated pod "annotationupdate1f1a7336-978c-49d3-a6cc-af8b617f2a3c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:40:38.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4525" for this suite.
Oct 24 02:40:50.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:40:50.479: INFO: namespace downward-api-4525 deletion completed in 12.149429246s

• [SLOW TEST:18.806 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:40:50.479: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-16.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-16.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 24 02:40:54.616: INFO: DNS probes using dns-16/dns-test-d055009c-723f-4970-aac2-33cdfc39e31f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:40:54.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-16" for this suite.
Oct 24 02:41:00.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:41:00.787: INFO: namespace dns-16 deletion completed in 6.146966674s

• [SLOW TEST:10.308 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:41:00.788: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-f73e4c5b-83f9-4508-9dc4-8cf7334d6aaf
STEP: Creating a pod to test consume secrets
Oct 24 02:41:00.850: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c65693f0-50a6-4afc-8b5e-92a724ea1015" in namespace "projected-6647" to be "success or failure"
Oct 24 02:41:00.855: INFO: Pod "pod-projected-secrets-c65693f0-50a6-4afc-8b5e-92a724ea1015": Phase="Pending", Reason="", readiness=false. Elapsed: 4.74025ms
Oct 24 02:41:02.859: INFO: Pod "pod-projected-secrets-c65693f0-50a6-4afc-8b5e-92a724ea1015": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009197692s
Oct 24 02:41:04.864: INFO: Pod "pod-projected-secrets-c65693f0-50a6-4afc-8b5e-92a724ea1015": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014583723s
STEP: Saw pod success
Oct 24 02:41:04.865: INFO: Pod "pod-projected-secrets-c65693f0-50a6-4afc-8b5e-92a724ea1015" satisfied condition "success or failure"
Oct 24 02:41:04.868: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-secrets-c65693f0-50a6-4afc-8b5e-92a724ea1015 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 24 02:41:04.897: INFO: Waiting for pod pod-projected-secrets-c65693f0-50a6-4afc-8b5e-92a724ea1015 to disappear
Oct 24 02:41:04.900: INFO: Pod pod-projected-secrets-c65693f0-50a6-4afc-8b5e-92a724ea1015 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:41:04.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6647" for this suite.
Oct 24 02:41:10.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:41:11.053: INFO: namespace projected-6647 deletion completed in 6.148583769s

• [SLOW TEST:10.265 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:41:11.054: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 24 02:41:13.125: INFO: &Pod{ObjectMeta:{send-events-c7c3927e-eaba-47b9-bbb9-8f14f56592f1  events-1776 /api/v1/namespaces/events-1776/pods/send-events-c7c3927e-eaba-47b9-bbb9-8f14f56592f1 390d65e6-7bb3-45da-8d85-610aaf98650f 26425 0 2019-10-24 02:41:11 +0000 UTC <nil> <nil> map[name:foo time:101066112] map[cni.projectcalico.org/podIP:10.244.1.27/32] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-5p8mr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-5p8mr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-5p8mr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:41:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:41:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:41:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:41:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.1.27,StartTime:2019-10-24 02:41:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 02:41:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://b9e0f92b03f8ed2fa52df878aa849a43d247e7fb91f0956cfb943b471d9ad94a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.27,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Oct 24 02:41:15.132: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 24 02:41:17.138: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:41:17.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1776" for this suite.
Oct 24 02:42:01.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:42:01.305: INFO: namespace events-1776 deletion completed in 44.153849238s

• [SLOW TEST:50.251 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:42:01.305: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-6cc2d4d1-cdc4-4593-b3b3-3ac7336c0561 in namespace container-probe-2706
Oct 24 02:42:03.374: INFO: Started pod liveness-6cc2d4d1-cdc4-4593-b3b3-3ac7336c0561 in namespace container-probe-2706
STEP: checking the pod's current state and verifying that restartCount is present
Oct 24 02:42:03.377: INFO: Initial restart count of pod liveness-6cc2d4d1-cdc4-4593-b3b3-3ac7336c0561 is 0
Oct 24 02:42:23.434: INFO: Restart count of pod container-probe-2706/liveness-6cc2d4d1-cdc4-4593-b3b3-3ac7336c0561 is now 1 (20.056580346s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:42:23.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2706" for this suite.
Oct 24 02:42:29.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:42:29.604: INFO: namespace container-probe-2706 deletion completed in 6.148256563s

• [SLOW TEST:28.299 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:42:29.604: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 24 02:42:29.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3357'
Oct 24 02:42:29.835: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 24 02:42:29.835: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Oct 24 02:42:29.844: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct 24 02:42:29.858: INFO: scanned /root for discovery docs: <nil>
Oct 24 02:42:29.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-3357'
Oct 24 02:42:45.790: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 24 02:42:45.790: INFO: stdout: "Created e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a\nScaling up e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Oct 24 02:42:45.790: INFO: stdout: "Created e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a\nScaling up e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Oct 24 02:42:45.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-3357'
Oct 24 02:42:45.967: INFO: stderr: ""
Oct 24 02:42:45.967: INFO: stdout: "e2e-test-httpd-rc-4zqcv e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a-pjhp8 "
STEP: Replicas for run=e2e-test-httpd-rc: expected=1 actual=2
Oct 24 02:42:50.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-3357'
Oct 24 02:42:51.150: INFO: stderr: ""
Oct 24 02:42:51.150: INFO: stdout: "e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a-pjhp8 "
Oct 24 02:42:51.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a-pjhp8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3357'
Oct 24 02:42:51.313: INFO: stderr: ""
Oct 24 02:42:51.313: INFO: stdout: "true"
Oct 24 02:42:51.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a-pjhp8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3357'
Oct 24 02:42:51.476: INFO: stderr: ""
Oct 24 02:42:51.476: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Oct 24 02:42:51.476: INFO: e2e-test-httpd-rc-b17db7073fd9089cd221dc64f160a41a-pjhp8 is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Oct 24 02:42:51.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete rc e2e-test-httpd-rc --namespace=kubectl-3357'
Oct 24 02:42:51.644: INFO: stderr: ""
Oct 24 02:42:51.645: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:42:51.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3357" for this suite.
Oct 24 02:42:57.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:42:57.822: INFO: namespace kubectl-3357 deletion completed in 6.172097109s

• [SLOW TEST:28.218 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:42:57.824: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:42:59.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4970" for this suite.
Oct 24 02:43:43.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:43:44.095: INFO: namespace kubelet-test-4970 deletion completed in 44.148798294s

• [SLOW TEST:46.271 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:43:44.097: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 24 02:43:48.208: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 02:43:48.213: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 02:43:50.213: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 02:43:50.217: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 24 02:43:52.213: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 24 02:43:52.218: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:43:52.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6901" for this suite.
Oct 24 02:44:20.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:44:20.367: INFO: namespace container-lifecycle-hook-6901 deletion completed in 28.142803461s

• [SLOW TEST:36.270 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:44:20.367: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-3a37c0f6-0ec0-47b2-b08f-5e12f841d13a
Oct 24 02:44:20.421: INFO: Pod name my-hostname-basic-3a37c0f6-0ec0-47b2-b08f-5e12f841d13a: Found 0 pods out of 1
Oct 24 02:44:25.426: INFO: Pod name my-hostname-basic-3a37c0f6-0ec0-47b2-b08f-5e12f841d13a: Found 1 pods out of 1
Oct 24 02:44:25.426: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-3a37c0f6-0ec0-47b2-b08f-5e12f841d13a" are running
Oct 24 02:44:25.430: INFO: Pod "my-hostname-basic-3a37c0f6-0ec0-47b2-b08f-5e12f841d13a-j29zv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 02:44:20 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 02:44:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 02:44:22 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-24 02:44:20 +0000 UTC Reason: Message:}])
Oct 24 02:44:25.430: INFO: Trying to dial the pod
Oct 24 02:44:30.447: INFO: Controller my-hostname-basic-3a37c0f6-0ec0-47b2-b08f-5e12f841d13a: Got expected result from replica 1 [my-hostname-basic-3a37c0f6-0ec0-47b2-b08f-5e12f841d13a-j29zv]: "my-hostname-basic-3a37c0f6-0ec0-47b2-b08f-5e12f841d13a-j29zv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:44:30.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7667" for this suite.
Oct 24 02:44:36.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:44:36.626: INFO: namespace replication-controller-7667 deletion completed in 6.173500613s

• [SLOW TEST:16.259 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:44:36.627: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 24 02:44:36.697: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-a 7f7b0ad7-42b8-4603-b23b-81e177e2fa37 26968 0 2019-10-24 02:44:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 24 02:44:36.697: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-a 7f7b0ad7-42b8-4603-b23b-81e177e2fa37 26968 0 2019-10-24 02:44:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 24 02:44:46.708: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-a 7f7b0ad7-42b8-4603-b23b-81e177e2fa37 26984 0 2019-10-24 02:44:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 24 02:44:46.708: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-a 7f7b0ad7-42b8-4603-b23b-81e177e2fa37 26984 0 2019-10-24 02:44:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 24 02:44:56.719: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-a 7f7b0ad7-42b8-4603-b23b-81e177e2fa37 26999 0 2019-10-24 02:44:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 24 02:44:56.719: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-a 7f7b0ad7-42b8-4603-b23b-81e177e2fa37 26999 0 2019-10-24 02:44:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 24 02:45:06.729: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-a 7f7b0ad7-42b8-4603-b23b-81e177e2fa37 27014 0 2019-10-24 02:44:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 24 02:45:06.729: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-a 7f7b0ad7-42b8-4603-b23b-81e177e2fa37 27014 0 2019-10-24 02:44:36 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 24 02:45:16.740: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-b e77a0f28-e0e2-47f9-a319-8700e5968dc9 27031 0 2019-10-24 02:45:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 24 02:45:16.740: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-b e77a0f28-e0e2-47f9-a319-8700e5968dc9 27031 0 2019-10-24 02:45:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 24 02:45:26.749: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-b e77a0f28-e0e2-47f9-a319-8700e5968dc9 27047 0 2019-10-24 02:45:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 24 02:45:26.749: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9311 /api/v1/namespaces/watch-9311/configmaps/e2e-watch-test-configmap-b e77a0f28-e0e2-47f9-a319-8700e5968dc9 27047 0 2019-10-24 02:45:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:45:36.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9311" for this suite.
Oct 24 02:45:42.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:45:42.905: INFO: namespace watch-9311 deletion completed in 6.148945615s

• [SLOW TEST:66.279 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:45:42.906: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 24 02:45:42.973: INFO: Waiting up to 5m0s for pod "pod-225d5619-f411-4c3d-9fca-8202036a2f35" in namespace "emptydir-3434" to be "success or failure"
Oct 24 02:45:42.977: INFO: Pod "pod-225d5619-f411-4c3d-9fca-8202036a2f35": Phase="Pending", Reason="", readiness=false. Elapsed: 4.657368ms
Oct 24 02:45:44.983: INFO: Pod "pod-225d5619-f411-4c3d-9fca-8202036a2f35": Phase="Running", Reason="", readiness=true. Elapsed: 2.010142252s
Oct 24 02:45:46.987: INFO: Pod "pod-225d5619-f411-4c3d-9fca-8202036a2f35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014791822s
STEP: Saw pod success
Oct 24 02:45:46.987: INFO: Pod "pod-225d5619-f411-4c3d-9fca-8202036a2f35" satisfied condition "success or failure"
Oct 24 02:45:46.991: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-225d5619-f411-4c3d-9fca-8202036a2f35 container test-container: <nil>
STEP: delete the pod
Oct 24 02:45:47.036: INFO: Waiting for pod pod-225d5619-f411-4c3d-9fca-8202036a2f35 to disappear
Oct 24 02:45:47.042: INFO: Pod pod-225d5619-f411-4c3d-9fca-8202036a2f35 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:45:47.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3434" for this suite.
Oct 24 02:45:53.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:45:53.201: INFO: namespace emptydir-3434 deletion completed in 6.153548953s

• [SLOW TEST:10.295 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:45:53.201: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-1c9e131d-cd80-4b44-8264-3156d17741ec
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-1c9e131d-cd80-4b44-8264-3156d17741ec
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:45:57.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8670" for this suite.
Oct 24 02:46:09.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:46:09.485: INFO: namespace projected-8670 deletion completed in 12.152254531s

• [SLOW TEST:16.284 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:46:09.486: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 24 02:46:09.545: INFO: Waiting up to 5m0s for pod "pod-5e5dab6c-3f4c-4344-be81-bc35595b1256" in namespace "emptydir-5315" to be "success or failure"
Oct 24 02:46:09.549: INFO: Pod "pod-5e5dab6c-3f4c-4344-be81-bc35595b1256": Phase="Pending", Reason="", readiness=false. Elapsed: 4.365973ms
Oct 24 02:46:11.555: INFO: Pod "pod-5e5dab6c-3f4c-4344-be81-bc35595b1256": Phase="Running", Reason="", readiness=true. Elapsed: 2.010074296s
Oct 24 02:46:13.561: INFO: Pod "pod-5e5dab6c-3f4c-4344-be81-bc35595b1256": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01592015s
STEP: Saw pod success
Oct 24 02:46:13.561: INFO: Pod "pod-5e5dab6c-3f4c-4344-be81-bc35595b1256" satisfied condition "success or failure"
Oct 24 02:46:13.565: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-5e5dab6c-3f4c-4344-be81-bc35595b1256 container test-container: <nil>
STEP: delete the pod
Oct 24 02:46:13.593: INFO: Waiting for pod pod-5e5dab6c-3f4c-4344-be81-bc35595b1256 to disappear
Oct 24 02:46:13.597: INFO: Pod pod-5e5dab6c-3f4c-4344-be81-bc35595b1256 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:46:13.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5315" for this suite.
Oct 24 02:46:19.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:46:19.758: INFO: namespace emptydir-5315 deletion completed in 6.156733386s

• [SLOW TEST:10.272 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:46:19.759: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1774
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 24 02:46:19.810: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 24 02:46:39.900: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.63:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1774 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 02:46:39.901: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 02:46:40.053: INFO: Found all expected endpoints: [netserver-0]
Oct 24 02:46:40.058: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.38:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1774 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 02:46:40.058: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 02:46:40.216: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:46:40.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1774" for this suite.
Oct 24 02:46:52.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:46:52.374: INFO: namespace pod-network-test-1774 deletion completed in 12.152111427s

• [SLOW TEST:32.615 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:46:52.375: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct 24 02:46:52.428: INFO: Waiting up to 5m0s for pod "downward-api-a75270ca-245c-4200-8e54-71ad7ac29345" in namespace "downward-api-2" to be "success or failure"
Oct 24 02:46:52.434: INFO: Pod "downward-api-a75270ca-245c-4200-8e54-71ad7ac29345": Phase="Pending", Reason="", readiness=false. Elapsed: 5.527673ms
Oct 24 02:46:54.439: INFO: Pod "downward-api-a75270ca-245c-4200-8e54-71ad7ac29345": Phase="Running", Reason="", readiness=true. Elapsed: 2.010611673s
Oct 24 02:46:56.445: INFO: Pod "downward-api-a75270ca-245c-4200-8e54-71ad7ac29345": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01675612s
STEP: Saw pod success
Oct 24 02:46:56.445: INFO: Pod "downward-api-a75270ca-245c-4200-8e54-71ad7ac29345" satisfied condition "success or failure"
Oct 24 02:46:56.449: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod downward-api-a75270ca-245c-4200-8e54-71ad7ac29345 container dapi-container: <nil>
STEP: delete the pod
Oct 24 02:46:56.477: INFO: Waiting for pod downward-api-a75270ca-245c-4200-8e54-71ad7ac29345 to disappear
Oct 24 02:46:56.482: INFO: Pod downward-api-a75270ca-245c-4200-8e54-71ad7ac29345 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:46:56.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2" for this suite.
Oct 24 02:47:02.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:47:02.633: INFO: namespace downward-api-2 deletion completed in 6.14655821s

• [SLOW TEST:10.258 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:47:02.634: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 24 02:47:02.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4058'
Oct 24 02:47:03.001: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 24 02:47:03.001: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Oct 24 02:47:03.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete jobs e2e-test-httpd-job --namespace=kubectl-4058'
Oct 24 02:47:03.187: INFO: stderr: ""
Oct 24 02:47:03.187: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:47:03.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4058" for this suite.
Oct 24 02:47:09.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:47:09.337: INFO: namespace kubectl-4058 deletion completed in 6.144149987s

• [SLOW TEST:6.703 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:47:09.337: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 24 02:47:09.403: INFO: Waiting up to 5m0s for pod "pod-09b7891c-fc92-444e-bb90-bd3c6f51d84b" in namespace "emptydir-6666" to be "success or failure"
Oct 24 02:47:09.408: INFO: Pod "pod-09b7891c-fc92-444e-bb90-bd3c6f51d84b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.773973ms
Oct 24 02:47:11.413: INFO: Pod "pod-09b7891c-fc92-444e-bb90-bd3c6f51d84b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009778758s
STEP: Saw pod success
Oct 24 02:47:11.413: INFO: Pod "pod-09b7891c-fc92-444e-bb90-bd3c6f51d84b" satisfied condition "success or failure"
Oct 24 02:47:11.417: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-09b7891c-fc92-444e-bb90-bd3c6f51d84b container test-container: <nil>
STEP: delete the pod
Oct 24 02:47:11.444: INFO: Waiting for pod pod-09b7891c-fc92-444e-bb90-bd3c6f51d84b to disappear
Oct 24 02:47:11.447: INFO: Pod pod-09b7891c-fc92-444e-bb90-bd3c6f51d84b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:47:11.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6666" for this suite.
Oct 24 02:47:17.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:47:17.598: INFO: namespace emptydir-6666 deletion completed in 6.145616925s

• [SLOW TEST:8.260 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:47:17.598: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3500
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Oct 24 02:47:17.672: INFO: Found 0 stateful pods, waiting for 3
Oct 24 02:47:27.680: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 02:47:27.680: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 02:47:27.680: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 02:47:27.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-3500 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 02:47:28.042: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 02:47:28.042: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 02:47:28.042: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Oct 24 02:47:38.081: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 24 02:47:48.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-3500 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 02:47:48.448: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 02:47:48.448: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 02:47:48.448: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 02:48:08.476: INFO: Waiting for StatefulSet statefulset-3500/ss2 to complete update
Oct 24 02:48:08.476: INFO: Waiting for Pod statefulset-3500/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Oct 24 02:48:18.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-3500 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 02:48:18.817: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 02:48:18.817: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 02:48:18.817: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 02:48:28.856: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 24 02:48:38.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-3500 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 02:48:39.220: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 02:48:39.220: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 02:48:39.220: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 02:48:59.250: INFO: Waiting for StatefulSet statefulset-3500/ss2 to complete update
Oct 24 02:48:59.250: INFO: Waiting for Pod statefulset-3500/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 24 02:49:09.261: INFO: Deleting all statefulset in ns statefulset-3500
Oct 24 02:49:09.266: INFO: Scaling statefulset ss2 to 0
Oct 24 02:49:29.287: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 02:49:29.291: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:49:29.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3500" for this suite.
Oct 24 02:49:41.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:49:41.467: INFO: namespace statefulset-3500 deletion completed in 12.152174253s

• [SLOW TEST:143.869 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:49:41.468: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Oct 24 02:49:41.512: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:50:06.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1788" for this suite.
Oct 24 02:50:12.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:50:12.414: INFO: namespace crd-publish-openapi-1788 deletion completed in 6.137326027s

• [SLOW TEST:30.946 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:50:12.415: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-6a3471d6-4723-43e7-8283-ef274bc38b80 in namespace container-probe-4909
Oct 24 02:50:16.478: INFO: Started pod busybox-6a3471d6-4723-43e7-8283-ef274bc38b80 in namespace container-probe-4909
STEP: checking the pod's current state and verifying that restartCount is present
Oct 24 02:50:16.482: INFO: Initial restart count of pod busybox-6a3471d6-4723-43e7-8283-ef274bc38b80 is 0
Oct 24 02:51:06.622: INFO: Restart count of pod container-probe-4909/busybox-6a3471d6-4723-43e7-8283-ef274bc38b80 is now 1 (50.14014894s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:51:06.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4909" for this suite.
Oct 24 02:51:12.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:51:12.812: INFO: namespace container-probe-4909 deletion completed in 6.168725342s

• [SLOW TEST:60.397 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:51:12.812: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Oct 24 02:51:13.918: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1024 02:51:13.918103      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 24 02:51:13.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9974" for this suite.
Oct 24 02:51:19.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:51:20.067: INFO: namespace gc-9974 deletion completed in 6.143539867s

• [SLOW TEST:7.255 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:51:20.067: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-5573
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5573 to expose endpoints map[]
Oct 24 02:51:20.128: INFO: Get endpoints failed (4.259175ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct 24 02:51:21.134: INFO: successfully validated that service endpoint-test2 in namespace services-5573 exposes endpoints map[] (1.009469768s elapsed)
STEP: Creating pod pod1 in namespace services-5573
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5573 to expose endpoints map[pod1:[80]]
Oct 24 02:51:23.170: INFO: successfully validated that service endpoint-test2 in namespace services-5573 exposes endpoints map[pod1:[80]] (2.025896651s elapsed)
STEP: Creating pod pod2 in namespace services-5573
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5573 to expose endpoints map[pod1:[80] pod2:[80]]
Oct 24 02:51:25.221: INFO: successfully validated that service endpoint-test2 in namespace services-5573 exposes endpoints map[pod1:[80] pod2:[80]] (2.045483128s elapsed)
STEP: Deleting pod pod1 in namespace services-5573
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5573 to expose endpoints map[pod2:[80]]
Oct 24 02:51:26.247: INFO: successfully validated that service endpoint-test2 in namespace services-5573 exposes endpoints map[pod2:[80]] (1.018505862s elapsed)
STEP: Deleting pod pod2 in namespace services-5573
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5573 to expose endpoints map[]
Oct 24 02:51:27.264: INFO: successfully validated that service endpoint-test2 in namespace services-5573 exposes endpoints map[] (1.010401981s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:51:27.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5573" for this suite.
Oct 24 02:51:39.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:51:39.451: INFO: namespace services-5573 deletion completed in 12.153229387s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.384 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:51:39.451: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-880
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-880
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-880
Oct 24 02:51:39.522: INFO: Found 0 stateful pods, waiting for 1
Oct 24 02:51:49.527: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 24 02:51:49.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-880 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 02:51:49.856: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 02:51:49.856: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 02:51:49.856: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 02:51:49.861: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 24 02:51:59.866: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 02:51:59.866: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 02:51:59.882: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 24 02:51:59.882: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:39 +0000 UTC  }]
Oct 24 02:51:59.882: INFO: 
Oct 24 02:51:59.882: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 24 02:52:00.888: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995814319s
Oct 24 02:52:01.909: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989806073s
Oct 24 02:52:02.914: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.96915425s
Oct 24 02:52:03.920: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.963803948s
Oct 24 02:52:04.925: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.958087318s
Oct 24 02:52:05.932: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.952429579s
Oct 24 02:52:06.943: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.945768601s
Oct 24 02:52:07.950: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.934962414s
Oct 24 02:52:08.957: INFO: Verifying statefulset ss doesn't scale past 3 for another 927.825111ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-880
Oct 24 02:52:09.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-880 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 02:52:10.310: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct 24 02:52:10.310: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 02:52:10.310: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 02:52:10.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-880 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 02:52:10.644: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 24 02:52:10.644: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 02:52:10.644: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 02:52:10.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-880 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct 24 02:52:10.990: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct 24 02:52:10.990: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct 24 02:52:10.990: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct 24 02:52:10.995: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 02:52:10.996: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 24 02:52:10.996: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 24 02:52:11.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-880 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 02:52:11.324: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 02:52:11.325: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 02:52:11.325: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 02:52:11.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-880 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 02:52:11.675: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 02:52:11.675: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 02:52:11.675: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 02:52:11.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=statefulset-880 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct 24 02:52:12.000: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct 24 02:52:12.000: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct 24 02:52:12.000: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct 24 02:52:12.000: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 02:52:12.004: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 24 02:52:22.013: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 02:52:22.013: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 02:52:22.013: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 24 02:52:22.027: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 24 02:52:22.028: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:39 +0000 UTC  }]
Oct 24 02:52:22.028: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:59 +0000 UTC  }]
Oct 24 02:52:22.028: INFO: ss-2  mip-bd-vm40.mip.storage.hpecorp.net  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:59 +0000 UTC  }]
Oct 24 02:52:22.028: INFO: 
Oct 24 02:52:22.028: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 24 02:52:23.035: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 24 02:52:23.036: INFO: ss-0  mip-bd-vm40.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:39 +0000 UTC  }]
Oct 24 02:52:23.036: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:59 +0000 UTC  }]
Oct 24 02:52:23.036: INFO: ss-2  mip-bd-vm40.mip.storage.hpecorp.net  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:59 +0000 UTC  }]
Oct 24 02:52:23.036: INFO: 
Oct 24 02:52:23.036: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 24 02:52:24.044: INFO: POD   NODE                                 PHASE    GRACE  CONDITIONS
Oct 24 02:52:24.044: INFO: ss-1  mip-bd-vm41.mip.storage.hpecorp.net  Running  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:52:12 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-24 02:51:59 +0000 UTC  }]
Oct 24 02:52:24.044: INFO: 
Oct 24 02:52:24.044: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 24 02:52:25.048: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.978665175s
Oct 24 02:52:26.054: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.974297425s
Oct 24 02:52:27.058: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.969120067s
Oct 24 02:52:28.064: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.964223774s
Oct 24 02:52:29.069: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.958995109s
Oct 24 02:52:30.074: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.954026005s
Oct 24 02:52:31.079: INFO: Verifying statefulset ss doesn't scale past 0 for another 948.422653ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-880
Oct 24 02:52:32.087: INFO: Scaling statefulset ss to 0
Oct 24 02:52:32.100: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct 24 02:52:32.104: INFO: Deleting all statefulset in ns statefulset-880
Oct 24 02:52:32.107: INFO: Scaling statefulset ss to 0
Oct 24 02:52:32.119: INFO: Waiting for statefulset status.replicas updated to 0
Oct 24 02:52:32.123: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:52:32.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-880" for this suite.
Oct 24 02:52:44.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:52:44.301: INFO: namespace statefulset-880 deletion completed in 12.156475773s

• [SLOW TEST:64.849 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:52:44.301: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-676f9cda-1298-4f4a-b90e-3088fa0d0b01 in namespace container-probe-7887
Oct 24 02:52:46.368: INFO: Started pod liveness-676f9cda-1298-4f4a-b90e-3088fa0d0b01 in namespace container-probe-7887
STEP: checking the pod's current state and verifying that restartCount is present
Oct 24 02:52:46.372: INFO: Initial restart count of pod liveness-676f9cda-1298-4f4a-b90e-3088fa0d0b01 is 0
Oct 24 02:52:58.407: INFO: Restart count of pod container-probe-7887/liveness-676f9cda-1298-4f4a-b90e-3088fa0d0b01 is now 1 (12.035404289s elapsed)
Oct 24 02:53:18.459: INFO: Restart count of pod container-probe-7887/liveness-676f9cda-1298-4f4a-b90e-3088fa0d0b01 is now 2 (32.087096102s elapsed)
Oct 24 02:53:38.508: INFO: Restart count of pod container-probe-7887/liveness-676f9cda-1298-4f4a-b90e-3088fa0d0b01 is now 3 (52.136742952s elapsed)
Oct 24 02:53:58.561: INFO: Restart count of pod container-probe-7887/liveness-676f9cda-1298-4f4a-b90e-3088fa0d0b01 is now 4 (1m12.189450108s elapsed)
Oct 24 02:55:02.737: INFO: Restart count of pod container-probe-7887/liveness-676f9cda-1298-4f4a-b90e-3088fa0d0b01 is now 5 (2m16.365264377s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:55:02.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7887" for this suite.
Oct 24 02:55:08.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:55:08.908: INFO: namespace container-probe-7887 deletion completed in 6.150183642s

• [SLOW TEST:144.607 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:55:08.908: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-5205f673-cb56-475b-800d-8670bfca11f1
STEP: Creating a pod to test consume secrets
Oct 24 02:55:09.031: INFO: Waiting up to 5m0s for pod "pod-secrets-37e6f5ed-accc-455a-b15a-771eb83a3ca3" in namespace "secrets-9528" to be "success or failure"
Oct 24 02:55:09.038: INFO: Pod "pod-secrets-37e6f5ed-accc-455a-b15a-771eb83a3ca3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.573583ms
Oct 24 02:55:11.043: INFO: Pod "pod-secrets-37e6f5ed-accc-455a-b15a-771eb83a3ca3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012493169s
STEP: Saw pod success
Oct 24 02:55:11.043: INFO: Pod "pod-secrets-37e6f5ed-accc-455a-b15a-771eb83a3ca3" satisfied condition "success or failure"
Oct 24 02:55:11.047: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-secrets-37e6f5ed-accc-455a-b15a-771eb83a3ca3 container secret-volume-test: <nil>
STEP: delete the pod
Oct 24 02:55:11.096: INFO: Waiting for pod pod-secrets-37e6f5ed-accc-455a-b15a-771eb83a3ca3 to disappear
Oct 24 02:55:11.101: INFO: Pod pod-secrets-37e6f5ed-accc-455a-b15a-771eb83a3ca3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:55:11.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9528" for this suite.
Oct 24 02:55:17.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:55:17.256: INFO: namespace secrets-9528 deletion completed in 6.150238613s
STEP: Destroying namespace "secret-namespace-4745" for this suite.
Oct 24 02:55:23.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:55:23.406: INFO: namespace secret-namespace-4745 deletion completed in 6.1503049s

• [SLOW TEST:14.498 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:55:23.406: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 02:55:23.999: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 02:55:27.031: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:55:27.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3839" for this suite.
Oct 24 02:55:33.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:55:33.259: INFO: namespace webhook-3839 deletion completed in 6.14853687s
STEP: Destroying namespace "webhook-3839-markers" for this suite.
Oct 24 02:55:39.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:55:39.416: INFO: namespace webhook-3839-markers deletion completed in 6.157041185s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.029 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:55:39.436: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:55:41.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5968" for this suite.
Oct 24 02:56:01.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:56:01.690: INFO: namespace containers-5968 deletion completed in 20.157123437s

• [SLOW TEST:22.254 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:56:01.690: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Oct 24 02:56:01.753: INFO: Waiting up to 5m0s for pod "var-expansion-b134733a-e4db-4745-874e-91847b63062c" in namespace "var-expansion-5092" to be "success or failure"
Oct 24 02:56:01.757: INFO: Pod "var-expansion-b134733a-e4db-4745-874e-91847b63062c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.588104ms
Oct 24 02:56:03.764: INFO: Pod "var-expansion-b134733a-e4db-4745-874e-91847b63062c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010678032s
STEP: Saw pod success
Oct 24 02:56:03.764: INFO: Pod "var-expansion-b134733a-e4db-4745-874e-91847b63062c" satisfied condition "success or failure"
Oct 24 02:56:03.771: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod var-expansion-b134733a-e4db-4745-874e-91847b63062c container dapi-container: <nil>
STEP: delete the pod
Oct 24 02:56:03.799: INFO: Waiting for pod var-expansion-b134733a-e4db-4745-874e-91847b63062c to disappear
Oct 24 02:56:03.802: INFO: Pod var-expansion-b134733a-e4db-4745-874e-91847b63062c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:56:03.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5092" for this suite.
Oct 24 02:56:09.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:56:09.962: INFO: namespace var-expansion-5092 deletion completed in 6.154472525s

• [SLOW TEST:8.271 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:56:09.962: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-95516954-be8e-4c0f-bacc-804386a669ff
STEP: Creating a pod to test consume configMaps
Oct 24 02:56:10.034: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-87c795b8-f1cb-42c5-8d25-86c08bfab5fd" in namespace "projected-3" to be "success or failure"
Oct 24 02:56:10.038: INFO: Pod "pod-projected-configmaps-87c795b8-f1cb-42c5-8d25-86c08bfab5fd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.506277ms
Oct 24 02:56:12.042: INFO: Pod "pod-projected-configmaps-87c795b8-f1cb-42c5-8d25-86c08bfab5fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007551524s
STEP: Saw pod success
Oct 24 02:56:12.042: INFO: Pod "pod-projected-configmaps-87c795b8-f1cb-42c5-8d25-86c08bfab5fd" satisfied condition "success or failure"
Oct 24 02:56:12.046: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-87c795b8-f1cb-42c5-8d25-86c08bfab5fd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 02:56:12.072: INFO: Waiting for pod pod-projected-configmaps-87c795b8-f1cb-42c5-8d25-86c08bfab5fd to disappear
Oct 24 02:56:12.076: INFO: Pod pod-projected-configmaps-87c795b8-f1cb-42c5-8d25-86c08bfab5fd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:56:12.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3" for this suite.
Oct 24 02:56:18.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:56:18.232: INFO: namespace projected-3 deletion completed in 6.151241188s

• [SLOW TEST:8.270 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:56:18.233: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:56:26.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3667" for this suite.
Oct 24 02:56:32.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:56:32.503: INFO: namespace job-3667 deletion completed in 6.204237509s

• [SLOW TEST:14.270 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:56:32.504: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:56:32.553: INFO: Creating deployment "webserver-deployment"
Oct 24 02:56:32.560: INFO: Waiting for observed generation 1
Oct 24 02:56:34.572: INFO: Waiting for all required pods to come up
Oct 24 02:56:34.579: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 24 02:56:36.594: INFO: Waiting for deployment "webserver-deployment" to complete
Oct 24 02:56:36.605: INFO: Updating deployment "webserver-deployment" with a non-existent image
Oct 24 02:56:36.614: INFO: Updating deployment webserver-deployment
Oct 24 02:56:36.614: INFO: Waiting for observed generation 2
Oct 24 02:56:38.624: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 24 02:56:38.628: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 24 02:56:38.632: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct 24 02:56:38.642: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 24 02:56:38.642: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 24 02:56:38.646: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct 24 02:56:38.653: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Oct 24 02:56:38.653: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Oct 24 02:56:38.662: INFO: Updating deployment webserver-deployment
Oct 24 02:56:38.662: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Oct 24 02:56:38.671: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 24 02:56:38.686: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct 24 02:56:38.736: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-1980 /apis/apps/v1/namespaces/deployment-1980/deployments/webserver-deployment bc9c1f00-2b17-4d2d-9064-e7569556dbd4 29532 3 2019-10-24 02:56:32 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006309958 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-10-24 02:56:36 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-10-24 02:56:38 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Oct 24 02:56:38.750: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-1980 /apis/apps/v1/namespaces/deployment-1980/replicasets/webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 29515 3 2019-10-24 02:56:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment bc9c1f00-2b17-4d2d-9064-e7569556dbd4 0xc006309e67 0xc006309e68}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006309ed8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 02:56:38.750: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Oct 24 02:56:38.750: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-1980 /apis/apps/v1/namespaces/deployment-1980/replicasets/webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 29511 3 2019-10-24 02:56:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment bc9c1f00-2b17-4d2d-9064-e7569556dbd4 0xc006309da7 0xc006309da8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006309e08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Oct 24 02:56:38.783: INFO: Pod "webserver-deployment-595b5b9587-57mrz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-57mrz webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-57mrz 5591468f-5622-4192-addb-8d71bca9ee9d 29421 0 2019-10-24 02:56:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.1.66/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc0086e1d47 0xc0086e1d48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.1.66,StartTime:2019-10-24 02:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 02:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/httpd:2.4.38-alpine,ImageID:docker-pullable://docker.io/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://0984ebaacaef911d05e93f0f5173110bd41c2bd1af4c867f09c80e206cd08d4d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.66,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.784: INFO: Pod "webserver-deployment-595b5b9587-7p8fh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7p8fh webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-7p8fh 5f392cfb-8461-409d-a3aa-997fbfd8803a 29547 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc0086e1eb0 0xc0086e1eb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.784: INFO: Pod "webserver-deployment-595b5b9587-b8z22" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-b8z22 webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-b8z22 123e9f30-34ae-456d-91ab-f8fa3267b02a 29539 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc0086e1fb0 0xc0086e1fb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.785: INFO: Pod "webserver-deployment-595b5b9587-cx5sd" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-cx5sd webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-cx5sd 4dc0f635-2ba4-4bc0-a659-5e0cad2234af 29427 0 2019-10-24 02:56:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.1.68/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc0060a4227 0xc0060a4228}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.1.68,StartTime:2019-10-24 02:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 02:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/httpd:2.4.38-alpine,ImageID:docker-pullable://docker.io/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://090326c5c62f6e1880eb239eeba0977b2238d4254da96d45f06519e8fe8bfe09,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.68,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.785: INFO: Pod "webserver-deployment-595b5b9587-dkxnq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dkxnq webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-dkxnq 6dfdb7bb-7a91-4784-8f15-b644563de061 29543 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc0060a4a40 0xc0060a4a41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 02:56:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.785: INFO: Pod "webserver-deployment-595b5b9587-dr48h" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dr48h webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-dr48h 3a766a8e-68c3-4dbc-880d-33ffa954e015 29412 0 2019-10-24 02:56:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.2.72/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc0060a4e67 0xc0060a4e68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.2.72,StartTime:2019-10-24 02:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 02:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/httpd:2.4.38-alpine,ImageID:docker-pullable://docker.io/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://881fc3b10707fc135b453a599a5ef9402f8af94119c9d269a53822c30d18104f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.72,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.786: INFO: Pod "webserver-deployment-595b5b9587-f5d6t" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-f5d6t webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-f5d6t 5404dcc9-84f9-4d7c-bc87-da7a25fdf2ed 29542 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc0060a5400 0xc0060a5401}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.786: INFO: Pod "webserver-deployment-595b5b9587-k2fmz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-k2fmz webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-k2fmz 7b862d69-c3e3-4aa4-b62d-1e092debf2dd 29552 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc0060a5587 0xc0060a5588}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.786: INFO: Pod "webserver-deployment-595b5b9587-kk5qd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kk5qd webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-kk5qd 44c81b2b-c20a-412d-9514-b530d6bf0c7b 29523 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc0060a59e0 0xc0060a59e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.786: INFO: Pod "webserver-deployment-595b5b9587-m4jwn" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-m4jwn webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-m4jwn 0a0bfd55-5b95-4027-baec-6bf56df53ad0 29544 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc0060a5be0 0xc0060a5be1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.787: INFO: Pod "webserver-deployment-595b5b9587-m5wsx" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-m5wsx webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-m5wsx 36592bdc-a061-440b-a0ba-aa127cfd17a5 29403 0 2019-10-24 02:56:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.2.71/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc00587c057 0xc00587c058}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.2.71,StartTime:2019-10-24 02:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 02:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/httpd:2.4.38-alpine,ImageID:docker-pullable://docker.io/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3fe6fadf5ab3595a84376652675aa5106f2a7dd6278360695595e9fc1b5b096c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.71,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.788: INFO: Pod "webserver-deployment-595b5b9587-mtf95" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mtf95 webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-mtf95 f8e31131-35c3-4f0f-b195-c4e8a38c6b00 29546 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc00587c1c0 0xc00587c1c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.788: INFO: Pod "webserver-deployment-595b5b9587-n2mvz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-n2mvz webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-n2mvz 9a58eb32-03ec-404c-8ad1-f3339d86b4d1 29541 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc00587c370 0xc00587c371}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.788: INFO: Pod "webserver-deployment-595b5b9587-nqp54" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nqp54 webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-nqp54 ab81425c-42ad-4ff4-8c40-f4b3c2fc57a9 29433 0 2019-10-24 02:56:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.1.69/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc00587c4a7 0xc00587c4a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.1.69,StartTime:2019-10-24 02:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 02:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/httpd:2.4.38-alpine,ImageID:docker-pullable://docker.io/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://46ddd45193cb161949d64ef013dd6349b8f8ba792cf98d6241dd574cb65eac47,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.69,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.789: INFO: Pod "webserver-deployment-595b5b9587-pfkb6" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pfkb6 webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-pfkb6 542b3ae6-858d-4abd-a475-9e1b4b343f4b 29409 0 2019-10-24 02:56:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.2.73/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc00587c6f0 0xc00587c6f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.138,PodIP:10.244.2.73,StartTime:2019-10-24 02:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 02:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/httpd:2.4.38-alpine,ImageID:docker-pullable://docker.io/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1eba7a07ddd11823ca46719012031d29ab61016bd9cc150ac3d8b26902674214,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.2.73,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.790: INFO: Pod "webserver-deployment-595b5b9587-q286r" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-q286r webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-q286r ddbaaf32-2d69-4bc4-91e3-8c867ee437c6 29525 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc00587c850 0xc00587c851}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.790: INFO: Pod "webserver-deployment-595b5b9587-s8ghb" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-s8ghb webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-s8ghb 3f6a42d3-b87c-4571-8465-7f3a3ceb71cc 29424 0 2019-10-24 02:56:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.1.67/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc00587c960 0xc00587c961}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.1.67,StartTime:2019-10-24 02:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 02:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/httpd:2.4.38-alpine,ImageID:docker-pullable://docker.io/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://e1ab7b6ccf05196fdfe3e2bb4017c458540e2aa8d8d18902224e2243de2f1214,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.67,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.790: INFO: Pod "webserver-deployment-595b5b9587-skdg2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-skdg2 webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-skdg2 ff13069f-7363-4c79-94b0-2f3f14a56aa1 29553 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc00587cac0 0xc00587cac1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.790: INFO: Pod "webserver-deployment-595b5b9587-x8q8m" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-x8q8m webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-x8q8m 92d4477d-480a-43ed-b42b-8ad8768226a6 29437 0 2019-10-24 02:56:32 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.244.1.70/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc00587cbd0 0xc00587cbd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.1.70,StartTime:2019-10-24 02:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 02:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/httpd:2.4.38-alpine,ImageID:docker-pullable://docker.io/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://84970155e02739657c70cef33f84f524fb400b84530a8a4263ce548237ae285b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.70,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.792: INFO: Pod "webserver-deployment-595b5b9587-z5g86" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-z5g86 webserver-deployment-595b5b9587- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-595b5b9587-z5g86 18e9d005-c2f8-4a77-ba87-5e6a45b27e77 29540 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 dd84f77e-2d4a-4fba-b4d3-026a1fb69b9d 0xc00587cd30 0xc00587cd31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.792: INFO: Pod "webserver-deployment-c7997dcc8-5s9xs" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5s9xs webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-5s9xs 751bb09d-2c56-46df-8c59-8ce8419705d2 29533 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587ce17 0xc00587ce18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.792: INFO: Pod "webserver-deployment-c7997dcc8-5v8w2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5v8w2 webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-5v8w2 d14cfc6c-4c3f-4cc6-9118-447075027e95 29530 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587cf30 0xc00587cf31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.793: INFO: Pod "webserver-deployment-c7997dcc8-76pd9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-76pd9 webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-76pd9 205667c9-c65f-413f-b6b5-86dd4efd8745 29498 0 2019-10-24 02:56:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.1.71/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587d050 0xc00587d051}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 02:56:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.793: INFO: Pod "webserver-deployment-c7997dcc8-9mvzd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-9mvzd webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-9mvzd b40d381e-c86b-40ba-8cfe-df4ce74a38de 29550 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587d1b7 0xc00587d1b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.793: INFO: Pod "webserver-deployment-c7997dcc8-grvh8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-grvh8 webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-grvh8 6a7a4926-53cc-493c-b75a-0bb815479868 29538 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587d2d0 0xc00587d2d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.794: INFO: Pod "webserver-deployment-c7997dcc8-hzx4j" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hzx4j webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-hzx4j ebea8a0b-4ed4-4dff-ab1a-7e4e601f80ec 29497 0 2019-10-24 02:56:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.2.74/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587d3d7 0xc00587d3d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 02:56:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.794: INFO: Pod "webserver-deployment-c7997dcc8-jzfjr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-jzfjr webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-jzfjr 6f943916-e84b-4ff6-be19-393c80dd01b9 29551 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587d547 0xc00587d548}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.794: INFO: Pod "webserver-deployment-c7997dcc8-tbvkv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tbvkv webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-tbvkv 08ae65a4-7324-4212-b436-b6e1dd3ea236 29500 0 2019-10-24 02:56:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.2.75/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587d657 0xc00587d658}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm41.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.138,PodIP:,StartTime:2019-10-24 02:56:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.795: INFO: Pod "webserver-deployment-c7997dcc8-tqm8l" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tqm8l webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-tqm8l 0c2cec40-2a57-4608-8213-f61cd78ed6ae 29545 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587d7c7 0xc00587d7c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.795: INFO: Pod "webserver-deployment-c7997dcc8-v8dg4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-v8dg4 webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-v8dg4 c8ad114d-e160-4c56-b9cb-2d420a510467 29549 0 2019-10-24 02:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587d8c7 0xc00587d8c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.795: INFO: Pod "webserver-deployment-c7997dcc8-vs59t" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vs59t webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-vs59t 58c6444a-a45b-458f-a27c-3c1c6664a9ae 29507 0 2019-10-24 02:56:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.1.73/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587d9d7 0xc00587d9d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 02:56:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct 24 02:56:38.795: INFO: Pod "webserver-deployment-c7997dcc8-x7xls" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-x7xls webserver-deployment-c7997dcc8- deployment-1980 /api/v1/namespaces/deployment-1980/pods/webserver-deployment-c7997dcc8-x7xls c0274652-65a9-4076-a8f8-35f7fa59f1c1 29503 0 2019-10-24 02:56:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.244.1.72/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0f77745f-a3c7-46ad-91a8-5448f4cadf65 0xc00587db57 0xc00587db58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-67zgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-67zgh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-67zgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:,StartTime:2019-10-24 02:56:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:56:38.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1980" for this suite.
Oct 24 02:56:46.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:56:47.025: INFO: namespace deployment-1980 deletion completed in 8.214828509s

• [SLOW TEST:14.521 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:56:47.026: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 02:56:47.083: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 24 02:56:52.088: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 24 02:56:52.088: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 24 02:56:54.096: INFO: Creating deployment "test-rollover-deployment"
Oct 24 02:56:54.107: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 24 02:56:56.115: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 24 02:56:56.122: INFO: Ensure that both replica sets have 1 created replica
Oct 24 02:56:56.129: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 24 02:56:56.137: INFO: Updating deployment test-rollover-deployment
Oct 24 02:56:56.137: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 24 02:56:58.146: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 24 02:56:58.155: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 24 02:56:58.163: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 02:56:58.163: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482617, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 02:57:00.180: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 02:57:00.180: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482617, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 02:57:02.173: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 02:57:02.173: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482617, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 02:57:04.174: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 02:57:04.174: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482617, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 02:57:06.173: INFO: all replica sets need to contain the pod-template-hash label
Oct 24 02:57:06.173: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482617, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482614, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 24 02:57:08.173: INFO: 
Oct 24 02:57:08.173: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct 24 02:57:08.184: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-8768 /apis/apps/v1/namespaces/deployment-8768/deployments/test-rollover-deployment 53091e00-86b4-4369-9b82-663ad96a279f 29962 2 2019-10-24 02:56:54 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00352d918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-10-24 02:56:54 +0000 UTC,LastTransitionTime:2019-10-24 02:56:54 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-10-24 02:57:07 +0000 UTC,LastTransitionTime:2019-10-24 02:56:54 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 24 02:57:08.188: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-8768 /apis/apps/v1/namespaces/deployment-8768/replicasets/test-rollover-deployment-7d7dc6548c 1921d519-691a-4464-9d7e-7fe4d9e86613 29951 2 2019-10-24 02:56:56 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 53091e00-86b4-4369-9b82-663ad96a279f 0xc00352ddf7 0xc00352ddf8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00352de58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 24 02:57:08.188: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 24 02:57:08.189: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-8768 /apis/apps/v1/namespaces/deployment-8768/replicasets/test-rollover-controller 64a4d080-52bd-4d49-8530-b18d58d506f8 29961 2 2019-10-24 02:56:47 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 53091e00-86b4-4369-9b82-663ad96a279f 0xc00352dd27 0xc00352dd28}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00352dd88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 02:57:08.189: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-8768 /apis/apps/v1/namespaces/deployment-8768/replicasets/test-rollover-deployment-f6c94f66c e71f0863-241f-46fd-a64e-dbdf716fa179 29923 2 2019-10-24 02:56:54 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 53091e00-86b4-4369-9b82-663ad96a279f 0xc00352dec0 0xc00352dec1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00352df38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 02:57:08.193: INFO: Pod "test-rollover-deployment-7d7dc6548c-v787q" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-v787q test-rollover-deployment-7d7dc6548c- deployment-8768 /api/v1/namespaces/deployment-8768/pods/test-rollover-deployment-7d7dc6548c-v787q 41b0c427-0228-4db9-b77a-16cb1a0470f0 29934 0 2019-10-24 02:56:56 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[cni.projectcalico.org/podIP:10.244.1.86/32] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 1921d519-691a-4464-9d7e-7fe4d9e86613 0xc0033ea4b7 0xc0033ea4b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-f47hw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-f47hw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-f47hw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 02:56:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.1.86,StartTime:2019-10-24 02:56:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 02:56:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/redis:5.0.5-alpine,ImageID:docker-pullable://docker.io/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://f38e512b49c6e07cf229c30c6c90e97576fde280eba6225b28a843e9d9d99e46,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.86,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:57:08.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8768" for this suite.
Oct 24 02:57:14.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:57:14.491: INFO: namespace deployment-8768 deletion completed in 6.29369592s

• [SLOW TEST:27.465 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:57:14.491: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct 24 02:57:14.538: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:57:18.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7629" for this suite.
Oct 24 02:57:30.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:57:30.997: INFO: namespace init-container-7629 deletion completed in 12.149664044s

• [SLOW TEST:16.506 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:57:30.997: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-a9d47d2d-4cfb-4bcf-9938-dc0c39a4726b
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:57:31.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8785" for this suite.
Oct 24 02:57:37.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:57:37.198: INFO: namespace secrets-8785 deletion completed in 6.147980722s

• [SLOW TEST:6.201 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:57:37.198: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7292
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 24 02:57:37.247: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 24 02:57:59.339: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.89:8080/dial?request=hostName&protocol=udp&host=10.244.1.88&port=8081&tries=1'] Namespace:pod-network-test-7292 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 02:57:59.339: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 02:57:59.484: INFO: Waiting for endpoints: map[]
Oct 24 02:57:59.488: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.89:8080/dial?request=hostName&protocol=udp&host=10.244.2.88&port=8081&tries=1'] Namespace:pod-network-test-7292 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 24 02:57:59.488: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
Oct 24 02:57:59.631: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:57:59.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7292" for this suite.
Oct 24 02:58:11.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:58:11.781: INFO: namespace pod-network-test-7292 deletion completed in 12.145275469s

• [SLOW TEST:34.583 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:58:11.782: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct 24 02:58:12.363: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct 24 02:58:14.377: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482692, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482692, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482692, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707482692, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct 24 02:58:17.396: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:58:17.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8964" for this suite.
Oct 24 02:58:29.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:58:29.847: INFO: namespace webhook-8964 deletion completed in 12.169694624s
STEP: Destroying namespace "webhook-8964-markers" for this suite.
Oct 24 02:58:35.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:58:35.993: INFO: namespace webhook-8964-markers deletion completed in 6.145421959s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.229 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:58:36.011: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-7141
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-7141
STEP: creating replication controller externalsvc in namespace services-7141
I1024 02:58:36.098501      23 runners.go:184] Created replication controller with name: externalsvc, namespace: services-7141, replica count: 2
I1024 02:58:39.149133      23 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Oct 24 02:58:39.180: INFO: Creating new exec pod
Oct 24 02:58:41.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 exec --namespace=services-7141 execpod8tqkp -- /bin/sh -x -c nslookup nodeport-service'
Oct 24 02:58:41.659: INFO: stderr: "+ nslookup nodeport-service\n"
Oct 24 02:58:41.659: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-7141.svc.cluster.local\tcanonical name = externalsvc.services-7141.svc.cluster.local.\nName:\texternalsvc.services-7141.svc.cluster.local\nAddress: 10.96.140.4\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7141, will wait for the garbage collector to delete the pods
Oct 24 02:58:41.723: INFO: Deleting ReplicationController externalsvc took: 8.571469ms
Oct 24 02:58:41.823: INFO: Terminating ReplicationController externalsvc pods took: 100.230575ms
Oct 24 02:58:55.749: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:58:55.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7141" for this suite.
Oct 24 02:59:01.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:59:01.945: INFO: namespace services-7141 deletion completed in 6.162713681s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:25.934 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:59:01.945: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct 24 02:59:01.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-330'
Oct 24 02:59:02.161: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 24 02:59:02.161: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Oct 24 02:59:02.177: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-crsd2]
Oct 24 02:59:02.178: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-crsd2" in namespace "kubectl-330" to be "running and ready"
Oct 24 02:59:02.184: INFO: Pod "e2e-test-httpd-rc-crsd2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0165ms
Oct 24 02:59:04.189: INFO: Pod "e2e-test-httpd-rc-crsd2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011748112s
Oct 24 02:59:04.189: INFO: Pod "e2e-test-httpd-rc-crsd2" satisfied condition "running and ready"
Oct 24 02:59:04.189: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-crsd2]
Oct 24 02:59:04.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 logs rc/e2e-test-httpd-rc --namespace=kubectl-330'
Oct 24 02:59:04.442: INFO: stderr: ""
Oct 24 02:59:04.442: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.1.95. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.1.95. Set the 'ServerName' directive globally to suppress this message\n[Thu Oct 24 02:59:03.233958 2019] [mpm_event:notice] [pid 1:tid 139673051560808] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Thu Oct 24 02:59:03.234071 2019] [core:notice] [pid 1:tid 139673051560808] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Oct 24 02:59:04.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete rc e2e-test-httpd-rc --namespace=kubectl-330'
Oct 24 02:59:04.629: INFO: stderr: ""
Oct 24 02:59:04.629: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:59:04.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-330" for this suite.
Oct 24 02:59:10.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:59:10.789: INFO: namespace kubectl-330 deletion completed in 6.15464478s

• [SLOW TEST:8.844 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:59:10.789: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-12bc5273-87cf-4d5e-99ec-c562ec892b58
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-12bc5273-87cf-4d5e-99ec-c562ec892b58
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:59:14.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4707" for this suite.
Oct 24 02:59:26.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:59:27.092: INFO: namespace configmap-4707 deletion completed in 12.17426727s

• [SLOW TEST:16.303 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:59:27.092: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-85q8
STEP: Creating a pod to test atomic-volume-subpath
Oct 24 02:59:27.161: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-85q8" in namespace "subpath-7374" to be "success or failure"
Oct 24 02:59:27.173: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.443241ms
Oct 24 02:59:29.178: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Running", Reason="", readiness=true. Elapsed: 2.01669256s
Oct 24 02:59:31.185: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Running", Reason="", readiness=true. Elapsed: 4.023695469s
Oct 24 02:59:33.190: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Running", Reason="", readiness=true. Elapsed: 6.028560181s
Oct 24 02:59:35.194: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Running", Reason="", readiness=true. Elapsed: 8.033112211s
Oct 24 02:59:37.200: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Running", Reason="", readiness=true. Elapsed: 10.038542603s
Oct 24 02:59:39.205: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Running", Reason="", readiness=true. Elapsed: 12.043719241s
Oct 24 02:59:41.210: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Running", Reason="", readiness=true. Elapsed: 14.04903271s
Oct 24 02:59:43.215: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Running", Reason="", readiness=true. Elapsed: 16.05428048s
Oct 24 02:59:45.220: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Running", Reason="", readiness=true. Elapsed: 18.059015105s
Oct 24 02:59:47.226: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Running", Reason="", readiness=true. Elapsed: 20.064531106s
Oct 24 02:59:49.230: INFO: Pod "pod-subpath-test-secret-85q8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.068851555s
STEP: Saw pod success
Oct 24 02:59:49.230: INFO: Pod "pod-subpath-test-secret-85q8" satisfied condition "success or failure"
Oct 24 02:59:49.234: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-subpath-test-secret-85q8 container test-container-subpath-secret-85q8: <nil>
STEP: delete the pod
Oct 24 02:59:49.268: INFO: Waiting for pod pod-subpath-test-secret-85q8 to disappear
Oct 24 02:59:49.272: INFO: Pod pod-subpath-test-secret-85q8 no longer exists
STEP: Deleting pod pod-subpath-test-secret-85q8
Oct 24 02:59:49.272: INFO: Deleting pod "pod-subpath-test-secret-85q8" in namespace "subpath-7374"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:59:49.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7374" for this suite.
Oct 24 02:59:55.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 02:59:55.432: INFO: namespace subpath-7374 deletion completed in 6.151745533s

• [SLOW TEST:28.340 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 02:59:55.433: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-410fe7fc-2c74-4f00-919b-edae26a82308
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 02:59:57.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9609" for this suite.
Oct 24 03:00:09.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:00:09.698: INFO: namespace configmap-9609 deletion completed in 12.152915446s

• [SLOW TEST:14.265 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 03:00:09.698: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 03:00:09.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 version'
Oct 24 03:00:09.897: INFO: stderr: ""
Oct 24 03:00:09.897: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:18:23Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:09:08Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 03:00:09.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4090" for this suite.
Oct 24 03:00:15.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:00:16.050: INFO: namespace kubectl-4090 deletion completed in 6.147253236s

• [SLOW TEST:6.352 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 03:00:16.050: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 03:00:33.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7762" for this suite.
Oct 24 03:00:39.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:00:39.304: INFO: namespace resourcequota-7762 deletion completed in 6.150694178s

• [SLOW TEST:23.254 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 03:00:39.304: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 03:00:50.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2927" for this suite.
Oct 24 03:00:56.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:00:56.551: INFO: namespace resourcequota-2927 deletion completed in 6.148611653s

• [SLOW TEST:17.246 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 03:00:56.551: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-3dc40f3e-dc27-4911-98a1-158f39769b7a
STEP: Creating a pod to test consume configMaps
Oct 24 03:00:56.611: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-615839d5-23eb-4791-a52f-a0ce8e2ea50c" in namespace "projected-4705" to be "success or failure"
Oct 24 03:00:56.615: INFO: Pod "pod-projected-configmaps-615839d5-23eb-4791-a52f-a0ce8e2ea50c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.952245ms
Oct 24 03:00:58.622: INFO: Pod "pod-projected-configmaps-615839d5-23eb-4791-a52f-a0ce8e2ea50c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010253033s
STEP: Saw pod success
Oct 24 03:00:58.622: INFO: Pod "pod-projected-configmaps-615839d5-23eb-4791-a52f-a0ce8e2ea50c" satisfied condition "success or failure"
Oct 24 03:00:58.626: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-projected-configmaps-615839d5-23eb-4791-a52f-a0ce8e2ea50c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 24 03:00:58.651: INFO: Waiting for pod pod-projected-configmaps-615839d5-23eb-4791-a52f-a0ce8e2ea50c to disappear
Oct 24 03:00:58.655: INFO: Pod pod-projected-configmaps-615839d5-23eb-4791-a52f-a0ce8e2ea50c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 03:00:58.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4705" for this suite.
Oct 24 03:01:04.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:01:04.810: INFO: namespace projected-4705 deletion completed in 6.150586639s

• [SLOW TEST:8.260 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 03:01:04.811: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Oct 24 03:01:04.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 create -f - --namespace=kubectl-6149'
Oct 24 03:01:05.342: INFO: stderr: ""
Oct 24 03:01:05.342: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 03:01:05.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6149'
Oct 24 03:01:05.542: INFO: stderr: ""
Oct 24 03:01:05.542: INFO: stdout: "update-demo-nautilus-jg9bc update-demo-nautilus-qsx8d "
Oct 24 03:01:05.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-jg9bc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:05.713: INFO: stderr: ""
Oct 24 03:01:05.713: INFO: stdout: ""
Oct 24 03:01:05.713: INFO: update-demo-nautilus-jg9bc is created but not running
Oct 24 03:01:10.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6149'
Oct 24 03:01:10.892: INFO: stderr: ""
Oct 24 03:01:10.892: INFO: stdout: "update-demo-nautilus-jg9bc update-demo-nautilus-qsx8d "
Oct 24 03:01:10.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-jg9bc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:11.073: INFO: stderr: ""
Oct 24 03:01:11.073: INFO: stdout: "true"
Oct 24 03:01:11.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-jg9bc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:11.241: INFO: stderr: ""
Oct 24 03:01:11.241: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 03:01:11.241: INFO: validating pod update-demo-nautilus-jg9bc
Oct 24 03:01:11.250: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 03:01:11.250: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 03:01:11.250: INFO: update-demo-nautilus-jg9bc is verified up and running
Oct 24 03:01:11.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-qsx8d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:11.426: INFO: stderr: ""
Oct 24 03:01:11.426: INFO: stdout: "true"
Oct 24 03:01:11.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-qsx8d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:11.605: INFO: stderr: ""
Oct 24 03:01:11.605: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 03:01:11.605: INFO: validating pod update-demo-nautilus-qsx8d
Oct 24 03:01:11.613: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 03:01:11.613: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 03:01:11.613: INFO: update-demo-nautilus-qsx8d is verified up and running
STEP: scaling down the replication controller
Oct 24 03:01:11.616: INFO: scanned /root for discovery docs: <nil>
Oct 24 03:01:11.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6149'
Oct 24 03:01:12.857: INFO: stderr: ""
Oct 24 03:01:12.857: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 03:01:12.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6149'
Oct 24 03:01:13.052: INFO: stderr: ""
Oct 24 03:01:13.052: INFO: stdout: "update-demo-nautilus-jg9bc update-demo-nautilus-qsx8d "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 24 03:01:18.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6149'
Oct 24 03:01:18.236: INFO: stderr: ""
Oct 24 03:01:18.236: INFO: stdout: "update-demo-nautilus-qsx8d "
Oct 24 03:01:18.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-qsx8d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:18.408: INFO: stderr: ""
Oct 24 03:01:18.408: INFO: stdout: "true"
Oct 24 03:01:18.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-qsx8d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:18.573: INFO: stderr: ""
Oct 24 03:01:18.573: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 03:01:18.573: INFO: validating pod update-demo-nautilus-qsx8d
Oct 24 03:01:18.580: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 03:01:18.580: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 03:01:18.580: INFO: update-demo-nautilus-qsx8d is verified up and running
STEP: scaling up the replication controller
Oct 24 03:01:18.585: INFO: scanned /root for discovery docs: <nil>
Oct 24 03:01:18.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6149'
Oct 24 03:01:19.788: INFO: stderr: ""
Oct 24 03:01:19.788: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 24 03:01:19.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6149'
Oct 24 03:01:19.957: INFO: stderr: ""
Oct 24 03:01:19.957: INFO: stdout: "update-demo-nautilus-qsx8d update-demo-nautilus-xplnm "
Oct 24 03:01:19.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-qsx8d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:20.127: INFO: stderr: ""
Oct 24 03:01:20.127: INFO: stdout: "true"
Oct 24 03:01:20.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-qsx8d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:20.292: INFO: stderr: ""
Oct 24 03:01:20.292: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 03:01:20.292: INFO: validating pod update-demo-nautilus-qsx8d
Oct 24 03:01:20.297: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 03:01:20.297: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 03:01:20.297: INFO: update-demo-nautilus-qsx8d is verified up and running
Oct 24 03:01:20.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-xplnm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:20.467: INFO: stderr: ""
Oct 24 03:01:20.468: INFO: stdout: ""
Oct 24 03:01:20.468: INFO: update-demo-nautilus-xplnm is created but not running
Oct 24 03:01:25.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6149'
Oct 24 03:01:25.656: INFO: stderr: ""
Oct 24 03:01:25.656: INFO: stdout: "update-demo-nautilus-qsx8d update-demo-nautilus-xplnm "
Oct 24 03:01:25.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-qsx8d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:25.874: INFO: stderr: ""
Oct 24 03:01:25.874: INFO: stdout: "true"
Oct 24 03:01:25.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-qsx8d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:26.076: INFO: stderr: ""
Oct 24 03:01:26.076: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 03:01:26.076: INFO: validating pod update-demo-nautilus-qsx8d
Oct 24 03:01:26.082: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 03:01:26.082: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 03:01:26.082: INFO: update-demo-nautilus-qsx8d is verified up and running
Oct 24 03:01:26.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-xplnm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:26.262: INFO: stderr: ""
Oct 24 03:01:26.262: INFO: stdout: "true"
Oct 24 03:01:26.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods update-demo-nautilus-xplnm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6149'
Oct 24 03:01:26.460: INFO: stderr: ""
Oct 24 03:01:26.460: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 24 03:01:26.460: INFO: validating pod update-demo-nautilus-xplnm
Oct 24 03:01:26.467: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 24 03:01:26.467: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 24 03:01:26.467: INFO: update-demo-nautilus-xplnm is verified up and running
STEP: using delete to clean up resources
Oct 24 03:01:26.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 delete --grace-period=0 --force -f - --namespace=kubectl-6149'
Oct 24 03:01:26.657: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 24 03:01:26.657: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 24 03:01:26.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6149'
Oct 24 03:01:26.865: INFO: stderr: "No resources found in kubectl-6149 namespace.\n"
Oct 24 03:01:26.865: INFO: stdout: ""
Oct 24 03:01:26.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-000479258 get pods -l name=update-demo --namespace=kubectl-6149 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 24 03:01:27.053: INFO: stderr: ""
Oct 24 03:01:27.053: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 03:01:27.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6149" for this suite.
Oct 24 03:01:39.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:01:39.201: INFO: namespace kubectl-6149 deletion completed in 12.142962836s

• [SLOW TEST:34.390 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 03:01:39.202: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Oct 24 03:01:41.778: INFO: Successfully updated pod "adopt-release-5h5q5"
STEP: Checking that the Job readopts the Pod
Oct 24 03:01:41.778: INFO: Waiting up to 15m0s for pod "adopt-release-5h5q5" in namespace "job-2328" to be "adopted"
Oct 24 03:01:41.784: INFO: Pod "adopt-release-5h5q5": Phase="Running", Reason="", readiness=true. Elapsed: 5.477142ms
Oct 24 03:01:43.789: INFO: Pod "adopt-release-5h5q5": Phase="Running", Reason="", readiness=true. Elapsed: 2.010522454s
Oct 24 03:01:43.789: INFO: Pod "adopt-release-5h5q5" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Oct 24 03:01:44.300: INFO: Successfully updated pod "adopt-release-5h5q5"
STEP: Checking that the Job releases the Pod
Oct 24 03:01:44.300: INFO: Waiting up to 15m0s for pod "adopt-release-5h5q5" in namespace "job-2328" to be "released"
Oct 24 03:01:44.306: INFO: Pod "adopt-release-5h5q5": Phase="Running", Reason="", readiness=true. Elapsed: 5.949429ms
Oct 24 03:01:46.311: INFO: Pod "adopt-release-5h5q5": Phase="Running", Reason="", readiness=true. Elapsed: 2.010737543s
Oct 24 03:01:46.311: INFO: Pod "adopt-release-5h5q5" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 03:01:46.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2328" for this suite.
Oct 24 03:02:30.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:02:30.477: INFO: namespace job-2328 deletion completed in 44.161682248s

• [SLOW TEST:51.275 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 03:02:30.478: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 03:02:30.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6036" for this suite.
Oct 24 03:02:36.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:02:36.744: INFO: namespace custom-resource-definition-6036 deletion completed in 6.200381406s

• [SLOW TEST:6.266 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 03:02:36.745: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9799
I1024 03:02:36.800211      23 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9799, replica count: 1
I1024 03:02:37.850823      23 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1024 03:02:38.851184      23 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1024 03:02:39.851591      23 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 24 03:02:39.964: INFO: Created: latency-svc-ptwxd
Oct 24 03:02:39.973: INFO: Got endpoints: latency-svc-ptwxd [21.189359ms]
Oct 24 03:02:39.998: INFO: Created: latency-svc-64gpl
Oct 24 03:02:40.006: INFO: Got endpoints: latency-svc-64gpl [32.649885ms]
Oct 24 03:02:40.022: INFO: Created: latency-svc-qgl49
Oct 24 03:02:40.029: INFO: Created: latency-svc-fpxt7
Oct 24 03:02:40.036: INFO: Got endpoints: latency-svc-fpxt7 [62.783991ms]
Oct 24 03:02:40.037: INFO: Got endpoints: latency-svc-qgl49 [63.512044ms]
Oct 24 03:02:40.045: INFO: Created: latency-svc-zmhjx
Oct 24 03:02:40.053: INFO: Got endpoints: latency-svc-zmhjx [79.775434ms]
Oct 24 03:02:40.059: INFO: Created: latency-svc-bvr6w
Oct 24 03:02:40.064: INFO: Got endpoints: latency-svc-bvr6w [90.636948ms]
Oct 24 03:02:40.075: INFO: Created: latency-svc-h4lxx
Oct 24 03:02:40.081: INFO: Created: latency-svc-n6mcm
Oct 24 03:02:40.092: INFO: Created: latency-svc-2mvx5
Oct 24 03:02:40.094: INFO: Got endpoints: latency-svc-n6mcm [120.042719ms]
Oct 24 03:02:40.094: INFO: Got endpoints: latency-svc-h4lxx [120.578817ms]
Oct 24 03:02:40.102: INFO: Got endpoints: latency-svc-2mvx5 [128.145996ms]
Oct 24 03:02:40.103: INFO: Created: latency-svc-qj9xm
Oct 24 03:02:40.107: INFO: Got endpoints: latency-svc-qj9xm [133.902752ms]
Oct 24 03:02:40.112: INFO: Created: latency-svc-5sf52
Oct 24 03:02:40.117: INFO: Got endpoints: latency-svc-5sf52 [143.678227ms]
Oct 24 03:02:40.127: INFO: Created: latency-svc-v5j7f
Oct 24 03:02:40.132: INFO: Got endpoints: latency-svc-v5j7f [159.209925ms]
Oct 24 03:02:40.138: INFO: Created: latency-svc-q9k4q
Oct 24 03:02:40.144: INFO: Got endpoints: latency-svc-q9k4q [170.706479ms]
Oct 24 03:02:40.149: INFO: Created: latency-svc-2tc4d
Oct 24 03:02:40.157: INFO: Created: latency-svc-275gm
Oct 24 03:02:40.157: INFO: Got endpoints: latency-svc-2tc4d [183.899893ms]
Oct 24 03:02:40.165: INFO: Got endpoints: latency-svc-275gm [191.254152ms]
Oct 24 03:02:40.167: INFO: Created: latency-svc-sj57c
Oct 24 03:02:40.173: INFO: Got endpoints: latency-svc-sj57c [199.676915ms]
Oct 24 03:02:40.184: INFO: Created: latency-svc-kxv4q
Oct 24 03:02:40.189: INFO: Got endpoints: latency-svc-kxv4q [183.640933ms]
Oct 24 03:02:40.191: INFO: Created: latency-svc-mtqhs
Oct 24 03:02:40.200: INFO: Got endpoints: latency-svc-mtqhs [163.346357ms]
Oct 24 03:02:40.207: INFO: Created: latency-svc-gnd62
Oct 24 03:02:40.209: INFO: Got endpoints: latency-svc-gnd62 [172.693382ms]
Oct 24 03:02:40.216: INFO: Created: latency-svc-fmm2b
Oct 24 03:02:40.221: INFO: Got endpoints: latency-svc-fmm2b [167.758925ms]
Oct 24 03:02:40.227: INFO: Created: latency-svc-ndb5z
Oct 24 03:02:40.228: INFO: Got endpoints: latency-svc-ndb5z [163.586312ms]
Oct 24 03:02:40.233: INFO: Created: latency-svc-gbvvs
Oct 24 03:02:40.238: INFO: Got endpoints: latency-svc-gbvvs [144.62132ms]
Oct 24 03:02:40.242: INFO: Created: latency-svc-xr49q
Oct 24 03:02:40.248: INFO: Got endpoints: latency-svc-xr49q [153.4164ms]
Oct 24 03:02:40.250: INFO: Created: latency-svc-k48f9
Oct 24 03:02:40.259: INFO: Created: latency-svc-lctxb
Oct 24 03:02:40.260: INFO: Got endpoints: latency-svc-k48f9 [158.177302ms]
Oct 24 03:02:40.266: INFO: Got endpoints: latency-svc-lctxb [158.352252ms]
Oct 24 03:02:40.272: INFO: Created: latency-svc-lzxwj
Oct 24 03:02:40.279: INFO: Got endpoints: latency-svc-lzxwj [161.329141ms]
Oct 24 03:02:40.281: INFO: Created: latency-svc-w7lcx
Oct 24 03:02:40.289: INFO: Got endpoints: latency-svc-w7lcx [156.180333ms]
Oct 24 03:02:40.291: INFO: Created: latency-svc-75ztj
Oct 24 03:02:40.298: INFO: Got endpoints: latency-svc-75ztj [153.905033ms]
Oct 24 03:02:40.306: INFO: Created: latency-svc-fffzj
Oct 24 03:02:40.306: INFO: Got endpoints: latency-svc-fffzj [148.441266ms]
Oct 24 03:02:40.308: INFO: Created: latency-svc-wlzxb
Oct 24 03:02:40.314: INFO: Got endpoints: latency-svc-wlzxb [149.349616ms]
Oct 24 03:02:40.323: INFO: Created: latency-svc-qw8sb
Oct 24 03:02:40.324: INFO: Created: latency-svc-m72kt
Oct 24 03:02:40.329: INFO: Got endpoints: latency-svc-qw8sb [155.083869ms]
Oct 24 03:02:40.333: INFO: Got endpoints: latency-svc-m72kt [143.38135ms]
Oct 24 03:02:40.340: INFO: Created: latency-svc-pnrxl
Oct 24 03:02:40.345: INFO: Got endpoints: latency-svc-pnrxl [144.677019ms]
Oct 24 03:02:40.347: INFO: Created: latency-svc-kvk7b
Oct 24 03:02:40.354: INFO: Got endpoints: latency-svc-kvk7b [25.52587ms]
Oct 24 03:02:40.355: INFO: Created: latency-svc-p8zw4
Oct 24 03:02:40.368: INFO: Got endpoints: latency-svc-p8zw4 [158.511869ms]
Oct 24 03:02:40.374: INFO: Created: latency-svc-5hqwg
Oct 24 03:02:40.384: INFO: Created: latency-svc-w257f
Oct 24 03:02:40.384: INFO: Got endpoints: latency-svc-5hqwg [163.150894ms]
Oct 24 03:02:40.393: INFO: Got endpoints: latency-svc-w257f [165.239031ms]
Oct 24 03:02:40.401: INFO: Created: latency-svc-7f2cm
Oct 24 03:02:40.407: INFO: Got endpoints: latency-svc-7f2cm [168.466723ms]
Oct 24 03:02:40.411: INFO: Created: latency-svc-zd5lv
Oct 24 03:02:40.415: INFO: Created: latency-svc-fqsc8
Oct 24 03:02:40.424: INFO: Got endpoints: latency-svc-zd5lv [175.852441ms]
Oct 24 03:02:40.428: INFO: Created: latency-svc-zjn7r
Oct 24 03:02:40.435: INFO: Created: latency-svc-dxtcx
Oct 24 03:02:40.446: INFO: Created: latency-svc-l7thd
Oct 24 03:02:40.452: INFO: Created: latency-svc-464sl
Oct 24 03:02:40.466: INFO: Created: latency-svc-dzkcx
Oct 24 03:02:40.473: INFO: Created: latency-svc-h586r
Oct 24 03:02:40.475: INFO: Got endpoints: latency-svc-fqsc8 [214.880997ms]
Oct 24 03:02:40.484: INFO: Created: latency-svc-p5l5v
Oct 24 03:02:40.494: INFO: Created: latency-svc-bx9br
Oct 24 03:02:40.500: INFO: Created: latency-svc-jn6tz
Oct 24 03:02:40.503: INFO: Created: latency-svc-4d4jm
Oct 24 03:02:40.512: INFO: Created: latency-svc-8hnzs
Oct 24 03:02:40.519: INFO: Created: latency-svc-d4fcp
Oct 24 03:02:40.522: INFO: Got endpoints: latency-svc-zjn7r [255.901873ms]
Oct 24 03:02:40.532: INFO: Created: latency-svc-462vg
Oct 24 03:02:40.537: INFO: Created: latency-svc-97t95
Oct 24 03:02:40.542: INFO: Created: latency-svc-gjbbj
Oct 24 03:02:40.550: INFO: Created: latency-svc-lsqgd
Oct 24 03:02:40.572: INFO: Got endpoints: latency-svc-dxtcx [293.117721ms]
Oct 24 03:02:40.609: INFO: Created: latency-svc-nnsr6
Oct 24 03:02:40.622: INFO: Got endpoints: latency-svc-l7thd [333.148709ms]
Oct 24 03:02:40.634: INFO: Created: latency-svc-vqp65
Oct 24 03:02:40.673: INFO: Got endpoints: latency-svc-464sl [375.205214ms]
Oct 24 03:02:40.693: INFO: Created: latency-svc-6xm48
Oct 24 03:02:40.721: INFO: Got endpoints: latency-svc-dzkcx [415.164168ms]
Oct 24 03:02:40.736: INFO: Created: latency-svc-qw7lq
Oct 24 03:02:40.772: INFO: Got endpoints: latency-svc-h586r [457.644933ms]
Oct 24 03:02:40.783: INFO: Created: latency-svc-hz5kl
Oct 24 03:02:40.821: INFO: Got endpoints: latency-svc-p5l5v [487.992966ms]
Oct 24 03:02:40.832: INFO: Created: latency-svc-2kpr4
Oct 24 03:02:40.870: INFO: Got endpoints: latency-svc-bx9br [525.796762ms]
Oct 24 03:02:40.895: INFO: Created: latency-svc-25hrm
Oct 24 03:02:40.921: INFO: Got endpoints: latency-svc-jn6tz [566.640603ms]
Oct 24 03:02:40.937: INFO: Created: latency-svc-ppnxh
Oct 24 03:02:40.971: INFO: Got endpoints: latency-svc-4d4jm [602.530938ms]
Oct 24 03:02:40.984: INFO: Created: latency-svc-hjnsl
Oct 24 03:02:41.020: INFO: Got endpoints: latency-svc-8hnzs [635.84933ms]
Oct 24 03:02:41.032: INFO: Created: latency-svc-c64xq
Oct 24 03:02:41.073: INFO: Got endpoints: latency-svc-d4fcp [679.620408ms]
Oct 24 03:02:41.084: INFO: Created: latency-svc-xg4kp
Oct 24 03:02:41.120: INFO: Got endpoints: latency-svc-462vg [713.399472ms]
Oct 24 03:02:41.132: INFO: Created: latency-svc-gp8xx
Oct 24 03:02:41.172: INFO: Got endpoints: latency-svc-97t95 [747.888871ms]
Oct 24 03:02:41.182: INFO: Created: latency-svc-47kcb
Oct 24 03:02:41.223: INFO: Got endpoints: latency-svc-gjbbj [748.496245ms]
Oct 24 03:02:41.235: INFO: Created: latency-svc-fm52g
Oct 24 03:02:41.271: INFO: Got endpoints: latency-svc-lsqgd [749.35119ms]
Oct 24 03:02:41.288: INFO: Created: latency-svc-66g7d
Oct 24 03:02:41.320: INFO: Got endpoints: latency-svc-nnsr6 [748.520181ms]
Oct 24 03:02:41.331: INFO: Created: latency-svc-pl6ln
Oct 24 03:02:41.373: INFO: Got endpoints: latency-svc-vqp65 [750.780867ms]
Oct 24 03:02:41.388: INFO: Created: latency-svc-5tmtw
Oct 24 03:02:41.423: INFO: Got endpoints: latency-svc-6xm48 [749.369185ms]
Oct 24 03:02:41.435: INFO: Created: latency-svc-g6qm7
Oct 24 03:02:41.472: INFO: Got endpoints: latency-svc-qw7lq [751.246333ms]
Oct 24 03:02:41.486: INFO: Created: latency-svc-2nttf
Oct 24 03:02:41.521: INFO: Got endpoints: latency-svc-hz5kl [749.231876ms]
Oct 24 03:02:41.533: INFO: Created: latency-svc-xtvqh
Oct 24 03:02:41.571: INFO: Got endpoints: latency-svc-2kpr4 [749.75686ms]
Oct 24 03:02:41.587: INFO: Created: latency-svc-szd5x
Oct 24 03:02:41.622: INFO: Got endpoints: latency-svc-25hrm [751.261959ms]
Oct 24 03:02:41.633: INFO: Created: latency-svc-nqw7t
Oct 24 03:02:41.672: INFO: Got endpoints: latency-svc-ppnxh [750.804826ms]
Oct 24 03:02:41.684: INFO: Created: latency-svc-r8pmn
Oct 24 03:02:41.721: INFO: Got endpoints: latency-svc-hjnsl [750.394013ms]
Oct 24 03:02:41.732: INFO: Created: latency-svc-wdd2c
Oct 24 03:02:41.771: INFO: Got endpoints: latency-svc-c64xq [750.629956ms]
Oct 24 03:02:41.788: INFO: Created: latency-svc-bdpbq
Oct 24 03:02:41.822: INFO: Got endpoints: latency-svc-xg4kp [748.603964ms]
Oct 24 03:02:41.835: INFO: Created: latency-svc-g8jvh
Oct 24 03:02:41.871: INFO: Got endpoints: latency-svc-gp8xx [750.1132ms]
Oct 24 03:02:41.881: INFO: Created: latency-svc-cdzvv
Oct 24 03:02:41.922: INFO: Got endpoints: latency-svc-47kcb [750.288977ms]
Oct 24 03:02:41.933: INFO: Created: latency-svc-kthtn
Oct 24 03:02:41.971: INFO: Got endpoints: latency-svc-fm52g [748.035819ms]
Oct 24 03:02:41.985: INFO: Created: latency-svc-jt76m
Oct 24 03:02:42.021: INFO: Got endpoints: latency-svc-66g7d [750.172199ms]
Oct 24 03:02:42.033: INFO: Created: latency-svc-h94kc
Oct 24 03:02:42.070: INFO: Got endpoints: latency-svc-pl6ln [749.983463ms]
Oct 24 03:02:42.085: INFO: Created: latency-svc-9zz94
Oct 24 03:02:42.120: INFO: Got endpoints: latency-svc-5tmtw [747.658705ms]
Oct 24 03:02:42.131: INFO: Created: latency-svc-gcbjj
Oct 24 03:02:42.172: INFO: Got endpoints: latency-svc-g6qm7 [749.144952ms]
Oct 24 03:02:42.191: INFO: Created: latency-svc-wk28v
Oct 24 03:02:42.220: INFO: Got endpoints: latency-svc-2nttf [747.963238ms]
Oct 24 03:02:42.231: INFO: Created: latency-svc-q9khk
Oct 24 03:02:42.270: INFO: Got endpoints: latency-svc-xtvqh [748.700674ms]
Oct 24 03:02:42.285: INFO: Created: latency-svc-t7dcp
Oct 24 03:02:42.321: INFO: Got endpoints: latency-svc-szd5x [750.16503ms]
Oct 24 03:02:42.333: INFO: Created: latency-svc-fpvf8
Oct 24 03:02:42.372: INFO: Got endpoints: latency-svc-nqw7t [750.663211ms]
Oct 24 03:02:42.389: INFO: Created: latency-svc-bn7jh
Oct 24 03:02:42.422: INFO: Got endpoints: latency-svc-r8pmn [749.862646ms]
Oct 24 03:02:42.433: INFO: Created: latency-svc-fczsf
Oct 24 03:02:42.472: INFO: Got endpoints: latency-svc-wdd2c [751.288636ms]
Oct 24 03:02:42.483: INFO: Created: latency-svc-llqbs
Oct 24 03:02:42.521: INFO: Got endpoints: latency-svc-bdpbq [750.295518ms]
Oct 24 03:02:42.533: INFO: Created: latency-svc-42ksw
Oct 24 03:02:42.572: INFO: Got endpoints: latency-svc-g8jvh [750.888386ms]
Oct 24 03:02:42.587: INFO: Created: latency-svc-zdmfr
Oct 24 03:02:42.620: INFO: Got endpoints: latency-svc-cdzvv [749.744322ms]
Oct 24 03:02:42.631: INFO: Created: latency-svc-b4dzs
Oct 24 03:02:42.673: INFO: Got endpoints: latency-svc-kthtn [750.80885ms]
Oct 24 03:02:42.684: INFO: Created: latency-svc-8jwwt
Oct 24 03:02:42.720: INFO: Got endpoints: latency-svc-jt76m [748.656983ms]
Oct 24 03:02:42.732: INFO: Created: latency-svc-g4hwk
Oct 24 03:02:42.772: INFO: Got endpoints: latency-svc-h94kc [750.318932ms]
Oct 24 03:02:42.787: INFO: Created: latency-svc-gb6w5
Oct 24 03:02:42.823: INFO: Got endpoints: latency-svc-9zz94 [752.160557ms]
Oct 24 03:02:42.833: INFO: Created: latency-svc-4t5x4
Oct 24 03:02:42.871: INFO: Got endpoints: latency-svc-gcbjj [750.625995ms]
Oct 24 03:02:42.884: INFO: Created: latency-svc-48tcw
Oct 24 03:02:42.921: INFO: Got endpoints: latency-svc-wk28v [749.071823ms]
Oct 24 03:02:42.940: INFO: Created: latency-svc-bfs29
Oct 24 03:02:42.971: INFO: Got endpoints: latency-svc-q9khk [750.502238ms]
Oct 24 03:02:42.982: INFO: Created: latency-svc-9fjqj
Oct 24 03:02:43.020: INFO: Got endpoints: latency-svc-t7dcp [750.422756ms]
Oct 24 03:02:43.033: INFO: Created: latency-svc-msqpj
Oct 24 03:02:43.071: INFO: Got endpoints: latency-svc-fpvf8 [750.344472ms]
Oct 24 03:02:43.082: INFO: Created: latency-svc-5p7jm
Oct 24 03:02:43.122: INFO: Got endpoints: latency-svc-bn7jh [749.184207ms]
Oct 24 03:02:43.134: INFO: Created: latency-svc-mw65f
Oct 24 03:02:43.171: INFO: Got endpoints: latency-svc-fczsf [749.823468ms]
Oct 24 03:02:43.186: INFO: Created: latency-svc-mznjn
Oct 24 03:02:43.221: INFO: Got endpoints: latency-svc-llqbs [748.35588ms]
Oct 24 03:02:43.235: INFO: Created: latency-svc-xpv5k
Oct 24 03:02:43.271: INFO: Got endpoints: latency-svc-42ksw [749.432121ms]
Oct 24 03:02:43.287: INFO: Created: latency-svc-n9kbs
Oct 24 03:02:43.321: INFO: Got endpoints: latency-svc-zdmfr [747.962834ms]
Oct 24 03:02:43.333: INFO: Created: latency-svc-sr92v
Oct 24 03:02:43.371: INFO: Got endpoints: latency-svc-b4dzs [750.43578ms]
Oct 24 03:02:43.383: INFO: Created: latency-svc-kvhs4
Oct 24 03:02:43.421: INFO: Got endpoints: latency-svc-8jwwt [747.728566ms]
Oct 24 03:02:43.432: INFO: Created: latency-svc-grg26
Oct 24 03:02:43.472: INFO: Got endpoints: latency-svc-g4hwk [752.004529ms]
Oct 24 03:02:43.485: INFO: Created: latency-svc-q68d6
Oct 24 03:02:43.521: INFO: Got endpoints: latency-svc-gb6w5 [749.576091ms]
Oct 24 03:02:43.534: INFO: Created: latency-svc-b84pb
Oct 24 03:02:43.573: INFO: Got endpoints: latency-svc-4t5x4 [750.809851ms]
Oct 24 03:02:43.586: INFO: Created: latency-svc-hdg6v
Oct 24 03:02:43.620: INFO: Got endpoints: latency-svc-48tcw [749.288244ms]
Oct 24 03:02:43.633: INFO: Created: latency-svc-fj8tn
Oct 24 03:02:43.672: INFO: Got endpoints: latency-svc-bfs29 [750.612145ms]
Oct 24 03:02:43.685: INFO: Created: latency-svc-8gxx9
Oct 24 03:02:43.720: INFO: Got endpoints: latency-svc-9fjqj [749.625372ms]
Oct 24 03:02:43.733: INFO: Created: latency-svc-bw5fs
Oct 24 03:02:43.772: INFO: Got endpoints: latency-svc-msqpj [751.336345ms]
Oct 24 03:02:43.785: INFO: Created: latency-svc-6kcrb
Oct 24 03:02:43.821: INFO: Got endpoints: latency-svc-5p7jm [749.56936ms]
Oct 24 03:02:43.834: INFO: Created: latency-svc-4lc8v
Oct 24 03:02:43.874: INFO: Got endpoints: latency-svc-mw65f [751.857439ms]
Oct 24 03:02:43.898: INFO: Created: latency-svc-t5j2c
Oct 24 03:02:43.921: INFO: Got endpoints: latency-svc-mznjn [749.864266ms]
Oct 24 03:02:43.934: INFO: Created: latency-svc-pt5cw
Oct 24 03:02:43.971: INFO: Got endpoints: latency-svc-xpv5k [750.032213ms]
Oct 24 03:02:43.983: INFO: Created: latency-svc-zw7sg
Oct 24 03:02:44.020: INFO: Got endpoints: latency-svc-n9kbs [749.461835ms]
Oct 24 03:02:44.033: INFO: Created: latency-svc-whbh5
Oct 24 03:02:44.070: INFO: Got endpoints: latency-svc-sr92v [749.749917ms]
Oct 24 03:02:44.081: INFO: Created: latency-svc-p9jdv
Oct 24 03:02:44.120: INFO: Got endpoints: latency-svc-kvhs4 [749.343437ms]
Oct 24 03:02:44.136: INFO: Created: latency-svc-xbhkj
Oct 24 03:02:44.172: INFO: Got endpoints: latency-svc-grg26 [750.959021ms]
Oct 24 03:02:44.186: INFO: Created: latency-svc-zr8pw
Oct 24 03:02:44.220: INFO: Got endpoints: latency-svc-q68d6 [748.220497ms]
Oct 24 03:02:44.233: INFO: Created: latency-svc-g7q9d
Oct 24 03:02:44.270: INFO: Got endpoints: latency-svc-b84pb [749.109801ms]
Oct 24 03:02:44.282: INFO: Created: latency-svc-zv5d7
Oct 24 03:02:44.322: INFO: Got endpoints: latency-svc-hdg6v [748.472983ms]
Oct 24 03:02:44.334: INFO: Created: latency-svc-pcfln
Oct 24 03:02:44.371: INFO: Got endpoints: latency-svc-fj8tn [750.339863ms]
Oct 24 03:02:44.383: INFO: Created: latency-svc-qh5z9
Oct 24 03:02:44.422: INFO: Got endpoints: latency-svc-8gxx9 [750.178786ms]
Oct 24 03:02:44.437: INFO: Created: latency-svc-wwrbd
Oct 24 03:02:44.475: INFO: Got endpoints: latency-svc-bw5fs [754.896489ms]
Oct 24 03:02:44.504: INFO: Created: latency-svc-xm9rl
Oct 24 03:02:44.521: INFO: Got endpoints: latency-svc-6kcrb [749.014256ms]
Oct 24 03:02:44.532: INFO: Created: latency-svc-z57w5
Oct 24 03:02:44.571: INFO: Got endpoints: latency-svc-4lc8v [750.521501ms]
Oct 24 03:02:44.585: INFO: Created: latency-svc-kckwn
Oct 24 03:02:44.622: INFO: Got endpoints: latency-svc-t5j2c [747.978025ms]
Oct 24 03:02:44.633: INFO: Created: latency-svc-qczr7
Oct 24 03:02:44.672: INFO: Got endpoints: latency-svc-pt5cw [750.245176ms]
Oct 24 03:02:44.682: INFO: Created: latency-svc-gr2dx
Oct 24 03:02:44.721: INFO: Got endpoints: latency-svc-zw7sg [750.422288ms]
Oct 24 03:02:44.734: INFO: Created: latency-svc-m5pxn
Oct 24 03:02:44.774: INFO: Got endpoints: latency-svc-whbh5 [753.509614ms]
Oct 24 03:02:44.786: INFO: Created: latency-svc-fhhx9
Oct 24 03:02:44.822: INFO: Got endpoints: latency-svc-p9jdv [751.351557ms]
Oct 24 03:02:44.833: INFO: Created: latency-svc-g6mq8
Oct 24 03:02:44.870: INFO: Got endpoints: latency-svc-xbhkj [750.007645ms]
Oct 24 03:02:44.881: INFO: Created: latency-svc-88f7g
Oct 24 03:02:44.921: INFO: Got endpoints: latency-svc-zr8pw [749.060406ms]
Oct 24 03:02:44.935: INFO: Created: latency-svc-7mgtx
Oct 24 03:02:44.972: INFO: Got endpoints: latency-svc-g7q9d [751.267321ms]
Oct 24 03:02:44.987: INFO: Created: latency-svc-5ffcq
Oct 24 03:02:45.020: INFO: Got endpoints: latency-svc-zv5d7 [749.837157ms]
Oct 24 03:02:45.056: INFO: Created: latency-svc-lwhl2
Oct 24 03:02:45.072: INFO: Got endpoints: latency-svc-pcfln [750.141813ms]
Oct 24 03:02:45.085: INFO: Created: latency-svc-79lz8
Oct 24 03:02:45.122: INFO: Got endpoints: latency-svc-qh5z9 [751.006166ms]
Oct 24 03:02:45.134: INFO: Created: latency-svc-b9r4j
Oct 24 03:02:45.170: INFO: Got endpoints: latency-svc-wwrbd [748.186526ms]
Oct 24 03:02:45.181: INFO: Created: latency-svc-h7vq5
Oct 24 03:02:45.221: INFO: Got endpoints: latency-svc-xm9rl [745.50949ms]
Oct 24 03:02:45.234: INFO: Created: latency-svc-qc44d
Oct 24 03:02:45.270: INFO: Got endpoints: latency-svc-z57w5 [749.007285ms]
Oct 24 03:02:45.281: INFO: Created: latency-svc-gtgmf
Oct 24 03:02:45.320: INFO: Got endpoints: latency-svc-kckwn [748.862121ms]
Oct 24 03:02:45.331: INFO: Created: latency-svc-s6gkq
Oct 24 03:02:45.370: INFO: Got endpoints: latency-svc-qczr7 [748.076559ms]
Oct 24 03:02:45.380: INFO: Created: latency-svc-m9lvc
Oct 24 03:02:45.422: INFO: Got endpoints: latency-svc-gr2dx [750.060039ms]
Oct 24 03:02:45.435: INFO: Created: latency-svc-kh9h7
Oct 24 03:02:45.472: INFO: Got endpoints: latency-svc-m5pxn [750.551365ms]
Oct 24 03:02:45.488: INFO: Created: latency-svc-rbrpl
Oct 24 03:02:45.521: INFO: Got endpoints: latency-svc-fhhx9 [746.762066ms]
Oct 24 03:02:45.535: INFO: Created: latency-svc-6qbnp
Oct 24 03:02:45.575: INFO: Got endpoints: latency-svc-g6mq8 [753.230998ms]
Oct 24 03:02:45.588: INFO: Created: latency-svc-gkqkr
Oct 24 03:02:45.622: INFO: Got endpoints: latency-svc-88f7g [751.441016ms]
Oct 24 03:02:45.635: INFO: Created: latency-svc-kt9bb
Oct 24 03:02:45.671: INFO: Got endpoints: latency-svc-7mgtx [750.461307ms]
Oct 24 03:02:45.683: INFO: Created: latency-svc-nccmz
Oct 24 03:02:45.721: INFO: Got endpoints: latency-svc-5ffcq [749.069288ms]
Oct 24 03:02:45.733: INFO: Created: latency-svc-2zfd7
Oct 24 03:02:45.772: INFO: Got endpoints: latency-svc-lwhl2 [751.626291ms]
Oct 24 03:02:45.788: INFO: Created: latency-svc-c56zx
Oct 24 03:02:45.822: INFO: Got endpoints: latency-svc-79lz8 [749.376813ms]
Oct 24 03:02:45.835: INFO: Created: latency-svc-28vnc
Oct 24 03:02:45.876: INFO: Got endpoints: latency-svc-b9r4j [753.63218ms]
Oct 24 03:02:45.889: INFO: Created: latency-svc-xrz9l
Oct 24 03:02:45.924: INFO: Got endpoints: latency-svc-h7vq5 [753.281066ms]
Oct 24 03:02:45.935: INFO: Created: latency-svc-xvd5f
Oct 24 03:02:45.970: INFO: Got endpoints: latency-svc-qc44d [749.423397ms]
Oct 24 03:02:45.987: INFO: Created: latency-svc-jh6xg
Oct 24 03:02:46.020: INFO: Got endpoints: latency-svc-gtgmf [750.582041ms]
Oct 24 03:02:46.035: INFO: Created: latency-svc-mmgmk
Oct 24 03:02:46.071: INFO: Got endpoints: latency-svc-s6gkq [750.477676ms]
Oct 24 03:02:46.084: INFO: Created: latency-svc-fkxzt
Oct 24 03:02:46.121: INFO: Got endpoints: latency-svc-m9lvc [751.133903ms]
Oct 24 03:02:46.134: INFO: Created: latency-svc-d968v
Oct 24 03:02:46.171: INFO: Got endpoints: latency-svc-kh9h7 [749.303979ms]
Oct 24 03:02:46.183: INFO: Created: latency-svc-p97dt
Oct 24 03:02:46.221: INFO: Got endpoints: latency-svc-rbrpl [748.651486ms]
Oct 24 03:02:46.233: INFO: Created: latency-svc-ftqzb
Oct 24 03:02:46.272: INFO: Got endpoints: latency-svc-6qbnp [751.206488ms]
Oct 24 03:02:46.286: INFO: Created: latency-svc-sx2wn
Oct 24 03:02:46.321: INFO: Got endpoints: latency-svc-gkqkr [746.068956ms]
Oct 24 03:02:46.331: INFO: Created: latency-svc-9xcf6
Oct 24 03:02:46.373: INFO: Got endpoints: latency-svc-kt9bb [750.800436ms]
Oct 24 03:02:46.385: INFO: Created: latency-svc-t6xvv
Oct 24 03:02:46.421: INFO: Got endpoints: latency-svc-nccmz [749.432011ms]
Oct 24 03:02:46.435: INFO: Created: latency-svc-9pwq4
Oct 24 03:02:46.472: INFO: Got endpoints: latency-svc-2zfd7 [750.808987ms]
Oct 24 03:02:46.487: INFO: Created: latency-svc-mddgs
Oct 24 03:02:46.522: INFO: Got endpoints: latency-svc-c56zx [749.385653ms]
Oct 24 03:02:46.533: INFO: Created: latency-svc-kck2k
Oct 24 03:02:46.572: INFO: Got endpoints: latency-svc-28vnc [750.601818ms]
Oct 24 03:02:46.583: INFO: Created: latency-svc-xl7fl
Oct 24 03:02:46.622: INFO: Got endpoints: latency-svc-xrz9l [746.034823ms]
Oct 24 03:02:46.633: INFO: Created: latency-svc-26pj6
Oct 24 03:02:46.671: INFO: Got endpoints: latency-svc-xvd5f [747.223848ms]
Oct 24 03:02:46.683: INFO: Created: latency-svc-q7hkx
Oct 24 03:02:46.722: INFO: Got endpoints: latency-svc-jh6xg [751.232551ms]
Oct 24 03:02:46.734: INFO: Created: latency-svc-ljlck
Oct 24 03:02:46.771: INFO: Got endpoints: latency-svc-mmgmk [750.849958ms]
Oct 24 03:02:46.788: INFO: Created: latency-svc-sblfb
Oct 24 03:02:46.822: INFO: Got endpoints: latency-svc-fkxzt [750.73951ms]
Oct 24 03:02:46.836: INFO: Created: latency-svc-t7wq6
Oct 24 03:02:46.871: INFO: Got endpoints: latency-svc-d968v [750.466743ms]
Oct 24 03:02:46.885: INFO: Created: latency-svc-gr5gw
Oct 24 03:02:46.922: INFO: Got endpoints: latency-svc-p97dt [751.064246ms]
Oct 24 03:02:46.940: INFO: Created: latency-svc-g8n4z
Oct 24 03:02:46.974: INFO: Got endpoints: latency-svc-ftqzb [753.20409ms]
Oct 24 03:02:46.988: INFO: Created: latency-svc-snbtb
Oct 24 03:02:47.021: INFO: Got endpoints: latency-svc-sx2wn [748.900007ms]
Oct 24 03:02:47.035: INFO: Created: latency-svc-568qs
Oct 24 03:02:47.071: INFO: Got endpoints: latency-svc-9xcf6 [749.354867ms]
Oct 24 03:02:47.085: INFO: Created: latency-svc-sb48h
Oct 24 03:02:47.121: INFO: Got endpoints: latency-svc-t6xvv [748.465607ms]
Oct 24 03:02:47.134: INFO: Created: latency-svc-5s5cg
Oct 24 03:02:47.171: INFO: Got endpoints: latency-svc-9pwq4 [750.230609ms]
Oct 24 03:02:47.182: INFO: Created: latency-svc-x9rjt
Oct 24 03:02:47.220: INFO: Got endpoints: latency-svc-mddgs [748.382198ms]
Oct 24 03:02:47.232: INFO: Created: latency-svc-4pt6p
Oct 24 03:02:47.272: INFO: Got endpoints: latency-svc-kck2k [749.960691ms]
Oct 24 03:02:47.288: INFO: Created: latency-svc-ddbnt
Oct 24 03:02:47.320: INFO: Got endpoints: latency-svc-xl7fl [747.324264ms]
Oct 24 03:02:47.331: INFO: Created: latency-svc-4srk2
Oct 24 03:02:47.372: INFO: Got endpoints: latency-svc-26pj6 [750.237671ms]
Oct 24 03:02:47.385: INFO: Created: latency-svc-7w5gw
Oct 24 03:02:47.421: INFO: Got endpoints: latency-svc-q7hkx [749.923661ms]
Oct 24 03:02:47.443: INFO: Created: latency-svc-hxb4v
Oct 24 03:02:47.471: INFO: Got endpoints: latency-svc-ljlck [749.145379ms]
Oct 24 03:02:47.482: INFO: Created: latency-svc-s98tq
Oct 24 03:02:47.521: INFO: Got endpoints: latency-svc-sblfb [749.484502ms]
Oct 24 03:02:47.536: INFO: Created: latency-svc-8xgkj
Oct 24 03:02:47.570: INFO: Got endpoints: latency-svc-t7wq6 [748.73783ms]
Oct 24 03:02:47.582: INFO: Created: latency-svc-hwzqj
Oct 24 03:02:47.622: INFO: Got endpoints: latency-svc-gr5gw [750.583522ms]
Oct 24 03:02:47.635: INFO: Created: latency-svc-b58gc
Oct 24 03:02:47.672: INFO: Got endpoints: latency-svc-g8n4z [749.292326ms]
Oct 24 03:02:47.686: INFO: Created: latency-svc-gmm54
Oct 24 03:02:47.721: INFO: Got endpoints: latency-svc-snbtb [747.113937ms]
Oct 24 03:02:47.735: INFO: Created: latency-svc-phnb2
Oct 24 03:02:47.771: INFO: Got endpoints: latency-svc-568qs [750.102194ms]
Oct 24 03:02:47.786: INFO: Created: latency-svc-9cbpk
Oct 24 03:02:47.821: INFO: Got endpoints: latency-svc-sb48h [750.533953ms]
Oct 24 03:02:47.870: INFO: Got endpoints: latency-svc-5s5cg [749.080506ms]
Oct 24 03:02:47.921: INFO: Got endpoints: latency-svc-x9rjt [750.294557ms]
Oct 24 03:02:47.973: INFO: Got endpoints: latency-svc-4pt6p [752.680888ms]
Oct 24 03:02:48.021: INFO: Got endpoints: latency-svc-ddbnt [749.093819ms]
Oct 24 03:02:48.070: INFO: Got endpoints: latency-svc-4srk2 [750.134936ms]
Oct 24 03:02:48.122: INFO: Got endpoints: latency-svc-7w5gw [749.856774ms]
Oct 24 03:02:48.175: INFO: Got endpoints: latency-svc-hxb4v [753.500414ms]
Oct 24 03:02:48.220: INFO: Got endpoints: latency-svc-s98tq [749.16034ms]
Oct 24 03:02:48.271: INFO: Got endpoints: latency-svc-8xgkj [750.491646ms]
Oct 24 03:02:48.322: INFO: Got endpoints: latency-svc-hwzqj [750.884417ms]
Oct 24 03:02:48.370: INFO: Got endpoints: latency-svc-b58gc [748.023889ms]
Oct 24 03:02:48.421: INFO: Got endpoints: latency-svc-gmm54 [749.736688ms]
Oct 24 03:02:48.472: INFO: Got endpoints: latency-svc-phnb2 [750.615352ms]
Oct 24 03:02:48.521: INFO: Got endpoints: latency-svc-9cbpk [750.18501ms]
Oct 24 03:02:48.522: INFO: Latencies: [25.52587ms 32.649885ms 62.783991ms 63.512044ms 79.775434ms 90.636948ms 120.042719ms 120.578817ms 128.145996ms 133.902752ms 143.38135ms 143.678227ms 144.62132ms 144.677019ms 148.441266ms 149.349616ms 153.4164ms 153.905033ms 155.083869ms 156.180333ms 158.177302ms 158.352252ms 158.511869ms 159.209925ms 161.329141ms 163.150894ms 163.346357ms 163.586312ms 165.239031ms 167.758925ms 168.466723ms 170.706479ms 172.693382ms 175.852441ms 183.640933ms 183.899893ms 191.254152ms 199.676915ms 214.880997ms 255.901873ms 293.117721ms 333.148709ms 375.205214ms 415.164168ms 457.644933ms 487.992966ms 525.796762ms 566.640603ms 602.530938ms 635.84933ms 679.620408ms 713.399472ms 745.50949ms 746.034823ms 746.068956ms 746.762066ms 747.113937ms 747.223848ms 747.324264ms 747.658705ms 747.728566ms 747.888871ms 747.962834ms 747.963238ms 747.978025ms 748.023889ms 748.035819ms 748.076559ms 748.186526ms 748.220497ms 748.35588ms 748.382198ms 748.465607ms 748.472983ms 748.496245ms 748.520181ms 748.603964ms 748.651486ms 748.656983ms 748.700674ms 748.73783ms 748.862121ms 748.900007ms 749.007285ms 749.014256ms 749.060406ms 749.069288ms 749.071823ms 749.080506ms 749.093819ms 749.109801ms 749.144952ms 749.145379ms 749.16034ms 749.184207ms 749.231876ms 749.288244ms 749.292326ms 749.303979ms 749.343437ms 749.35119ms 749.354867ms 749.369185ms 749.376813ms 749.385653ms 749.423397ms 749.432011ms 749.432121ms 749.461835ms 749.484502ms 749.56936ms 749.576091ms 749.625372ms 749.736688ms 749.744322ms 749.749917ms 749.75686ms 749.823468ms 749.837157ms 749.856774ms 749.862646ms 749.864266ms 749.923661ms 749.960691ms 749.983463ms 750.007645ms 750.032213ms 750.060039ms 750.102194ms 750.1132ms 750.134936ms 750.141813ms 750.16503ms 750.172199ms 750.178786ms 750.18501ms 750.230609ms 750.237671ms 750.245176ms 750.288977ms 750.294557ms 750.295518ms 750.318932ms 750.339863ms 750.344472ms 750.394013ms 750.422288ms 750.422756ms 750.43578ms 750.461307ms 750.466743ms 750.477676ms 750.491646ms 750.502238ms 750.521501ms 750.533953ms 750.551365ms 750.582041ms 750.583522ms 750.601818ms 750.612145ms 750.615352ms 750.625995ms 750.629956ms 750.663211ms 750.73951ms 750.780867ms 750.800436ms 750.804826ms 750.80885ms 750.808987ms 750.809851ms 750.849958ms 750.884417ms 750.888386ms 750.959021ms 751.006166ms 751.064246ms 751.133903ms 751.206488ms 751.232551ms 751.246333ms 751.261959ms 751.267321ms 751.288636ms 751.336345ms 751.351557ms 751.441016ms 751.626291ms 751.857439ms 752.004529ms 752.160557ms 752.680888ms 753.20409ms 753.230998ms 753.281066ms 753.500414ms 753.509614ms 753.63218ms 754.896489ms]
Oct 24 03:02:48.522: INFO: 50 %ile: 749.35119ms
Oct 24 03:02:48.522: INFO: 90 %ile: 751.232551ms
Oct 24 03:02:48.522: INFO: 99 %ile: 753.63218ms
Oct 24 03:02:48.522: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 03:02:48.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9799" for this suite.
Oct 24 03:03:14.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:03:14.680: INFO: namespace svc-latency-9799 deletion completed in 26.149500042s

• [SLOW TEST:37.935 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 03:03:14.680: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 03:03:14.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7506" for this suite.
Oct 24 03:03:20.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:03:20.914: INFO: namespace resourcequota-7506 deletion completed in 6.150259681s

• [SLOW TEST:6.234 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 03:03:20.915: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct 24 03:03:20.957: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 24 03:03:20.968: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 24 03:03:25.975: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 24 03:03:25.975: INFO: Creating deployment "test-rolling-update-deployment"
Oct 24 03:03:25.980: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 24 03:03:25.988: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 24 03:03:27.998: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 24 03:03:28.001: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct 24 03:03:28.013: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-526 /apis/apps/v1/namespaces/deployment-526/deployments/test-rolling-update-deployment f7ed8fd5-f1b2-40d8-be82-098800931ee7 32744 1 2019-10-24 03:03:25 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001aceb88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-10-24 03:03:26 +0000 UTC,LastTransitionTime:2019-10-24 03:03:26 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-10-24 03:03:27 +0000 UTC,LastTransitionTime:2019-10-24 03:03:26 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct 24 03:03:28.018: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-526 /apis/apps/v1/namespaces/deployment-526/replicasets/test-rolling-update-deployment-55d946486 311ba103-ffaf-4d38-a8dc-9b5f3c05fe9e 32733 1 2019-10-24 03:03:25 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment f7ed8fd5-f1b2-40d8-be82-098800931ee7 0xc001acf440 0xc001acf441}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001acf4c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct 24 03:03:28.018: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 24 03:03:28.018: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-526 /apis/apps/v1/namespaces/deployment-526/replicasets/test-rolling-update-controller 26a87c0a-e6b1-4716-8943-979a9960b1ad 32742 2 2019-10-24 03:03:20 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment f7ed8fd5-f1b2-40d8-be82-098800931ee7 0xc001acf337 0xc001acf338}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001acf3a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct 24 03:03:28.023: INFO: Pod "test-rolling-update-deployment-55d946486-zkjq6" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-zkjq6 test-rolling-update-deployment-55d946486- deployment-526 /api/v1/namespaces/deployment-526/pods/test-rolling-update-deployment-55d946486-zkjq6 9234219f-5ce1-4ad8-b4b9-7a180bc50418 32732 0 2019-10-24 03:03:25 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[cni.projectcalico.org/podIP:10.244.1.107/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 311ba103-ffaf-4d38-a8dc-9b5f3c05fe9e 0xc001acfcd0 0xc001acfcd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-v4ll7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-v4ll7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-v4ll7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:mip-bd-vm40.mip.storage.hpecorp.net,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 03:03:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 03:03:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 03:03:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-24 03:03:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:16.143.20.137,PodIP:10.244.1.107,StartTime:2019-10-24 03:03:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-24 03:03:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/redis:5.0.5-alpine,ImageID:docker-pullable://docker.io/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://066bba592b135d059d4b8c7131f61967371458ed3f6ce15b59bb7fc4b1fb3050,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.107,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 03:03:28.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-526" for this suite.
Oct 24 03:03:34.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:03:34.348: INFO: namespace deployment-526 deletion completed in 6.320042286s

• [SLOW TEST:13.433 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct 24 03:03:34.348: INFO: >>> kubeConfig: /tmp/kubeconfig-000479258
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 24 03:03:34.403: INFO: Waiting up to 5m0s for pod "pod-2909466f-bd7b-41b9-9f90-efb59ebf1f57" in namespace "emptydir-6312" to be "success or failure"
Oct 24 03:03:34.407: INFO: Pod "pod-2909466f-bd7b-41b9-9f90-efb59ebf1f57": Phase="Pending", Reason="", readiness=false. Elapsed: 4.001047ms
Oct 24 03:03:36.412: INFO: Pod "pod-2909466f-bd7b-41b9-9f90-efb59ebf1f57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00845824s
STEP: Saw pod success
Oct 24 03:03:36.412: INFO: Pod "pod-2909466f-bd7b-41b9-9f90-efb59ebf1f57" satisfied condition "success or failure"
Oct 24 03:03:36.415: INFO: Trying to get logs from node mip-bd-vm40.mip.storage.hpecorp.net pod pod-2909466f-bd7b-41b9-9f90-efb59ebf1f57 container test-container: <nil>
STEP: delete the pod
Oct 24 03:03:36.461: INFO: Waiting for pod pod-2909466f-bd7b-41b9-9f90-efb59ebf1f57 to disappear
Oct 24 03:03:36.464: INFO: Pod pod-2909466f-bd7b-41b9-9f90-efb59ebf1f57 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct 24 03:03:36.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6312" for this suite.
Oct 24 03:03:42.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 24 03:03:42.624: INFO: namespace emptydir-6312 deletion completed in 6.155790587s

• [SLOW TEST:8.276 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSOct 24 03:03:42.625: INFO: Running AfterSuite actions on all nodes
Oct 24 03:03:42.625: INFO: Running AfterSuite actions on node 1
Oct 24 03:03:42.625: INFO: Skipping dumping logs from cluster

Ran 274 of 4897 Specs in 6850.729 seconds
SUCCESS! -- 274 Passed | 0 Failed | 0 Pending | 4623 Skipped
PASS

Ginkgo ran 1 suite in 1h54m14.004426865s
Test Suite Passed
